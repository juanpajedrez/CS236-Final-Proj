{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Pre trained to test\n",
    "\n",
    "One of the key components for the evaluation of the models is to compare between the VGGnet16 discriminative approach accuracies <br>\n",
    "vs the accuracies obtained by using a VGGnet16 as encoder with a deep generative model in between. <br><br>\n",
    "This jupyter notebook has the objective to, not only retrieve the accuracies of the VGGnet16 pretrained, but to obtain also <br>\n",
    "the layer features before the last classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Import necessary modules\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "plt.rcParams['figure.figsize'] = [20, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the path to here\n",
    "\n",
    "Make sure the setup the paths properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myrea\\Desktop\\Stanford_CS236\\project\\cs236_project\\CS236-Final-Proj\\test\n"
     ]
    }
   ],
   "source": [
    "#Path to assign tests (copy path directly)\n",
    "test_path = r\"C:\\Users\\myrea\\Desktop\\Stanford_CS236\\project\\cs236_project\\CS236-Final-Proj\\test\"\n",
    "\n",
    "#Set the path to this working directory\n",
    "os.chdir(test_path)\n",
    "print(os.getcwd())\n",
    "\n",
    "import sys\n",
    "#Append the path the src folder\n",
    "sys.path.append(r'C:\\Users\\myrea\\Desktop\\Stanford_CS236\\project\\cs236_project\\CS236-Final-Proj\\src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary module for downloading\n",
    "\n",
    "Note for this: EVERYTIME There is a change inside the download <br>\n",
    "the changes inside the file would only be shown if the jupyter kernel is restarted. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from utils import CXReader, DfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data path\n",
    "data_path = os.path.join(test_path, os.pardir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dataframes of the data\n",
    "First, lets obtain the dataframes for the data and check that all metadata <br>\n",
    "information has been set up properly. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112124/112124 [00:00<00:00, 521699.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file: miccai2023_nih-cxr-lt_labels_test.csv has been retrieved\n",
      "The file: miccai2023_nih-cxr-lt_labels_train.csv has been retrieved\n",
      "The file: miccai2023_nih-cxr-lt_labels_val.csv has been retrieved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a dataframe compiler\n",
    "df_compiler = DfReader()\n",
    "\n",
    "#set the path and retrieve the dataframes\n",
    "df_compiler.set_folder_path(data_path)\n",
    "\n",
    "#Get the dataframe holder and names\n",
    "dfs_holder, dfs_names = df_compiler.get_dfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the images and labels\n",
    "\n",
    "Also, obtain DataLoaders for test, train, and validation datasets using <br>\n",
    "the Dataloader class from pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a single image and its labels\n",
      "Image: torch.Size([3, 224, 224]), labels: torch.Size([20])\n",
      "batch number: 0\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 20])\n",
      "batch number: 1\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 20])\n",
      "batch number: 2\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 20])\n",
      "batch number: 3\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 20])\n",
      "batch number: 4\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 20])\n",
      "batch number: 5\n",
      "Shape of batch of images and labels\n",
      "Images: torch.Size([32, 3, 224, 224]), labels: torch.Size([32, 20])\n",
      "It can iterate through all batches\n"
     ]
    }
   ],
   "source": [
    "# Get the device if cuda or not\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Define a transformations for the VGGnet16 (requires a 224,224)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "#Create datasets and dataloaders\n",
    "test_dataset = CXReader(data_path=data_path, dataframe=dfs_holder[0], transform=transform, device=device)\n",
    "train_dataset = CXReader(data_path=data_path, dataframe=dfs_holder[1], transform=transform,device=device)\n",
    "val_dataset = CXReader(data_path=data_path, dataframe=dfs_holder[2], transform=transform, device=device)\n",
    "\n",
    "#Sampled images from train to see single shape\n",
    "samp3_image, label3 = train_dataset[1]\n",
    "print(\"Shape of a single image and its labels\")\n",
    "print(f\"Image: {samp3_image.shape}, labels: {label3.shape}\")\n",
    "\n",
    "#With batch size of 32, and shuffle true, and num workers = 4\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,  num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,  num_workers=2)\n",
    "\n",
    "#Iterate inside a batch\n",
    "for idx, batch in enumerate(train_loader):\n",
    "    print(f\"batch number: {idx}\")\n",
    "    images, labels = batch\n",
    "    print(\"Shape of batch of images and labels\")\n",
    "    print(f\"Images: {images.shape}, labels: {labels.shape}\")\n",
    "    if idx == 5:\n",
    "        print(\"It can iterate through all batches\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the vgg16 pretrained model\n",
    "\n",
    "Check if you have GPU Envidia! Else, use the cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pretrained model\n",
    "vgg16 = models.vgg16(pretrained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify the last layer\n",
    "We know that VGGnet16 has a last linear layer with 1000 output units...<br>\n",
    "However, this doesnt really resemble our problem per se...<br><br>\n",
    "Lets do this! Lets replace the last layer with a linear layer that has the same <br> number of classes as our data!. (In our case, is 20).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg16.features)\n",
    "print(vgg16.avgpool)\n",
    "print(vgg16.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW CODE CELL to conduct fine-tuning on Vggnet16 only on the last (Linear) layer\n",
    "\n",
    "# First, freeze all the parameters\n",
    "for param in vgg16.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=20, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Modify the last layer for the last 20 classes\n",
    "num_classes = 20  # Number of classes for your specific task\n",
    "num_features = vgg16.classifier[-1].in_features\n",
    "\n",
    "# Replace the last layer with a new fully connected layer\n",
    "vgg16.classifier[-1] = nn.Linear(num_features, num_classes)\n",
    "vgg16.classifier.add_module(\"sigmoid\", nn.Sigmoid()) #Add sigmoid activation for binary classification between diffs\n",
    "print(vgg16.classifier)\n",
    "\n",
    "# # Set requires_grad to False for the modified layer\n",
    "# for param in vgg16.classifier[-1].parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW CODE CELL\n",
    "\n",
    "# Create state_dict path\n",
    "state_dict_path = os.path.join(test_path, os.pardir, \"state_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<generator object Module.parameters at 0x00000191923DFA70>]\n"
     ]
    }
   ],
   "source": [
    "# NEW CODE CELL to perform fine-tuning\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "vgg16 = vgg16.to(device)\n",
    "vgg16.train()\n",
    "params_to_update = [vgg16.classifier[-2].parameters()]\n",
    "print(params_to_update)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(*params_to_update, lr=0.01)\n",
    "\n",
    "def finetune_model(model, data_loader, num_epochs, device:str):\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-------------')\n",
    "            \n",
    "        for idx, batch in enumerate(data_loader):\n",
    "            images_inputs, images_labels = batch\n",
    "            images_inputs, images_labels = images_inputs.to(device), images_labels.to(device)\n",
    "\n",
    "            # Convert labels to float type (also need to move to CUDA again!)\n",
    "            images_labels = images_labels.to(torch.float64)\n",
    "\n",
    "            # initialize optimizer\n",
    "            optimizer.zero_grad()            \n",
    "            outputs = model(images_inputs)\n",
    "            \n",
    "            # compute loss\n",
    "            loss = criterion(outputs, images_labels)\n",
    "            \n",
    "            # predict labels\n",
    "            pred_labels = (outputs > 0.5).float()\n",
    "\n",
    "            # Calculate TP, FP, TN, FN and accuracy\n",
    "            TP = torch.sum((pred_labels == 1) & (images_labels == 1)).item()\n",
    "            FP = torch.sum((pred_labels == 1) & (images_labels == 0)).item()\n",
    "            TN = torch.sum((pred_labels == 0) & (images_labels == 0)).item()\n",
    "            FN = torch.sum((pred_labels == 0) & (images_labels == 1)).item()\n",
    "            accuracy = ((TP + TN) / (TP + FP + TN + FN)) * 100.0                \n",
    "\n",
    "            loss.backward()\n",
    "            print(f\"iter {idx} ---  Loss: {loss}    Accuracy: {accuracy}\")\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Save parameters for each epoch\n",
    "        torch.save(model.state_dict(), os.path.join(state_dict_path, \"vgg16_finetune_params.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "-------------\n",
      "iter 0 ---  Loss: 2.963076278567314    Accuracy: 88.125\n",
      "iter 1 ---  Loss: 2.757241867482662    Accuracy: 86.71875\n",
      "iter 2 ---  Loss: 3.0281482860445976    Accuracy: 87.96875\n",
      "iter 3 ---  Loss: 2.7170959785580635    Accuracy: 88.75\n",
      "iter 4 ---  Loss: 3.2998723685741425    Accuracy: 87.1875\n",
      "iter 5 ---  Loss: 3.0873119458556175    Accuracy: 87.8125\n",
      "iter 6 ---  Loss: 2.757817395031452    Accuracy: 86.09375\n",
      "iter 7 ---  Loss: 2.9092340767383575    Accuracy: 89.21875\n",
      "iter 8 ---  Loss: 3.1889036670327187    Accuracy: 87.03125\n",
      "iter 9 ---  Loss: 2.7469331547617912    Accuracy: 90.0\n",
      "iter 10 ---  Loss: 3.21889116615057    Accuracy: 86.5625\n",
      "iter 11 ---  Loss: 3.335458554327488    Accuracy: 88.28125\n",
      "iter 12 ---  Loss: 3.2115119323134422    Accuracy: 87.34375\n",
      "iter 13 ---  Loss: 3.0066206976771355    Accuracy: 87.03125\n",
      "iter 14 ---  Loss: 3.027671255171299    Accuracy: 86.40625\n",
      "iter 15 ---  Loss: 2.944521762430668    Accuracy: 87.8125\n",
      "iter 16 ---  Loss: 2.5643158182501793    Accuracy: 88.125\n",
      "iter 17 ---  Loss: 3.0333040803670883    Accuracy: 85.9375\n",
      "iter 18 ---  Loss: 2.7416955307126045    Accuracy: 89.53125\n",
      "iter 19 ---  Loss: 3.172182135283947    Accuracy: 86.25\n",
      "iter 20 ---  Loss: 2.8062429428100586    Accuracy: 87.65625\n",
      "iter 21 ---  Loss: 3.1956128403544426    Accuracy: 87.5\n",
      "iter 22 ---  Loss: 3.8671446219086647    Accuracy: 87.5\n",
      "iter 23 ---  Loss: 3.5309849679470062    Accuracy: 86.71875\n",
      "iter 24 ---  Loss: 2.717947870492935    Accuracy: 87.8125\n",
      "iter 25 ---  Loss: 2.777250297367573    Accuracy: 87.96875\n",
      "iter 26 ---  Loss: 2.8497304022312164    Accuracy: 86.5625\n",
      "iter 27 ---  Loss: 3.7528525665402412    Accuracy: 87.8125\n",
      "iter 28 ---  Loss: 3.5528485029935837    Accuracy: 86.71875\n",
      "iter 29 ---  Loss: 2.756985142827034    Accuracy: 88.59375\n",
      "iter 30 ---  Loss: 3.899251565337181    Accuracy: 87.65625\n",
      "iter 31 ---  Loss: 3.3918993920087814    Accuracy: 85.3125\n",
      "iter 32 ---  Loss: 3.5212378799915314    Accuracy: 86.09375\n",
      "iter 33 ---  Loss: 3.3628320917487144    Accuracy: 86.71875\n",
      "iter 34 ---  Loss: 2.9501721039414406    Accuracy: 86.40625\n",
      "iter 35 ---  Loss: 3.230510860681534    Accuracy: 85.15625\n",
      "iter 36 ---  Loss: 3.3545326590538025    Accuracy: 87.8125\n",
      "iter 37 ---  Loss: 3.413085140287876    Accuracy: 87.5\n",
      "iter 38 ---  Loss: 2.50079894810915    Accuracy: 88.59375\n",
      "iter 39 ---  Loss: 3.1365831717848778    Accuracy: 86.09375\n",
      "iter 40 ---  Loss: 3.0178658962249756    Accuracy: 88.4375\n",
      "iter 41 ---  Loss: 2.562732107937336    Accuracy: 87.34375\n",
      "iter 42 ---  Loss: 3.4794073179364204    Accuracy: 87.8125\n",
      "iter 43 ---  Loss: 3.2014068961143494    Accuracy: 85.46875\n",
      "iter 44 ---  Loss: 3.057230420410633    Accuracy: 85.46875\n",
      "iter 45 ---  Loss: 2.6679394990205765    Accuracy: 89.21875\n",
      "iter 46 ---  Loss: 3.318680427968502    Accuracy: 85.9375\n",
      "iter 47 ---  Loss: 2.6256204321980476    Accuracy: 87.1875\n",
      "iter 48 ---  Loss: 3.782592810690403    Accuracy: 86.5625\n",
      "iter 49 ---  Loss: 3.1485251039266586    Accuracy: 87.96875\n",
      "iter 50 ---  Loss: 3.242267891764641    Accuracy: 85.78125\n",
      "iter 51 ---  Loss: 2.916627436876297    Accuracy: 86.5625\n",
      "iter 52 ---  Loss: 3.070999287068844    Accuracy: 86.5625\n",
      "iter 53 ---  Loss: 3.4957297071814537    Accuracy: 86.875\n",
      "iter 54 ---  Loss: 3.860824838280678    Accuracy: 86.5625\n",
      "iter 55 ---  Loss: 3.1302826032042503    Accuracy: 87.1875\n",
      "iter 56 ---  Loss: 2.9430562555789948    Accuracy: 87.96875\n",
      "iter 57 ---  Loss: 3.577261731028557    Accuracy: 86.71875\n",
      "iter 58 ---  Loss: 2.9626846462488174    Accuracy: 85.9375\n",
      "iter 59 ---  Loss: 3.238348089158535    Accuracy: 87.34375\n",
      "iter 60 ---  Loss: 2.8151910379529    Accuracy: 88.59375\n",
      "iter 61 ---  Loss: 2.976526193320751    Accuracy: 86.5625\n",
      "iter 62 ---  Loss: 3.0901994481682777    Accuracy: 86.875\n",
      "iter 63 ---  Loss: 3.0400555953383446    Accuracy: 86.875\n",
      "iter 64 ---  Loss: 3.3963951990008354    Accuracy: 86.25\n",
      "iter 65 ---  Loss: 2.7614001855254173    Accuracy: 88.28125\n",
      "iter 66 ---  Loss: 2.6027800291776657    Accuracy: 87.1875\n",
      "iter 67 ---  Loss: 3.0528951287269592    Accuracy: 86.09375\n",
      "iter 68 ---  Loss: 3.6879991590976715    Accuracy: 84.375\n",
      "iter 69 ---  Loss: 3.3076950013637543    Accuracy: 85.9375\n",
      "iter 70 ---  Loss: 2.806049160659313    Accuracy: 88.59375\n",
      "iter 71 ---  Loss: 2.8951549902558327    Accuracy: 87.5\n",
      "iter 72 ---  Loss: 2.765069894492626    Accuracy: 87.1875\n",
      "iter 73 ---  Loss: 3.1189281344413757    Accuracy: 87.96875\n",
      "iter 74 ---  Loss: 3.117428705096245    Accuracy: 87.96875\n",
      "iter 75 ---  Loss: 3.224040426313877    Accuracy: 87.8125\n",
      "iter 76 ---  Loss: 3.096847042441368    Accuracy: 84.6875\n",
      "iter 77 ---  Loss: 2.736903630197048    Accuracy: 87.5\n",
      "iter 78 ---  Loss: 3.4565419703722    Accuracy: 87.03125\n",
      "iter 79 ---  Loss: 3.2194937467575073    Accuracy: 87.65625\n",
      "iter 80 ---  Loss: 2.549578942358494    Accuracy: 87.65625\n",
      "iter 81 ---  Loss: 2.9500356912612915    Accuracy: 88.28125\n",
      "iter 82 ---  Loss: 2.6339048966765404    Accuracy: 88.125\n",
      "iter 83 ---  Loss: 3.072143167257309    Accuracy: 86.5625\n",
      "iter 84 ---  Loss: 3.0549162328243256    Accuracy: 87.34375\n",
      "iter 85 ---  Loss: 3.2483254596590996    Accuracy: 86.09375\n",
      "iter 86 ---  Loss: 2.795562319457531    Accuracy: 87.65625\n",
      "iter 87 ---  Loss: 2.9265471175312996    Accuracy: 89.84375\n",
      "iter 88 ---  Loss: 2.8976710811257362    Accuracy: 86.71875\n",
      "iter 89 ---  Loss: 2.996858850121498    Accuracy: 88.75\n",
      "iter 90 ---  Loss: 2.919339641928673    Accuracy: 87.96875\n",
      "iter 91 ---  Loss: 3.1398074999451637    Accuracy: 87.03125\n",
      "iter 92 ---  Loss: 2.8789517134428024    Accuracy: 87.03125\n",
      "iter 93 ---  Loss: 3.5150170251727104    Accuracy: 86.875\n",
      "iter 94 ---  Loss: 2.5687132626771927    Accuracy: 88.125\n",
      "iter 95 ---  Loss: 3.013120248913765    Accuracy: 86.09375\n",
      "iter 96 ---  Loss: 2.820350579917431    Accuracy: 86.09375\n",
      "iter 97 ---  Loss: 3.3972037583589554    Accuracy: 85.15625\n",
      "iter 98 ---  Loss: 3.1061629205942154    Accuracy: 86.40625\n",
      "iter 99 ---  Loss: 3.182776689529419    Accuracy: 86.09375\n",
      "iter 100 ---  Loss: 3.45904578268528    Accuracy: 85.9375\n",
      "iter 101 ---  Loss: 3.4168166145682335    Accuracy: 86.875\n",
      "iter 102 ---  Loss: 3.077967047691345    Accuracy: 88.59375\n",
      "iter 103 ---  Loss: 2.766718938946724    Accuracy: 88.75\n",
      "iter 104 ---  Loss: 2.8169453889131546    Accuracy: 87.34375\n",
      "iter 105 ---  Loss: 3.1678255945444107    Accuracy: 87.1875\n",
      "iter 106 ---  Loss: 2.7870091050863266    Accuracy: 87.96875\n",
      "iter 107 ---  Loss: 3.042867034673691    Accuracy: 87.65625\n",
      "iter 108 ---  Loss: 2.991023540496826    Accuracy: 87.8125\n",
      "iter 109 ---  Loss: 2.9236953780055046    Accuracy: 89.0625\n",
      "iter 110 ---  Loss: 2.9650727286934853    Accuracy: 88.28125\n",
      "iter 111 ---  Loss: 3.438452534377575    Accuracy: 87.03125\n",
      "iter 112 ---  Loss: 3.620791085064411    Accuracy: 85.9375\n",
      "iter 113 ---  Loss: 3.3140885308384895    Accuracy: 85.3125\n",
      "iter 114 ---  Loss: 3.464707523584366    Accuracy: 87.03125\n",
      "iter 115 ---  Loss: 3.0915872901678085    Accuracy: 85.625\n",
      "iter 116 ---  Loss: 3.1433209031820297    Accuracy: 87.03125\n",
      "iter 117 ---  Loss: 2.9757597148418427    Accuracy: 87.8125\n",
      "iter 118 ---  Loss: 2.8237152621150017    Accuracy: 88.4375\n",
      "iter 119 ---  Loss: 3.480390951037407    Accuracy: 86.40625\n",
      "iter 120 ---  Loss: 2.9401852563023567    Accuracy: 88.90625\n",
      "iter 121 ---  Loss: 2.976648800075054    Accuracy: 87.5\n",
      "iter 122 ---  Loss: 3.0194558426737785    Accuracy: 88.4375\n",
      "iter 123 ---  Loss: 3.1649967432022095    Accuracy: 86.875\n",
      "iter 124 ---  Loss: 3.4205688163638115    Accuracy: 86.25\n",
      "iter 125 ---  Loss: 3.0576914101839066    Accuracy: 86.5625\n",
      "iter 126 ---  Loss: 3.6050483360886574    Accuracy: 83.90625\n",
      "iter 127 ---  Loss: 2.712635040283203    Accuracy: 88.75\n",
      "iter 128 ---  Loss: 3.105094850063324    Accuracy: 86.71875\n",
      "iter 129 ---  Loss: 3.2279384583234787    Accuracy: 85.9375\n",
      "iter 130 ---  Loss: 3.458017587661743    Accuracy: 86.5625\n",
      "iter 131 ---  Loss: 3.5948067978024483    Accuracy: 84.53125\n",
      "iter 132 ---  Loss: 2.5075624510645866    Accuracy: 88.125\n",
      "iter 133 ---  Loss: 3.167685441672802    Accuracy: 86.71875\n",
      "iter 134 ---  Loss: 3.0177236944437027    Accuracy: 87.34375\n",
      "iter 135 ---  Loss: 3.2004777267575264    Accuracy: 87.8125\n",
      "iter 136 ---  Loss: 3.0898877158761024    Accuracy: 88.125\n",
      "iter 137 ---  Loss: 3.368598446249962    Accuracy: 86.5625\n",
      "iter 138 ---  Loss: 2.8059051111340523    Accuracy: 90.0\n",
      "iter 139 ---  Loss: 3.9148934856057167    Accuracy: 85.625\n",
      "iter 140 ---  Loss: 3.5750109553337097    Accuracy: 85.78125\n",
      "iter 141 ---  Loss: 2.9282646104693413    Accuracy: 86.40625\n",
      "iter 142 ---  Loss: 3.821690611541271    Accuracy: 84.6875\n",
      "iter 143 ---  Loss: 3.5490448772907257    Accuracy: 86.875\n",
      "iter 144 ---  Loss: 2.848342575132847    Accuracy: 88.28125\n",
      "iter 145 ---  Loss: 2.835521124303341    Accuracy: 87.65625\n",
      "iter 146 ---  Loss: 2.67263912409544    Accuracy: 86.5625\n",
      "iter 147 ---  Loss: 3.1912728026509285    Accuracy: 86.5625\n",
      "iter 148 ---  Loss: 3.4576446264982224    Accuracy: 86.5625\n",
      "iter 149 ---  Loss: 3.533756911754608    Accuracy: 87.5\n",
      "iter 150 ---  Loss: 2.9845031574368477    Accuracy: 88.59375\n",
      "iter 151 ---  Loss: 2.9348033666610718    Accuracy: 87.8125\n",
      "iter 152 ---  Loss: 3.0886828303337097    Accuracy: 87.03125\n",
      "iter 153 ---  Loss: 3.4333455488085747    Accuracy: 85.625\n",
      "iter 154 ---  Loss: 2.849056325852871    Accuracy: 87.65625\n",
      "iter 155 ---  Loss: 3.016696184873581    Accuracy: 86.71875\n",
      "iter 156 ---  Loss: 2.4297886341810226    Accuracy: 88.75\n",
      "iter 157 ---  Loss: 2.9013611748814583    Accuracy: 87.65625\n",
      "iter 158 ---  Loss: 3.404460981488228    Accuracy: 85.15625\n",
      "iter 159 ---  Loss: 2.8761193081736565    Accuracy: 87.1875\n",
      "iter 160 ---  Loss: 3.127244994044304    Accuracy: 87.8125\n",
      "iter 161 ---  Loss: 2.526354156434536    Accuracy: 89.0625\n",
      "iter 162 ---  Loss: 3.0704206377267838    Accuracy: 86.40625\n",
      "iter 163 ---  Loss: 3.335594803094864    Accuracy: 87.5\n",
      "iter 164 ---  Loss: 3.241608440876007    Accuracy: 86.40625\n",
      "iter 165 ---  Loss: 2.6236272752285004    Accuracy: 87.03125\n",
      "iter 166 ---  Loss: 3.194778837263584    Accuracy: 85.625\n",
      "iter 167 ---  Loss: 3.4509115889668465    Accuracy: 85.15625\n",
      "iter 168 ---  Loss: 2.8084027767181396    Accuracy: 87.96875\n",
      "iter 169 ---  Loss: 2.603742405772209    Accuracy: 86.25\n",
      "iter 170 ---  Loss: 3.401178777217865    Accuracy: 86.875\n",
      "iter 171 ---  Loss: 2.791567750275135    Accuracy: 86.40625\n",
      "iter 172 ---  Loss: 2.76209969073534    Accuracy: 87.8125\n",
      "iter 173 ---  Loss: 3.3004227057099342    Accuracy: 86.40625\n",
      "iter 174 ---  Loss: 3.065862625837326    Accuracy: 87.34375\n",
      "iter 175 ---  Loss: 3.429237686097622    Accuracy: 84.6875\n",
      "iter 176 ---  Loss: 2.7831710800528526    Accuracy: 85.15625\n",
      "iter 177 ---  Loss: 3.535473257303238    Accuracy: 85.46875\n",
      "iter 178 ---  Loss: 2.601190008223057    Accuracy: 86.5625\n",
      "iter 179 ---  Loss: 2.738996744155884    Accuracy: 88.90625\n",
      "iter 180 ---  Loss: 2.683505490422249    Accuracy: 87.03125\n",
      "iter 181 ---  Loss: 2.9684941172599792    Accuracy: 86.71875\n",
      "iter 182 ---  Loss: 3.191893234848976    Accuracy: 85.78125\n",
      "iter 183 ---  Loss: 3.076966941356659    Accuracy: 87.65625\n",
      "iter 184 ---  Loss: 3.5272978991270065    Accuracy: 84.53125\n",
      "iter 185 ---  Loss: 3.2379957512021065    Accuracy: 85.15625\n",
      "iter 186 ---  Loss: 2.7032354548573494    Accuracy: 88.125\n",
      "iter 187 ---  Loss: 2.8585124239325523    Accuracy: 88.125\n",
      "iter 188 ---  Loss: 3.1778483390808105    Accuracy: 86.25\n",
      "iter 189 ---  Loss: 3.006941206753254    Accuracy: 87.34375\n",
      "iter 190 ---  Loss: 2.7160614877939224    Accuracy: 86.40625\n",
      "iter 191 ---  Loss: 2.919551432132721    Accuracy: 85.78125\n",
      "iter 192 ---  Loss: 3.2174841538071632    Accuracy: 87.03125\n",
      "iter 193 ---  Loss: 2.9861238077282906    Accuracy: 85.46875\n",
      "iter 194 ---  Loss: 2.6229346320033073    Accuracy: 88.75\n",
      "iter 195 ---  Loss: 3.0747154355049133    Accuracy: 87.5\n",
      "iter 196 ---  Loss: 2.7563191950321198    Accuracy: 87.34375\n",
      "iter 197 ---  Loss: 2.9332408234477043    Accuracy: 88.59375\n",
      "iter 198 ---  Loss: 3.0402070358395576    Accuracy: 87.8125\n",
      "iter 199 ---  Loss: 2.928201623260975    Accuracy: 87.65625\n",
      "iter 200 ---  Loss: 2.7188198417425156    Accuracy: 87.1875\n",
      "iter 201 ---  Loss: 2.6978917717933655    Accuracy: 87.34375\n",
      "iter 202 ---  Loss: 3.359401486814022    Accuracy: 85.625\n",
      "iter 203 ---  Loss: 3.040512055158615    Accuracy: 88.125\n",
      "iter 204 ---  Loss: 3.167965844273567    Accuracy: 88.125\n",
      "iter 205 ---  Loss: 2.810353383421898    Accuracy: 87.03125\n",
      "iter 206 ---  Loss: 2.88095486164093    Accuracy: 85.3125\n",
      "iter 207 ---  Loss: 2.832829102873802    Accuracy: 86.09375\n",
      "iter 208 ---  Loss: 3.249192051589489    Accuracy: 86.25\n",
      "iter 209 ---  Loss: 2.7869999930262566    Accuracy: 88.125\n",
      "iter 210 ---  Loss: 2.991546131670475    Accuracy: 86.09375\n",
      "iter 211 ---  Loss: 3.3030191361904144    Accuracy: 87.1875\n",
      "iter 212 ---  Loss: 3.4903862923383713    Accuracy: 86.5625\n",
      "iter 213 ---  Loss: 2.9652379751205444    Accuracy: 86.875\n",
      "iter 214 ---  Loss: 2.7708004266023636    Accuracy: 86.71875\n",
      "iter 215 ---  Loss: 3.2274766117334366    Accuracy: 86.5625\n",
      "iter 216 ---  Loss: 2.961744524538517    Accuracy: 88.125\n",
      "iter 217 ---  Loss: 3.2310074642300606    Accuracy: 86.875\n",
      "iter 218 ---  Loss: 2.740731544792652    Accuracy: 85.625\n",
      "iter 219 ---  Loss: 3.5645178481936455    Accuracy: 87.5\n",
      "iter 220 ---  Loss: 2.7278627306222916    Accuracy: 88.59375\n",
      "iter 221 ---  Loss: 2.7258151173591614    Accuracy: 86.5625\n",
      "iter 222 ---  Loss: 2.7927244752645493    Accuracy: 87.34375\n",
      "iter 223 ---  Loss: 2.790590338408947    Accuracy: 89.21875\n",
      "iter 224 ---  Loss: 3.602601572871208    Accuracy: 86.71875\n",
      "iter 225 ---  Loss: 2.8306280001997948    Accuracy: 87.96875\n",
      "iter 226 ---  Loss: 2.7472975850105286    Accuracy: 87.03125\n",
      "iter 227 ---  Loss: 2.8020188584923744    Accuracy: 87.65625\n",
      "iter 228 ---  Loss: 3.5844540745019913    Accuracy: 85.625\n",
      "iter 229 ---  Loss: 3.201658807694912    Accuracy: 86.71875\n",
      "iter 230 ---  Loss: 2.937365874648094    Accuracy: 87.03125\n",
      "iter 231 ---  Loss: 3.297354780137539    Accuracy: 87.5\n",
      "iter 232 ---  Loss: 3.2008087784051895    Accuracy: 86.875\n",
      "iter 233 ---  Loss: 2.760164648294449    Accuracy: 88.59375\n",
      "iter 234 ---  Loss: 2.9600272476673126    Accuracy: 88.4375\n",
      "iter 235 ---  Loss: 3.12941475212574    Accuracy: 87.03125\n",
      "iter 236 ---  Loss: 3.2855819016695023    Accuracy: 87.65625\n",
      "iter 237 ---  Loss: 2.771371364593506    Accuracy: 84.53125\n",
      "iter 238 ---  Loss: 2.9137918651103973    Accuracy: 85.9375\n",
      "iter 239 ---  Loss: 2.8463669791817665    Accuracy: 87.8125\n",
      "iter 240 ---  Loss: 3.2038236558437347    Accuracy: 85.78125\n",
      "iter 241 ---  Loss: 3.117190934717655    Accuracy: 85.0\n",
      "iter 242 ---  Loss: 3.3703134432435036    Accuracy: 85.78125\n",
      "iter 243 ---  Loss: 2.757186137139797    Accuracy: 89.0625\n",
      "iter 244 ---  Loss: 3.134733907878399    Accuracy: 86.40625\n",
      "iter 245 ---  Loss: 2.935535289347172    Accuracy: 85.625\n",
      "iter 246 ---  Loss: 3.1862810254096985    Accuracy: 86.09375\n",
      "iter 247 ---  Loss: 2.600422315299511    Accuracy: 87.34375\n",
      "iter 248 ---  Loss: 3.748545967042446    Accuracy: 82.8125\n",
      "iter 249 ---  Loss: 3.7105614617466927    Accuracy: 87.03125\n",
      "iter 250 ---  Loss: 3.1246402114629745    Accuracy: 86.875\n",
      "iter 251 ---  Loss: 2.8015234768390656    Accuracy: 86.25\n",
      "iter 252 ---  Loss: 3.2901963219046593    Accuracy: 86.25\n",
      "iter 253 ---  Loss: 3.4485927522182465    Accuracy: 85.46875\n",
      "iter 254 ---  Loss: 2.6867491230368614    Accuracy: 87.96875\n",
      "iter 255 ---  Loss: 3.1055625453591347    Accuracy: 85.15625\n",
      "iter 256 ---  Loss: 3.3430205062031746    Accuracy: 85.625\n",
      "iter 257 ---  Loss: 3.0338411927223206    Accuracy: 87.1875\n",
      "iter 258 ---  Loss: 3.3909594491124153    Accuracy: 85.9375\n",
      "iter 259 ---  Loss: 3.0979137271642685    Accuracy: 86.5625\n",
      "iter 260 ---  Loss: 2.715884178876877    Accuracy: 86.25\n",
      "iter 261 ---  Loss: 3.6945041120052338    Accuracy: 83.59375\n",
      "iter 262 ---  Loss: 2.5987151861190796    Accuracy: 86.09375\n",
      "iter 263 ---  Loss: 3.028425231575966    Accuracy: 85.46875\n",
      "iter 264 ---  Loss: 3.2960734888911247    Accuracy: 86.25\n",
      "iter 265 ---  Loss: 3.6075616851449013    Accuracy: 88.125\n",
      "iter 266 ---  Loss: 3.393346220254898    Accuracy: 87.03125\n",
      "iter 267 ---  Loss: 2.438973091542721    Accuracy: 88.125\n",
      "iter 268 ---  Loss: 3.415732115507126    Accuracy: 87.1875\n",
      "iter 269 ---  Loss: 3.228919953107834    Accuracy: 87.03125\n",
      "iter 270 ---  Loss: 3.489024043083191    Accuracy: 87.96875\n",
      "iter 271 ---  Loss: 2.724603734910488    Accuracy: 86.25\n",
      "iter 272 ---  Loss: 3.0120686441659927    Accuracy: 87.8125\n",
      "iter 273 ---  Loss: 2.9921893551945686    Accuracy: 88.59375\n",
      "iter 274 ---  Loss: 3.465496651828289    Accuracy: 85.46875\n",
      "iter 275 ---  Loss: 3.4437854662537575    Accuracy: 86.25\n",
      "iter 276 ---  Loss: 3.2621468380093575    Accuracy: 84.0625\n",
      "iter 277 ---  Loss: 2.881700411438942    Accuracy: 87.34375\n",
      "iter 278 ---  Loss: 2.660034604370594    Accuracy: 87.5\n",
      "iter 279 ---  Loss: 2.577731393277645    Accuracy: 88.125\n",
      "iter 280 ---  Loss: 3.624748468399048    Accuracy: 86.40625\n",
      "iter 281 ---  Loss: 2.7227444648742676    Accuracy: 87.03125\n",
      "iter 282 ---  Loss: 2.7862181589007378    Accuracy: 89.0625\n",
      "iter 283 ---  Loss: 3.1710114553570747    Accuracy: 87.03125\n",
      "iter 284 ---  Loss: 3.4971020370721817    Accuracy: 85.78125\n",
      "iter 285 ---  Loss: 3.23209285736084    Accuracy: 88.4375\n",
      "iter 286 ---  Loss: 3.4004746824502945    Accuracy: 85.9375\n",
      "iter 287 ---  Loss: 3.5172482058405876    Accuracy: 85.46875\n",
      "iter 288 ---  Loss: 3.0647600516676903    Accuracy: 86.875\n",
      "iter 289 ---  Loss: 3.560739077627659    Accuracy: 85.3125\n",
      "iter 290 ---  Loss: 3.288912057876587    Accuracy: 87.34375\n",
      "iter 291 ---  Loss: 3.0465961769223213    Accuracy: 85.15625\n",
      "iter 292 ---  Loss: 3.4661029055714607    Accuracy: 85.9375\n",
      "iter 293 ---  Loss: 3.4659873619675636    Accuracy: 84.0625\n",
      "iter 294 ---  Loss: 3.4796263948082924    Accuracy: 85.9375\n",
      "iter 295 ---  Loss: 3.1475521996617317    Accuracy: 85.15625\n",
      "iter 296 ---  Loss: 2.449029505252838    Accuracy: 87.5\n",
      "iter 297 ---  Loss: 3.2167420089244843    Accuracy: 86.25\n",
      "iter 298 ---  Loss: 3.269173853099346    Accuracy: 86.40625\n",
      "iter 299 ---  Loss: 2.878218851983547    Accuracy: 86.25\n",
      "iter 300 ---  Loss: 3.1401054561138153    Accuracy: 88.75\n",
      "iter 301 ---  Loss: 2.5563606172800064    Accuracy: 88.59375\n",
      "iter 302 ---  Loss: 2.9043816700577736    Accuracy: 86.71875\n",
      "iter 303 ---  Loss: 3.1851379349827766    Accuracy: 88.28125\n",
      "iter 304 ---  Loss: 3.586570680141449    Accuracy: 85.78125\n",
      "iter 305 ---  Loss: 2.9471701234579086    Accuracy: 89.6875\n",
      "iter 306 ---  Loss: 2.9385580271482468    Accuracy: 87.5\n",
      "iter 307 ---  Loss: 3.0547643303871155    Accuracy: 88.125\n",
      "iter 308 ---  Loss: 2.7395509257912636    Accuracy: 87.65625\n",
      "iter 309 ---  Loss: 3.2146889567375183    Accuracy: 87.5\n",
      "iter 310 ---  Loss: 3.2206306234002113    Accuracy: 87.96875\n",
      "iter 311 ---  Loss: 2.7925932109355927    Accuracy: 87.1875\n",
      "iter 312 ---  Loss: 2.9518816247582436    Accuracy: 86.5625\n",
      "iter 313 ---  Loss: 3.266666404902935    Accuracy: 88.28125\n",
      "iter 314 ---  Loss: 2.7932905703783035    Accuracy: 85.9375\n",
      "iter 315 ---  Loss: 3.654358461499214    Accuracy: 85.46875\n",
      "iter 316 ---  Loss: 3.019331805408001    Accuracy: 86.5625\n",
      "iter 317 ---  Loss: 3.3229401037096977    Accuracy: 87.03125\n",
      "iter 318 ---  Loss: 3.1673112139105797    Accuracy: 86.71875\n",
      "iter 319 ---  Loss: 2.921977274119854    Accuracy: 87.34375\n",
      "iter 320 ---  Loss: 3.2115766406059265    Accuracy: 86.09375\n",
      "iter 321 ---  Loss: 2.677109770476818    Accuracy: 89.0625\n",
      "iter 322 ---  Loss: 2.9543469324707985    Accuracy: 85.9375\n",
      "iter 323 ---  Loss: 2.8463204503059387    Accuracy: 87.8125\n",
      "iter 324 ---  Loss: 2.772332601249218    Accuracy: 86.09375\n",
      "iter 325 ---  Loss: 3.153954118490219    Accuracy: 87.03125\n",
      "iter 326 ---  Loss: 2.797648899257183    Accuracy: 86.875\n",
      "iter 327 ---  Loss: 2.884054958820343    Accuracy: 88.4375\n",
      "iter 328 ---  Loss: 2.9767887368798256    Accuracy: 87.34375\n",
      "iter 329 ---  Loss: 3.1695944741368294    Accuracy: 86.875\n",
      "iter 330 ---  Loss: 3.293617755174637    Accuracy: 85.15625\n",
      "iter 331 ---  Loss: 3.1023688539862633    Accuracy: 85.46875\n",
      "iter 332 ---  Loss: 3.2299444302916527    Accuracy: 86.71875\n",
      "iter 333 ---  Loss: 3.000470519065857    Accuracy: 87.8125\n",
      "iter 334 ---  Loss: 2.7407642751932144    Accuracy: 86.5625\n",
      "iter 335 ---  Loss: 2.9950279146432877    Accuracy: 88.28125\n",
      "iter 336 ---  Loss: 2.9973744601011276    Accuracy: 88.125\n",
      "iter 337 ---  Loss: 2.645719639956951    Accuracy: 87.5\n",
      "iter 338 ---  Loss: 2.9123690500855446    Accuracy: 87.5\n",
      "iter 339 ---  Loss: 2.8469657972455025    Accuracy: 87.65625\n",
      "iter 340 ---  Loss: 3.1476283594965935    Accuracy: 85.625\n",
      "iter 341 ---  Loss: 2.6860905066132545    Accuracy: 88.75\n",
      "iter 342 ---  Loss: 2.8916031569242477    Accuracy: 88.75\n",
      "iter 343 ---  Loss: 3.3830694183707237    Accuracy: 85.46875\n",
      "iter 344 ---  Loss: 3.0596445724368095    Accuracy: 85.78125\n",
      "iter 345 ---  Loss: 3.0200612545013428    Accuracy: 88.28125\n",
      "iter 346 ---  Loss: 2.9067240953445435    Accuracy: 87.8125\n",
      "iter 347 ---  Loss: 3.1280453503131866    Accuracy: 86.09375\n",
      "iter 348 ---  Loss: 2.992668144404888    Accuracy: 86.71875\n",
      "iter 349 ---  Loss: 2.9403417631983757    Accuracy: 85.625\n",
      "iter 350 ---  Loss: 3.2517461329698563    Accuracy: 87.5\n",
      "iter 351 ---  Loss: 3.2005256339907646    Accuracy: 85.15625\n",
      "iter 352 ---  Loss: 2.9760973751544952    Accuracy: 87.5\n",
      "iter 353 ---  Loss: 2.756445288658142    Accuracy: 88.90625\n",
      "iter 354 ---  Loss: 3.0917129889130592    Accuracy: 86.40625\n",
      "iter 355 ---  Loss: 3.1918736696243286    Accuracy: 85.9375\n",
      "iter 356 ---  Loss: 2.545448213815689    Accuracy: 86.09375\n",
      "iter 357 ---  Loss: 4.067889139056206    Accuracy: 84.375\n",
      "iter 358 ---  Loss: 3.860321991145611    Accuracy: 85.0\n",
      "iter 359 ---  Loss: 3.2252471894025803    Accuracy: 87.1875\n",
      "iter 360 ---  Loss: 3.2069086730480194    Accuracy: 87.8125\n",
      "iter 361 ---  Loss: 2.968969188630581    Accuracy: 85.9375\n",
      "iter 362 ---  Loss: 3.4657996743917465    Accuracy: 86.09375\n",
      "iter 363 ---  Loss: 2.8393823727965355    Accuracy: 88.4375\n",
      "iter 364 ---  Loss: 3.0514736101031303    Accuracy: 86.40625\n",
      "iter 365 ---  Loss: 3.1560307666659355    Accuracy: 87.03125\n",
      "iter 366 ---  Loss: 3.259241059422493    Accuracy: 85.9375\n",
      "iter 367 ---  Loss: 2.8225198537111282    Accuracy: 88.28125\n",
      "iter 368 ---  Loss: 3.1129600182175636    Accuracy: 88.75\n",
      "iter 369 ---  Loss: 2.954007089138031    Accuracy: 86.40625\n",
      "iter 370 ---  Loss: 3.1533921286463737    Accuracy: 87.8125\n",
      "iter 371 ---  Loss: 3.6293461695313454    Accuracy: 86.875\n",
      "iter 372 ---  Loss: 3.3865539506077766    Accuracy: 84.53125\n",
      "iter 373 ---  Loss: 3.2494754940271378    Accuracy: 86.5625\n",
      "iter 374 ---  Loss: 3.2872884199023247    Accuracy: 86.40625\n",
      "iter 375 ---  Loss: 3.358554594218731    Accuracy: 87.34375\n",
      "iter 376 ---  Loss: 3.4914019256830215    Accuracy: 85.78125\n",
      "iter 377 ---  Loss: 2.9024198949337006    Accuracy: 88.59375\n",
      "iter 378 ---  Loss: 3.060019515454769    Accuracy: 88.4375\n",
      "iter 379 ---  Loss: 3.2311969995498657    Accuracy: 87.03125\n",
      "iter 380 ---  Loss: 2.7592371106147766    Accuracy: 86.875\n",
      "iter 381 ---  Loss: 3.4821344390511513    Accuracy: 87.03125\n",
      "iter 382 ---  Loss: 3.0635558739304543    Accuracy: 85.15625\n",
      "iter 383 ---  Loss: 2.965002655982971    Accuracy: 88.59375\n",
      "iter 384 ---  Loss: 2.9282960146665573    Accuracy: 87.96875\n",
      "iter 385 ---  Loss: 2.6615891978144646    Accuracy: 88.4375\n",
      "iter 386 ---  Loss: 3.3817273154854774    Accuracy: 85.3125\n",
      "iter 387 ---  Loss: 2.765938811004162    Accuracy: 85.46875\n",
      "iter 388 ---  Loss: 2.8028619214892387    Accuracy: 86.40625\n",
      "iter 389 ---  Loss: 3.6133580431342125    Accuracy: 85.3125\n",
      "iter 390 ---  Loss: 2.8828940466046333    Accuracy: 86.875\n",
      "iter 391 ---  Loss: 2.9424084052443504    Accuracy: 87.34375\n",
      "iter 392 ---  Loss: 3.1071810498833656    Accuracy: 85.625\n",
      "iter 393 ---  Loss: 2.726236157119274    Accuracy: 88.4375\n",
      "iter 394 ---  Loss: 2.9157337620854378    Accuracy: 87.96875\n",
      "iter 395 ---  Loss: 2.601457066833973    Accuracy: 87.96875\n",
      "iter 396 ---  Loss: 2.6554350927472115    Accuracy: 86.40625\n",
      "iter 397 ---  Loss: 2.5312784388661385    Accuracy: 87.5\n",
      "iter 398 ---  Loss: 2.976180426776409    Accuracy: 87.1875\n",
      "iter 399 ---  Loss: 2.9184879809617996    Accuracy: 87.5\n",
      "iter 400 ---  Loss: 2.863742411136627    Accuracy: 88.4375\n",
      "iter 401 ---  Loss: 3.3312257826328278    Accuracy: 84.21875\n",
      "iter 402 ---  Loss: 2.7620016783475876    Accuracy: 87.8125\n",
      "iter 403 ---  Loss: 3.768556632101536    Accuracy: 85.15625\n",
      "iter 404 ---  Loss: 2.7981019765138626    Accuracy: 87.1875\n",
      "iter 405 ---  Loss: 3.226894535124302    Accuracy: 87.5\n",
      "iter 406 ---  Loss: 3.0658858716487885    Accuracy: 87.5\n",
      "iter 407 ---  Loss: 3.602613739669323    Accuracy: 87.34375\n",
      "iter 408 ---  Loss: 2.9922439381480217    Accuracy: 89.375\n",
      "iter 409 ---  Loss: 3.2061580792069435    Accuracy: 87.96875\n",
      "iter 410 ---  Loss: 3.2383205965161324    Accuracy: 86.71875\n",
      "iter 411 ---  Loss: 3.1465799808502197    Accuracy: 86.71875\n",
      "iter 412 ---  Loss: 2.7272397354245186    Accuracy: 88.125\n",
      "iter 413 ---  Loss: 2.9188510477542877    Accuracy: 88.59375\n",
      "iter 414 ---  Loss: 2.6396196112036705    Accuracy: 88.59375\n",
      "iter 415 ---  Loss: 3.313079372048378    Accuracy: 86.25\n",
      "iter 416 ---  Loss: 3.4008685871958733    Accuracy: 84.53125\n",
      "iter 417 ---  Loss: 3.2451818734407425    Accuracy: 86.5625\n",
      "iter 418 ---  Loss: 3.5691855549812317    Accuracy: 86.71875\n",
      "iter 419 ---  Loss: 3.1925315111875534    Accuracy: 87.8125\n",
      "iter 420 ---  Loss: 2.4686305969953537    Accuracy: 89.53125\n",
      "iter 421 ---  Loss: 3.1788340508937836    Accuracy: 86.40625\n",
      "iter 422 ---  Loss: 2.8705133572220802    Accuracy: 85.78125\n",
      "iter 423 ---  Loss: 3.0590269342064857    Accuracy: 87.34375\n",
      "iter 424 ---  Loss: 2.9440182894468307    Accuracy: 86.875\n",
      "iter 425 ---  Loss: 3.4469322562217712    Accuracy: 87.34375\n",
      "iter 426 ---  Loss: 3.66141190379858    Accuracy: 87.34375\n",
      "iter 427 ---  Loss: 3.1956453546881676    Accuracy: 87.5\n",
      "iter 428 ---  Loss: 2.578644774854183    Accuracy: 88.28125\n",
      "iter 429 ---  Loss: 3.000038355588913    Accuracy: 88.125\n",
      "iter 430 ---  Loss: 3.044238068163395    Accuracy: 87.03125\n",
      "iter 431 ---  Loss: 3.021903984248638    Accuracy: 87.03125\n",
      "iter 432 ---  Loss: 3.3313178569078445    Accuracy: 88.4375\n",
      "iter 433 ---  Loss: 2.636489026248455    Accuracy: 87.65625\n",
      "iter 434 ---  Loss: 2.7517944052815437    Accuracy: 87.65625\n",
      "iter 435 ---  Loss: 3.656554028391838    Accuracy: 86.09375\n",
      "iter 436 ---  Loss: 3.0097209811210632    Accuracy: 88.125\n",
      "iter 437 ---  Loss: 3.2205080166459084    Accuracy: 86.09375\n",
      "iter 438 ---  Loss: 3.0777243301272392    Accuracy: 89.53125\n",
      "iter 439 ---  Loss: 2.964377798140049    Accuracy: 88.59375\n",
      "iter 440 ---  Loss: 2.909579887986183    Accuracy: 87.34375\n",
      "iter 441 ---  Loss: 2.7618720158934593    Accuracy: 88.59375\n",
      "iter 442 ---  Loss: 2.9310152977705    Accuracy: 88.28125\n",
      "iter 443 ---  Loss: 2.7376562654972076    Accuracy: 89.53125\n",
      "iter 444 ---  Loss: 2.826416090130806    Accuracy: 87.65625\n",
      "iter 445 ---  Loss: 2.8502489998936653    Accuracy: 87.34375\n",
      "iter 446 ---  Loss: 2.6500332057476044    Accuracy: 89.6875\n",
      "iter 447 ---  Loss: 2.5062269493937492    Accuracy: 89.53125\n",
      "iter 448 ---  Loss: 3.225055046379566    Accuracy: 86.25\n",
      "iter 449 ---  Loss: 3.166363537311554    Accuracy: 86.09375\n",
      "iter 450 ---  Loss: 2.4841270968317986    Accuracy: 88.90625\n",
      "iter 451 ---  Loss: 2.947074271738529    Accuracy: 88.59375\n",
      "iter 452 ---  Loss: 3.0777523666620255    Accuracy: 87.96875\n",
      "iter 453 ---  Loss: 3.649580202996731    Accuracy: 85.625\n",
      "iter 454 ---  Loss: 3.346067249774933    Accuracy: 86.25\n",
      "iter 455 ---  Loss: 3.3816955536603928    Accuracy: 85.78125\n",
      "iter 456 ---  Loss: 3.719189867377281    Accuracy: 85.625\n",
      "iter 457 ---  Loss: 3.066701225936413    Accuracy: 85.3125\n",
      "iter 458 ---  Loss: 2.7723299115896225    Accuracy: 86.5625\n",
      "iter 459 ---  Loss: 2.4890713840723038    Accuracy: 87.96875\n",
      "iter 460 ---  Loss: 2.9565678164362907    Accuracy: 86.71875\n",
      "iter 461 ---  Loss: 2.712964817881584    Accuracy: 87.8125\n",
      "iter 462 ---  Loss: 2.8955142572522163    Accuracy: 88.75\n",
      "iter 463 ---  Loss: 2.5345638021826744    Accuracy: 87.5\n",
      "iter 464 ---  Loss: 3.047345243394375    Accuracy: 86.40625\n",
      "iter 465 ---  Loss: 3.3563549369573593    Accuracy: 88.75\n",
      "iter 466 ---  Loss: 3.4204306975007057    Accuracy: 88.75\n",
      "iter 467 ---  Loss: 3.4221793189644814    Accuracy: 87.65625\n",
      "iter 468 ---  Loss: 2.6102565601468086    Accuracy: 88.59375\n",
      "iter 469 ---  Loss: 3.307308793067932    Accuracy: 86.25\n",
      "iter 470 ---  Loss: 3.3951831087470055    Accuracy: 87.1875\n",
      "iter 471 ---  Loss: 2.8100143745541573    Accuracy: 88.90625\n",
      "iter 472 ---  Loss: 2.9588175415992737    Accuracy: 87.5\n",
      "iter 473 ---  Loss: 3.185994565486908    Accuracy: 86.09375\n",
      "iter 474 ---  Loss: 2.7772896215319633    Accuracy: 88.28125\n",
      "iter 475 ---  Loss: 2.6822649613022804    Accuracy: 87.5\n",
      "iter 476 ---  Loss: 2.7620998546481133    Accuracy: 90.15625\n",
      "iter 477 ---  Loss: 2.47238752245903    Accuracy: 88.125\n",
      "iter 478 ---  Loss: 2.9211066514253616    Accuracy: 89.84375\n",
      "iter 479 ---  Loss: 3.0397224351763725    Accuracy: 87.96875\n",
      "iter 480 ---  Loss: 3.2557804733514786    Accuracy: 88.28125\n",
      "iter 481 ---  Loss: 2.809319995343685    Accuracy: 87.96875\n",
      "iter 482 ---  Loss: 2.5374578833580017    Accuracy: 90.46875\n",
      "iter 483 ---  Loss: 2.858320415019989    Accuracy: 88.4375\n",
      "iter 484 ---  Loss: 2.963048495352268    Accuracy: 87.65625\n",
      "iter 485 ---  Loss: 2.750117376446724    Accuracy: 88.75\n",
      "iter 486 ---  Loss: 2.9628686904907227    Accuracy: 88.75\n",
      "iter 487 ---  Loss: 2.991812840104103    Accuracy: 88.125\n",
      "iter 488 ---  Loss: 2.627413146197796    Accuracy: 89.375\n",
      "iter 489 ---  Loss: 2.7494947984814644    Accuracy: 88.4375\n",
      "iter 490 ---  Loss: 3.3513231948018074    Accuracy: 87.1875\n",
      "iter 491 ---  Loss: 3.275046579539776    Accuracy: 87.96875\n",
      "iter 492 ---  Loss: 2.7761067897081375    Accuracy: 87.8125\n",
      "iter 493 ---  Loss: 2.73119293153286    Accuracy: 89.0625\n",
      "iter 494 ---  Loss: 3.049196258187294    Accuracy: 88.4375\n",
      "iter 495 ---  Loss: 2.692430481314659    Accuracy: 87.34375\n",
      "iter 496 ---  Loss: 3.1419360265135765    Accuracy: 88.125\n",
      "iter 497 ---  Loss: 3.4187096655368805    Accuracy: 88.4375\n",
      "iter 498 ---  Loss: 4.42168977111578    Accuracy: 86.71875\n",
      "iter 499 ---  Loss: 3.3840892985463142    Accuracy: 87.5\n",
      "iter 500 ---  Loss: 3.12353528290987    Accuracy: 89.0625\n",
      "iter 501 ---  Loss: 2.722301386296749    Accuracy: 85.78125\n",
      "iter 502 ---  Loss: 3.1271589174866676    Accuracy: 86.40625\n",
      "iter 503 ---  Loss: 3.7906854525208473    Accuracy: 88.59375\n",
      "iter 504 ---  Loss: 3.1137024015188217    Accuracy: 87.34375\n",
      "iter 505 ---  Loss: 2.968712218105793    Accuracy: 86.5625\n",
      "iter 506 ---  Loss: 2.8730922117829323    Accuracy: 87.5\n",
      "iter 507 ---  Loss: 2.9753333106637    Accuracy: 87.03125\n",
      "iter 508 ---  Loss: 3.3657595217227936    Accuracy: 87.1875\n",
      "iter 509 ---  Loss: 2.992584429681301    Accuracy: 89.375\n",
      "iter 510 ---  Loss: 2.5625715255737305    Accuracy: 90.15625\n",
      "iter 511 ---  Loss: 2.593114994466305    Accuracy: 88.90625\n",
      "iter 512 ---  Loss: 3.293880708515644    Accuracy: 85.9375\n",
      "iter 513 ---  Loss: 3.0689243376255035    Accuracy: 86.5625\n",
      "iter 514 ---  Loss: 3.3188653588294983    Accuracy: 89.375\n",
      "iter 515 ---  Loss: 2.7925287187099457    Accuracy: 88.125\n",
      "iter 516 ---  Loss: 3.134617358446121    Accuracy: 87.8125\n",
      "iter 517 ---  Loss: 3.8861529529094696    Accuracy: 86.25\n",
      "iter 518 ---  Loss: 3.522003747522831    Accuracy: 86.5625\n",
      "iter 519 ---  Loss: 3.0539014264941216    Accuracy: 87.34375\n",
      "iter 520 ---  Loss: 3.1923737600445747    Accuracy: 88.28125\n",
      "iter 521 ---  Loss: 3.6511204540729523    Accuracy: 87.03125\n",
      "iter 522 ---  Loss: 2.866063177585602    Accuracy: 87.5\n",
      "iter 523 ---  Loss: 2.936566837131977    Accuracy: 86.40625\n",
      "iter 524 ---  Loss: 3.2064825519919395    Accuracy: 86.5625\n",
      "iter 525 ---  Loss: 2.6220686212182045    Accuracy: 87.65625\n",
      "iter 526 ---  Loss: 3.2566491216421127    Accuracy: 87.8125\n",
      "iter 527 ---  Loss: 3.1063895523548126    Accuracy: 87.65625\n",
      "iter 528 ---  Loss: 3.3066276609897614    Accuracy: 87.5\n",
      "iter 529 ---  Loss: 3.1990648061037064    Accuracy: 88.90625\n",
      "iter 530 ---  Loss: 3.2359303012490273    Accuracy: 88.4375\n",
      "iter 531 ---  Loss: 2.936142474412918    Accuracy: 89.6875\n",
      "iter 532 ---  Loss: 3.13389078527689    Accuracy: 88.59375\n",
      "iter 533 ---  Loss: 2.9899473190307617    Accuracy: 88.28125\n",
      "iter 534 ---  Loss: 2.8271466121077538    Accuracy: 87.8125\n",
      "iter 535 ---  Loss: 3.3435905799269676    Accuracy: 85.3125\n",
      "iter 536 ---  Loss: 2.8698240146040916    Accuracy: 87.03125\n",
      "iter 537 ---  Loss: 3.491363152861595    Accuracy: 87.03125\n",
      "iter 538 ---  Loss: 2.9713261425495148    Accuracy: 88.28125\n",
      "iter 539 ---  Loss: 3.3860316574573517    Accuracy: 86.25\n",
      "iter 540 ---  Loss: 3.5269223898649216    Accuracy: 85.0\n",
      "iter 541 ---  Loss: 3.750115565955639    Accuracy: 86.25\n",
      "iter 542 ---  Loss: 2.9318937361240387    Accuracy: 87.03125\n",
      "iter 543 ---  Loss: 3.464439131319523    Accuracy: 86.71875\n",
      "iter 544 ---  Loss: 2.959841787815094    Accuracy: 88.28125\n",
      "iter 545 ---  Loss: 3.147282138466835    Accuracy: 88.4375\n",
      "iter 546 ---  Loss: 3.730090267956257    Accuracy: 85.0\n",
      "iter 547 ---  Loss: 3.235166624188423    Accuracy: 85.78125\n",
      "iter 548 ---  Loss: 2.677557684481144    Accuracy: 87.8125\n",
      "iter 549 ---  Loss: 3.031751833856106    Accuracy: 85.9375\n",
      "iter 550 ---  Loss: 2.7432651221752167    Accuracy: 88.59375\n",
      "iter 551 ---  Loss: 3.597419247031212    Accuracy: 88.28125\n",
      "iter 552 ---  Loss: 2.9745829105377197    Accuracy: 88.4375\n",
      "iter 553 ---  Loss: 2.9377415627241135    Accuracy: 88.59375\n",
      "iter 554 ---  Loss: 2.7404706478118896    Accuracy: 87.03125\n",
      "iter 555 ---  Loss: 3.019586034119129    Accuracy: 89.21875\n",
      "iter 556 ---  Loss: 2.568683810532093    Accuracy: 90.3125\n",
      "iter 557 ---  Loss: 3.2571316212415695    Accuracy: 86.25\n",
      "iter 558 ---  Loss: 3.0551312789320946    Accuracy: 87.1875\n",
      "iter 559 ---  Loss: 2.6566785275936127    Accuracy: 87.96875\n",
      "iter 560 ---  Loss: 3.6583870500326157    Accuracy: 85.3125\n",
      "iter 561 ---  Loss: 3.257897399365902    Accuracy: 87.03125\n",
      "iter 562 ---  Loss: 3.0891910046339035    Accuracy: 84.6875\n",
      "iter 563 ---  Loss: 2.9134297594428062    Accuracy: 87.34375\n",
      "iter 564 ---  Loss: 2.9546452835202217    Accuracy: 87.5\n",
      "iter 565 ---  Loss: 3.2668388560414314    Accuracy: 86.5625\n",
      "iter 566 ---  Loss: 3.3179398477077484    Accuracy: 85.15625\n",
      "iter 567 ---  Loss: 2.7869975715875626    Accuracy: 86.25\n",
      "iter 568 ---  Loss: 3.0697506591677666    Accuracy: 86.40625\n",
      "iter 569 ---  Loss: 3.4047015085816383    Accuracy: 85.9375\n",
      "iter 570 ---  Loss: 3.061759054660797    Accuracy: 86.71875\n",
      "iter 571 ---  Loss: 3.7327785193920135    Accuracy: 86.25\n",
      "iter 572 ---  Loss: 3.4873848408460617    Accuracy: 86.40625\n",
      "iter 573 ---  Loss: 2.7327670603990555    Accuracy: 86.09375\n",
      "iter 574 ---  Loss: 3.593487113714218    Accuracy: 86.25\n",
      "iter 575 ---  Loss: 2.924070820212364    Accuracy: 87.34375\n",
      "iter 576 ---  Loss: 2.858347572386265    Accuracy: 86.5625\n",
      "iter 577 ---  Loss: 3.1990868002176285    Accuracy: 86.09375\n",
      "iter 578 ---  Loss: 2.580119304358959    Accuracy: 87.34375\n",
      "iter 579 ---  Loss: 3.413214795291424    Accuracy: 86.09375\n",
      "iter 580 ---  Loss: 2.6252493262290955    Accuracy: 87.1875\n",
      "iter 581 ---  Loss: 2.6286035552620888    Accuracy: 87.65625\n",
      "iter 582 ---  Loss: 2.820044621825218    Accuracy: 87.5\n",
      "iter 583 ---  Loss: 2.8019902035593987    Accuracy: 87.03125\n",
      "iter 584 ---  Loss: 3.329085223376751    Accuracy: 87.5\n",
      "iter 585 ---  Loss: 2.7283094748854637    Accuracy: 89.6875\n",
      "iter 586 ---  Loss: 2.9642819464206696    Accuracy: 88.59375\n",
      "iter 587 ---  Loss: 3.228808216750622    Accuracy: 87.8125\n",
      "iter 588 ---  Loss: 3.0898297131061554    Accuracy: 85.9375\n",
      "iter 589 ---  Loss: 3.1857727393507957    Accuracy: 86.5625\n",
      "iter 590 ---  Loss: 3.38255076110363    Accuracy: 85.9375\n",
      "iter 591 ---  Loss: 3.165242426097393    Accuracy: 86.875\n",
      "iter 592 ---  Loss: 2.9477691501379013    Accuracy: 88.125\n",
      "iter 593 ---  Loss: 3.6660256907343864    Accuracy: 85.15625\n",
      "iter 594 ---  Loss: 2.737306348979473    Accuracy: 87.03125\n",
      "iter 595 ---  Loss: 2.6146562919020653    Accuracy: 87.96875\n",
      "iter 596 ---  Loss: 2.850150763988495    Accuracy: 87.5\n",
      "iter 597 ---  Loss: 2.8767064437270164    Accuracy: 86.09375\n",
      "iter 598 ---  Loss: 3.0866385251283646    Accuracy: 86.40625\n",
      "iter 599 ---  Loss: 2.8332891911268234    Accuracy: 86.875\n",
      "iter 600 ---  Loss: 3.0844894498586655    Accuracy: 87.96875\n",
      "iter 601 ---  Loss: 3.6272363364696503    Accuracy: 85.78125\n",
      "iter 602 ---  Loss: 3.1408165767788887    Accuracy: 87.8125\n",
      "iter 603 ---  Loss: 2.575387269258499    Accuracy: 88.59375\n",
      "iter 604 ---  Loss: 3.1116795763373375    Accuracy: 88.28125\n",
      "iter 605 ---  Loss: 3.3940604105591774    Accuracy: 85.9375\n",
      "iter 606 ---  Loss: 3.3042189180850983    Accuracy: 88.90625\n",
      "iter 607 ---  Loss: 2.6025244742631912    Accuracy: 89.0625\n",
      "iter 608 ---  Loss: 2.6363394260406494    Accuracy: 87.65625\n",
      "iter 609 ---  Loss: 3.0768072083592415    Accuracy: 86.25\n",
      "iter 610 ---  Loss: 3.111309863626957    Accuracy: 88.75\n",
      "iter 611 ---  Loss: 2.6576500087976456    Accuracy: 88.28125\n",
      "iter 612 ---  Loss: 2.553664915263653    Accuracy: 90.46875\n",
      "iter 613 ---  Loss: 3.3805856108665466    Accuracy: 86.875\n",
      "iter 614 ---  Loss: 3.2130611538887024    Accuracy: 86.5625\n",
      "iter 615 ---  Loss: 3.0181127563118935    Accuracy: 86.875\n",
      "iter 616 ---  Loss: 3.5714350566267967    Accuracy: 88.59375\n",
      "iter 617 ---  Loss: 4.085204295814037    Accuracy: 82.96875\n",
      "iter 618 ---  Loss: 3.2358739972114563    Accuracy: 88.59375\n",
      "iter 619 ---  Loss: 2.7096225544810295    Accuracy: 87.8125\n",
      "iter 620 ---  Loss: 2.792831301689148    Accuracy: 89.21875\n",
      "iter 621 ---  Loss: 3.07804474234581    Accuracy: 86.71875\n",
      "iter 622 ---  Loss: 3.5961091965436935    Accuracy: 87.03125\n",
      "iter 623 ---  Loss: 3.046151675283909    Accuracy: 87.8125\n",
      "iter 624 ---  Loss: 3.314340353012085    Accuracy: 87.65625\n",
      "iter 625 ---  Loss: 2.455482043325901    Accuracy: 88.125\n",
      "iter 626 ---  Loss: 2.750662110745907    Accuracy: 88.28125\n",
      "iter 627 ---  Loss: 2.861064240336418    Accuracy: 88.125\n",
      "iter 628 ---  Loss: 3.588195316493511    Accuracy: 85.3125\n",
      "iter 629 ---  Loss: 3.0084831044077873    Accuracy: 88.125\n",
      "iter 630 ---  Loss: 3.5758028626441956    Accuracy: 85.0\n",
      "iter 631 ---  Loss: 2.840626783668995    Accuracy: 88.4375\n",
      "iter 632 ---  Loss: 3.146899536252022    Accuracy: 87.65625\n",
      "iter 633 ---  Loss: 3.060194708406925    Accuracy: 87.96875\n",
      "iter 634 ---  Loss: 3.0657770931720734    Accuracy: 89.375\n",
      "iter 635 ---  Loss: 3.568028785288334    Accuracy: 86.71875\n",
      "iter 636 ---  Loss: 2.5031818971037865    Accuracy: 88.59375\n",
      "iter 637 ---  Loss: 3.3073975816369057    Accuracy: 86.875\n",
      "iter 638 ---  Loss: 3.0485505014657974    Accuracy: 85.46875\n",
      "iter 639 ---  Loss: 3.2780251801013947    Accuracy: 85.78125\n",
      "iter 640 ---  Loss: 3.335848890244961    Accuracy: 86.5625\n",
      "iter 641 ---  Loss: 3.0578431263566017    Accuracy: 87.34375\n",
      "iter 642 ---  Loss: 3.131115108728409    Accuracy: 87.03125\n",
      "iter 643 ---  Loss: 3.1718776300549507    Accuracy: 87.65625\n",
      "iter 644 ---  Loss: 2.7074170634150505    Accuracy: 88.75\n",
      "iter 645 ---  Loss: 3.4336879923939705    Accuracy: 86.25\n",
      "iter 646 ---  Loss: 2.609311431646347    Accuracy: 87.65625\n",
      "iter 647 ---  Loss: 3.205490432679653    Accuracy: 85.9375\n",
      "iter 648 ---  Loss: 3.424348793923855    Accuracy: 85.3125\n",
      "iter 649 ---  Loss: 3.626922585070133    Accuracy: 86.40625\n",
      "iter 650 ---  Loss: 3.2918692007660866    Accuracy: 85.78125\n",
      "iter 651 ---  Loss: 3.674578294157982    Accuracy: 86.5625\n",
      "iter 652 ---  Loss: 2.903577722609043    Accuracy: 87.34375\n",
      "iter 653 ---  Loss: 3.410831533372402    Accuracy: 86.09375\n",
      "iter 654 ---  Loss: 3.019126869738102    Accuracy: 87.03125\n",
      "iter 655 ---  Loss: 2.8088492527604103    Accuracy: 87.65625\n",
      "iter 656 ---  Loss: 2.7966270223259926    Accuracy: 87.96875\n",
      "iter 657 ---  Loss: 3.061874009668827    Accuracy: 86.875\n",
      "iter 658 ---  Loss: 2.643232263624668    Accuracy: 89.0625\n",
      "iter 659 ---  Loss: 3.0072257593274117    Accuracy: 85.78125\n",
      "iter 660 ---  Loss: 2.863354556262493    Accuracy: 87.65625\n",
      "iter 661 ---  Loss: 2.6453817188739777    Accuracy: 87.1875\n",
      "iter 662 ---  Loss: 2.612354353070259    Accuracy: 88.4375\n",
      "iter 663 ---  Loss: 3.2018662691116333    Accuracy: 87.5\n",
      "iter 664 ---  Loss: 2.639064870774746    Accuracy: 87.8125\n",
      "iter 665 ---  Loss: 3.1653546392917633    Accuracy: 86.875\n",
      "iter 666 ---  Loss: 2.935701221227646    Accuracy: 89.0625\n",
      "iter 667 ---  Loss: 3.0671182051301003    Accuracy: 87.5\n",
      "iter 668 ---  Loss: 2.947230964899063    Accuracy: 87.1875\n",
      "iter 669 ---  Loss: 2.792161285877228    Accuracy: 86.71875\n",
      "iter 670 ---  Loss: 3.1965648382902145    Accuracy: 87.03125\n",
      "iter 671 ---  Loss: 3.6797944977879524    Accuracy: 85.0\n",
      "iter 672 ---  Loss: 3.1790718510746956    Accuracy: 87.5\n",
      "iter 673 ---  Loss: 3.431439980864525    Accuracy: 87.03125\n",
      "iter 674 ---  Loss: 3.0885703340172768    Accuracy: 86.40625\n",
      "iter 675 ---  Loss: 2.9129332080483437    Accuracy: 86.09375\n",
      "iter 676 ---  Loss: 3.3182224184274673    Accuracy: 86.40625\n",
      "iter 677 ---  Loss: 2.854397028684616    Accuracy: 87.03125\n",
      "iter 678 ---  Loss: 2.749986246228218    Accuracy: 86.875\n",
      "iter 679 ---  Loss: 2.9676611572504044    Accuracy: 86.71875\n",
      "iter 680 ---  Loss: 2.9737246483564377    Accuracy: 86.09375\n",
      "iter 681 ---  Loss: 3.094837486743927    Accuracy: 86.09375\n",
      "iter 682 ---  Loss: 2.6167052164673805    Accuracy: 88.59375\n",
      "iter 683 ---  Loss: 2.7285868749022484    Accuracy: 88.59375\n",
      "iter 684 ---  Loss: 2.9239667654037476    Accuracy: 88.90625\n",
      "iter 685 ---  Loss: 2.986816883087158    Accuracy: 88.125\n",
      "iter 686 ---  Loss: 3.233943894505501    Accuracy: 86.5625\n",
      "iter 687 ---  Loss: 3.1480914503335953    Accuracy: 86.5625\n",
      "iter 688 ---  Loss: 2.7592231035232544    Accuracy: 88.125\n",
      "iter 689 ---  Loss: 3.292619653046131    Accuracy: 86.40625\n",
      "iter 690 ---  Loss: 3.1811647787690163    Accuracy: 86.71875\n",
      "iter 691 ---  Loss: 3.6860444098711014    Accuracy: 86.09375\n",
      "iter 692 ---  Loss: 2.836138352751732    Accuracy: 85.46875\n",
      "iter 693 ---  Loss: 3.1475092470645905    Accuracy: 86.09375\n",
      "iter 694 ---  Loss: 2.729810357093811    Accuracy: 86.25\n",
      "iter 695 ---  Loss: 3.212767094373703    Accuracy: 86.5625\n",
      "iter 696 ---  Loss: 3.4824110344052315    Accuracy: 85.78125\n",
      "iter 697 ---  Loss: 2.8620095625519753    Accuracy: 85.3125\n",
      "iter 698 ---  Loss: 2.8948352932929993    Accuracy: 87.34375\n",
      "iter 699 ---  Loss: 3.237024500966072    Accuracy: 86.71875\n",
      "iter 700 ---  Loss: 3.1349905356764793    Accuracy: 85.78125\n",
      "iter 701 ---  Loss: 3.2375881671905518    Accuracy: 87.03125\n",
      "iter 702 ---  Loss: 2.688465639948845    Accuracy: 89.53125\n",
      "iter 703 ---  Loss: 3.846912495791912    Accuracy: 86.09375\n",
      "iter 704 ---  Loss: 2.5985471084713936    Accuracy: 87.5\n",
      "iter 705 ---  Loss: 2.979460246860981    Accuracy: 86.5625\n",
      "iter 706 ---  Loss: 3.154262460768223    Accuracy: 86.875\n",
      "iter 707 ---  Loss: 3.3973701745271683    Accuracy: 86.875\n",
      "iter 708 ---  Loss: 2.657157853245735    Accuracy: 86.71875\n",
      "iter 709 ---  Loss: 3.5347908288240433    Accuracy: 86.875\n",
      "iter 710 ---  Loss: 3.0246807634830475    Accuracy: 87.34375\n",
      "iter 711 ---  Loss: 2.6349495351314545    Accuracy: 87.5\n",
      "iter 712 ---  Loss: 2.9111645221710205    Accuracy: 88.4375\n",
      "iter 713 ---  Loss: 2.973648712038994    Accuracy: 85.78125\n",
      "iter 714 ---  Loss: 2.7406893372535706    Accuracy: 86.5625\n",
      "iter 715 ---  Loss: 3.1359009742736816    Accuracy: 88.125\n",
      "iter 716 ---  Loss: 3.0539777129888535    Accuracy: 86.09375\n",
      "iter 717 ---  Loss: 3.755109928548336    Accuracy: 86.875\n",
      "iter 718 ---  Loss: 3.368108667433262    Accuracy: 87.34375\n",
      "iter 719 ---  Loss: 2.8628777265548706    Accuracy: 87.34375\n",
      "iter 720 ---  Loss: 2.9256875440478325    Accuracy: 87.34375\n",
      "iter 721 ---  Loss: 3.612441509962082    Accuracy: 84.84375\n",
      "iter 722 ---  Loss: 2.8974583595991135    Accuracy: 87.34375\n",
      "iter 723 ---  Loss: 2.635022394359112    Accuracy: 87.8125\n",
      "iter 724 ---  Loss: 2.492205873131752    Accuracy: 87.8125\n",
      "iter 725 ---  Loss: 2.7311507239937782    Accuracy: 87.34375\n",
      "iter 726 ---  Loss: 3.3757229894399643    Accuracy: 87.34375\n",
      "iter 727 ---  Loss: 2.4891408383846283    Accuracy: 87.5\n",
      "iter 728 ---  Loss: 3.36544356495142    Accuracy: 86.40625\n",
      "iter 729 ---  Loss: 2.9875018298625946    Accuracy: 87.8125\n",
      "iter 730 ---  Loss: 3.229881279170513    Accuracy: 87.5\n",
      "iter 731 ---  Loss: 2.8956763073801994    Accuracy: 88.59375\n",
      "iter 732 ---  Loss: 2.725370332598686    Accuracy: 87.03125\n",
      "iter 733 ---  Loss: 2.9542001485824585    Accuracy: 87.65625\n",
      "iter 734 ---  Loss: 2.8369924277067184    Accuracy: 87.03125\n",
      "iter 735 ---  Loss: 2.809647113084793    Accuracy: 87.5\n",
      "iter 736 ---  Loss: 3.0196795389056206    Accuracy: 88.75\n",
      "iter 737 ---  Loss: 3.126829892396927    Accuracy: 85.9375\n",
      "iter 738 ---  Loss: 3.3838100731372833    Accuracy: 87.1875\n",
      "iter 739 ---  Loss: 2.7004997357726097    Accuracy: 87.65625\n",
      "iter 740 ---  Loss: 3.8691671565175056    Accuracy: 85.15625\n",
      "iter 741 ---  Loss: 3.3683215528726578    Accuracy: 87.1875\n",
      "iter 742 ---  Loss: 3.2235587686300278    Accuracy: 85.0\n",
      "iter 743 ---  Loss: 3.4859504252672195    Accuracy: 85.9375\n",
      "iter 744 ---  Loss: 2.626183621585369    Accuracy: 85.78125\n",
      "iter 745 ---  Loss: 3.4067754447460175    Accuracy: 85.9375\n",
      "iter 746 ---  Loss: 2.7379247918725014    Accuracy: 85.46875\n",
      "iter 747 ---  Loss: 2.8624153584241867    Accuracy: 87.1875\n",
      "iter 748 ---  Loss: 2.6250472888350487    Accuracy: 86.5625\n",
      "iter 749 ---  Loss: 3.4997325241565704    Accuracy: 85.3125\n",
      "iter 750 ---  Loss: 2.6234294921159744    Accuracy: 87.34375\n",
      "iter 751 ---  Loss: 2.8690566942095757    Accuracy: 86.40625\n",
      "iter 752 ---  Loss: 2.9402719140052795    Accuracy: 87.1875\n",
      "iter 753 ---  Loss: 3.4184442907571793    Accuracy: 87.5\n",
      "iter 754 ---  Loss: 2.7503382116556168    Accuracy: 87.5\n",
      "iter 755 ---  Loss: 2.767284892499447    Accuracy: 87.5\n",
      "iter 756 ---  Loss: 3.541835144162178    Accuracy: 85.3125\n",
      "iter 757 ---  Loss: 3.038973443210125    Accuracy: 87.96875\n",
      "iter 758 ---  Loss: 2.5784527733922005    Accuracy: 86.875\n",
      "iter 759 ---  Loss: 3.018483005464077    Accuracy: 87.1875\n",
      "iter 760 ---  Loss: 2.743471398949623    Accuracy: 89.0625\n",
      "iter 761 ---  Loss: 3.0346157178282738    Accuracy: 87.5\n",
      "iter 762 ---  Loss: 3.0156191289424896    Accuracy: 85.625\n",
      "iter 763 ---  Loss: 3.1100332140922546    Accuracy: 85.3125\n",
      "iter 764 ---  Loss: 2.90577781945467    Accuracy: 88.75\n",
      "iter 765 ---  Loss: 2.811056785285473    Accuracy: 88.28125\n",
      "iter 766 ---  Loss: 3.1678357124328613    Accuracy: 87.03125\n",
      "iter 767 ---  Loss: 2.8842480406165123    Accuracy: 87.34375\n",
      "iter 768 ---  Loss: 2.971860207617283    Accuracy: 87.03125\n",
      "iter 769 ---  Loss: 2.5629843175411224    Accuracy: 88.125\n",
      "iter 770 ---  Loss: 2.763561926782131    Accuracy: 89.0625\n",
      "iter 771 ---  Loss: 3.040763258934021    Accuracy: 87.8125\n",
      "iter 772 ---  Loss: 2.6192849576473236    Accuracy: 88.90625\n",
      "iter 773 ---  Loss: 3.340746246278286    Accuracy: 85.3125\n",
      "iter 774 ---  Loss: 3.560929462313652    Accuracy: 87.8125\n",
      "iter 775 ---  Loss: 2.779758006334305    Accuracy: 89.53125\n",
      "iter 776 ---  Loss: 3.0924872532486916    Accuracy: 87.1875\n",
      "iter 777 ---  Loss: 3.862275093793869    Accuracy: 86.40625\n",
      "iter 778 ---  Loss: 3.2597047686576843    Accuracy: 85.78125\n",
      "iter 779 ---  Loss: 2.7996407225728035    Accuracy: 88.28125\n",
      "iter 780 ---  Loss: 3.4408587142825127    Accuracy: 87.1875\n",
      "iter 781 ---  Loss: 3.0705302953720093    Accuracy: 87.5\n",
      "iter 782 ---  Loss: 3.244082622230053    Accuracy: 86.25\n",
      "iter 783 ---  Loss: 3.248978279531002    Accuracy: 88.4375\n",
      "iter 784 ---  Loss: 2.820737987756729    Accuracy: 87.34375\n",
      "iter 785 ---  Loss: 3.0414954349398613    Accuracy: 86.40625\n",
      "iter 786 ---  Loss: 4.000168018043041    Accuracy: 86.5625\n",
      "iter 787 ---  Loss: 2.6945325657725334    Accuracy: 87.1875\n",
      "iter 788 ---  Loss: 4.054262362420559    Accuracy: 85.9375\n",
      "iter 789 ---  Loss: 2.7643104791641235    Accuracy: 87.8125\n",
      "iter 790 ---  Loss: 3.1096682101488113    Accuracy: 87.96875\n",
      "iter 791 ---  Loss: 2.8703233003616333    Accuracy: 87.03125\n",
      "iter 792 ---  Loss: 2.587564066052437    Accuracy: 88.125\n",
      "iter 793 ---  Loss: 2.6995639130473137    Accuracy: 89.0625\n",
      "iter 794 ---  Loss: 2.899357333779335    Accuracy: 87.03125\n",
      "iter 795 ---  Loss: 3.228057362139225    Accuracy: 87.96875\n",
      "iter 796 ---  Loss: 2.7641178742051125    Accuracy: 87.8125\n",
      "iter 797 ---  Loss: 3.4014897122979164    Accuracy: 85.15625\n",
      "iter 798 ---  Loss: 2.7456141114234924    Accuracy: 87.65625\n",
      "iter 799 ---  Loss: 2.706883817911148    Accuracy: 89.0625\n",
      "iter 800 ---  Loss: 3.031621903181076    Accuracy: 88.125\n",
      "iter 801 ---  Loss: 3.360536076128483    Accuracy: 87.1875\n",
      "iter 802 ---  Loss: 2.810788430273533    Accuracy: 85.9375\n",
      "iter 803 ---  Loss: 3.5421920716762543    Accuracy: 85.625\n",
      "iter 804 ---  Loss: 3.128790706396103    Accuracy: 86.5625\n",
      "iter 805 ---  Loss: 3.106868326663971    Accuracy: 86.875\n",
      "iter 806 ---  Loss: 2.8001580983400345    Accuracy: 87.65625\n",
      "iter 807 ---  Loss: 3.096678115427494    Accuracy: 87.34375\n",
      "iter 808 ---  Loss: 3.3055501133203506    Accuracy: 85.46875\n",
      "iter 809 ---  Loss: 3.07569719851017    Accuracy: 87.65625\n",
      "iter 810 ---  Loss: 3.3654108867049217    Accuracy: 86.40625\n",
      "iter 811 ---  Loss: 2.984734870493412    Accuracy: 87.1875\n",
      "iter 812 ---  Loss: 3.3437935933470726    Accuracy: 87.1875\n",
      "iter 813 ---  Loss: 2.8079942613840103    Accuracy: 88.75\n",
      "iter 814 ---  Loss: 2.6452281400561333    Accuracy: 87.5\n",
      "iter 815 ---  Loss: 3.044919103384018    Accuracy: 86.875\n",
      "iter 816 ---  Loss: 2.929744467139244    Accuracy: 88.28125\n",
      "iter 817 ---  Loss: 3.3744810447096825    Accuracy: 86.71875\n",
      "iter 818 ---  Loss: 3.468153163790703    Accuracy: 85.46875\n",
      "iter 819 ---  Loss: 3.2034628242254257    Accuracy: 85.3125\n",
      "iter 820 ---  Loss: 3.1642329916357994    Accuracy: 87.8125\n",
      "iter 821 ---  Loss: 4.342266000807285    Accuracy: 84.6875\n",
      "iter 822 ---  Loss: 3.3120241463184357    Accuracy: 85.15625\n",
      "iter 823 ---  Loss: 3.1206907108426094    Accuracy: 85.9375\n",
      "iter 824 ---  Loss: 3.5787669494748116    Accuracy: 87.34375\n",
      "iter 825 ---  Loss: 3.2595288679003716    Accuracy: 87.1875\n",
      "iter 826 ---  Loss: 3.3014439716935158    Accuracy: 87.03125\n",
      "iter 827 ---  Loss: 3.2640523687005043    Accuracy: 86.875\n",
      "iter 828 ---  Loss: 2.520190082490444    Accuracy: 89.53125\n",
      "iter 829 ---  Loss: 3.3989173397421837    Accuracy: 87.34375\n",
      "iter 830 ---  Loss: 3.321456328034401    Accuracy: 86.25\n",
      "iter 831 ---  Loss: 2.9400287196040154    Accuracy: 89.0625\n",
      "iter 832 ---  Loss: 3.499500162899494    Accuracy: 86.25\n",
      "iter 833 ---  Loss: 3.2208892107009888    Accuracy: 85.9375\n",
      "iter 834 ---  Loss: 2.9598530679941177    Accuracy: 85.0\n",
      "iter 835 ---  Loss: 2.508586600422859    Accuracy: 87.96875\n",
      "iter 836 ---  Loss: 3.0901676788926125    Accuracy: 88.125\n",
      "iter 837 ---  Loss: 4.063205316662788    Accuracy: 86.25\n",
      "iter 838 ---  Loss: 2.79839226603508    Accuracy: 87.96875\n",
      "iter 839 ---  Loss: 2.7636242881417274    Accuracy: 87.65625\n",
      "iter 840 ---  Loss: 3.2165922448039055    Accuracy: 85.9375\n",
      "iter 841 ---  Loss: 3.081039123237133    Accuracy: 88.125\n",
      "iter 842 ---  Loss: 3.234862230718136    Accuracy: 86.71875\n",
      "iter 843 ---  Loss: 3.1323846578598022    Accuracy: 89.0625\n",
      "iter 844 ---  Loss: 2.8114993572235107    Accuracy: 86.09375\n",
      "iter 845 ---  Loss: 3.081466220319271    Accuracy: 87.65625\n",
      "iter 846 ---  Loss: 2.9549084305763245    Accuracy: 86.5625\n",
      "iter 847 ---  Loss: 2.6290463358163834    Accuracy: 88.90625\n",
      "iter 848 ---  Loss: 3.149873338639736    Accuracy: 88.59375\n",
      "iter 849 ---  Loss: 2.7365865632891655    Accuracy: 89.53125\n",
      "iter 850 ---  Loss: 3.6574619337916374    Accuracy: 87.65625\n",
      "iter 851 ---  Loss: 3.355821765959263    Accuracy: 87.5\n",
      "iter 852 ---  Loss: 3.5497163832187653    Accuracy: 87.1875\n",
      "iter 853 ---  Loss: 2.971575565636158    Accuracy: 87.5\n",
      "iter 854 ---  Loss: 3.7650015875697136    Accuracy: 86.09375\n",
      "iter 855 ---  Loss: 3.029887869954109    Accuracy: 85.78125\n",
      "iter 856 ---  Loss: 3.307238422334194    Accuracy: 87.03125\n",
      "iter 857 ---  Loss: 3.0057847276329994    Accuracy: 86.40625\n",
      "iter 858 ---  Loss: 2.7322108671069145    Accuracy: 88.4375\n",
      "iter 859 ---  Loss: 2.4965218380093575    Accuracy: 89.375\n",
      "iter 860 ---  Loss: 3.1903388798236847    Accuracy: 86.40625\n",
      "iter 861 ---  Loss: 3.2783449217677116    Accuracy: 87.5\n",
      "iter 862 ---  Loss: 2.610245816409588    Accuracy: 88.90625\n",
      "iter 863 ---  Loss: 2.9686228930950165    Accuracy: 88.90625\n",
      "iter 864 ---  Loss: 3.0084671154618263    Accuracy: 86.40625\n",
      "iter 865 ---  Loss: 3.1131681725382805    Accuracy: 88.125\n",
      "iter 866 ---  Loss: 2.816622331738472    Accuracy: 88.125\n",
      "iter 867 ---  Loss: 3.2281690910458565    Accuracy: 87.03125\n",
      "iter 868 ---  Loss: 3.6010873541235924    Accuracy: 86.09375\n",
      "iter 869 ---  Loss: 3.3386565148830414    Accuracy: 88.125\n",
      "iter 870 ---  Loss: 3.2163827046751976    Accuracy: 86.5625\n",
      "iter 871 ---  Loss: 2.9311918914318085    Accuracy: 86.25\n",
      "iter 872 ---  Loss: 2.7956344932317734    Accuracy: 88.125\n",
      "iter 873 ---  Loss: 3.1025703251361847    Accuracy: 86.875\n",
      "iter 874 ---  Loss: 2.672499358654022    Accuracy: 88.4375\n",
      "iter 875 ---  Loss: 3.042726494371891    Accuracy: 87.34375\n",
      "iter 876 ---  Loss: 3.1645735427737236    Accuracy: 85.625\n",
      "iter 877 ---  Loss: 3.58194350451231    Accuracy: 87.65625\n",
      "iter 878 ---  Loss: 2.550827145576477    Accuracy: 89.21875\n",
      "iter 879 ---  Loss: 3.006090924143791    Accuracy: 88.28125\n",
      "iter 880 ---  Loss: 2.580946445465088    Accuracy: 87.8125\n",
      "iter 881 ---  Loss: 3.1524102985858917    Accuracy: 88.125\n",
      "iter 882 ---  Loss: 2.799688845872879    Accuracy: 87.1875\n",
      "iter 883 ---  Loss: 2.969822309911251    Accuracy: 86.71875\n",
      "iter 884 ---  Loss: 2.6493482440710068    Accuracy: 89.21875\n",
      "iter 885 ---  Loss: 2.8085619658231735    Accuracy: 87.03125\n",
      "iter 886 ---  Loss: 2.7486628741025925    Accuracy: 89.53125\n",
      "iter 887 ---  Loss: 2.965383656322956    Accuracy: 87.65625\n",
      "iter 888 ---  Loss: 2.8017102852463722    Accuracy: 88.90625\n",
      "iter 889 ---  Loss: 3.5353891476988792    Accuracy: 86.875\n",
      "iter 890 ---  Loss: 2.7707728520035744    Accuracy: 87.8125\n",
      "iter 891 ---  Loss: 2.9631982520222664    Accuracy: 85.625\n",
      "iter 892 ---  Loss: 3.4255192428827286    Accuracy: 87.5\n",
      "iter 893 ---  Loss: 3.432467855513096    Accuracy: 87.1875\n",
      "iter 894 ---  Loss: 2.8116383999586105    Accuracy: 89.0625\n",
      "iter 895 ---  Loss: 2.9368286952376366    Accuracy: 86.40625\n",
      "iter 896 ---  Loss: 3.03830249607563    Accuracy: 87.1875\n",
      "iter 897 ---  Loss: 3.1612291038036346    Accuracy: 87.03125\n",
      "iter 898 ---  Loss: 3.2019453048706055    Accuracy: 87.1875\n",
      "iter 899 ---  Loss: 3.1084062829613686    Accuracy: 87.96875\n",
      "iter 900 ---  Loss: 2.7367270290851593    Accuracy: 88.75\n",
      "iter 901 ---  Loss: 3.1779568195343018    Accuracy: 87.96875\n",
      "iter 902 ---  Loss: 3.022480070590973    Accuracy: 87.65625\n",
      "iter 903 ---  Loss: 2.8135625272989273    Accuracy: 87.03125\n",
      "iter 904 ---  Loss: 3.333632245659828    Accuracy: 88.28125\n",
      "iter 905 ---  Loss: 3.2587617933750153    Accuracy: 86.5625\n",
      "iter 906 ---  Loss: 3.068396270275116    Accuracy: 86.875\n",
      "iter 907 ---  Loss: 3.545448713004589    Accuracy: 86.25\n",
      "iter 908 ---  Loss: 3.027981013059616    Accuracy: 90.0\n",
      "iter 909 ---  Loss: 2.903316155076027    Accuracy: 86.71875\n",
      "iter 910 ---  Loss: 2.7949234694242477    Accuracy: 88.90625\n",
      "iter 911 ---  Loss: 2.9484052062034607    Accuracy: 87.5\n",
      "iter 912 ---  Loss: 3.060020036995411    Accuracy: 85.78125\n",
      "iter 913 ---  Loss: 3.0937496796250343    Accuracy: 87.03125\n",
      "iter 914 ---  Loss: 2.5258110612630844    Accuracy: 90.15625\n",
      "iter 915 ---  Loss: 3.2628387436270714    Accuracy: 87.03125\n",
      "iter 916 ---  Loss: 2.9247291833162308    Accuracy: 87.03125\n",
      "iter 917 ---  Loss: 2.6917261481285095    Accuracy: 87.5\n",
      "iter 918 ---  Loss: 2.7633450478315353    Accuracy: 87.03125\n",
      "iter 919 ---  Loss: 2.8489081785082817    Accuracy: 87.5\n",
      "iter 920 ---  Loss: 2.991764597594738    Accuracy: 88.28125\n",
      "iter 921 ---  Loss: 3.0236681774258614    Accuracy: 87.65625\n",
      "iter 922 ---  Loss: 3.0617434456944466    Accuracy: 88.125\n",
      "iter 923 ---  Loss: 2.714506208896637    Accuracy: 88.75\n",
      "iter 924 ---  Loss: 3.2514338716864586    Accuracy: 87.65625\n",
      "iter 925 ---  Loss: 2.8123436495661736    Accuracy: 87.03125\n",
      "iter 926 ---  Loss: 2.86028091609478    Accuracy: 88.4375\n",
      "iter 927 ---  Loss: 3.40652397274971    Accuracy: 86.5625\n",
      "iter 928 ---  Loss: 2.88121884316206    Accuracy: 87.34375\n",
      "iter 929 ---  Loss: 3.244157426059246    Accuracy: 87.65625\n",
      "iter 930 ---  Loss: 2.741728611290455    Accuracy: 89.375\n",
      "iter 931 ---  Loss: 3.050086572766304    Accuracy: 88.28125\n",
      "iter 932 ---  Loss: 3.283526748418808    Accuracy: 86.40625\n",
      "iter 933 ---  Loss: 3.0794130116701126    Accuracy: 87.5\n",
      "iter 934 ---  Loss: 3.4607352539896965    Accuracy: 84.6875\n",
      "iter 935 ---  Loss: 3.2280846163630486    Accuracy: 87.65625\n",
      "iter 936 ---  Loss: 2.349889025092125    Accuracy: 89.53125\n",
      "iter 937 ---  Loss: 3.3570464104413986    Accuracy: 86.09375\n",
      "iter 938 ---  Loss: 2.9663404896855354    Accuracy: 87.65625\n",
      "iter 939 ---  Loss: 2.955753654241562    Accuracy: 87.34375\n",
      "iter 940 ---  Loss: 3.1178072318434715    Accuracy: 88.59375\n",
      "iter 941 ---  Loss: 4.334992550313473    Accuracy: 87.1875\n",
      "iter 942 ---  Loss: 3.078108564019203    Accuracy: 86.25\n",
      "iter 943 ---  Loss: 3.428623929619789    Accuracy: 85.46875\n",
      "iter 944 ---  Loss: 3.3784452006220818    Accuracy: 86.40625\n",
      "iter 945 ---  Loss: 3.800546906888485    Accuracy: 86.875\n",
      "iter 946 ---  Loss: 3.0452397614717484    Accuracy: 86.40625\n",
      "iter 947 ---  Loss: 2.80363766849041    Accuracy: 87.1875\n",
      "iter 948 ---  Loss: 3.22390079498291    Accuracy: 87.65625\n",
      "iter 949 ---  Loss: 2.7857209369540215    Accuracy: 87.5\n",
      "iter 950 ---  Loss: 2.5411353409290314    Accuracy: 88.75\n",
      "iter 951 ---  Loss: 3.435588590800762    Accuracy: 87.5\n",
      "iter 952 ---  Loss: 2.9383923336863518    Accuracy: 88.28125\n",
      "iter 953 ---  Loss: 3.63353730738163    Accuracy: 88.28125\n",
      "iter 954 ---  Loss: 3.249926269054413    Accuracy: 86.875\n",
      "iter 955 ---  Loss: 2.5290471091866493    Accuracy: 87.8125\n",
      "iter 956 ---  Loss: 2.43174310028553    Accuracy: 87.5\n",
      "iter 957 ---  Loss: 3.5068524330854416    Accuracy: 86.71875\n",
      "iter 958 ---  Loss: 3.138659656047821    Accuracy: 89.53125\n",
      "iter 959 ---  Loss: 2.846183329820633    Accuracy: 87.96875\n",
      "iter 960 ---  Loss: 3.4514915198087692    Accuracy: 86.71875\n",
      "iter 961 ---  Loss: 2.6511825025081635    Accuracy: 88.59375\n",
      "iter 962 ---  Loss: 3.0178938508033752    Accuracy: 88.4375\n",
      "iter 963 ---  Loss: 2.8501470759510994    Accuracy: 87.96875\n",
      "iter 964 ---  Loss: 3.3112493827939034    Accuracy: 85.78125\n",
      "iter 965 ---  Loss: 3.814738728106022    Accuracy: 84.53125\n",
      "iter 966 ---  Loss: 2.7777765318751335    Accuracy: 87.1875\n",
      "iter 967 ---  Loss: 3.238143503665924    Accuracy: 86.25\n",
      "iter 968 ---  Loss: 3.258239693939686    Accuracy: 87.5\n",
      "iter 969 ---  Loss: 3.562601789832115    Accuracy: 87.5\n",
      "iter 970 ---  Loss: 3.210634745657444    Accuracy: 86.71875\n",
      "iter 971 ---  Loss: 2.741272449493408    Accuracy: 87.1875\n",
      "iter 972 ---  Loss: 2.8107736483216286    Accuracy: 88.75\n",
      "iter 973 ---  Loss: 2.9785245284438133    Accuracy: 87.34375\n",
      "iter 974 ---  Loss: 3.583096906542778    Accuracy: 87.03125\n",
      "iter 975 ---  Loss: 3.508255325257778    Accuracy: 86.5625\n",
      "iter 976 ---  Loss: 3.925942651927471    Accuracy: 86.09375\n",
      "iter 977 ---  Loss: 2.9241324588656425    Accuracy: 87.1875\n",
      "iter 978 ---  Loss: 2.9565884098410606    Accuracy: 88.4375\n",
      "iter 979 ---  Loss: 3.177460737526417    Accuracy: 89.0625\n",
      "iter 980 ---  Loss: 2.8559433966875076    Accuracy: 89.21875\n",
      "iter 981 ---  Loss: 3.2068626284599304    Accuracy: 88.90625\n",
      "iter 982 ---  Loss: 2.8804300650954247    Accuracy: 89.375\n",
      "iter 983 ---  Loss: 3.2921970784664154    Accuracy: 85.625\n",
      "iter 984 ---  Loss: 2.9734273552894592    Accuracy: 86.71875\n",
      "iter 985 ---  Loss: 2.693101793527603    Accuracy: 88.90625\n",
      "iter 986 ---  Loss: 3.2148590311408043    Accuracy: 86.71875\n",
      "iter 987 ---  Loss: 2.851177327334881    Accuracy: 87.96875\n",
      "iter 988 ---  Loss: 2.6974937692284584    Accuracy: 89.375\n",
      "iter 989 ---  Loss: 3.4435251504182816    Accuracy: 85.625\n",
      "iter 990 ---  Loss: 2.9856086671352386    Accuracy: 87.8125\n",
      "iter 991 ---  Loss: 3.2400889471173286    Accuracy: 86.40625\n",
      "iter 992 ---  Loss: 3.491272732615471    Accuracy: 85.78125\n",
      "iter 993 ---  Loss: 2.923286184668541    Accuracy: 85.3125\n",
      "iter 994 ---  Loss: 3.0005618929862976    Accuracy: 88.75\n",
      "iter 995 ---  Loss: 3.4899686500430107    Accuracy: 85.78125\n",
      "iter 996 ---  Loss: 3.363104522228241    Accuracy: 85.0\n",
      "iter 997 ---  Loss: 3.4226073920726776    Accuracy: 86.40625\n",
      "iter 998 ---  Loss: 2.942504271864891    Accuracy: 89.0625\n",
      "iter 999 ---  Loss: 2.8267479985952377    Accuracy: 86.5625\n",
      "iter 1000 ---  Loss: 2.7469437569379807    Accuracy: 87.96875\n",
      "iter 1001 ---  Loss: 3.2384214773774147    Accuracy: 89.375\n",
      "iter 1002 ---  Loss: 3.027811400592327    Accuracy: 88.59375\n",
      "iter 1003 ---  Loss: 3.2596669793128967    Accuracy: 86.09375\n",
      "iter 1004 ---  Loss: 3.677131876349449    Accuracy: 87.8125\n",
      "iter 1005 ---  Loss: 3.4155117198824883    Accuracy: 87.03125\n",
      "iter 1006 ---  Loss: 3.0543478429317474    Accuracy: 87.5\n",
      "iter 1007 ---  Loss: 2.9894135892391205    Accuracy: 86.09375\n",
      "iter 1008 ---  Loss: 2.944999910891056    Accuracy: 87.1875\n",
      "iter 1009 ---  Loss: 3.668512634932995    Accuracy: 86.875\n",
      "iter 1010 ---  Loss: 3.1610878109931946    Accuracy: 87.65625\n",
      "iter 1011 ---  Loss: 3.0735784769058228    Accuracy: 87.8125\n",
      "iter 1012 ---  Loss: 3.0547439381480217    Accuracy: 87.5\n",
      "iter 1013 ---  Loss: 3.657391808927059    Accuracy: 87.1875\n",
      "iter 1014 ---  Loss: 3.2486942186951637    Accuracy: 86.71875\n",
      "iter 1015 ---  Loss: 2.6301184743642807    Accuracy: 87.8125\n",
      "iter 1016 ---  Loss: 2.945034109055996    Accuracy: 87.03125\n",
      "iter 1017 ---  Loss: 2.882834568619728    Accuracy: 89.84375\n",
      "iter 1018 ---  Loss: 3.283290319144726    Accuracy: 86.875\n",
      "iter 1019 ---  Loss: 2.9967433735728264    Accuracy: 89.0625\n",
      "iter 1020 ---  Loss: 3.66202948987484    Accuracy: 85.46875\n",
      "iter 1021 ---  Loss: 2.9751566350460052    Accuracy: 86.5625\n",
      "iter 1022 ---  Loss: 3.8217316642403603    Accuracy: 85.0\n",
      "iter 1023 ---  Loss: 3.2277993112802505    Accuracy: 85.46875\n",
      "iter 1024 ---  Loss: 3.4173621982336044    Accuracy: 87.1875\n",
      "iter 1025 ---  Loss: 2.9242692440748215    Accuracy: 87.1875\n",
      "iter 1026 ---  Loss: 3.0139861926436424    Accuracy: 87.8125\n",
      "iter 1027 ---  Loss: 2.788506619632244    Accuracy: 87.03125\n",
      "iter 1028 ---  Loss: 2.5685180947184563    Accuracy: 90.3125\n",
      "iter 1029 ---  Loss: 2.980240948498249    Accuracy: 86.71875\n",
      "iter 1030 ---  Loss: 3.599107436835766    Accuracy: 86.25\n",
      "iter 1031 ---  Loss: 3.348103366792202    Accuracy: 85.625\n",
      "iter 1032 ---  Loss: 3.0941441282629967    Accuracy: 87.5\n",
      "iter 1033 ---  Loss: 2.782782129943371    Accuracy: 86.40625\n",
      "iter 1034 ---  Loss: 3.2050382494926453    Accuracy: 86.875\n",
      "iter 1035 ---  Loss: 3.572168253362179    Accuracy: 85.46875\n",
      "iter 1036 ---  Loss: 2.5232955142855644    Accuracy: 88.75\n",
      "iter 1037 ---  Loss: 3.0945296809077263    Accuracy: 88.125\n",
      "iter 1038 ---  Loss: 2.895009309053421    Accuracy: 87.8125\n",
      "iter 1039 ---  Loss: 2.865879148244858    Accuracy: 86.25\n",
      "iter 1040 ---  Loss: 2.8540757820010185    Accuracy: 87.34375\n",
      "iter 1041 ---  Loss: 2.551723524928093    Accuracy: 88.75\n",
      "iter 1042 ---  Loss: 3.038896858692169    Accuracy: 87.65625\n",
      "iter 1043 ---  Loss: 2.968454025685787    Accuracy: 88.125\n",
      "iter 1044 ---  Loss: 2.9530998691916466    Accuracy: 87.03125\n",
      "iter 1045 ---  Loss: 2.888276182115078    Accuracy: 86.25\n",
      "iter 1046 ---  Loss: 2.4942652210593224    Accuracy: 90.46875\n",
      "iter 1047 ---  Loss: 2.809038430452347    Accuracy: 88.28125\n",
      "iter 1048 ---  Loss: 3.348179206252098    Accuracy: 86.25\n",
      "iter 1049 ---  Loss: 3.2362969890236855    Accuracy: 87.1875\n",
      "iter 1050 ---  Loss: 3.6893442422151566    Accuracy: 85.0\n",
      "iter 1051 ---  Loss: 3.468995802104473    Accuracy: 87.03125\n",
      "iter 1052 ---  Loss: 3.186111658811569    Accuracy: 87.03125\n",
      "iter 1053 ---  Loss: 2.9513100683689117    Accuracy: 86.71875\n",
      "iter 1054 ---  Loss: 3.5772583559155464    Accuracy: 88.28125\n",
      "iter 1055 ---  Loss: 3.211178705096245    Accuracy: 89.84375\n",
      "iter 1056 ---  Loss: 2.9929489120841026    Accuracy: 88.75\n",
      "iter 1057 ---  Loss: 3.2201394140720367    Accuracy: 89.21875\n",
      "iter 1058 ---  Loss: 2.8586950823664665    Accuracy: 88.28125\n",
      "iter 1059 ---  Loss: 3.7889958322048187    Accuracy: 87.03125\n",
      "iter 1060 ---  Loss: 3.0165838673710823    Accuracy: 87.65625\n",
      "iter 1061 ---  Loss: 3.1483195796608925    Accuracy: 88.90625\n",
      "iter 1062 ---  Loss: 2.9125636145472527    Accuracy: 89.0625\n",
      "iter 1063 ---  Loss: 3.5196532011032104    Accuracy: 87.1875\n",
      "iter 1064 ---  Loss: 3.4496461004018784    Accuracy: 86.09375\n",
      "iter 1065 ---  Loss: 3.0994787737727165    Accuracy: 88.59375\n",
      "iter 1066 ---  Loss: 2.9360098987817764    Accuracy: 85.78125\n",
      "iter 1067 ---  Loss: 2.6386971175670624    Accuracy: 88.90625\n",
      "iter 1068 ---  Loss: 2.763954646885395    Accuracy: 87.8125\n",
      "iter 1069 ---  Loss: 3.5693289786577225    Accuracy: 87.03125\n",
      "iter 1070 ---  Loss: 3.5195204466581345    Accuracy: 87.1875\n",
      "iter 1071 ---  Loss: 2.8917097970843315    Accuracy: 89.53125\n",
      "iter 1072 ---  Loss: 2.8493985012173653    Accuracy: 87.96875\n",
      "iter 1073 ---  Loss: 2.8782967925071716    Accuracy: 88.90625\n",
      "iter 1074 ---  Loss: 2.7179969176650047    Accuracy: 87.5\n",
      "iter 1075 ---  Loss: 3.0334198102355003    Accuracy: 87.5\n",
      "iter 1076 ---  Loss: 3.3178073912858963    Accuracy: 88.125\n",
      "iter 1077 ---  Loss: 3.0935778990387917    Accuracy: 85.9375\n",
      "iter 1078 ---  Loss: 3.4837764650583267    Accuracy: 87.65625\n",
      "iter 1079 ---  Loss: 3.069969728589058    Accuracy: 89.84375\n",
      "iter 1080 ---  Loss: 2.7513795271515846    Accuracy: 87.5\n",
      "iter 1081 ---  Loss: 2.9657445773482323    Accuracy: 86.40625\n",
      "iter 1082 ---  Loss: 3.322057381272316    Accuracy: 90.625\n",
      "iter 1083 ---  Loss: 2.732214629650116    Accuracy: 90.9375\n",
      "iter 1084 ---  Loss: 2.6488239243626595    Accuracy: 87.1875\n",
      "iter 1085 ---  Loss: 2.8680029585957527    Accuracy: 87.96875\n",
      "iter 1086 ---  Loss: 3.036930449306965    Accuracy: 88.75\n",
      "iter 1087 ---  Loss: 3.187890760600567    Accuracy: 87.8125\n",
      "iter 1088 ---  Loss: 2.8134759590029716    Accuracy: 88.4375\n",
      "iter 1089 ---  Loss: 2.8260600566864014    Accuracy: 88.59375\n",
      "iter 1090 ---  Loss: 3.0649884715676308    Accuracy: 86.25\n",
      "iter 1091 ---  Loss: 3.668315105140209    Accuracy: 87.5\n",
      "iter 1092 ---  Loss: 3.400468848645687    Accuracy: 85.0\n",
      "iter 1093 ---  Loss: 4.013833791017532    Accuracy: 85.625\n",
      "iter 1094 ---  Loss: 3.3508912324905396    Accuracy: 86.5625\n",
      "iter 1095 ---  Loss: 3.37199180573225    Accuracy: 85.46875\n",
      "iter 1096 ---  Loss: 3.099126696586609    Accuracy: 86.875\n",
      "iter 1097 ---  Loss: 3.5515851229429245    Accuracy: 87.1875\n",
      "iter 1098 ---  Loss: 3.147563397884369    Accuracy: 86.25\n",
      "iter 1099 ---  Loss: 3.40974760055542    Accuracy: 87.1875\n",
      "iter 1100 ---  Loss: 3.722726993262768    Accuracy: 85.0\n",
      "iter 1101 ---  Loss: 2.710683546960354    Accuracy: 87.34375\n",
      "iter 1102 ---  Loss: 3.0231216698884964    Accuracy: 87.34375\n",
      "iter 1103 ---  Loss: 2.8614256009459496    Accuracy: 87.5\n",
      "iter 1104 ---  Loss: 3.1617357432842255    Accuracy: 85.625\n",
      "iter 1105 ---  Loss: 2.8556343615055084    Accuracy: 88.90625\n",
      "iter 1106 ---  Loss: 2.82289819419384    Accuracy: 88.28125\n",
      "iter 1107 ---  Loss: 3.0253210067749023    Accuracy: 87.65625\n",
      "iter 1108 ---  Loss: 3.6568735390901566    Accuracy: 85.3125\n",
      "iter 1109 ---  Loss: 2.9568213373422623    Accuracy: 87.8125\n",
      "iter 1110 ---  Loss: 2.801271989941597    Accuracy: 87.34375\n",
      "iter 1111 ---  Loss: 2.945397213101387    Accuracy: 88.125\n",
      "iter 1112 ---  Loss: 2.862116128206253    Accuracy: 89.21875\n",
      "iter 1113 ---  Loss: 2.978861279785633    Accuracy: 87.1875\n",
      "iter 1114 ---  Loss: 2.9898736774921417    Accuracy: 88.125\n",
      "iter 1115 ---  Loss: 3.2719025015830994    Accuracy: 86.875\n",
      "iter 1116 ---  Loss: 2.958126910030842    Accuracy: 88.75\n",
      "iter 1117 ---  Loss: 2.841986484825611    Accuracy: 87.34375\n",
      "iter 1118 ---  Loss: 3.081420287489891    Accuracy: 87.1875\n",
      "iter 1119 ---  Loss: 3.4856330156326294    Accuracy: 86.875\n",
      "iter 1120 ---  Loss: 2.8798257037997246    Accuracy: 87.5\n",
      "iter 1121 ---  Loss: 3.8515776991844177    Accuracy: 87.34375\n",
      "iter 1122 ---  Loss: 2.738021858036518    Accuracy: 88.4375\n",
      "iter 1123 ---  Loss: 3.0034750178456306    Accuracy: 86.71875\n",
      "iter 1124 ---  Loss: 2.9902137145400047    Accuracy: 87.96875\n",
      "iter 1125 ---  Loss: 3.21913393586874    Accuracy: 87.03125\n",
      "iter 1126 ---  Loss: 3.357126012444496    Accuracy: 86.09375\n",
      "iter 1127 ---  Loss: 2.7591941505670547    Accuracy: 86.09375\n",
      "iter 1128 ---  Loss: 3.316719137132168    Accuracy: 86.09375\n",
      "iter 1129 ---  Loss: 3.1162675842642784    Accuracy: 87.8125\n",
      "iter 1130 ---  Loss: 2.9911479502916336    Accuracy: 88.59375\n",
      "iter 1131 ---  Loss: 3.0502831861376762    Accuracy: 86.71875\n",
      "iter 1132 ---  Loss: 3.618297502398491    Accuracy: 86.71875\n",
      "iter 1133 ---  Loss: 3.0536623671650887    Accuracy: 88.28125\n",
      "iter 1134 ---  Loss: 3.209704115986824    Accuracy: 87.96875\n",
      "iter 1135 ---  Loss: 3.131249710917473    Accuracy: 88.125\n",
      "iter 1136 ---  Loss: 3.3353859037160873    Accuracy: 87.8125\n",
      "iter 1137 ---  Loss: 3.1885047256946564    Accuracy: 86.5625\n",
      "iter 1138 ---  Loss: 2.9664586633443832    Accuracy: 85.9375\n",
      "iter 1139 ---  Loss: 3.555151291191578    Accuracy: 85.9375\n",
      "iter 1140 ---  Loss: 3.7478993982076645    Accuracy: 87.1875\n",
      "iter 1141 ---  Loss: 2.8253980204463005    Accuracy: 88.4375\n",
      "iter 1142 ---  Loss: 2.7243859618902206    Accuracy: 88.4375\n",
      "iter 1143 ---  Loss: 3.4175828397274017    Accuracy: 87.1875\n",
      "iter 1144 ---  Loss: 3.1398902609944344    Accuracy: 87.5\n",
      "iter 1145 ---  Loss: 2.9280173927545547    Accuracy: 88.125\n",
      "iter 1146 ---  Loss: 2.687924385070801    Accuracy: 87.1875\n",
      "iter 1147 ---  Loss: 2.535954773426056    Accuracy: 87.34375\n",
      "iter 1148 ---  Loss: 2.8732927069067955    Accuracy: 89.21875\n",
      "iter 1149 ---  Loss: 2.6790096387267113    Accuracy: 88.28125\n",
      "iter 1150 ---  Loss: 2.5145436823368073    Accuracy: 88.59375\n",
      "iter 1151 ---  Loss: 2.8354874551296234    Accuracy: 89.53125\n",
      "iter 1152 ---  Loss: 2.702998176217079    Accuracy: 87.8125\n",
      "iter 1153 ---  Loss: 2.689857967197895    Accuracy: 89.84375\n",
      "iter 1154 ---  Loss: 3.1503521502017975    Accuracy: 86.40625\n",
      "iter 1155 ---  Loss: 3.60200797021389    Accuracy: 84.53125\n",
      "iter 1156 ---  Loss: 3.269191838800907    Accuracy: 87.8125\n",
      "iter 1157 ---  Loss: 3.133359596133232    Accuracy: 85.78125\n",
      "iter 1158 ---  Loss: 3.686855971813202    Accuracy: 87.1875\n",
      "iter 1159 ---  Loss: 2.869455650448799    Accuracy: 87.34375\n",
      "iter 1160 ---  Loss: 2.625383086502552    Accuracy: 88.59375\n",
      "iter 1161 ---  Loss: 3.7015213295817375    Accuracy: 84.53125\n",
      "iter 1162 ---  Loss: 2.7255974486470222    Accuracy: 88.125\n",
      "iter 1163 ---  Loss: 2.9276386201381683    Accuracy: 88.75\n",
      "iter 1164 ---  Loss: 2.6160456463694572    Accuracy: 89.375\n",
      "iter 1165 ---  Loss: 3.2188229337334633    Accuracy: 87.34375\n",
      "iter 1166 ---  Loss: 3.2728991582989693    Accuracy: 87.03125\n",
      "iter 1167 ---  Loss: 2.8904616460204124    Accuracy: 87.65625\n",
      "iter 1168 ---  Loss: 3.285106971859932    Accuracy: 86.875\n",
      "iter 1169 ---  Loss: 3.537767171859741    Accuracy: 86.5625\n",
      "iter 1170 ---  Loss: 3.3022445291280746    Accuracy: 86.09375\n",
      "iter 1171 ---  Loss: 2.9261609837412834    Accuracy: 86.25\n",
      "iter 1172 ---  Loss: 2.8468816727399826    Accuracy: 85.9375\n",
      "iter 1173 ---  Loss: 2.8305876553058624    Accuracy: 88.59375\n",
      "iter 1174 ---  Loss: 3.1105228289961815    Accuracy: 86.25\n",
      "iter 1175 ---  Loss: 3.970207564532757    Accuracy: 85.46875\n",
      "iter 1176 ---  Loss: 2.7127626314759254    Accuracy: 86.71875\n",
      "iter 1177 ---  Loss: 2.777971774339676    Accuracy: 88.59375\n",
      "iter 1178 ---  Loss: 2.5662900805473328    Accuracy: 87.34375\n",
      "iter 1179 ---  Loss: 2.691446006298065    Accuracy: 87.8125\n",
      "iter 1180 ---  Loss: 3.68840953707695    Accuracy: 85.625\n",
      "iter 1181 ---  Loss: 3.5666314512491226    Accuracy: 87.8125\n",
      "iter 1182 ---  Loss: 3.505516216158867    Accuracy: 87.34375\n",
      "iter 1183 ---  Loss: 2.937979146838188    Accuracy: 87.5\n",
      "iter 1184 ---  Loss: 2.6556886807084084    Accuracy: 88.59375\n",
      "iter 1185 ---  Loss: 2.9988729879260063    Accuracy: 85.9375\n",
      "iter 1186 ---  Loss: 3.12463691085577    Accuracy: 88.28125\n",
      "iter 1187 ---  Loss: 2.8920360058546066    Accuracy: 88.125\n",
      "iter 1188 ---  Loss: 3.521557867527008    Accuracy: 86.5625\n",
      "iter 1189 ---  Loss: 2.9998043552041054    Accuracy: 87.96875\n",
      "iter 1190 ---  Loss: 2.823310323059559    Accuracy: 87.65625\n",
      "iter 1191 ---  Loss: 3.0888888835906982    Accuracy: 86.875\n",
      "iter 1192 ---  Loss: 2.962960846722126    Accuracy: 86.875\n",
      "iter 1193 ---  Loss: 3.14236381649971    Accuracy: 86.09375\n",
      "iter 1194 ---  Loss: 3.3128573819994926    Accuracy: 89.375\n",
      "iter 1195 ---  Loss: 2.948869653046131    Accuracy: 87.96875\n",
      "iter 1196 ---  Loss: 3.017340935766697    Accuracy: 87.8125\n",
      "iter 1197 ---  Loss: 2.9411401376128197    Accuracy: 87.03125\n",
      "iter 1198 ---  Loss: 3.1451551616191864    Accuracy: 87.34375\n",
      "iter 1199 ---  Loss: 2.9476374611258507    Accuracy: 88.59375\n",
      "iter 1200 ---  Loss: 2.59245303273201    Accuracy: 86.875\n",
      "iter 1201 ---  Loss: 3.0871290639042854    Accuracy: 86.25\n",
      "iter 1202 ---  Loss: 2.8073635697364807    Accuracy: 87.65625\n",
      "iter 1203 ---  Loss: 2.6247519850730896    Accuracy: 86.875\n",
      "iter 1204 ---  Loss: 3.7186389192938805    Accuracy: 86.71875\n",
      "iter 1205 ---  Loss: 3.7518193796277046    Accuracy: 87.34375\n",
      "iter 1206 ---  Loss: 2.5494905561208725    Accuracy: 89.21875\n",
      "iter 1207 ---  Loss: 2.8005326688289642    Accuracy: 87.65625\n",
      "iter 1208 ---  Loss: 3.0291301384568214    Accuracy: 88.125\n",
      "iter 1209 ---  Loss: 3.4576925560832024    Accuracy: 87.1875\n",
      "iter 1210 ---  Loss: 3.8596057817339897    Accuracy: 86.25\n",
      "iter 1211 ---  Loss: 3.250767022371292    Accuracy: 87.34375\n",
      "iter 1212 ---  Loss: 3.220220111310482    Accuracy: 88.75\n",
      "iter 1213 ---  Loss: 3.3903348445892334    Accuracy: 87.34375\n",
      "iter 1214 ---  Loss: 3.353818893432617    Accuracy: 87.8125\n",
      "iter 1215 ---  Loss: 3.1229076832532883    Accuracy: 85.625\n",
      "iter 1216 ---  Loss: 3.2989987283945084    Accuracy: 86.875\n",
      "iter 1217 ---  Loss: 2.939230300486088    Accuracy: 87.96875\n",
      "iter 1218 ---  Loss: 2.579766161739826    Accuracy: 88.90625\n",
      "iter 1219 ---  Loss: 2.8470667228102684    Accuracy: 87.5\n",
      "iter 1220 ---  Loss: 3.8797984048724174    Accuracy: 85.625\n",
      "iter 1221 ---  Loss: 3.3344853669404984    Accuracy: 85.78125\n",
      "iter 1222 ---  Loss: 3.46303478628397    Accuracy: 87.96875\n",
      "iter 1223 ---  Loss: 2.971981391310692    Accuracy: 87.34375\n",
      "iter 1224 ---  Loss: 2.9432819336652756    Accuracy: 86.40625\n",
      "iter 1225 ---  Loss: 3.1613182947039604    Accuracy: 86.875\n",
      "iter 1226 ---  Loss: 3.293949745595455    Accuracy: 87.8125\n",
      "iter 1227 ---  Loss: 3.3636312186717987    Accuracy: 89.53125\n",
      "iter 1228 ---  Loss: 3.158292695879936    Accuracy: 87.8125\n",
      "iter 1229 ---  Loss: 3.0748025998473167    Accuracy: 86.875\n",
      "iter 1230 ---  Loss: 3.019302524626255    Accuracy: 84.6875\n",
      "iter 1231 ---  Loss: 3.101997785270214    Accuracy: 88.28125\n",
      "iter 1232 ---  Loss: 2.756134159862995    Accuracy: 87.96875\n",
      "iter 1233 ---  Loss: 3.176223546266556    Accuracy: 86.71875\n",
      "iter 1234 ---  Loss: 4.442495197057724    Accuracy: 84.84375\n",
      "iter 1235 ---  Loss: 3.0471289679408073    Accuracy: 88.4375\n",
      "iter 1236 ---  Loss: 3.2774892672896385    Accuracy: 85.625\n",
      "iter 1237 ---  Loss: 2.632638320326805    Accuracy: 88.90625\n",
      "iter 1238 ---  Loss: 2.72162002325058    Accuracy: 87.65625\n",
      "iter 1239 ---  Loss: 2.7296081855893135    Accuracy: 87.5\n",
      "iter 1240 ---  Loss: 3.675544686615467    Accuracy: 86.40625\n",
      "iter 1241 ---  Loss: 2.8687138333916664    Accuracy: 86.875\n",
      "iter 1242 ---  Loss: 3.166162461042404    Accuracy: 85.78125\n",
      "iter 1243 ---  Loss: 2.8338444009423256    Accuracy: 87.1875\n",
      "iter 1244 ---  Loss: 3.6207234635949135    Accuracy: 87.34375\n",
      "iter 1245 ---  Loss: 2.995143808424473    Accuracy: 86.5625\n",
      "iter 1246 ---  Loss: 3.1862032786011696    Accuracy: 88.125\n",
      "iter 1247 ---  Loss: 2.890313968062401    Accuracy: 89.53125\n",
      "iter 1248 ---  Loss: 2.77021511644125    Accuracy: 87.8125\n",
      "iter 1249 ---  Loss: 2.708082064986229    Accuracy: 85.78125\n",
      "iter 1250 ---  Loss: 2.592602603137493    Accuracy: 87.65625\n",
      "iter 1251 ---  Loss: 2.8679773584008217    Accuracy: 88.28125\n",
      "iter 1252 ---  Loss: 3.6738294288516045    Accuracy: 86.40625\n",
      "iter 1253 ---  Loss: 3.1965625658631325    Accuracy: 87.96875\n",
      "iter 1254 ---  Loss: 2.8590231090784073    Accuracy: 88.59375\n",
      "iter 1255 ---  Loss: 2.8819815516471863    Accuracy: 88.75\n",
      "iter 1256 ---  Loss: 2.9588609784841537    Accuracy: 89.0625\n",
      "iter 1257 ---  Loss: 3.1952099576592445    Accuracy: 87.96875\n",
      "iter 1258 ---  Loss: 3.079009525477886    Accuracy: 88.4375\n",
      "iter 1259 ---  Loss: 3.382304459810257    Accuracy: 87.65625\n",
      "iter 1260 ---  Loss: 3.207162484526634    Accuracy: 87.96875\n",
      "iter 1261 ---  Loss: 3.394988529384136    Accuracy: 85.3125\n",
      "iter 1262 ---  Loss: 2.7099049389362335    Accuracy: 88.59375\n",
      "iter 1263 ---  Loss: 2.967768833041191    Accuracy: 89.0625\n",
      "iter 1264 ---  Loss: 2.8728754073381424    Accuracy: 87.34375\n",
      "iter 1265 ---  Loss: 3.3264050111174583    Accuracy: 86.09375\n",
      "iter 1266 ---  Loss: 3.427132859826088    Accuracy: 85.9375\n",
      "iter 1267 ---  Loss: 2.9306238144636154    Accuracy: 86.875\n",
      "iter 1268 ---  Loss: 2.810881994664669    Accuracy: 86.40625\n",
      "iter 1269 ---  Loss: 3.0723819881677628    Accuracy: 87.65625\n",
      "iter 1270 ---  Loss: 2.945382222533226    Accuracy: 88.75\n",
      "iter 1271 ---  Loss: 3.4506801068782806    Accuracy: 87.03125\n",
      "iter 1272 ---  Loss: 2.850822389125824    Accuracy: 87.65625\n",
      "iter 1273 ---  Loss: 3.3334858119487762    Accuracy: 85.46875\n",
      "iter 1274 ---  Loss: 2.8021534234285355    Accuracy: 87.34375\n",
      "iter 1275 ---  Loss: 2.61111069470644    Accuracy: 87.96875\n",
      "iter 1276 ---  Loss: 2.7030640989542007    Accuracy: 86.5625\n",
      "iter 1277 ---  Loss: 3.217404119670391    Accuracy: 86.71875\n",
      "iter 1278 ---  Loss: 3.417459152638912    Accuracy: 87.5\n",
      "iter 1279 ---  Loss: 3.226502887904644    Accuracy: 86.5625\n",
      "iter 1280 ---  Loss: 3.6114948391914368    Accuracy: 86.5625\n",
      "iter 1281 ---  Loss: 3.292149230837822    Accuracy: 88.125\n",
      "iter 1282 ---  Loss: 2.7534156292676926    Accuracy: 88.4375\n",
      "iter 1283 ---  Loss: 3.13857888430357    Accuracy: 87.1875\n",
      "iter 1284 ---  Loss: 3.0838572159409523    Accuracy: 87.8125\n",
      "iter 1285 ---  Loss: 3.306893676519394    Accuracy: 86.875\n",
      "iter 1286 ---  Loss: 3.066173642873764    Accuracy: 87.65625\n",
      "iter 1287 ---  Loss: 3.285207986831665    Accuracy: 88.28125\n",
      "iter 1288 ---  Loss: 3.0873167514801025    Accuracy: 88.4375\n",
      "iter 1289 ---  Loss: 2.6500478461384773    Accuracy: 89.21875\n",
      "iter 1290 ---  Loss: 2.9823122546076775    Accuracy: 88.28125\n",
      "iter 1291 ---  Loss: 2.951815165579319    Accuracy: 87.65625\n",
      "iter 1292 ---  Loss: 3.137411743402481    Accuracy: 87.8125\n",
      "iter 1293 ---  Loss: 2.9531697407364845    Accuracy: 87.34375\n",
      "iter 1294 ---  Loss: 2.7988545447587967    Accuracy: 88.4375\n",
      "iter 1295 ---  Loss: 3.175224579870701    Accuracy: 87.5\n",
      "iter 1296 ---  Loss: 2.9970389381051064    Accuracy: 85.46875\n",
      "iter 1297 ---  Loss: 2.5796413719654083    Accuracy: 87.34375\n",
      "iter 1298 ---  Loss: 3.116175465285778    Accuracy: 87.03125\n",
      "iter 1299 ---  Loss: 2.543100394308567    Accuracy: 88.125\n",
      "iter 1300 ---  Loss: 2.8177531138062477    Accuracy: 88.4375\n",
      "iter 1301 ---  Loss: 3.469605937600136    Accuracy: 87.8125\n",
      "iter 1302 ---  Loss: 2.6173636317253113    Accuracy: 88.90625\n",
      "iter 1303 ---  Loss: 3.073116034269333    Accuracy: 87.96875\n",
      "iter 1304 ---  Loss: 3.602073810994625    Accuracy: 87.65625\n",
      "iter 1305 ---  Loss: 3.1690583676099777    Accuracy: 87.34375\n",
      "iter 1306 ---  Loss: 2.8860338032245636    Accuracy: 86.09375\n",
      "iter 1307 ---  Loss: 3.1928714886307716    Accuracy: 86.25\n",
      "iter 1308 ---  Loss: 2.698609210550785    Accuracy: 86.40625\n",
      "iter 1309 ---  Loss: 3.0134166479110718    Accuracy: 86.40625\n",
      "iter 1310 ---  Loss: 3.2338757365942    Accuracy: 87.8125\n",
      "iter 1311 ---  Loss: 3.613629773259163    Accuracy: 87.1875\n",
      "iter 1312 ---  Loss: 3.357120633125305    Accuracy: 86.5625\n",
      "iter 1313 ---  Loss: 3.1526813581585884    Accuracy: 86.71875\n",
      "iter 1314 ---  Loss: 3.071446366608143    Accuracy: 85.625\n",
      "iter 1315 ---  Loss: 3.59089881926775    Accuracy: 86.5625\n",
      "iter 1316 ---  Loss: 3.8103212043642998    Accuracy: 84.53125\n",
      "iter 1317 ---  Loss: 2.911971352994442    Accuracy: 85.9375\n",
      "iter 1318 ---  Loss: 3.368379458785057    Accuracy: 88.28125\n",
      "iter 1319 ---  Loss: 3.2054363414645195    Accuracy: 85.0\n",
      "iter 1320 ---  Loss: 3.542890876531601    Accuracy: 86.25\n",
      "iter 1321 ---  Loss: 2.613341338932514    Accuracy: 87.5\n",
      "iter 1322 ---  Loss: 3.6794576048851013    Accuracy: 87.5\n",
      "iter 1323 ---  Loss: 3.3798064440488815    Accuracy: 87.5\n",
      "iter 1324 ---  Loss: 2.8939814269542694    Accuracy: 86.875\n",
      "iter 1325 ---  Loss: 4.046286933124065    Accuracy: 85.15625\n",
      "iter 1326 ---  Loss: 3.223908692598343    Accuracy: 87.1875\n",
      "iter 1327 ---  Loss: 3.5495071932673454    Accuracy: 83.75\n",
      "iter 1328 ---  Loss: 2.592314913868904    Accuracy: 87.5\n",
      "iter 1329 ---  Loss: 3.608727902173996    Accuracy: 85.78125\n",
      "iter 1330 ---  Loss: 3.324977785348892    Accuracy: 86.5625\n",
      "iter 1331 ---  Loss: 2.9346113428473473    Accuracy: 87.5\n",
      "iter 1332 ---  Loss: 2.8671190813183784    Accuracy: 87.34375\n",
      "iter 1333 ---  Loss: 3.072989284992218    Accuracy: 86.71875\n",
      "iter 1334 ---  Loss: 3.087560825049877    Accuracy: 87.8125\n",
      "iter 1335 ---  Loss: 3.5586793646216393    Accuracy: 87.34375\n",
      "iter 1336 ---  Loss: 3.2027815878391266    Accuracy: 85.3125\n",
      "iter 1337 ---  Loss: 2.8881780952215195    Accuracy: 87.5\n",
      "iter 1338 ---  Loss: 2.8590792790055275    Accuracy: 88.4375\n",
      "iter 1339 ---  Loss: 3.2620128616690636    Accuracy: 86.71875\n",
      "iter 1340 ---  Loss: 3.369885765016079    Accuracy: 85.9375\n",
      "iter 1341 ---  Loss: 3.1372851878404617    Accuracy: 86.5625\n",
      "iter 1342 ---  Loss: 3.003157325088978    Accuracy: 86.09375\n",
      "iter 1343 ---  Loss: 2.8120833337306976    Accuracy: 88.125\n",
      "iter 1344 ---  Loss: 3.0168135687708855    Accuracy: 87.5\n",
      "iter 1345 ---  Loss: 3.5144192054867744    Accuracy: 86.5625\n",
      "iter 1346 ---  Loss: 3.3700618371367455    Accuracy: 85.0\n",
      "iter 1347 ---  Loss: 3.5233732536435127    Accuracy: 86.40625\n",
      "iter 1348 ---  Loss: 2.788753405213356    Accuracy: 88.125\n",
      "iter 1349 ---  Loss: 2.878845199942589    Accuracy: 86.40625\n",
      "iter 1350 ---  Loss: 3.311572916805744    Accuracy: 87.34375\n",
      "iter 1351 ---  Loss: 3.2367972880601883    Accuracy: 88.4375\n",
      "iter 1352 ---  Loss: 2.756532162427902    Accuracy: 89.6875\n",
      "iter 1353 ---  Loss: 2.6730675101280212    Accuracy: 88.90625\n",
      "iter 1354 ---  Loss: 3.822486773133278    Accuracy: 85.9375\n",
      "iter 1355 ---  Loss: 3.5697054639458656    Accuracy: 87.65625\n",
      "iter 1356 ---  Loss: 3.371843710541725    Accuracy: 87.5\n",
      "iter 1357 ---  Loss: 3.0673692002892494    Accuracy: 86.5625\n",
      "iter 1358 ---  Loss: 2.97974394261837    Accuracy: 87.1875\n",
      "iter 1359 ---  Loss: 2.9019992649555206    Accuracy: 87.96875\n",
      "iter 1360 ---  Loss: 2.8879252523183823    Accuracy: 87.34375\n",
      "iter 1361 ---  Loss: 2.855787493288517    Accuracy: 86.875\n",
      "iter 1362 ---  Loss: 3.033544734120369    Accuracy: 88.4375\n",
      "iter 1363 ---  Loss: 3.0747185945510864    Accuracy: 87.5\n",
      "iter 1364 ---  Loss: 3.6341289654374123    Accuracy: 87.5\n",
      "iter 1365 ---  Loss: 3.2869896218180656    Accuracy: 85.3125\n",
      "iter 1366 ---  Loss: 3.1662414595484734    Accuracy: 85.78125\n",
      "iter 1367 ---  Loss: 3.0989329665899277    Accuracy: 86.875\n",
      "iter 1368 ---  Loss: 3.178778737783432    Accuracy: 86.71875\n",
      "iter 1369 ---  Loss: 2.572562448680401    Accuracy: 89.21875\n",
      "iter 1370 ---  Loss: 2.942854665219784    Accuracy: 87.34375\n",
      "iter 1371 ---  Loss: 3.1585920453071594    Accuracy: 87.34375\n",
      "iter 1372 ---  Loss: 2.7271416187286377    Accuracy: 87.34375\n",
      "iter 1373 ---  Loss: 3.5160052701830864    Accuracy: 86.40625\n",
      "iter 1374 ---  Loss: 3.223366968333721    Accuracy: 86.40625\n",
      "iter 1375 ---  Loss: 2.80817998200655    Accuracy: 86.25\n",
      "iter 1376 ---  Loss: 2.9620392844080925    Accuracy: 87.96875\n",
      "iter 1377 ---  Loss: 3.346913881599903    Accuracy: 87.34375\n",
      "iter 1378 ---  Loss: 3.4066976606845856    Accuracy: 85.46875\n",
      "iter 1379 ---  Loss: 2.7161179035902023    Accuracy: 87.34375\n",
      "iter 1380 ---  Loss: 3.2495231702923775    Accuracy: 87.96875\n",
      "iter 1381 ---  Loss: 3.0451184660196304    Accuracy: 87.34375\n",
      "iter 1382 ---  Loss: 3.173395097255707    Accuracy: 87.03125\n",
      "iter 1383 ---  Loss: 3.2977806627750397    Accuracy: 87.34375\n",
      "iter 1384 ---  Loss: 3.0071170330047607    Accuracy: 89.21875\n",
      "iter 1385 ---  Loss: 2.9090136364102364    Accuracy: 87.03125\n",
      "iter 1386 ---  Loss: 3.0294346287846565    Accuracy: 86.5625\n",
      "iter 1387 ---  Loss: 3.178753450512886    Accuracy: 87.03125\n",
      "iter 1388 ---  Loss: 3.501215636730194    Accuracy: 85.15625\n",
      "iter 1389 ---  Loss: 2.9898149594664574    Accuracy: 85.625\n",
      "iter 1390 ---  Loss: 2.3273067846894264    Accuracy: 88.28125\n",
      "iter 1391 ---  Loss: 3.0078015252947807    Accuracy: 88.4375\n",
      "iter 1392 ---  Loss: 3.43924231082201    Accuracy: 86.71875\n",
      "iter 1393 ---  Loss: 2.8146099224686623    Accuracy: 85.9375\n",
      "iter 1394 ---  Loss: 2.914406307041645    Accuracy: 87.34375\n",
      "iter 1395 ---  Loss: 3.3008207455277443    Accuracy: 86.5625\n",
      "iter 1396 ---  Loss: 2.477209396660328    Accuracy: 89.0625\n",
      "iter 1397 ---  Loss: 3.5432438626885414    Accuracy: 87.34375\n",
      "iter 1398 ---  Loss: 2.743576303124428    Accuracy: 87.5\n",
      "iter 1399 ---  Loss: 2.706915147602558    Accuracy: 89.0625\n",
      "iter 1400 ---  Loss: 3.214114062488079    Accuracy: 86.71875\n",
      "iter 1401 ---  Loss: 2.8726104721426964    Accuracy: 86.71875\n",
      "iter 1402 ---  Loss: 2.931638203561306    Accuracy: 88.90625\n",
      "iter 1403 ---  Loss: 3.3645859360694885    Accuracy: 88.59375\n",
      "iter 1404 ---  Loss: 2.5576807633042336    Accuracy: 88.125\n",
      "iter 1405 ---  Loss: 2.9379405230283737    Accuracy: 88.59375\n",
      "iter 1406 ---  Loss: 3.0700489431619644    Accuracy: 85.46875\n",
      "iter 1407 ---  Loss: 3.2428744211792946    Accuracy: 86.09375\n",
      "iter 1408 ---  Loss: 2.935396194458008    Accuracy: 87.34375\n",
      "iter 1409 ---  Loss: 3.288510926067829    Accuracy: 88.125\n",
      "iter 1410 ---  Loss: 2.5761701986193657    Accuracy: 87.1875\n",
      "iter 1411 ---  Loss: 3.0735170170664787    Accuracy: 89.6875\n",
      "iter 1412 ---  Loss: 3.189480274915695    Accuracy: 87.1875\n",
      "iter 1413 ---  Loss: 2.9462599083781242    Accuracy: 87.96875\n",
      "iter 1414 ---  Loss: 2.996895097196102    Accuracy: 87.34375\n",
      "iter 1415 ---  Loss: 2.8349545374512672    Accuracy: 87.65625\n",
      "iter 1416 ---  Loss: 2.7864110991358757    Accuracy: 88.125\n",
      "iter 1417 ---  Loss: 3.0539416000247    Accuracy: 87.65625\n",
      "iter 1418 ---  Loss: 3.664688140153885    Accuracy: 86.71875\n",
      "iter 1419 ---  Loss: 2.8382426276803017    Accuracy: 88.28125\n",
      "iter 1420 ---  Loss: 2.936147630214691    Accuracy: 88.4375\n",
      "iter 1421 ---  Loss: 3.3088370636105537    Accuracy: 87.8125\n",
      "iter 1422 ---  Loss: 2.7345804572105408    Accuracy: 87.96875\n",
      "iter 1423 ---  Loss: 3.7332178130745888    Accuracy: 85.46875\n",
      "iter 1424 ---  Loss: 2.8162451907992363    Accuracy: 89.0625\n",
      "iter 1425 ---  Loss: 3.18001402169466    Accuracy: 87.65625\n",
      "iter 1426 ---  Loss: 3.046380393207073    Accuracy: 87.03125\n",
      "iter 1427 ---  Loss: 2.7209977507591248    Accuracy: 86.71875\n",
      "iter 1428 ---  Loss: 3.1377415135502815    Accuracy: 87.1875\n",
      "iter 1429 ---  Loss: 3.126195937395096    Accuracy: 89.375\n",
      "iter 1430 ---  Loss: 2.7074358835816383    Accuracy: 88.59375\n",
      "iter 1431 ---  Loss: 3.374333880841732    Accuracy: 86.25\n",
      "iter 1432 ---  Loss: 3.348191112279892    Accuracy: 85.78125\n",
      "iter 1433 ---  Loss: 3.240520268678665    Accuracy: 88.90625\n",
      "iter 1434 ---  Loss: 3.1135857850313187    Accuracy: 87.8125\n",
      "iter 1435 ---  Loss: 3.220107778906822    Accuracy: 88.28125\n",
      "iter 1436 ---  Loss: 2.986765906214714    Accuracy: 87.96875\n",
      "iter 1437 ---  Loss: 3.0677190646529198    Accuracy: 85.9375\n",
      "iter 1438 ---  Loss: 2.852905087172985    Accuracy: 88.28125\n",
      "iter 1439 ---  Loss: 2.5631297901272774    Accuracy: 88.75\n",
      "iter 1440 ---  Loss: 3.3052789866924286    Accuracy: 86.875\n",
      "iter 1441 ---  Loss: 3.0391731411218643    Accuracy: 88.75\n",
      "iter 1442 ---  Loss: 2.67456366866827    Accuracy: 88.90625\n",
      "iter 1443 ---  Loss: 2.632198505103588    Accuracy: 86.5625\n",
      "iter 1444 ---  Loss: 3.2446659430861473    Accuracy: 87.1875\n",
      "iter 1445 ---  Loss: 2.996287666261196    Accuracy: 88.125\n",
      "iter 1446 ---  Loss: 2.7082395032048225    Accuracy: 88.125\n",
      "iter 1447 ---  Loss: 3.042656570672989    Accuracy: 87.1875\n",
      "iter 1448 ---  Loss: 2.679512955248356    Accuracy: 86.875\n",
      "iter 1449 ---  Loss: 2.9924100637435913    Accuracy: 86.09375\n",
      "iter 1450 ---  Loss: 3.366752438247204    Accuracy: 86.875\n",
      "iter 1451 ---  Loss: 3.834510199725628    Accuracy: 85.3125\n",
      "iter 1452 ---  Loss: 2.8475334122776985    Accuracy: 86.25\n",
      "iter 1453 ---  Loss: 3.5306688025593758    Accuracy: 88.75\n",
      "iter 1454 ---  Loss: 3.122986003756523    Accuracy: 87.8125\n",
      "iter 1455 ---  Loss: 3.6159682124853134    Accuracy: 87.34375\n",
      "iter 1456 ---  Loss: 3.7362029552459717    Accuracy: 88.4375\n",
      "iter 1457 ---  Loss: 3.134619429707527    Accuracy: 87.1875\n",
      "iter 1458 ---  Loss: 3.104268841445446    Accuracy: 88.75\n",
      "iter 1459 ---  Loss: 3.3383155539631844    Accuracy: 85.625\n",
      "iter 1460 ---  Loss: 2.5679755434393883    Accuracy: 89.6875\n",
      "iter 1461 ---  Loss: 3.3558604940772057    Accuracy: 86.71875\n",
      "iter 1462 ---  Loss: 2.9051351472735405    Accuracy: 88.125\n",
      "iter 1463 ---  Loss: 2.7908312901854515    Accuracy: 87.65625\n",
      "iter 1464 ---  Loss: 3.15870713442564    Accuracy: 87.8125\n",
      "iter 1465 ---  Loss: 3.431252546608448    Accuracy: 85.46875\n",
      "iter 1466 ---  Loss: 3.1333537101745605    Accuracy: 86.09375\n",
      "iter 1467 ---  Loss: 3.4957492649555206    Accuracy: 86.875\n",
      "iter 1468 ---  Loss: 3.656395807862282    Accuracy: 85.46875\n",
      "iter 1469 ---  Loss: 2.868121735751629    Accuracy: 87.8125\n",
      "iter 1470 ---  Loss: 3.054983526468277    Accuracy: 88.75\n",
      "iter 1471 ---  Loss: 3.4986549764871597    Accuracy: 87.1875\n",
      "iter 1472 ---  Loss: 2.8751255497336388    Accuracy: 88.28125\n",
      "iter 1473 ---  Loss: 3.2088818550109863    Accuracy: 86.71875\n",
      "iter 1474 ---  Loss: 3.101555220782757    Accuracy: 86.875\n",
      "iter 1475 ---  Loss: 2.8403998762369156    Accuracy: 86.71875\n",
      "iter 1476 ---  Loss: 2.517774775624275    Accuracy: 89.0625\n",
      "iter 1477 ---  Loss: 2.8845901414752007    Accuracy: 87.96875\n",
      "iter 1478 ---  Loss: 2.765084356069565    Accuracy: 88.75\n",
      "iter 1479 ---  Loss: 3.396740771830082    Accuracy: 87.1875\n",
      "iter 1480 ---  Loss: 3.1801552772521973    Accuracy: 88.28125\n",
      "iter 1481 ---  Loss: 3.181644804775715    Accuracy: 88.4375\n",
      "iter 1482 ---  Loss: 2.8267772793769836    Accuracy: 87.5\n",
      "iter 1483 ---  Loss: 2.7021151036024094    Accuracy: 87.34375\n",
      "iter 1484 ---  Loss: 3.534102573990822    Accuracy: 86.25\n",
      "iter 1485 ---  Loss: 3.1845709532499313    Accuracy: 87.5\n",
      "iter 1486 ---  Loss: 3.4161789789795876    Accuracy: 86.5625\n",
      "iter 1487 ---  Loss: 2.6869685873389244    Accuracy: 88.90625\n",
      "iter 1488 ---  Loss: 2.9635036513209343    Accuracy: 88.125\n",
      "iter 1489 ---  Loss: 2.791386365890503    Accuracy: 87.03125\n",
      "iter 1490 ---  Loss: 3.322732701897621    Accuracy: 87.34375\n",
      "iter 1491 ---  Loss: 3.01620315015316    Accuracy: 86.40625\n",
      "iter 1492 ---  Loss: 3.1728114634752274    Accuracy: 85.46875\n",
      "iter 1493 ---  Loss: 3.1341904625296593    Accuracy: 85.625\n",
      "iter 1494 ---  Loss: 2.7559482231736183    Accuracy: 87.65625\n",
      "iter 1495 ---  Loss: 2.8462725803256035    Accuracy: 87.96875\n",
      "iter 1496 ---  Loss: 2.6843037381768227    Accuracy: 87.65625\n",
      "iter 1497 ---  Loss: 3.0473506078124046    Accuracy: 87.5\n",
      "iter 1498 ---  Loss: 3.1400487422943115    Accuracy: 86.40625\n",
      "iter 1499 ---  Loss: 2.600907564163208    Accuracy: 86.875\n",
      "iter 1500 ---  Loss: 3.079178787767887    Accuracy: 87.03125\n",
      "iter 1501 ---  Loss: 3.089779242873192    Accuracy: 88.125\n",
      "iter 1502 ---  Loss: 2.4877402558922768    Accuracy: 89.84375\n",
      "iter 1503 ---  Loss: 3.6432426050305367    Accuracy: 86.71875\n",
      "iter 1504 ---  Loss: 3.5078864097595215    Accuracy: 86.25\n",
      "iter 1505 ---  Loss: 3.777303822338581    Accuracy: 86.5625\n",
      "iter 1506 ---  Loss: 3.1607201918959618    Accuracy: 86.25\n",
      "iter 1507 ---  Loss: 3.027783066034317    Accuracy: 87.8125\n",
      "iter 1508 ---  Loss: 2.680162228643894    Accuracy: 87.34375\n",
      "iter 1509 ---  Loss: 2.86740942299366    Accuracy: 85.9375\n",
      "iter 1510 ---  Loss: 2.9599044024944305    Accuracy: 87.65625\n",
      "iter 1511 ---  Loss: 2.78303025662899    Accuracy: 86.25\n",
      "iter 1512 ---  Loss: 2.747371941804886    Accuracy: 86.71875\n",
      "iter 1513 ---  Loss: 3.131612792611122    Accuracy: 88.75\n",
      "iter 1514 ---  Loss: 3.3440432772040367    Accuracy: 87.5\n",
      "iter 1515 ---  Loss: 3.186685137450695    Accuracy: 88.125\n",
      "iter 1516 ---  Loss: 3.0934452190995216    Accuracy: 89.53125\n",
      "iter 1517 ---  Loss: 2.9203628972172737    Accuracy: 87.96875\n",
      "iter 1518 ---  Loss: 2.686728961765766    Accuracy: 89.21875\n",
      "iter 1519 ---  Loss: 3.2286736220121384    Accuracy: 86.40625\n",
      "iter 1520 ---  Loss: 2.844021387398243    Accuracy: 86.875\n",
      "iter 1521 ---  Loss: 3.3265442550182343    Accuracy: 85.9375\n",
      "iter 1522 ---  Loss: 3.196645863354206    Accuracy: 87.8125\n",
      "iter 1523 ---  Loss: 3.471606157720089    Accuracy: 87.03125\n",
      "iter 1524 ---  Loss: 3.3441773653030396    Accuracy: 89.53125\n",
      "iter 1525 ---  Loss: 2.8289597034454346    Accuracy: 88.28125\n",
      "iter 1526 ---  Loss: 3.253321774303913    Accuracy: 88.4375\n",
      "iter 1527 ---  Loss: 2.8662730753421783    Accuracy: 88.125\n",
      "iter 1528 ---  Loss: 2.9376531690359116    Accuracy: 88.59375\n",
      "iter 1529 ---  Loss: 3.3788172975182533    Accuracy: 87.8125\n",
      "iter 1530 ---  Loss: 2.60640449821949    Accuracy: 88.125\n",
      "iter 1531 ---  Loss: 2.925079934298992    Accuracy: 85.9375\n",
      "iter 1532 ---  Loss: 2.7185764387249947    Accuracy: 88.59375\n",
      "iter 1533 ---  Loss: 3.142470322549343    Accuracy: 86.5625\n",
      "iter 1534 ---  Loss: 2.8990813866257668    Accuracy: 88.59375\n",
      "iter 1535 ---  Loss: 2.8540968522429466    Accuracy: 88.125\n",
      "iter 1536 ---  Loss: 3.035628356039524    Accuracy: 87.8125\n",
      "iter 1537 ---  Loss: 3.925844706594944    Accuracy: 84.375\n",
      "iter 1538 ---  Loss: 3.1643399074673653    Accuracy: 87.8125\n",
      "iter 1539 ---  Loss: 2.988439053297043    Accuracy: 86.5625\n",
      "iter 1540 ---  Loss: 2.4602943509817123    Accuracy: 87.5\n",
      "iter 1541 ---  Loss: 2.814331568777561    Accuracy: 88.4375\n",
      "iter 1542 ---  Loss: 3.5844129472970963    Accuracy: 87.65625\n",
      "iter 1543 ---  Loss: 2.550722435116768    Accuracy: 87.96875\n",
      "iter 1544 ---  Loss: 3.0183436647057533    Accuracy: 87.65625\n",
      "iter 1545 ---  Loss: 2.6635819002985954    Accuracy: 87.65625\n",
      "iter 1546 ---  Loss: 2.920136332511902    Accuracy: 88.28125\n",
      "iter 1547 ---  Loss: 3.356310874223709    Accuracy: 86.71875\n",
      "iter 1548 ---  Loss: 3.6466042399406433    Accuracy: 83.28125\n",
      "iter 1549 ---  Loss: 2.606659770011902    Accuracy: 88.28125\n",
      "iter 1550 ---  Loss: 3.033777594566345    Accuracy: 87.65625\n",
      "iter 1551 ---  Loss: 2.834223546087742    Accuracy: 88.125\n",
      "iter 1552 ---  Loss: 3.475136771798134    Accuracy: 86.40625\n",
      "iter 1553 ---  Loss: 3.5138218626379967    Accuracy: 87.8125\n",
      "iter 1554 ---  Loss: 3.279907427728176    Accuracy: 88.4375\n",
      "iter 1555 ---  Loss: 2.7754462733864784    Accuracy: 87.34375\n",
      "iter 1556 ---  Loss: 3.5760315731167793    Accuracy: 86.09375\n",
      "iter 1557 ---  Loss: 2.56058619171381    Accuracy: 89.6875\n",
      "iter 1558 ---  Loss: 3.2130446285009384    Accuracy: 86.25\n",
      "iter 1559 ---  Loss: 3.247947037220001    Accuracy: 88.125\n",
      "iter 1560 ---  Loss: 3.2849826514720917    Accuracy: 87.34375\n",
      "iter 1561 ---  Loss: 3.039003662765026    Accuracy: 88.125\n",
      "iter 1562 ---  Loss: 3.1682891845703125    Accuracy: 86.25\n",
      "iter 1563 ---  Loss: 2.858766570687294    Accuracy: 87.65625\n",
      "iter 1564 ---  Loss: 3.0765769481658936    Accuracy: 85.625\n",
      "iter 1565 ---  Loss: 3.0868673473596573    Accuracy: 87.65625\n",
      "iter 1566 ---  Loss: 3.321353316307068    Accuracy: 86.09375\n",
      "iter 1567 ---  Loss: 2.887070447206497    Accuracy: 88.59375\n",
      "iter 1568 ---  Loss: 3.26472557336092    Accuracy: 86.25\n",
      "iter 1569 ---  Loss: 3.2455454990267754    Accuracy: 88.59375\n",
      "iter 1570 ---  Loss: 3.023829497396946    Accuracy: 87.03125\n",
      "iter 1571 ---  Loss: 3.0108951926231384    Accuracy: 88.125\n",
      "iter 1572 ---  Loss: 2.709963783621788    Accuracy: 88.125\n",
      "iter 1573 ---  Loss: 2.8263752087950706    Accuracy: 86.5625\n",
      "iter 1574 ---  Loss: 3.1881945729255676    Accuracy: 86.71875\n",
      "iter 1575 ---  Loss: 3.5761637166142464    Accuracy: 87.03125\n",
      "iter 1576 ---  Loss: 2.6759490370750427    Accuracy: 88.59375\n",
      "iter 1577 ---  Loss: 3.644837364554405    Accuracy: 87.65625\n",
      "iter 1578 ---  Loss: 3.759336121380329    Accuracy: 86.25\n",
      "iter 1579 ---  Loss: 2.8412744477391243    Accuracy: 86.40625\n",
      "iter 1580 ---  Loss: 3.76572947204113    Accuracy: 86.40625\n",
      "iter 1581 ---  Loss: 3.2825311049818993    Accuracy: 88.28125\n",
      "iter 1582 ---  Loss: 3.1244301795959473    Accuracy: 87.34375\n",
      "iter 1583 ---  Loss: 2.788432478904724    Accuracy: 88.28125\n",
      "iter 1584 ---  Loss: 3.1328810453414917    Accuracy: 86.71875\n",
      "iter 1585 ---  Loss: 3.0738497972488403    Accuracy: 85.46875\n",
      "iter 1586 ---  Loss: 3.108248770236969    Accuracy: 85.3125\n",
      "iter 1587 ---  Loss: 3.6682932674884796    Accuracy: 86.875\n",
      "iter 1588 ---  Loss: 2.7025595977902412    Accuracy: 87.96875\n",
      "iter 1589 ---  Loss: 2.837266758084297    Accuracy: 88.59375\n",
      "iter 1590 ---  Loss: 2.6572157070040703    Accuracy: 89.0625\n",
      "iter 1591 ---  Loss: 2.8151006549596786    Accuracy: 87.96875\n",
      "iter 1592 ---  Loss: 3.770482823252678    Accuracy: 85.15625\n",
      "iter 1593 ---  Loss: 2.605312578380108    Accuracy: 88.59375\n",
      "iter 1594 ---  Loss: 3.641942948102951    Accuracy: 87.5\n",
      "iter 1595 ---  Loss: 3.128206104040146    Accuracy: 85.3125\n",
      "iter 1596 ---  Loss: 2.595671199262142    Accuracy: 87.34375\n",
      "iter 1597 ---  Loss: 2.9842200949788094    Accuracy: 86.25\n",
      "iter 1598 ---  Loss: 2.72445534914732    Accuracy: 88.125\n",
      "iter 1599 ---  Loss: 3.291307769715786    Accuracy: 87.34375\n",
      "iter 1600 ---  Loss: 3.0583198592066765    Accuracy: 87.5\n",
      "iter 1601 ---  Loss: 2.6896533519029617    Accuracy: 88.28125\n",
      "iter 1602 ---  Loss: 3.1421957686543465    Accuracy: 89.0625\n",
      "iter 1603 ---  Loss: 2.88781675696373    Accuracy: 87.8125\n",
      "iter 1604 ---  Loss: 3.4492214918136597    Accuracy: 87.03125\n",
      "iter 1605 ---  Loss: 3.371839754283428    Accuracy: 86.40625\n",
      "iter 1606 ---  Loss: 2.8022276535630226    Accuracy: 89.21875\n",
      "iter 1607 ---  Loss: 3.058662958443165    Accuracy: 87.96875\n",
      "iter 1608 ---  Loss: 3.2339945659041405    Accuracy: 85.78125\n",
      "iter 1609 ---  Loss: 3.178382620215416    Accuracy: 87.65625\n",
      "iter 1610 ---  Loss: 2.640359066426754    Accuracy: 87.8125\n",
      "iter 1611 ---  Loss: 3.7215857431292534    Accuracy: 87.1875\n",
      "iter 1612 ---  Loss: 2.8021713197231293    Accuracy: 87.1875\n",
      "iter 1613 ---  Loss: 3.4893405735492706    Accuracy: 85.15625\n",
      "iter 1614 ---  Loss: 3.0643723383545876    Accuracy: 87.96875\n",
      "iter 1615 ---  Loss: 2.9610923156142235    Accuracy: 88.4375\n",
      "iter 1616 ---  Loss: 3.138259470462799    Accuracy: 87.34375\n",
      "iter 1617 ---  Loss: 3.252897582948208    Accuracy: 86.875\n",
      "iter 1618 ---  Loss: 2.4655812084674835    Accuracy: 88.75\n",
      "iter 1619 ---  Loss: 3.4464692920446396    Accuracy: 87.5\n",
      "iter 1620 ---  Loss: 3.0328542664647102    Accuracy: 87.34375\n",
      "iter 1621 ---  Loss: 2.4260164201259613    Accuracy: 88.125\n",
      "iter 1622 ---  Loss: 3.140638679265976    Accuracy: 87.96875\n",
      "iter 1623 ---  Loss: 2.868214227259159    Accuracy: 87.03125\n",
      "iter 1624 ---  Loss: 3.2107276767492294    Accuracy: 87.34375\n",
      "iter 1625 ---  Loss: 3.9040065705776215    Accuracy: 86.40625\n",
      "iter 1626 ---  Loss: 2.464839145541191    Accuracy: 86.09375\n",
      "iter 1627 ---  Loss: 3.3347704634070396    Accuracy: 86.71875\n",
      "iter 1628 ---  Loss: 2.846469759941101    Accuracy: 89.6875\n",
      "iter 1629 ---  Loss: 3.1505033150315285    Accuracy: 87.8125\n",
      "iter 1630 ---  Loss: 3.280730240046978    Accuracy: 87.96875\n",
      "iter 1631 ---  Loss: 3.3238540291786194    Accuracy: 86.71875\n",
      "iter 1632 ---  Loss: 3.1590957790613174    Accuracy: 88.28125\n",
      "iter 1633 ---  Loss: 2.6941225305199623    Accuracy: 85.46875\n",
      "iter 1634 ---  Loss: 3.0886671766638756    Accuracy: 85.625\n",
      "iter 1635 ---  Loss: 2.793823428452015    Accuracy: 88.90625\n",
      "iter 1636 ---  Loss: 4.066279903054237    Accuracy: 87.34375\n",
      "iter 1637 ---  Loss: 3.566776841878891    Accuracy: 89.53125\n",
      "iter 1638 ---  Loss: 3.3385790660977364    Accuracy: 86.875\n",
      "iter 1639 ---  Loss: 3.2280067279934883    Accuracy: 83.90625\n",
      "iter 1640 ---  Loss: 2.999232843518257    Accuracy: 86.25\n",
      "iter 1641 ---  Loss: 3.1871868669986725    Accuracy: 87.65625\n",
      "iter 1642 ---  Loss: 3.388482801616192    Accuracy: 88.28125\n",
      "iter 1643 ---  Loss: 3.145089216530323    Accuracy: 87.65625\n",
      "iter 1644 ---  Loss: 2.955042503774166    Accuracy: 89.375\n",
      "iter 1645 ---  Loss: 3.0636364221572876    Accuracy: 88.59375\n",
      "iter 1646 ---  Loss: 2.5791606307029724    Accuracy: 88.75\n",
      "iter 1647 ---  Loss: 3.276829980313778    Accuracy: 86.875\n",
      "iter 1648 ---  Loss: 2.8621039986610413    Accuracy: 87.96875\n",
      "iter 1649 ---  Loss: 3.1843834593892097    Accuracy: 87.96875\n",
      "iter 1650 ---  Loss: 3.1984893232584    Accuracy: 87.34375\n",
      "iter 1651 ---  Loss: 3.6513333469629288    Accuracy: 87.34375\n",
      "iter 1652 ---  Loss: 3.0492150261998177    Accuracy: 86.40625\n",
      "iter 1653 ---  Loss: 3.4885642156004906    Accuracy: 85.78125\n",
      "iter 1654 ---  Loss: 3.1696963012218475    Accuracy: 86.25\n",
      "iter 1655 ---  Loss: 3.0255428850650787    Accuracy: 86.5625\n",
      "iter 1656 ---  Loss: 3.0772540867328644    Accuracy: 88.59375\n",
      "iter 1657 ---  Loss: 2.865379750728607    Accuracy: 87.03125\n",
      "iter 1658 ---  Loss: 2.9896568581461906    Accuracy: 86.25\n",
      "iter 1659 ---  Loss: 3.556161046028137    Accuracy: 86.09375\n",
      "iter 1660 ---  Loss: 3.036572754383087    Accuracy: 86.5625\n",
      "iter 1661 ---  Loss: 3.581133894622326    Accuracy: 86.71875\n",
      "iter 1662 ---  Loss: 3.339110940694809    Accuracy: 87.8125\n",
      "iter 1663 ---  Loss: 2.548134110867977    Accuracy: 87.34375\n",
      "iter 1664 ---  Loss: 2.8996561020612717    Accuracy: 86.875\n",
      "iter 1665 ---  Loss: 2.861318290233612    Accuracy: 88.125\n",
      "iter 1666 ---  Loss: 4.017186269164085    Accuracy: 85.9375\n",
      "iter 1667 ---  Loss: 2.6560654789209366    Accuracy: 87.5\n",
      "iter 1668 ---  Loss: 2.995310887694359    Accuracy: 88.75\n",
      "iter 1669 ---  Loss: 3.9586476162075996    Accuracy: 87.5\n",
      "iter 1670 ---  Loss: 2.8084058612585068    Accuracy: 85.78125\n",
      "iter 1671 ---  Loss: 3.1668339669704437    Accuracy: 86.25\n",
      "iter 1672 ---  Loss: 3.272181749343872    Accuracy: 86.09375\n",
      "iter 1673 ---  Loss: 2.789924494922161    Accuracy: 88.59375\n",
      "iter 1674 ---  Loss: 2.8459730744361877    Accuracy: 88.59375\n",
      "iter 1675 ---  Loss: 3.107001408934593    Accuracy: 87.8125\n",
      "iter 1676 ---  Loss: 3.6628320142626762    Accuracy: 86.40625\n",
      "iter 1677 ---  Loss: 2.6721321195364    Accuracy: 87.65625\n",
      "iter 1678 ---  Loss: 3.107662655413151    Accuracy: 87.5\n",
      "iter 1679 ---  Loss: 2.800000548362732    Accuracy: 88.59375\n",
      "iter 1680 ---  Loss: 3.2927050590515137    Accuracy: 87.65625\n",
      "iter 1681 ---  Loss: 2.8424054086208344    Accuracy: 88.59375\n",
      "iter 1682 ---  Loss: 2.6604064628481865    Accuracy: 89.375\n",
      "iter 1683 ---  Loss: 3.390320338308811    Accuracy: 86.71875\n",
      "iter 1684 ---  Loss: 3.1244387328624725    Accuracy: 86.875\n",
      "iter 1685 ---  Loss: 3.2107604071497917    Accuracy: 87.65625\n",
      "iter 1686 ---  Loss: 2.847660318017006    Accuracy: 88.90625\n",
      "iter 1687 ---  Loss: 2.803430624306202    Accuracy: 88.125\n",
      "iter 1688 ---  Loss: 2.946217864751816    Accuracy: 87.1875\n",
      "iter 1689 ---  Loss: 2.6998448967933655    Accuracy: 86.875\n",
      "iter 1690 ---  Loss: 3.2123231887817383    Accuracy: 87.5\n",
      "iter 1691 ---  Loss: 2.713278852403164    Accuracy: 88.28125\n",
      "iter 1692 ---  Loss: 2.915113113820553    Accuracy: 88.28125\n",
      "iter 1693 ---  Loss: 3.206333748996258    Accuracy: 86.71875\n",
      "iter 1694 ---  Loss: 2.6445285230875015    Accuracy: 87.5\n",
      "iter 1695 ---  Loss: 2.6075822934508324    Accuracy: 88.28125\n",
      "iter 1696 ---  Loss: 3.7922815680503845    Accuracy: 86.5625\n",
      "iter 1697 ---  Loss: 2.9031145572662354    Accuracy: 87.8125\n",
      "iter 1698 ---  Loss: 2.5280913785099983    Accuracy: 90.0\n",
      "iter 1699 ---  Loss: 2.53993359208107    Accuracy: 89.6875\n",
      "iter 1700 ---  Loss: 3.3734022304415703    Accuracy: 86.5625\n",
      "iter 1701 ---  Loss: 2.405877262353897    Accuracy: 88.28125\n",
      "iter 1702 ---  Loss: 2.9767139926552773    Accuracy: 86.71875\n",
      "iter 1703 ---  Loss: 3.39919975399971    Accuracy: 85.9375\n",
      "iter 1704 ---  Loss: 3.05668718367815    Accuracy: 87.34375\n",
      "iter 1705 ---  Loss: 3.5542982295155525    Accuracy: 86.5625\n",
      "iter 1706 ---  Loss: 2.6229417249560356    Accuracy: 87.5\n",
      "iter 1707 ---  Loss: 2.9362561404705048    Accuracy: 89.21875\n",
      "iter 1708 ---  Loss: 2.7997956201434135    Accuracy: 87.8125\n",
      "iter 1709 ---  Loss: 3.561878487467766    Accuracy: 88.28125\n",
      "iter 1710 ---  Loss: 2.9034088850021362    Accuracy: 87.96875\n",
      "iter 1711 ---  Loss: 2.733561486005783    Accuracy: 87.8125\n",
      "iter 1712 ---  Loss: 3.09180748462677    Accuracy: 89.375\n",
      "iter 1713 ---  Loss: 2.7653615921735764    Accuracy: 88.90625\n",
      "iter 1714 ---  Loss: 3.3531626909971237    Accuracy: 87.03125\n",
      "iter 1715 ---  Loss: 2.944629490375519    Accuracy: 87.34375\n",
      "iter 1716 ---  Loss: 3.3766946867108345    Accuracy: 85.0\n",
      "iter 1717 ---  Loss: 2.9557597786188126    Accuracy: 89.53125\n",
      "iter 1718 ---  Loss: 2.8668496757745743    Accuracy: 89.53125\n",
      "iter 1719 ---  Loss: 3.66170933842659    Accuracy: 86.40625\n",
      "iter 1720 ---  Loss: 3.2531080543994904    Accuracy: 86.40625\n",
      "iter 1721 ---  Loss: 3.2568334192037582    Accuracy: 87.8125\n",
      "iter 1722 ---  Loss: 3.2363034933805466    Accuracy: 87.96875\n",
      "iter 1723 ---  Loss: 2.8271616846323013    Accuracy: 88.59375\n",
      "iter 1724 ---  Loss: 2.9114957079291344    Accuracy: 88.4375\n",
      "iter 1725 ---  Loss: 2.7867836505174637    Accuracy: 88.90625\n",
      "iter 1726 ---  Loss: 3.227919362485409    Accuracy: 87.1875\n",
      "iter 1727 ---  Loss: 2.9660622403025627    Accuracy: 89.375\n",
      "iter 1728 ---  Loss: 2.7844496965408325    Accuracy: 88.28125\n",
      "iter 1729 ---  Loss: 2.906231828033924    Accuracy: 87.8125\n",
      "iter 1730 ---  Loss: 4.129474900662899    Accuracy: 85.625\n",
      "iter 1731 ---  Loss: 2.9689346998929977    Accuracy: 87.96875\n",
      "iter 1732 ---  Loss: 2.4538229033350945    Accuracy: 89.375\n",
      "iter 1733 ---  Loss: 2.662147916853428    Accuracy: 88.4375\n",
      "iter 1734 ---  Loss: 3.3792029097676277    Accuracy: 87.03125\n",
      "iter 1735 ---  Loss: 2.878225415945053    Accuracy: 87.96875\n",
      "iter 1736 ---  Loss: 3.5661701261997223    Accuracy: 86.71875\n",
      "iter 1737 ---  Loss: 3.2453426718711853    Accuracy: 87.8125\n",
      "iter 1738 ---  Loss: 2.6951918601989746    Accuracy: 88.125\n",
      "iter 1739 ---  Loss: 2.9142735451459885    Accuracy: 87.5\n",
      "iter 1740 ---  Loss: 3.1371344178915024    Accuracy: 89.53125\n",
      "iter 1741 ---  Loss: 3.003764495253563    Accuracy: 89.21875\n",
      "iter 1742 ---  Loss: 3.1816383078694344    Accuracy: 88.28125\n",
      "iter 1743 ---  Loss: 2.6226284205913544    Accuracy: 90.0\n",
      "iter 1744 ---  Loss: 2.8344955667853355    Accuracy: 86.25\n",
      "iter 1745 ---  Loss: 4.128577157855034    Accuracy: 83.75\n",
      "iter 1746 ---  Loss: 2.788725331425667    Accuracy: 87.1875\n",
      "iter 1747 ---  Loss: 2.5854694470763206    Accuracy: 88.4375\n",
      "iter 1748 ---  Loss: 2.2557834908366203    Accuracy: 91.40625\n",
      "iter 1749 ---  Loss: 3.4522922039031982    Accuracy: 89.375\n",
      "iter 1750 ---  Loss: 3.23382131755352    Accuracy: 88.4375\n",
      "iter 1751 ---  Loss: 3.311447337269783    Accuracy: 89.53125\n",
      "iter 1752 ---  Loss: 2.968544214963913    Accuracy: 86.40625\n",
      "iter 1753 ---  Loss: 3.2324130162596703    Accuracy: 87.8125\n",
      "iter 1754 ---  Loss: 2.7777603417634964    Accuracy: 88.28125\n",
      "iter 1755 ---  Loss: 2.9243665784597397    Accuracy: 87.03125\n",
      "iter 1756 ---  Loss: 2.8361483365297318    Accuracy: 87.5\n",
      "iter 1757 ---  Loss: 3.3707909286022186    Accuracy: 87.65625\n",
      "iter 1758 ---  Loss: 3.005890093743801    Accuracy: 86.25\n",
      "iter 1759 ---  Loss: 2.5888517126441    Accuracy: 87.1875\n",
      "iter 1760 ---  Loss: 3.2377566024661064    Accuracy: 87.1875\n",
      "iter 1761 ---  Loss: 2.997060276567936    Accuracy: 87.1875\n",
      "iter 1762 ---  Loss: 3.4325964152812958    Accuracy: 86.40625\n",
      "iter 1763 ---  Loss: 3.2115918695926666    Accuracy: 88.125\n",
      "iter 1764 ---  Loss: 3.146551266312599    Accuracy: 88.59375\n",
      "iter 1765 ---  Loss: 2.8426763638854027    Accuracy: 87.65625\n",
      "iter 1766 ---  Loss: 2.629143975675106    Accuracy: 89.53125\n",
      "iter 1767 ---  Loss: 3.1757285222411156    Accuracy: 86.25\n",
      "iter 1768 ---  Loss: 2.7333957999944687    Accuracy: 87.96875\n",
      "iter 1769 ---  Loss: 3.0765985772013664    Accuracy: 86.875\n",
      "iter 1770 ---  Loss: 3.657984897494316    Accuracy: 83.59375\n",
      "iter 1771 ---  Loss: 3.3393706753849983    Accuracy: 87.8125\n",
      "iter 1772 ---  Loss: 2.814150631427765    Accuracy: 88.4375\n",
      "iter 1773 ---  Loss: 2.8826994597911835    Accuracy: 87.1875\n",
      "iter 1774 ---  Loss: 2.8475891426205635    Accuracy: 87.8125\n",
      "iter 1775 ---  Loss: 2.865752011537552    Accuracy: 88.28125\n",
      "iter 1776 ---  Loss: 2.9379903078079224    Accuracy: 86.71875\n",
      "iter 1777 ---  Loss: 2.6253970935940742    Accuracy: 89.21875\n",
      "iter 1778 ---  Loss: 3.1952642425894737    Accuracy: 86.875\n",
      "iter 1779 ---  Loss: 2.6611382886767387    Accuracy: 87.96875\n",
      "iter 1780 ---  Loss: 3.098948083817959    Accuracy: 87.8125\n",
      "iter 1781 ---  Loss: 3.573442727327347    Accuracy: 85.3125\n",
      "iter 1782 ---  Loss: 2.7982338815927505    Accuracy: 87.5\n",
      "iter 1783 ---  Loss: 3.289322964847088    Accuracy: 86.25\n",
      "iter 1784 ---  Loss: 3.4693898260593414    Accuracy: 89.53125\n",
      "iter 1785 ---  Loss: 3.0723007768392563    Accuracy: 86.875\n",
      "iter 1786 ---  Loss: 2.9798184260725975    Accuracy: 88.125\n",
      "iter 1787 ---  Loss: 3.5829205960035324    Accuracy: 87.96875\n",
      "iter 1788 ---  Loss: 3.676109805703163    Accuracy: 86.5625\n",
      "iter 1789 ---  Loss: 3.2185060903429985    Accuracy: 86.875\n",
      "iter 1790 ---  Loss: 2.3616154491901398    Accuracy: 89.21875\n",
      "iter 1791 ---  Loss: 3.0107914209365845    Accuracy: 88.75\n",
      "iter 1792 ---  Loss: 3.1447760239243507    Accuracy: 88.4375\n",
      "iter 1793 ---  Loss: 3.212824985384941    Accuracy: 85.9375\n",
      "iter 1794 ---  Loss: 2.995304837822914    Accuracy: 88.28125\n",
      "iter 1795 ---  Loss: 3.1847831457853317    Accuracy: 87.65625\n",
      "iter 1796 ---  Loss: 3.008943222463131    Accuracy: 87.96875\n",
      "iter 1797 ---  Loss: 3.1667864099144936    Accuracy: 87.03125\n",
      "iter 1798 ---  Loss: 3.347604528069496    Accuracy: 87.34375\n",
      "iter 1799 ---  Loss: 2.610962986946106    Accuracy: 88.28125\n",
      "iter 1800 ---  Loss: 2.513050138950348    Accuracy: 89.53125\n",
      "iter 1801 ---  Loss: 2.804185837507248    Accuracy: 89.0625\n",
      "iter 1802 ---  Loss: 2.605403706431389    Accuracy: 87.5\n",
      "iter 1803 ---  Loss: 3.2876598089933395    Accuracy: 87.96875\n",
      "iter 1804 ---  Loss: 3.271491214632988    Accuracy: 86.40625\n",
      "iter 1805 ---  Loss: 2.9852578416466713    Accuracy: 87.8125\n",
      "iter 1806 ---  Loss: 3.0262806341052055    Accuracy: 88.28125\n",
      "iter 1807 ---  Loss: 3.2995383366942406    Accuracy: 87.5\n",
      "iter 1808 ---  Loss: 2.9449090883135796    Accuracy: 87.8125\n",
      "iter 1809 ---  Loss: 2.5612882375717163    Accuracy: 88.28125\n",
      "iter 1810 ---  Loss: 3.0163267850875854    Accuracy: 86.71875\n",
      "iter 1811 ---  Loss: 3.2420197501778603    Accuracy: 88.125\n",
      "iter 1812 ---  Loss: 3.115802399814129    Accuracy: 88.59375\n",
      "iter 1813 ---  Loss: 2.607242450118065    Accuracy: 87.5\n",
      "iter 1814 ---  Loss: 2.872645653784275    Accuracy: 86.09375\n",
      "iter 1815 ---  Loss: 3.0178738683462143    Accuracy: 87.1875\n",
      "iter 1816 ---  Loss: 3.4758745208382607    Accuracy: 86.5625\n",
      "iter 1817 ---  Loss: 3.5632178336381912    Accuracy: 86.5625\n",
      "iter 1818 ---  Loss: 3.1704054325819016    Accuracy: 87.34375\n",
      "iter 1819 ---  Loss: 3.257877938449383    Accuracy: 85.46875\n",
      "iter 1820 ---  Loss: 3.3427366837859154    Accuracy: 84.84375\n",
      "iter 1821 ---  Loss: 2.7037601843476295    Accuracy: 87.5\n",
      "iter 1822 ---  Loss: 3.018073856830597    Accuracy: 88.59375\n",
      "iter 1823 ---  Loss: 2.994324892759323    Accuracy: 88.90625\n",
      "iter 1824 ---  Loss: 3.513274796307087    Accuracy: 84.6875\n",
      "iter 1825 ---  Loss: 2.6723725497722626    Accuracy: 87.8125\n",
      "iter 1826 ---  Loss: 3.6614020243287086    Accuracy: 87.1875\n",
      "iter 1827 ---  Loss: 2.8042320981621742    Accuracy: 86.71875\n",
      "iter 1828 ---  Loss: 2.9494984298944473    Accuracy: 87.34375\n",
      "iter 1829 ---  Loss: 3.149045020341873    Accuracy: 87.8125\n",
      "iter 1830 ---  Loss: 3.062980078160763    Accuracy: 87.65625\n",
      "iter 1831 ---  Loss: 3.187634952366352    Accuracy: 85.3125\n",
      "iter 1832 ---  Loss: 3.326954163610935    Accuracy: 85.0\n",
      "iter 1833 ---  Loss: 2.6529185101389885    Accuracy: 87.34375\n",
      "iter 1834 ---  Loss: 2.853896476328373    Accuracy: 86.40625\n",
      "iter 1835 ---  Loss: 3.8439155220985413    Accuracy: 85.625\n",
      "iter 1836 ---  Loss: 3.142839327454567    Accuracy: 86.71875\n",
      "iter 1837 ---  Loss: 2.7246589064598083    Accuracy: 85.78125\n",
      "iter 1838 ---  Loss: 3.4603220224380493    Accuracy: 86.71875\n",
      "iter 1839 ---  Loss: 3.0726540461182594    Accuracy: 88.28125\n",
      "iter 1840 ---  Loss: 3.0281252190470695    Accuracy: 87.03125\n",
      "iter 1841 ---  Loss: 3.1564602330327034    Accuracy: 88.125\n",
      "iter 1842 ---  Loss: 2.9586267843842506    Accuracy: 87.03125\n",
      "iter 1843 ---  Loss: 2.9809011295437813    Accuracy: 86.09375\n",
      "iter 1844 ---  Loss: 2.6815799921751022    Accuracy: 89.21875\n",
      "iter 1845 ---  Loss: 2.6664943173527718    Accuracy: 89.0625\n",
      "iter 1846 ---  Loss: 3.458164408802986    Accuracy: 85.625\n",
      "iter 1847 ---  Loss: 3.1514686793088913    Accuracy: 86.71875\n",
      "iter 1848 ---  Loss: 3.382091201841831    Accuracy: 86.875\n",
      "iter 1849 ---  Loss: 3.0346818789839745    Accuracy: 87.65625\n",
      "iter 1850 ---  Loss: 3.2484523952007294    Accuracy: 87.03125\n",
      "iter 1851 ---  Loss: 3.6150134056806564    Accuracy: 86.25\n",
      "iter 1852 ---  Loss: 3.984249509871006    Accuracy: 87.34375\n",
      "iter 1853 ---  Loss: 3.2611177191138268    Accuracy: 86.40625\n",
      "iter 1854 ---  Loss: 2.922390043735504    Accuracy: 86.09375\n",
      "iter 1855 ---  Loss: 2.626966454088688    Accuracy: 88.90625\n",
      "iter 1856 ---  Loss: 2.965911380946636    Accuracy: 87.5\n",
      "iter 1857 ---  Loss: 3.365150511264801    Accuracy: 88.75\n",
      "iter 1858 ---  Loss: 2.8830079287290573    Accuracy: 86.25\n",
      "iter 1859 ---  Loss: 2.9363077357411385    Accuracy: 88.125\n",
      "iter 1860 ---  Loss: 2.8100240752100945    Accuracy: 89.0625\n",
      "iter 1861 ---  Loss: 2.970968872308731    Accuracy: 86.5625\n",
      "iter 1862 ---  Loss: 2.513296291232109    Accuracy: 87.5\n",
      "iter 1863 ---  Loss: 2.534962847828865    Accuracy: 88.28125\n",
      "iter 1864 ---  Loss: 2.9352922290563583    Accuracy: 87.5\n",
      "iter 1865 ---  Loss: 2.6908094733953476    Accuracy: 87.1875\n",
      "iter 1866 ---  Loss: 3.4066820815205574    Accuracy: 87.1875\n",
      "iter 1867 ---  Loss: 3.547257572412491    Accuracy: 84.53125\n",
      "iter 1868 ---  Loss: 3.2463585138320923    Accuracy: 87.96875\n",
      "iter 1869 ---  Loss: 2.926446810364723    Accuracy: 85.9375\n",
      "iter 1870 ---  Loss: 2.802737846970558    Accuracy: 89.21875\n",
      "iter 1871 ---  Loss: 2.98343862593174    Accuracy: 87.65625\n",
      "iter 1872 ---  Loss: 2.782144121825695    Accuracy: 88.4375\n",
      "iter 1873 ---  Loss: 3.073120266199112    Accuracy: 87.8125\n",
      "iter 1874 ---  Loss: 2.799050986766815    Accuracy: 87.1875\n",
      "iter 1875 ---  Loss: 3.0043102502822876    Accuracy: 86.875\n",
      "iter 1876 ---  Loss: 3.6978890374302864    Accuracy: 84.21875\n",
      "iter 1877 ---  Loss: 2.7738391309976578    Accuracy: 88.125\n",
      "iter 1878 ---  Loss: 2.900790996849537    Accuracy: 88.28125\n",
      "iter 1879 ---  Loss: 2.9266280233860016    Accuracy: 89.0625\n",
      "iter 1880 ---  Loss: 3.0492087975144386    Accuracy: 86.71875\n",
      "iter 1881 ---  Loss: 3.2759542763233185    Accuracy: 87.5\n",
      "iter 1882 ---  Loss: 3.081646144390106    Accuracy: 87.65625\n",
      "iter 1883 ---  Loss: 3.5418958365917206    Accuracy: 86.25\n",
      "iter 1884 ---  Loss: 3.5945882350206375    Accuracy: 87.5\n",
      "iter 1885 ---  Loss: 3.06501367688179    Accuracy: 87.8125\n",
      "iter 1886 ---  Loss: 2.890881158411503    Accuracy: 86.71875\n",
      "iter 1887 ---  Loss: 2.540599524974823    Accuracy: 89.6875\n",
      "iter 1888 ---  Loss: 2.656948611140251    Accuracy: 87.34375\n",
      "iter 1889 ---  Loss: 3.286292552947998    Accuracy: 86.875\n",
      "iter 1890 ---  Loss: 3.037314921617508    Accuracy: 86.875\n",
      "iter 1891 ---  Loss: 3.428157016634941    Accuracy: 87.8125\n",
      "iter 1892 ---  Loss: 2.7547023221850395    Accuracy: 87.34375\n",
      "iter 1893 ---  Loss: 2.7920499742031097    Accuracy: 87.96875\n",
      "iter 1894 ---  Loss: 2.781012676656246    Accuracy: 88.28125\n",
      "iter 1895 ---  Loss: 3.3915340453386307    Accuracy: 86.71875\n",
      "iter 1896 ---  Loss: 2.8612445294857025    Accuracy: 87.65625\n",
      "iter 1897 ---  Loss: 2.9204471185803413    Accuracy: 87.34375\n",
      "iter 1898 ---  Loss: 2.5654655173420906    Accuracy: 86.875\n",
      "iter 1899 ---  Loss: 3.341606482863426    Accuracy: 86.71875\n",
      "iter 1900 ---  Loss: 2.6981293335556984    Accuracy: 88.75\n",
      "iter 1901 ---  Loss: 2.8282876387238503    Accuracy: 88.28125\n",
      "iter 1902 ---  Loss: 2.717099152505398    Accuracy: 88.59375\n",
      "iter 1903 ---  Loss: 2.9478697329759598    Accuracy: 85.9375\n",
      "iter 1904 ---  Loss: 2.9381776973605156    Accuracy: 86.5625\n",
      "iter 1905 ---  Loss: 3.0750484094023705    Accuracy: 88.59375\n",
      "iter 1906 ---  Loss: 2.703574448823929    Accuracy: 88.59375\n",
      "iter 1907 ---  Loss: 3.6893671303987503    Accuracy: 87.03125\n",
      "iter 1908 ---  Loss: 3.391751140356064    Accuracy: 86.71875\n",
      "iter 1909 ---  Loss: 3.068648971617222    Accuracy: 88.125\n",
      "iter 1910 ---  Loss: 3.1060293167829514    Accuracy: 87.1875\n",
      "iter 1911 ---  Loss: 3.2093683555722237    Accuracy: 86.25\n",
      "iter 1912 ---  Loss: 3.1933530271053314    Accuracy: 86.875\n",
      "iter 1913 ---  Loss: 2.9348193556070328    Accuracy: 86.09375\n",
      "iter 1914 ---  Loss: 3.333125375211239    Accuracy: 87.65625\n",
      "iter 1915 ---  Loss: 3.3111745938658714    Accuracy: 87.34375\n",
      "iter 1916 ---  Loss: 2.5748744010925293    Accuracy: 87.5\n",
      "iter 1917 ---  Loss: 2.7265550270676613    Accuracy: 87.03125\n",
      "iter 1918 ---  Loss: 3.486817844212055    Accuracy: 85.78125\n",
      "iter 1919 ---  Loss: 3.573233485221863    Accuracy: 86.40625\n",
      "iter 1920 ---  Loss: 3.0910856127738953    Accuracy: 86.25\n",
      "iter 1921 ---  Loss: 3.03725752979517    Accuracy: 87.34375\n",
      "iter 1922 ---  Loss: 2.809254251420498    Accuracy: 86.71875\n",
      "iter 1923 ---  Loss: 2.892928183078766    Accuracy: 89.21875\n",
      "iter 1924 ---  Loss: 3.0938406363129616    Accuracy: 88.59375\n",
      "iter 1925 ---  Loss: 3.749667562544346    Accuracy: 86.5625\n",
      "iter 1926 ---  Loss: 2.694280929863453    Accuracy: 89.21875\n",
      "iter 1927 ---  Loss: 2.7363017946481705    Accuracy: 88.90625\n",
      "iter 1928 ---  Loss: 2.6937152072787285    Accuracy: 89.6875\n",
      "iter 1929 ---  Loss: 2.9957297444343567    Accuracy: 89.375\n",
      "iter 1930 ---  Loss: 3.7268106266856194    Accuracy: 85.15625\n",
      "iter 1931 ---  Loss: 2.6679513454437256    Accuracy: 90.0\n",
      "iter 1932 ---  Loss: 2.6021692007780075    Accuracy: 89.84375\n",
      "iter 1933 ---  Loss: 2.866212025284767    Accuracy: 86.09375\n",
      "iter 1934 ---  Loss: 3.3074156418442726    Accuracy: 87.8125\n",
      "iter 1935 ---  Loss: 3.439734548330307    Accuracy: 86.25\n",
      "iter 1936 ---  Loss: 3.0888337939977646    Accuracy: 86.40625\n",
      "iter 1937 ---  Loss: 3.9092058166861534    Accuracy: 85.78125\n",
      "iter 1938 ---  Loss: 2.9772660732269287    Accuracy: 86.09375\n",
      "iter 1939 ---  Loss: 2.798302508890629    Accuracy: 87.8125\n",
      "iter 1940 ---  Loss: 3.012379579246044    Accuracy: 85.78125\n",
      "iter 1941 ---  Loss: 3.452483966946602    Accuracy: 85.0\n",
      "iter 1942 ---  Loss: 2.6790801286697388    Accuracy: 88.59375\n",
      "iter 1943 ---  Loss: 3.3400066196918488    Accuracy: 88.125\n",
      "iter 1944 ---  Loss: 3.251067392528057    Accuracy: 85.9375\n",
      "iter 1945 ---  Loss: 2.8382572010159492    Accuracy: 87.65625\n",
      "iter 1946 ---  Loss: 3.1059286296367645    Accuracy: 88.4375\n",
      "iter 1947 ---  Loss: 3.340629070997238    Accuracy: 86.09375\n",
      "iter 1948 ---  Loss: 2.922889769077301    Accuracy: 87.1875\n",
      "iter 1949 ---  Loss: 2.9483812302351    Accuracy: 87.65625\n",
      "iter 1950 ---  Loss: 3.330019511282444    Accuracy: 84.6875\n",
      "iter 1951 ---  Loss: 3.0441104024648666    Accuracy: 87.34375\n",
      "iter 1952 ---  Loss: 3.732522204518318    Accuracy: 85.15625\n",
      "iter 1953 ---  Loss: 2.4191705137491226    Accuracy: 87.8125\n",
      "iter 1954 ---  Loss: 2.5133835896849632    Accuracy: 87.34375\n",
      "iter 1955 ---  Loss: 3.375593140721321    Accuracy: 86.71875\n",
      "iter 1956 ---  Loss: 3.425097331404686    Accuracy: 85.78125\n",
      "iter 1957 ---  Loss: 3.229583479464054    Accuracy: 85.3125\n",
      "iter 1958 ---  Loss: 3.153409518301487    Accuracy: 86.5625\n",
      "iter 1959 ---  Loss: 2.9965899884700775    Accuracy: 86.875\n",
      "iter 1960 ---  Loss: 3.6054462045431137    Accuracy: 87.8125\n",
      "iter 1961 ---  Loss: 3.2096296697854996    Accuracy: 86.875\n",
      "iter 1962 ---  Loss: 3.6675489246845245    Accuracy: 87.1875\n",
      "iter 1963 ---  Loss: 2.8053378611803055    Accuracy: 89.0625\n",
      "iter 1964 ---  Loss: 3.362081527709961    Accuracy: 87.65625\n",
      "iter 1965 ---  Loss: 3.5654716342687607    Accuracy: 85.9375\n",
      "iter 1966 ---  Loss: 3.2426892668008804    Accuracy: 86.5625\n",
      "iter 1967 ---  Loss: 2.663444086909294    Accuracy: 88.90625\n",
      "iter 1968 ---  Loss: 3.1453240290284157    Accuracy: 86.25\n",
      "iter 1969 ---  Loss: 3.2331390231847763    Accuracy: 87.96875\n",
      "iter 1970 ---  Loss: 2.7496595233678818    Accuracy: 87.34375\n",
      "iter 1971 ---  Loss: 3.0447051525115967    Accuracy: 86.5625\n",
      "iter 1972 ---  Loss: 3.066140830516815    Accuracy: 86.09375\n",
      "iter 1973 ---  Loss: 2.85150483250618    Accuracy: 87.03125\n",
      "iter 1974 ---  Loss: 2.5630669072270393    Accuracy: 87.8125\n",
      "iter 1975 ---  Loss: 2.7145624086260796    Accuracy: 88.125\n",
      "iter 1976 ---  Loss: 3.077521301805973    Accuracy: 88.75\n",
      "iter 1977 ---  Loss: 3.246613956987858    Accuracy: 86.71875\n",
      "iter 1978 ---  Loss: 3.1675829216837883    Accuracy: 85.625\n",
      "iter 1979 ---  Loss: 3.113327272236347    Accuracy: 88.28125\n",
      "iter 1980 ---  Loss: 3.1305434554815292    Accuracy: 84.21875\n",
      "iter 1981 ---  Loss: 2.9428462609648705    Accuracy: 88.125\n",
      "iter 1982 ---  Loss: 3.04766596108675    Accuracy: 86.71875\n",
      "iter 1983 ---  Loss: 2.557198867201805    Accuracy: 88.59375\n",
      "iter 1984 ---  Loss: 3.02797482162714    Accuracy: 86.25\n",
      "iter 1985 ---  Loss: 2.9811901971697807    Accuracy: 87.03125\n",
      "iter 1986 ---  Loss: 3.0257379338145256    Accuracy: 86.40625\n",
      "iter 1987 ---  Loss: 3.8515331000089645    Accuracy: 85.15625\n",
      "iter 1988 ---  Loss: 3.5710353329777718    Accuracy: 85.625\n",
      "iter 1989 ---  Loss: 3.3210112527012825    Accuracy: 86.71875\n",
      "iter 1990 ---  Loss: 3.123731590807438    Accuracy: 87.03125\n",
      "iter 1991 ---  Loss: 2.8130556792020798    Accuracy: 85.3125\n",
      "iter 1992 ---  Loss: 2.9128445461392403    Accuracy: 87.8125\n",
      "iter 1993 ---  Loss: 2.7504529878497124    Accuracy: 89.53125\n",
      "iter 1994 ---  Loss: 2.7874371334910393    Accuracy: 86.25\n",
      "iter 1995 ---  Loss: 2.752097986638546    Accuracy: 87.65625\n",
      "iter 1996 ---  Loss: 2.803329922258854    Accuracy: 88.125\n",
      "iter 1997 ---  Loss: 3.4696882739663124    Accuracy: 88.28125\n",
      "iter 1998 ---  Loss: 2.6635053157806396    Accuracy: 88.4375\n",
      "iter 1999 ---  Loss: 3.166214570403099    Accuracy: 88.75\n",
      "iter 2000 ---  Loss: 2.9148489460349083    Accuracy: 87.1875\n",
      "iter 2001 ---  Loss: 2.822386287152767    Accuracy: 87.65625\n",
      "iter 2002 ---  Loss: 3.0037646293640137    Accuracy: 86.71875\n",
      "iter 2003 ---  Loss: 3.295166790485382    Accuracy: 86.40625\n",
      "iter 2004 ---  Loss: 2.8464230448007584    Accuracy: 87.1875\n",
      "iter 2005 ---  Loss: 2.7323019355535507    Accuracy: 88.28125\n",
      "iter 2006 ---  Loss: 3.1741565093398094    Accuracy: 87.03125\n",
      "iter 2007 ---  Loss: 3.3443349301815033    Accuracy: 86.40625\n",
      "iter 2008 ---  Loss: 2.598244823515415    Accuracy: 87.96875\n",
      "iter 2009 ---  Loss: 3.2986591309309006    Accuracy: 88.59375\n",
      "iter 2010 ---  Loss: 2.9912707954645157    Accuracy: 86.09375\n",
      "iter 2011 ---  Loss: 2.57884681224823    Accuracy: 88.125\n",
      "iter 2012 ---  Loss: 4.004992462694645    Accuracy: 86.25\n",
      "iter 2013 ---  Loss: 2.654985398054123    Accuracy: 89.375\n",
      "iter 2014 ---  Loss: 2.9535657539963722    Accuracy: 87.03125\n",
      "iter 2015 ---  Loss: 2.994625300168991    Accuracy: 86.875\n",
      "iter 2016 ---  Loss: 2.73223415017128    Accuracy: 88.125\n",
      "iter 2017 ---  Loss: 2.7802923545241356    Accuracy: 90.0\n",
      "iter 2018 ---  Loss: 3.355549894273281    Accuracy: 88.4375\n",
      "iter 2019 ---  Loss: 2.8492147624492645    Accuracy: 86.71875\n",
      "iter 2020 ---  Loss: 2.8864667862653732    Accuracy: 87.65625\n",
      "iter 2021 ---  Loss: 3.4993347078561783    Accuracy: 85.15625\n",
      "iter 2022 ---  Loss: 3.3869451358914375    Accuracy: 86.875\n",
      "iter 2023 ---  Loss: 3.567767895758152    Accuracy: 86.25\n",
      "iter 2024 ---  Loss: 2.9093537032604218    Accuracy: 87.1875\n",
      "iter 2025 ---  Loss: 3.062016651034355    Accuracy: 87.5\n",
      "iter 2026 ---  Loss: 3.1859577149152756    Accuracy: 87.1875\n",
      "iter 2027 ---  Loss: 3.1029060557484627    Accuracy: 87.65625\n",
      "iter 2028 ---  Loss: 3.6697982475161552    Accuracy: 85.9375\n",
      "iter 2029 ---  Loss: 3.758028596639633    Accuracy: 85.78125\n",
      "iter 2030 ---  Loss: 3.4730162918567657    Accuracy: 85.78125\n",
      "iter 2031 ---  Loss: 3.3798701465129852    Accuracy: 85.0\n",
      "iter 2032 ---  Loss: 4.34739077091217    Accuracy: 86.09375\n",
      "iter 2033 ---  Loss: 2.6726583018898964    Accuracy: 87.5\n",
      "iter 2034 ---  Loss: 3.4499888569116592    Accuracy: 87.96875\n",
      "iter 2035 ---  Loss: 2.8539318963885307    Accuracy: 88.75\n",
      "iter 2036 ---  Loss: 3.691800110042095    Accuracy: 84.375\n",
      "iter 2037 ---  Loss: 2.592296965420246    Accuracy: 88.125\n",
      "iter 2038 ---  Loss: 3.416736327111721    Accuracy: 87.03125\n",
      "iter 2039 ---  Loss: 2.8070892617106438    Accuracy: 87.1875\n",
      "iter 2040 ---  Loss: 3.322990894317627    Accuracy: 86.875\n",
      "iter 2041 ---  Loss: 3.116518072783947    Accuracy: 85.9375\n",
      "iter 2042 ---  Loss: 2.945651449263096    Accuracy: 87.34375\n",
      "iter 2043 ---  Loss: 3.0312821343541145    Accuracy: 88.28125\n",
      "iter 2044 ---  Loss: 2.8006240651011467    Accuracy: 89.6875\n",
      "iter 2045 ---  Loss: 3.035430185496807    Accuracy: 86.09375\n",
      "iter 2046 ---  Loss: 2.9431140199303627    Accuracy: 86.5625\n",
      "iter 2047 ---  Loss: 3.2079334557056427    Accuracy: 88.28125\n",
      "iter 2048 ---  Loss: 2.916169136762619    Accuracy: 85.15625\n",
      "iter 2049 ---  Loss: 3.0550639033317566    Accuracy: 87.8125\n",
      "iter 2050 ---  Loss: 2.841595984995365    Accuracy: 88.4375\n",
      "iter 2051 ---  Loss: 3.54402993619442    Accuracy: 86.875\n",
      "iter 2052 ---  Loss: 3.1169480979442596    Accuracy: 87.1875\n",
      "iter 2053 ---  Loss: 3.3660663589835167    Accuracy: 86.71875\n",
      "iter 2054 ---  Loss: 3.2855478897690773    Accuracy: 87.1875\n",
      "iter 2055 ---  Loss: 3.3500106781721115    Accuracy: 87.8125\n",
      "iter 2056 ---  Loss: 2.943045921623707    Accuracy: 87.96875\n",
      "iter 2057 ---  Loss: 3.0937222093343735    Accuracy: 86.25\n",
      "iter 2058 ---  Loss: 3.2109812796115875    Accuracy: 85.78125\n",
      "iter 2059 ---  Loss: 3.1865336149930954    Accuracy: 87.8125\n",
      "iter 2060 ---  Loss: 2.926598936319351    Accuracy: 85.46875\n",
      "iter 2061 ---  Loss: 2.871459074318409    Accuracy: 87.1875\n",
      "iter 2062 ---  Loss: 2.85876128077507    Accuracy: 87.8125\n",
      "iter 2063 ---  Loss: 3.285054422914982    Accuracy: 86.09375\n",
      "iter 2064 ---  Loss: 3.1402371749281883    Accuracy: 87.8125\n",
      "iter 2065 ---  Loss: 3.5533907413482666    Accuracy: 85.78125\n",
      "iter 2066 ---  Loss: 2.7030514031648636    Accuracy: 87.65625\n",
      "iter 2067 ---  Loss: 2.880734421312809    Accuracy: 87.65625\n",
      "iter 2068 ---  Loss: 3.3067841976881027    Accuracy: 87.34375\n",
      "iter 2069 ---  Loss: 2.8732750937342644    Accuracy: 87.65625\n",
      "iter 2070 ---  Loss: 3.0444431602954865    Accuracy: 86.25\n",
      "iter 2071 ---  Loss: 2.8249137476086617    Accuracy: 89.53125\n",
      "iter 2072 ---  Loss: 3.265174575150013    Accuracy: 88.125\n",
      "iter 2073 ---  Loss: 3.061033435165882    Accuracy: 88.28125\n",
      "iter 2074 ---  Loss: 2.7898743748664856    Accuracy: 86.09375\n",
      "iter 2075 ---  Loss: 2.9820020496845245    Accuracy: 88.75\n",
      "iter 2076 ---  Loss: 3.445111282169819    Accuracy: 86.09375\n",
      "iter 2077 ---  Loss: 3.670290671288967    Accuracy: 84.84375\n",
      "iter 2078 ---  Loss: 3.1039068922400475    Accuracy: 85.46875\n",
      "iter 2079 ---  Loss: 3.217640958726406    Accuracy: 87.5\n",
      "iter 2080 ---  Loss: 2.697145789861679    Accuracy: 88.4375\n",
      "iter 2081 ---  Loss: 3.050682842731476    Accuracy: 89.0625\n",
      "iter 2082 ---  Loss: 2.902972422540188    Accuracy: 86.71875\n",
      "iter 2083 ---  Loss: 3.133523091673851    Accuracy: 87.65625\n",
      "iter 2084 ---  Loss: 3.1398265659809113    Accuracy: 88.4375\n",
      "iter 2085 ---  Loss: 2.778599537909031    Accuracy: 86.71875\n",
      "iter 2086 ---  Loss: 2.6930168867111206    Accuracy: 88.59375\n",
      "iter 2087 ---  Loss: 2.6479856744408607    Accuracy: 87.8125\n",
      "iter 2088 ---  Loss: 2.9537946954369545    Accuracy: 89.375\n",
      "iter 2089 ---  Loss: 2.7698376923799515    Accuracy: 88.59375\n",
      "iter 2090 ---  Loss: 3.3656694293022156    Accuracy: 88.75\n",
      "iter 2091 ---  Loss: 3.0478260293602943    Accuracy: 87.5\n",
      "iter 2092 ---  Loss: 2.79009473323822    Accuracy: 86.875\n",
      "iter 2093 ---  Loss: 3.0368950814008713    Accuracy: 87.1875\n",
      "iter 2094 ---  Loss: 4.030175030231476    Accuracy: 85.15625\n",
      "iter 2095 ---  Loss: 2.9463383853435516    Accuracy: 89.84375\n",
      "iter 2096 ---  Loss: 3.1113148257136345    Accuracy: 87.5\n",
      "iter 2097 ---  Loss: 3.202613592147827    Accuracy: 88.28125\n",
      "iter 2098 ---  Loss: 2.5757545605301857    Accuracy: 88.4375\n",
      "iter 2099 ---  Loss: 3.0208073928952217    Accuracy: 85.9375\n",
      "iter 2100 ---  Loss: 3.197102539241314    Accuracy: 86.5625\n",
      "iter 2101 ---  Loss: 2.9447940960526466    Accuracy: 87.03125\n",
      "iter 2102 ---  Loss: 2.793746404349804    Accuracy: 89.0625\n",
      "iter 2103 ---  Loss: 3.0451759919524193    Accuracy: 85.3125\n",
      "iter 2104 ---  Loss: 3.268275685608387    Accuracy: 85.0\n",
      "iter 2105 ---  Loss: 3.0607655495405197    Accuracy: 86.875\n",
      "iter 2106 ---  Loss: 2.757413662970066    Accuracy: 87.96875\n",
      "iter 2107 ---  Loss: 3.120912544429302    Accuracy: 85.9375\n",
      "iter 2108 ---  Loss: 3.934327259659767    Accuracy: 83.125\n",
      "iter 2109 ---  Loss: 3.4664586633443832    Accuracy: 85.625\n",
      "iter 2110 ---  Loss: 3.364723637700081    Accuracy: 84.53125\n",
      "iter 2111 ---  Loss: 3.151231661438942    Accuracy: 86.875\n",
      "iter 2112 ---  Loss: 3.368337020277977    Accuracy: 85.15625\n",
      "iter 2113 ---  Loss: 2.8493951857089996    Accuracy: 86.875\n",
      "iter 2114 ---  Loss: 3.2100100964307785    Accuracy: 85.9375\n",
      "iter 2115 ---  Loss: 3.578407697379589    Accuracy: 84.6875\n",
      "iter 2116 ---  Loss: 3.0604316890239716    Accuracy: 85.78125\n",
      "iter 2117 ---  Loss: 3.519302062690258    Accuracy: 85.78125\n",
      "iter 2118 ---  Loss: 3.4862299636006355    Accuracy: 86.40625\n",
      "iter 2119 ---  Loss: 2.565994530916214    Accuracy: 87.8125\n",
      "iter 2120 ---  Loss: 3.2751332446932793    Accuracy: 87.03125\n",
      "iter 2121 ---  Loss: 3.7346283569931984    Accuracy: 84.84375\n",
      "iter 2122 ---  Loss: 3.040332794189453    Accuracy: 90.3125\n",
      "iter 2123 ---  Loss: 3.5993957817554474    Accuracy: 85.3125\n",
      "iter 2124 ---  Loss: 2.730247639119625    Accuracy: 87.65625\n",
      "iter 2125 ---  Loss: 3.170115552842617    Accuracy: 89.6875\n",
      "iter 2126 ---  Loss: 3.0986350551247597    Accuracy: 85.625\n",
      "iter 2127 ---  Loss: 3.4167525246739388    Accuracy: 87.5\n",
      "iter 2128 ---  Loss: 2.812064714729786    Accuracy: 87.96875\n",
      "iter 2129 ---  Loss: 2.9914178252220154    Accuracy: 86.5625\n",
      "iter 2130 ---  Loss: 3.0865408405661583    Accuracy: 87.1875\n",
      "iter 2131 ---  Loss: 2.74407147616148    Accuracy: 87.5\n",
      "iter 2132 ---  Loss: 3.5921302884817123    Accuracy: 85.9375\n",
      "iter 2133 ---  Loss: 3.443019852042198    Accuracy: 86.09375\n",
      "iter 2134 ---  Loss: 2.686024948954582    Accuracy: 86.875\n",
      "iter 2135 ---  Loss: 2.9625447019934654    Accuracy: 87.65625\n",
      "iter 2136 ---  Loss: 2.723698005080223    Accuracy: 88.125\n",
      "iter 2137 ---  Loss: 3.6116824820637703    Accuracy: 86.25\n",
      "iter 2138 ---  Loss: 3.131763309240341    Accuracy: 86.5625\n",
      "iter 2139 ---  Loss: 3.0555436983704567    Accuracy: 86.5625\n",
      "iter 2140 ---  Loss: 3.0266185998916626    Accuracy: 87.03125\n",
      "iter 2141 ---  Loss: 3.6909207552671432    Accuracy: 85.46875\n",
      "iter 2142 ---  Loss: 2.9789411649107933    Accuracy: 87.1875\n",
      "iter 2143 ---  Loss: 3.18403959274292    Accuracy: 87.1875\n",
      "iter 2144 ---  Loss: 3.4168143942952156    Accuracy: 85.0\n",
      "iter 2145 ---  Loss: 2.9722491949796677    Accuracy: 86.5625\n",
      "iter 2146 ---  Loss: 2.9200183898210526    Accuracy: 86.5625\n",
      "iter 2147 ---  Loss: 3.2789073288440704    Accuracy: 86.875\n",
      "iter 2148 ---  Loss: 3.2748742178082466    Accuracy: 86.71875\n",
      "iter 2149 ---  Loss: 3.0127334147691727    Accuracy: 88.75\n",
      "iter 2150 ---  Loss: 3.3705349937081337    Accuracy: 85.3125\n",
      "iter 2151 ---  Loss: 2.4144948571920395    Accuracy: 88.75\n",
      "iter 2152 ---  Loss: 3.06480872631073    Accuracy: 86.5625\n",
      "iter 2153 ---  Loss: 3.552223466336727    Accuracy: 85.9375\n",
      "iter 2154 ---  Loss: 3.3732962384819984    Accuracy: 87.03125\n",
      "iter 2155 ---  Loss: 3.339980825781822    Accuracy: 86.40625\n",
      "iter 2156 ---  Loss: 3.058303751051426    Accuracy: 86.5625\n",
      "iter 2157 ---  Loss: 2.9725694432854652    Accuracy: 87.96875\n",
      "iter 2158 ---  Loss: 2.816871702671051    Accuracy: 86.71875\n",
      "iter 2159 ---  Loss: 3.205075442790985    Accuracy: 88.28125\n",
      "iter 2160 ---  Loss: 3.0050271674990654    Accuracy: 86.40625\n",
      "iter 2161 ---  Loss: 2.5873132050037384    Accuracy: 87.96875\n",
      "iter 2162 ---  Loss: 2.9759078919887543    Accuracy: 88.28125\n",
      "iter 2163 ---  Loss: 2.8495696634054184    Accuracy: 88.4375\n",
      "iter 2164 ---  Loss: 2.7149575501680374    Accuracy: 87.65625\n",
      "iter 2165 ---  Loss: 3.5192215889692307    Accuracy: 87.03125\n",
      "iter 2166 ---  Loss: 2.9190596491098404    Accuracy: 85.15625\n",
      "iter 2167 ---  Loss: 2.9819657132029533    Accuracy: 84.84375\n",
      "iter 2168 ---  Loss: 2.9204278215765953    Accuracy: 87.96875\n",
      "iter 2169 ---  Loss: 3.0069975405931473    Accuracy: 86.5625\n",
      "iter 2170 ---  Loss: 2.7349076196551323    Accuracy: 89.6875\n",
      "iter 2171 ---  Loss: 3.131777413189411    Accuracy: 87.8125\n",
      "iter 2172 ---  Loss: 2.775430142879486    Accuracy: 88.28125\n",
      "iter 2173 ---  Loss: 3.251318633556366    Accuracy: 88.75\n",
      "iter 2174 ---  Loss: 3.0593393445014954    Accuracy: 87.1875\n",
      "iter 2175 ---  Loss: 2.8635181188583374    Accuracy: 89.0625\n",
      "iter 2176 ---  Loss: 2.88609179854393    Accuracy: 88.59375\n",
      "iter 2177 ---  Loss: 2.652793601155281    Accuracy: 88.59375\n",
      "iter 2178 ---  Loss: 2.9414945393800735    Accuracy: 86.71875\n",
      "iter 2179 ---  Loss: 2.8819536194205284    Accuracy: 87.65625\n",
      "iter 2180 ---  Loss: 3.215443655848503    Accuracy: 87.5\n",
      "iter 2181 ---  Loss: 2.6966708600521088    Accuracy: 87.96875\n",
      "iter 2182 ---  Loss: 3.4550613686442375    Accuracy: 86.09375\n",
      "iter 2183 ---  Loss: 3.157743290066719    Accuracy: 86.25\n",
      "iter 2184 ---  Loss: 2.7168821692466736    Accuracy: 88.28125\n",
      "iter 2185 ---  Loss: 3.1133633106946945    Accuracy: 87.03125\n",
      "iter 2186 ---  Loss: 2.7234915867447853    Accuracy: 87.5\n",
      "iter 2187 ---  Loss: 2.8692258447408676    Accuracy: 86.71875\n",
      "iter 2188 ---  Loss: 2.942743629217148    Accuracy: 88.59375\n",
      "iter 2189 ---  Loss: 2.6697138622403145    Accuracy: 88.75\n",
      "iter 2190 ---  Loss: 3.1489085778594017    Accuracy: 87.03125\n",
      "iter 2191 ---  Loss: 3.4307016357779503    Accuracy: 86.71875\n",
      "iter 2192 ---  Loss: 2.9052367955446243    Accuracy: 87.1875\n",
      "iter 2193 ---  Loss: 3.117741137742996    Accuracy: 87.34375\n",
      "iter 2194 ---  Loss: 3.0750209614634514    Accuracy: 87.5\n",
      "iter 2195 ---  Loss: 2.8327260613441467    Accuracy: 86.875\n",
      "iter 2196 ---  Loss: 3.3844479843974113    Accuracy: 87.1875\n",
      "iter 2197 ---  Loss: 3.0142192244529724    Accuracy: 88.59375\n",
      "iter 2198 ---  Loss: 3.2657053247094154    Accuracy: 88.59375\n",
      "iter 2199 ---  Loss: 3.044365204870701    Accuracy: 88.125\n",
      "iter 2200 ---  Loss: 2.9718479961156845    Accuracy: 87.8125\n",
      "iter 2201 ---  Loss: 3.345857374370098    Accuracy: 87.1875\n",
      "iter 2202 ---  Loss: 3.5840081349015236    Accuracy: 84.84375\n",
      "iter 2203 ---  Loss: 3.6876927241683006    Accuracy: 86.09375\n",
      "iter 2204 ---  Loss: 3.053620956838131    Accuracy: 87.96875\n",
      "iter 2205 ---  Loss: 2.7264786809682846    Accuracy: 89.53125\n",
      "iter 2206 ---  Loss: 3.0368796288967133    Accuracy: 87.34375\n",
      "iter 2207 ---  Loss: 3.4949868842959404    Accuracy: 86.09375\n",
      "iter 2208 ---  Loss: 3.151321604847908    Accuracy: 87.65625\n",
      "iter 2209 ---  Loss: 2.8477598056197166    Accuracy: 86.71875\n",
      "iter 2210 ---  Loss: 3.41674030572176    Accuracy: 86.40625\n",
      "iter 2211 ---  Loss: 3.5180623456835747    Accuracy: 88.28125\n",
      "iter 2212 ---  Loss: 2.9196702912449837    Accuracy: 87.5\n",
      "iter 2213 ---  Loss: 2.8669483587145805    Accuracy: 89.21875\n",
      "iter 2214 ---  Loss: 2.8789836913347244    Accuracy: 88.4375\n",
      "iter 2215 ---  Loss: 3.1067890524864197    Accuracy: 84.84375\n",
      "iter 2216 ---  Loss: 2.9304109066724777    Accuracy: 87.34375\n",
      "iter 2217 ---  Loss: 2.996388003230095    Accuracy: 89.0625\n",
      "iter 2218 ---  Loss: 3.100944235920906    Accuracy: 89.53125\n",
      "iter 2219 ---  Loss: 3.144138529896736    Accuracy: 87.8125\n",
      "iter 2220 ---  Loss: 3.723611891269684    Accuracy: 86.40625\n",
      "iter 2221 ---  Loss: 2.869721941649914    Accuracy: 87.8125\n",
      "iter 2222 ---  Loss: 2.918238550424576    Accuracy: 89.53125\n",
      "iter 2223 ---  Loss: 3.372336760163307    Accuracy: 87.5\n",
      "iter 2224 ---  Loss: 3.099241226911545    Accuracy: 85.78125\n",
      "iter 2225 ---  Loss: 3.1837616860866547    Accuracy: 85.46875\n",
      "iter 2226 ---  Loss: 3.1924741938710213    Accuracy: 86.71875\n",
      "iter 2227 ---  Loss: 3.3260941803455353    Accuracy: 87.03125\n",
      "iter 2228 ---  Loss: 2.8043811172246933    Accuracy: 88.125\n",
      "iter 2229 ---  Loss: 2.883096106350422    Accuracy: 84.84375\n",
      "iter 2230 ---  Loss: 2.9116937294602394    Accuracy: 86.875\n",
      "iter 2231 ---  Loss: 2.640104703605175    Accuracy: 87.34375\n",
      "iter 2232 ---  Loss: 2.80456355959177    Accuracy: 87.34375\n",
      "iter 2233 ---  Loss: 3.639258176088333    Accuracy: 86.5625\n",
      "iter 2234 ---  Loss: 3.21277192234993    Accuracy: 86.875\n",
      "iter 2235 ---  Loss: 3.251473732292652    Accuracy: 86.71875\n",
      "iter 2236 ---  Loss: 3.1678115874528885    Accuracy: 86.875\n",
      "iter 2237 ---  Loss: 3.5039606615900993    Accuracy: 85.46875\n",
      "iter 2238 ---  Loss: 3.246165692806244    Accuracy: 88.59375\n",
      "iter 2239 ---  Loss: 3.816899634897709    Accuracy: 85.15625\n",
      "iter 2240 ---  Loss: 3.233051158487797    Accuracy: 87.34375\n",
      "iter 2241 ---  Loss: 3.031361110508442    Accuracy: 88.4375\n",
      "iter 2242 ---  Loss: 2.682912327349186    Accuracy: 88.125\n",
      "iter 2243 ---  Loss: 3.249978296458721    Accuracy: 85.15625\n",
      "iter 2244 ---  Loss: 2.8839220106601715    Accuracy: 87.03125\n",
      "iter 2245 ---  Loss: 4.052542500197887    Accuracy: 85.625\n",
      "iter 2246 ---  Loss: 2.8812872171401978    Accuracy: 86.25\n",
      "iter 2247 ---  Loss: 3.300557292997837    Accuracy: 87.34375\n",
      "iter 2248 ---  Loss: 2.6588886082172394    Accuracy: 88.28125\n",
      "iter 2249 ---  Loss: 3.1363542452454567    Accuracy: 86.25\n",
      "iter 2250 ---  Loss: 3.0577150508761406    Accuracy: 85.9375\n",
      "iter 2251 ---  Loss: 2.7501346692442894    Accuracy: 88.125\n",
      "iter 2252 ---  Loss: 2.918758377432823    Accuracy: 89.53125\n",
      "iter 2253 ---  Loss: 3.20386616140604    Accuracy: 86.25\n",
      "iter 2254 ---  Loss: 3.315461941063404    Accuracy: 86.71875\n",
      "iter 2255 ---  Loss: 2.7755918726325035    Accuracy: 89.0625\n",
      "iter 2256 ---  Loss: 2.7015498727560043    Accuracy: 87.5\n",
      "iter 2257 ---  Loss: 2.8908728137612343    Accuracy: 87.65625\n",
      "iter 2258 ---  Loss: 2.7515503093600273    Accuracy: 87.5\n",
      "iter 2259 ---  Loss: 3.5579798743128777    Accuracy: 85.0\n",
      "iter 2260 ---  Loss: 3.577556297183037    Accuracy: 87.65625\n",
      "iter 2261 ---  Loss: 3.1921408250927925    Accuracy: 86.5625\n",
      "iter 2262 ---  Loss: 2.7745703756809235    Accuracy: 87.65625\n",
      "iter 2263 ---  Loss: 2.91738723218441    Accuracy: 88.4375\n",
      "iter 2264 ---  Loss: 2.832552708685398    Accuracy: 87.03125\n",
      "iter 2265 ---  Loss: 3.6413668990135193    Accuracy: 85.3125\n",
      "iter 2266 ---  Loss: 2.688978709280491    Accuracy: 89.375\n",
      "iter 2267 ---  Loss: 2.8710168972611427    Accuracy: 85.9375\n",
      "iter 2268 ---  Loss: 2.8046878427267075    Accuracy: 87.5\n",
      "iter 2269 ---  Loss: 3.45890124887228    Accuracy: 86.40625\n",
      "iter 2270 ---  Loss: 2.95646233856678    Accuracy: 88.28125\n",
      "iter 2271 ---  Loss: 2.7286465764045715    Accuracy: 88.4375\n",
      "iter 2272 ---  Loss: 2.6194313541054726    Accuracy: 89.53125\n",
      "iter 2273 ---  Loss: 2.894026555120945    Accuracy: 85.78125\n",
      "iter 2274 ---  Loss: 2.770512692630291    Accuracy: 87.5\n",
      "iter 2275 ---  Loss: 3.2626325115561485    Accuracy: 88.59375\n",
      "iter 2276 ---  Loss: 2.5494892224669456    Accuracy: 88.4375\n",
      "iter 2277 ---  Loss: 2.713121511042118    Accuracy: 88.125\n",
      "iter 2278 ---  Loss: 2.628540761768818    Accuracy: 88.28125\n",
      "iter 2279 ---  Loss: 2.6962358579039574    Accuracy: 86.71875\n",
      "iter 2280 ---  Loss: 2.4571608379483223    Accuracy: 87.96875\n",
      "iter 2281 ---  Loss: 2.833252228796482    Accuracy: 88.90625\n",
      "iter 2282 ---  Loss: 3.7928583920001984    Accuracy: 87.1875\n",
      "iter 2283 ---  Loss: 3.1705127879977226    Accuracy: 87.34375\n",
      "iter 2284 ---  Loss: 3.4186947122216225    Accuracy: 86.875\n",
      "iter 2285 ---  Loss: 2.473445750772953    Accuracy: 88.90625\n",
      "iter 2286 ---  Loss: 2.587382785975933    Accuracy: 89.0625\n",
      "iter 2287 ---  Loss: 2.8991074562072754    Accuracy: 85.46875\n",
      "iter 2288 ---  Loss: 3.043189585208893    Accuracy: 88.90625\n",
      "iter 2289 ---  Loss: 3.1050409376621246    Accuracy: 87.5\n",
      "iter 2290 ---  Loss: 3.5303304493427277    Accuracy: 87.03125\n",
      "iter 2291 ---  Loss: 3.342719592154026    Accuracy: 87.1875\n",
      "iter 2292 ---  Loss: 3.2242577895522118    Accuracy: 87.03125\n",
      "iter 2293 ---  Loss: 2.7075916081666946    Accuracy: 87.1875\n",
      "iter 2294 ---  Loss: 2.8193140402436256    Accuracy: 87.65625\n",
      "iter 2295 ---  Loss: 2.9362831488251686    Accuracy: 87.8125\n",
      "iter 2296 ---  Loss: 2.941180795431137    Accuracy: 87.34375\n",
      "iter 2297 ---  Loss: 3.230504550039768    Accuracy: 87.8125\n",
      "iter 2298 ---  Loss: 3.0408614575862885    Accuracy: 88.4375\n",
      "iter 2299 ---  Loss: 2.9322403222322464    Accuracy: 86.5625\n",
      "iter 2300 ---  Loss: 3.0515494346618652    Accuracy: 88.28125\n",
      "iter 2301 ---  Loss: 3.8549973517656326    Accuracy: 85.78125\n",
      "iter 2302 ---  Loss: 3.365064449608326    Accuracy: 86.40625\n",
      "iter 2303 ---  Loss: 3.566969908773899    Accuracy: 87.34375\n",
      "iter 2304 ---  Loss: 3.519677497446537    Accuracy: 85.15625\n",
      "iter 2305 ---  Loss: 3.1630321368575096    Accuracy: 87.34375\n",
      "iter 2306 ---  Loss: 3.118009641766548    Accuracy: 86.71875\n",
      "iter 2307 ---  Loss: 2.9174949452281    Accuracy: 87.1875\n",
      "iter 2308 ---  Loss: 3.025769717991352    Accuracy: 87.34375\n",
      "iter 2309 ---  Loss: 3.5875247418880463    Accuracy: 85.625\n",
      "iter 2310 ---  Loss: 3.4753608405590057    Accuracy: 87.1875\n",
      "iter 2311 ---  Loss: 3.589151680469513    Accuracy: 86.71875\n",
      "iter 2312 ---  Loss: 2.8976602405309677    Accuracy: 86.875\n",
      "iter 2313 ---  Loss: 2.531563453376293    Accuracy: 89.53125\n",
      "iter 2314 ---  Loss: 3.141539789736271    Accuracy: 86.09375\n",
      "iter 2315 ---  Loss: 2.7024078518152237    Accuracy: 87.65625\n",
      "iter 2316 ---  Loss: 3.128519020974636    Accuracy: 85.46875\n",
      "iter 2317 ---  Loss: 2.8868719786405563    Accuracy: 87.65625\n",
      "iter 2318 ---  Loss: 3.016869954764843    Accuracy: 88.4375\n",
      "iter 2319 ---  Loss: 3.3667316883802414    Accuracy: 86.875\n",
      "iter 2320 ---  Loss: 2.6348665803670883    Accuracy: 88.4375\n",
      "iter 2321 ---  Loss: 2.9418989792466164    Accuracy: 88.28125\n",
      "iter 2322 ---  Loss: 2.5353744104504585    Accuracy: 90.0\n",
      "iter 2323 ---  Loss: 2.8973727598786354    Accuracy: 85.3125\n",
      "iter 2324 ---  Loss: 4.801149956882    Accuracy: 85.46875\n",
      "iter 2325 ---  Loss: 3.498953215777874    Accuracy: 86.71875\n",
      "iter 2326 ---  Loss: 2.3244278132915497    Accuracy: 88.4375\n",
      "iter 2327 ---  Loss: 3.392389379441738    Accuracy: 85.3125\n",
      "iter 2328 ---  Loss: 2.9537497982382774    Accuracy: 87.5\n",
      "iter 2329 ---  Loss: 2.9548789709806442    Accuracy: 88.90625\n",
      "iter 2330 ---  Loss: 4.063469909131527    Accuracy: 87.8125\n",
      "iter 2331 ---  Loss: 3.2431019470095634    Accuracy: 87.8125\n",
      "iter 2332 ---  Loss: 3.326539285480976    Accuracy: 87.03125\n",
      "iter 2333 ---  Loss: 2.8686496689915657    Accuracy: 88.28125\n",
      "iter 2334 ---  Loss: 3.405911661684513    Accuracy: 86.71875\n",
      "iter 2335 ---  Loss: 3.051990695297718    Accuracy: 87.65625\n",
      "iter 2336 ---  Loss: 3.185619078576565    Accuracy: 85.78125\n",
      "iter 2337 ---  Loss: 2.8793402910232544    Accuracy: 87.65625\n",
      "iter 2338 ---  Loss: 3.35255891084671    Accuracy: 87.65625\n",
      "iter 2339 ---  Loss: 3.1686748042702675    Accuracy: 86.40625\n",
      "iter 2340 ---  Loss: 2.965116024017334    Accuracy: 87.96875\n",
      "iter 2341 ---  Loss: 2.9427845627069473    Accuracy: 88.4375\n",
      "iter 2342 ---  Loss: 3.2627618834376335    Accuracy: 89.53125\n",
      "iter 2343 ---  Loss: 3.142167277634144    Accuracy: 88.125\n",
      "iter 2344 ---  Loss: 3.2056799605488777    Accuracy: 86.71875\n",
      "iter 2345 ---  Loss: 2.718314714729786    Accuracy: 89.375\n",
      "iter 2346 ---  Loss: 3.5102624744176865    Accuracy: 87.1875\n",
      "iter 2347 ---  Loss: 2.8767608776688576    Accuracy: 87.1875\n",
      "iter 2348 ---  Loss: 3.0305251255631447    Accuracy: 87.96875\n",
      "iter 2349 ---  Loss: 2.7442723363637924    Accuracy: 86.71875\n",
      "iter 2350 ---  Loss: 3.438367009162903    Accuracy: 86.5625\n",
      "iter 2351 ---  Loss: 3.7345171123743057    Accuracy: 84.84375\n",
      "iter 2352 ---  Loss: 3.1914788335561752    Accuracy: 86.71875\n",
      "iter 2353 ---  Loss: 3.07596468180418    Accuracy: 87.65625\n",
      "iter 2354 ---  Loss: 2.957281731069088    Accuracy: 85.625\n",
      "iter 2355 ---  Loss: 3.176807388663292    Accuracy: 86.5625\n",
      "iter 2356 ---  Loss: 3.6467606127262115    Accuracy: 87.8125\n",
      "iter 2357 ---  Loss: 3.3682440742850304    Accuracy: 87.65625\n",
      "iter 2358 ---  Loss: 3.2531232610344887    Accuracy: 85.9375\n",
      "iter 2359 ---  Loss: 2.7575226202607155    Accuracy: 87.34375\n",
      "iter 2360 ---  Loss: 3.3165328204631805    Accuracy: 86.5625\n",
      "iter 2361 ---  Loss: 3.6764279901981354    Accuracy: 86.09375\n",
      "iter 2362 ---  Loss: 3.3493001088500023    Accuracy: 87.65625\n",
      "iter 2363 ---  Loss: 3.723675563931465    Accuracy: 86.25\n",
      "iter 2364 ---  Loss: 3.2109522074460983    Accuracy: 87.96875\n",
      "iter 2365 ---  Loss: 2.8439658731222153    Accuracy: 86.5625\n",
      "iter 2366 ---  Loss: 2.662611111998558    Accuracy: 87.34375\n",
      "iter 2367 ---  Loss: 3.2722475975751877    Accuracy: 86.40625\n",
      "iter 2368 ---  Loss: 2.9441488310694695    Accuracy: 87.8125\n",
      "iter 2369 ---  Loss: 3.3526868000626564    Accuracy: 86.875\n",
      "iter 2370 ---  Loss: 3.3421791717410088    Accuracy: 88.4375\n",
      "iter 2371 ---  Loss: 3.108511246740818    Accuracy: 86.5625\n",
      "iter 2372 ---  Loss: 3.7849308997392654    Accuracy: 86.40625\n",
      "iter 2373 ---  Loss: 3.4829728454351425    Accuracy: 85.78125\n",
      "iter 2374 ---  Loss: 3.00959762185812    Accuracy: 88.28125\n",
      "iter 2375 ---  Loss: 2.9651529267430305    Accuracy: 86.25\n",
      "iter 2376 ---  Loss: 3.490761011838913    Accuracy: 87.1875\n",
      "iter 2377 ---  Loss: 2.998939096927643    Accuracy: 86.25\n",
      "iter 2378 ---  Loss: 2.633924387395382    Accuracy: 87.96875\n",
      "iter 2379 ---  Loss: 3.845316655933857    Accuracy: 84.53125\n",
      "iter 2380 ---  Loss: 3.0803668797016144    Accuracy: 87.03125\n",
      "iter 2381 ---  Loss: 3.6988877579569817    Accuracy: 86.25\n",
      "iter 2382 ---  Loss: 3.3074172884225845    Accuracy: 86.71875\n",
      "iter 2383 ---  Loss: 3.1181126683950424    Accuracy: 88.59375\n",
      "iter 2384 ---  Loss: 3.0421039387583733    Accuracy: 87.1875\n",
      "iter 2385 ---  Loss: 2.8131684064865112    Accuracy: 89.21875\n",
      "iter 2386 ---  Loss: 2.785108596086502    Accuracy: 88.28125\n",
      "iter 2387 ---  Loss: 3.998325400054455    Accuracy: 85.0\n",
      "iter 2388 ---  Loss: 3.117844171822071    Accuracy: 88.28125\n",
      "iter 2389 ---  Loss: 3.266428753733635    Accuracy: 87.34375\n",
      "iter 2390 ---  Loss: 3.5147550851106644    Accuracy: 85.0\n",
      "iter 2391 ---  Loss: 3.72077439725399    Accuracy: 84.84375\n",
      "iter 2392 ---  Loss: 2.972949653863907    Accuracy: 87.8125\n",
      "iter 2393 ---  Loss: 2.7116083949804306    Accuracy: 87.8125\n",
      "iter 2394 ---  Loss: 3.3085766583681107    Accuracy: 86.09375\n",
      "iter 2395 ---  Loss: 2.6717793494462967    Accuracy: 86.875\n",
      "iter 2396 ---  Loss: 2.777274839580059    Accuracy: 87.03125\n",
      "iter 2397 ---  Loss: 2.698826625943184    Accuracy: 90.15625\n",
      "iter 2398 ---  Loss: 2.6198370158672333    Accuracy: 87.03125\n",
      "iter 2399 ---  Loss: 3.823098301887512    Accuracy: 84.21875\n",
      "iter 2400 ---  Loss: 3.2609433978796005    Accuracy: 87.5\n",
      "iter 2401 ---  Loss: 3.092720188200474    Accuracy: 87.5\n",
      "iter 2402 ---  Loss: 3.850948929786682    Accuracy: 84.375\n",
      "iter 2403 ---  Loss: 2.753498114645481    Accuracy: 87.96875\n",
      "iter 2404 ---  Loss: 2.5227251797914505    Accuracy: 87.03125\n",
      "iter 2405 ---  Loss: 3.2576840817928314    Accuracy: 86.5625\n",
      "iter 2406 ---  Loss: 2.8478496000170708    Accuracy: 88.125\n",
      "iter 2407 ---  Loss: 3.095088630914688    Accuracy: 87.8125\n",
      "iter 2408 ---  Loss: 3.109450124204159    Accuracy: 86.5625\n",
      "iter 2409 ---  Loss: 3.266653463244438    Accuracy: 87.1875\n",
      "iter 2410 ---  Loss: 3.148461066186428    Accuracy: 86.09375\n",
      "iter 2411 ---  Loss: 2.8793708980083466    Accuracy: 86.875\n",
      "iter 2412 ---  Loss: 3.3289369642734528    Accuracy: 85.78125\n",
      "iter 2413 ---  Loss: 3.0332526937127113    Accuracy: 88.4375\n",
      "iter 2414 ---  Loss: 3.1115343272686005    Accuracy: 85.78125\n",
      "iter 2415 ---  Loss: 3.2611945047974586    Accuracy: 87.65625\n",
      "iter 2416 ---  Loss: 2.6870847567915916    Accuracy: 88.28125\n",
      "iter 2417 ---  Loss: 3.319209448993206    Accuracy: 86.09375\n",
      "iter 2418 ---  Loss: 3.1241938397288322    Accuracy: 86.40625\n",
      "iter 2419 ---  Loss: 2.765736110508442    Accuracy: 86.25\n",
      "iter 2420 ---  Loss: 2.826837994158268    Accuracy: 87.03125\n",
      "iter 2421 ---  Loss: 3.3473478332161903    Accuracy: 87.5\n",
      "iter 2422 ---  Loss: 2.812132939696312    Accuracy: 87.03125\n",
      "iter 2423 ---  Loss: 2.9006976038217545    Accuracy: 88.90625\n",
      "iter 2424 ---  Loss: 2.971900351345539    Accuracy: 87.03125\n",
      "iter 2425 ---  Loss: 3.7122485861182213    Accuracy: 87.03125\n",
      "iter 2426 ---  Loss: 3.2975632920861244    Accuracy: 86.5625\n",
      "iter 2427 ---  Loss: 3.0350188687443733    Accuracy: 88.4375\n",
      "iter 2428 ---  Loss: 3.298806019127369    Accuracy: 87.65625\n",
      "iter 2429 ---  Loss: 3.740348443388939    Accuracy: 86.5625\n",
      "iter 2430 ---  Loss: 2.904292732477188    Accuracy: 87.96875\n",
      "iter 2431 ---  Loss: 3.3634311631321907    Accuracy: 87.5\n",
      "iter 2432 ---  Loss: 2.808413051068783    Accuracy: 90.0\n",
      "iter 2433 ---  Loss: 2.74852155148983    Accuracy: 87.65625\n",
      "iter 2434 ---  Loss: 3.092067673802376    Accuracy: 86.25\n",
      "iter 2435 ---  Loss: 3.692050740122795    Accuracy: 86.5625\n",
      "iter 2436 ---  Loss: 3.2396518662571907    Accuracy: 88.59375\n",
      "iter 2437 ---  Loss: 3.5816241800785065    Accuracy: 87.1875\n",
      "iter 2438 ---  Loss: 2.8838801085948944    Accuracy: 86.71875\n",
      "iter 2439 ---  Loss: 2.867552228271961    Accuracy: 88.4375\n",
      "iter 2440 ---  Loss: 2.9871178567409515    Accuracy: 87.65625\n",
      "iter 2441 ---  Loss: 3.2334075570106506    Accuracy: 87.03125\n",
      "iter 2442 ---  Loss: 2.876540020108223    Accuracy: 87.96875\n",
      "iter 2443 ---  Loss: 2.92589358240366    Accuracy: 86.40625\n",
      "iter 2444 ---  Loss: 2.848868541419506    Accuracy: 87.1875\n",
      "iter 2445 ---  Loss: 3.3129876405000687    Accuracy: 87.5\n",
      "iter 2446 ---  Loss: 3.1852858439087868    Accuracy: 88.125\n",
      "iter 2447 ---  Loss: 3.6065920665860176    Accuracy: 87.03125\n",
      "iter 2448 ---  Loss: 2.8712628185749054    Accuracy: 88.75\n",
      "iter 2449 ---  Loss: 3.1485830545425415    Accuracy: 86.875\n",
      "iter 2450 ---  Loss: 3.3379538133740425    Accuracy: 86.71875\n",
      "iter 2451 ---  Loss: 2.9131627082824707    Accuracy: 87.96875\n",
      "iter 2452 ---  Loss: 3.0138539150357246    Accuracy: 85.9375\n",
      "iter 2453 ---  Loss: 3.2069253206253054    Accuracy: 89.5\n",
      "Epoch 2/4\n",
      "-------------\n",
      "iter 0 ---  Loss: 2.979926459491253    Accuracy: 86.09375\n",
      "iter 1 ---  Loss: 2.7294153943657875    Accuracy: 91.09375\n",
      "iter 2 ---  Loss: 3.2322361022233963    Accuracy: 87.34375\n",
      "iter 3 ---  Loss: 2.9488146379590034    Accuracy: 89.21875\n",
      "iter 4 ---  Loss: 3.1217161118984222    Accuracy: 86.875\n",
      "iter 5 ---  Loss: 3.481972947716713    Accuracy: 85.0\n",
      "iter 6 ---  Loss: 2.752245105803013    Accuracy: 86.25\n",
      "iter 7 ---  Loss: 2.701338365674019    Accuracy: 90.3125\n",
      "iter 8 ---  Loss: 2.761851541697979    Accuracy: 88.75\n",
      "iter 9 ---  Loss: 3.4586198776960373    Accuracy: 86.5625\n",
      "iter 10 ---  Loss: 2.9671567380428314    Accuracy: 86.71875\n",
      "iter 11 ---  Loss: 3.7069461420178413    Accuracy: 86.875\n",
      "iter 12 ---  Loss: 2.9771666824817657    Accuracy: 85.15625\n",
      "iter 13 ---  Loss: 3.020534060895443    Accuracy: 87.03125\n",
      "iter 14 ---  Loss: 3.13313976675272    Accuracy: 86.40625\n",
      "iter 15 ---  Loss: 2.9536162763834    Accuracy: 88.4375\n",
      "iter 16 ---  Loss: 3.0948430076241493    Accuracy: 85.9375\n",
      "iter 17 ---  Loss: 3.411093480885029    Accuracy: 88.4375\n",
      "iter 18 ---  Loss: 3.491046778857708    Accuracy: 86.875\n",
      "iter 19 ---  Loss: 3.3734909370541573    Accuracy: 86.71875\n",
      "iter 20 ---  Loss: 2.810127303004265    Accuracy: 88.4375\n",
      "iter 21 ---  Loss: 3.362185947597027    Accuracy: 84.6875\n",
      "iter 22 ---  Loss: 2.7469548881053925    Accuracy: 88.125\n",
      "iter 23 ---  Loss: 3.1378250643610954    Accuracy: 85.3125\n",
      "iter 24 ---  Loss: 3.426454782485962    Accuracy: 86.09375\n",
      "iter 25 ---  Loss: 2.8251479044556618    Accuracy: 86.40625\n",
      "iter 26 ---  Loss: 3.1410702541470528    Accuracy: 86.875\n",
      "iter 27 ---  Loss: 3.0965172424912453    Accuracy: 86.875\n",
      "iter 28 ---  Loss: 2.857825957238674    Accuracy: 85.9375\n",
      "iter 29 ---  Loss: 2.6043118610978127    Accuracy: 88.4375\n",
      "iter 30 ---  Loss: 3.6214488595724106    Accuracy: 85.3125\n",
      "iter 31 ---  Loss: 3.2053766772150993    Accuracy: 85.625\n",
      "iter 32 ---  Loss: 2.535631373524666    Accuracy: 88.125\n",
      "iter 33 ---  Loss: 2.8744418248534203    Accuracy: 88.125\n",
      "iter 34 ---  Loss: 3.159225322306156    Accuracy: 86.875\n",
      "iter 35 ---  Loss: 3.1314882785081863    Accuracy: 87.5\n",
      "iter 36 ---  Loss: 3.1557771116495132    Accuracy: 87.8125\n",
      "iter 37 ---  Loss: 3.420616567134857    Accuracy: 85.78125\n",
      "iter 38 ---  Loss: 3.698299817740917    Accuracy: 85.78125\n",
      "iter 39 ---  Loss: 2.670278772711754    Accuracy: 88.4375\n",
      "iter 40 ---  Loss: 3.820130333304405    Accuracy: 86.09375\n",
      "iter 41 ---  Loss: 2.9553961157798767    Accuracy: 86.40625\n",
      "iter 42 ---  Loss: 2.9405858367681503    Accuracy: 88.125\n",
      "iter 43 ---  Loss: 2.7009961381554604    Accuracy: 88.75\n",
      "iter 44 ---  Loss: 3.0136608928442    Accuracy: 86.25\n",
      "iter 45 ---  Loss: 2.7583985924720764    Accuracy: 87.34375\n",
      "iter 46 ---  Loss: 3.195436328649521    Accuracy: 87.34375\n",
      "iter 47 ---  Loss: 3.4727000668644905    Accuracy: 85.9375\n",
      "iter 48 ---  Loss: 3.016184017062187    Accuracy: 88.125\n",
      "iter 49 ---  Loss: 2.74376779794693    Accuracy: 87.1875\n",
      "iter 50 ---  Loss: 3.1437516286969185    Accuracy: 85.625\n",
      "iter 51 ---  Loss: 2.9978913068771362    Accuracy: 87.03125\n",
      "iter 52 ---  Loss: 2.9942319467663765    Accuracy: 87.96875\n",
      "iter 53 ---  Loss: 3.565008081495762    Accuracy: 85.9375\n",
      "iter 54 ---  Loss: 3.128873221576214    Accuracy: 87.5\n",
      "iter 55 ---  Loss: 2.8914361000061035    Accuracy: 88.125\n",
      "iter 56 ---  Loss: 2.9066919088363647    Accuracy: 87.1875\n",
      "iter 57 ---  Loss: 2.8571226447820663    Accuracy: 87.34375\n",
      "iter 58 ---  Loss: 3.127702474594116    Accuracy: 88.28125\n",
      "iter 59 ---  Loss: 3.123465672135353    Accuracy: 84.84375\n",
      "iter 60 ---  Loss: 2.7584743723273277    Accuracy: 87.8125\n",
      "iter 61 ---  Loss: 2.9206385910511017    Accuracy: 87.96875\n",
      "iter 62 ---  Loss: 2.864849865436554    Accuracy: 87.5\n",
      "iter 63 ---  Loss: 3.686999224126339    Accuracy: 85.9375\n",
      "iter 64 ---  Loss: 3.382525958120823    Accuracy: 86.875\n",
      "iter 65 ---  Loss: 3.0631732046604156    Accuracy: 87.5\n",
      "iter 66 ---  Loss: 3.1680332869291306    Accuracy: 86.40625\n",
      "iter 67 ---  Loss: 2.7439760714769363    Accuracy: 88.125\n",
      "iter 68 ---  Loss: 3.5349753573536873    Accuracy: 86.25\n",
      "iter 69 ---  Loss: 2.906655304133892    Accuracy: 87.03125\n",
      "iter 70 ---  Loss: 2.896072067320347    Accuracy: 87.34375\n",
      "iter 71 ---  Loss: 3.282206028699875    Accuracy: 87.65625\n",
      "iter 72 ---  Loss: 3.0110483914613724    Accuracy: 87.5\n",
      "iter 73 ---  Loss: 3.351333864033222    Accuracy: 86.25\n",
      "iter 74 ---  Loss: 2.7337468713521957    Accuracy: 88.125\n",
      "iter 75 ---  Loss: 2.5269711688160896    Accuracy: 87.5\n",
      "iter 76 ---  Loss: 2.9582154229283333    Accuracy: 87.96875\n",
      "iter 77 ---  Loss: 2.747407928109169    Accuracy: 86.5625\n",
      "iter 78 ---  Loss: 2.793643534183502    Accuracy: 88.4375\n",
      "iter 79 ---  Loss: 3.460289888083935    Accuracy: 86.5625\n",
      "iter 80 ---  Loss: 2.5734362676739693    Accuracy: 89.375\n",
      "iter 81 ---  Loss: 3.3265088871121407    Accuracy: 86.71875\n",
      "iter 82 ---  Loss: 2.96693604439497    Accuracy: 86.71875\n",
      "iter 83 ---  Loss: 3.245140217244625    Accuracy: 87.34375\n",
      "iter 84 ---  Loss: 2.4446370154619217    Accuracy: 90.15625\n",
      "iter 85 ---  Loss: 3.2597552314400673    Accuracy: 87.96875\n",
      "iter 86 ---  Loss: 3.512940287590027    Accuracy: 88.90625\n",
      "iter 87 ---  Loss: 3.42760943621397    Accuracy: 85.3125\n",
      "iter 88 ---  Loss: 2.8437846675515175    Accuracy: 87.1875\n",
      "iter 89 ---  Loss: 2.899932987987995    Accuracy: 87.8125\n",
      "iter 90 ---  Loss: 2.7058188766241074    Accuracy: 90.46875\n",
      "iter 91 ---  Loss: 3.547266975045204    Accuracy: 86.25\n",
      "iter 92 ---  Loss: 3.0827303379774094    Accuracy: 87.1875\n",
      "iter 93 ---  Loss: 2.9922643899917603    Accuracy: 85.625\n",
      "iter 94 ---  Loss: 3.4199962243437767    Accuracy: 85.0\n",
      "iter 95 ---  Loss: 3.1113977432250977    Accuracy: 87.96875\n",
      "iter 96 ---  Loss: 3.262006238102913    Accuracy: 85.9375\n",
      "iter 97 ---  Loss: 3.2822003960609436    Accuracy: 87.1875\n",
      "iter 98 ---  Loss: 2.653989516198635    Accuracy: 87.5\n",
      "iter 99 ---  Loss: 3.235609196126461    Accuracy: 86.25\n",
      "iter 100 ---  Loss: 2.8153375908732414    Accuracy: 89.53125\n",
      "iter 101 ---  Loss: 2.79280386865139    Accuracy: 87.65625\n",
      "iter 102 ---  Loss: 3.2330412417650223    Accuracy: 87.8125\n",
      "iter 103 ---  Loss: 2.76861372590065    Accuracy: 87.03125\n",
      "iter 104 ---  Loss: 3.2373636215925217    Accuracy: 84.84375\n",
      "iter 105 ---  Loss: 3.359551675617695    Accuracy: 86.40625\n",
      "iter 106 ---  Loss: 2.821523889899254    Accuracy: 88.28125\n",
      "iter 107 ---  Loss: 2.8553726822137833    Accuracy: 87.34375\n",
      "iter 108 ---  Loss: 2.8442282527685165    Accuracy: 89.0625\n",
      "iter 109 ---  Loss: 3.048004001379013    Accuracy: 86.09375\n",
      "iter 110 ---  Loss: 2.7553812339901924    Accuracy: 89.0625\n",
      "iter 111 ---  Loss: 2.567317083477974    Accuracy: 87.34375\n",
      "iter 112 ---  Loss: 2.7942476347088814    Accuracy: 86.09375\n",
      "iter 113 ---  Loss: 3.2400451079010963    Accuracy: 87.03125\n",
      "iter 114 ---  Loss: 3.3646049201488495    Accuracy: 85.46875\n",
      "iter 115 ---  Loss: 2.71937657892704    Accuracy: 87.8125\n",
      "iter 116 ---  Loss: 3.7767692133784294    Accuracy: 87.65625\n",
      "iter 117 ---  Loss: 3.0650679394602776    Accuracy: 87.34375\n",
      "iter 118 ---  Loss: 2.931140013039112    Accuracy: 87.5\n",
      "iter 119 ---  Loss: 3.252392038702965    Accuracy: 87.8125\n",
      "iter 120 ---  Loss: 2.8345315381884575    Accuracy: 87.34375\n",
      "iter 121 ---  Loss: 2.977634407579899    Accuracy: 86.5625\n",
      "iter 122 ---  Loss: 3.086107052862644    Accuracy: 88.75\n",
      "iter 123 ---  Loss: 2.9715664237737656    Accuracy: 87.8125\n",
      "iter 124 ---  Loss: 3.1271491423249245    Accuracy: 86.09375\n",
      "iter 125 ---  Loss: 3.2335986644029617    Accuracy: 86.5625\n",
      "iter 126 ---  Loss: 3.2886400297284126    Accuracy: 87.34375\n",
      "iter 127 ---  Loss: 3.2596636041998863    Accuracy: 86.5625\n",
      "iter 128 ---  Loss: 3.7784793823957443    Accuracy: 84.6875\n",
      "iter 129 ---  Loss: 3.4514091461896896    Accuracy: 85.78125\n",
      "iter 130 ---  Loss: 3.469802424311638    Accuracy: 86.71875\n",
      "iter 131 ---  Loss: 3.0220737755298615    Accuracy: 88.90625\n",
      "iter 132 ---  Loss: 3.0411890000104904    Accuracy: 87.96875\n",
      "iter 133 ---  Loss: 3.203050009906292    Accuracy: 86.5625\n",
      "iter 134 ---  Loss: 3.1487932279706    Accuracy: 86.09375\n",
      "iter 135 ---  Loss: 2.5165943950414658    Accuracy: 90.15625\n",
      "iter 136 ---  Loss: 3.2459371984004974    Accuracy: 87.03125\n",
      "iter 137 ---  Loss: 3.066942848265171    Accuracy: 85.78125\n",
      "iter 138 ---  Loss: 2.6925456523895264    Accuracy: 87.65625\n",
      "iter 139 ---  Loss: 3.481230206787586    Accuracy: 85.9375\n",
      "iter 140 ---  Loss: 3.4522791728377342    Accuracy: 85.0\n",
      "iter 141 ---  Loss: 3.0073320791125298    Accuracy: 85.78125\n",
      "iter 142 ---  Loss: 3.8285257518291473    Accuracy: 86.25\n",
      "iter 143 ---  Loss: 3.185340590775013    Accuracy: 84.84375\n",
      "iter 144 ---  Loss: 3.335603430867195    Accuracy: 86.09375\n",
      "iter 145 ---  Loss: 2.7663169279694557    Accuracy: 85.9375\n",
      "iter 146 ---  Loss: 3.3206245452165604    Accuracy: 87.8125\n",
      "iter 147 ---  Loss: 3.3415055871009827    Accuracy: 86.09375\n",
      "iter 148 ---  Loss: 2.928519405424595    Accuracy: 88.125\n",
      "iter 149 ---  Loss: 3.1377192735671997    Accuracy: 87.65625\n",
      "iter 150 ---  Loss: 3.163145624101162    Accuracy: 85.78125\n",
      "iter 151 ---  Loss: 3.6549334973096848    Accuracy: 86.09375\n",
      "iter 152 ---  Loss: 2.9827668964862823    Accuracy: 85.46875\n",
      "iter 153 ---  Loss: 3.33101300150156    Accuracy: 85.625\n",
      "iter 154 ---  Loss: 3.3486979007720947    Accuracy: 85.15625\n",
      "iter 155 ---  Loss: 2.9469968155026436    Accuracy: 86.875\n",
      "iter 156 ---  Loss: 3.041894018650055    Accuracy: 86.40625\n",
      "iter 157 ---  Loss: 2.9403592944145203    Accuracy: 88.75\n",
      "iter 158 ---  Loss: 3.152494415640831    Accuracy: 86.71875\n",
      "iter 159 ---  Loss: 2.8672512993216515    Accuracy: 87.8125\n",
      "iter 160 ---  Loss: 2.8947152718901634    Accuracy: 86.09375\n",
      "iter 161 ---  Loss: 2.9343086034059525    Accuracy: 87.03125\n",
      "iter 162 ---  Loss: 3.169408939778805    Accuracy: 88.125\n",
      "iter 163 ---  Loss: 3.2072506472468376    Accuracy: 86.875\n",
      "iter 164 ---  Loss: 2.8224411085247993    Accuracy: 88.28125\n",
      "iter 165 ---  Loss: 3.328002765774727    Accuracy: 86.875\n",
      "iter 166 ---  Loss: 3.551292262971401    Accuracy: 85.46875\n",
      "iter 167 ---  Loss: 3.3928676322102547    Accuracy: 84.21875\n",
      "iter 168 ---  Loss: 3.1168511658906937    Accuracy: 87.1875\n",
      "iter 169 ---  Loss: 3.1768075302243233    Accuracy: 88.125\n",
      "iter 170 ---  Loss: 3.1093382760882378    Accuracy: 84.53125\n",
      "iter 171 ---  Loss: 3.292898081243038    Accuracy: 87.1875\n",
      "iter 172 ---  Loss: 2.9244956746697426    Accuracy: 87.03125\n",
      "iter 173 ---  Loss: 3.5352968722581863    Accuracy: 87.96875\n",
      "iter 174 ---  Loss: 2.923612415790558    Accuracy: 88.59375\n",
      "iter 175 ---  Loss: 2.760815680027008    Accuracy: 86.40625\n",
      "iter 176 ---  Loss: 3.1819674149155617    Accuracy: 86.40625\n",
      "iter 177 ---  Loss: 2.8948222547769547    Accuracy: 87.03125\n",
      "iter 178 ---  Loss: 2.619268625974655    Accuracy: 88.125\n",
      "iter 179 ---  Loss: 3.2055340111255646    Accuracy: 85.0\n",
      "iter 180 ---  Loss: 3.763098329305649    Accuracy: 85.15625\n",
      "iter 181 ---  Loss: 2.6731881499290466    Accuracy: 89.21875\n",
      "iter 182 ---  Loss: 3.092335894703865    Accuracy: 87.96875\n",
      "iter 183 ---  Loss: 2.933116599917412    Accuracy: 87.5\n",
      "iter 184 ---  Loss: 2.880398392677307    Accuracy: 89.53125\n",
      "iter 185 ---  Loss: 3.9700185284018517    Accuracy: 86.71875\n",
      "iter 186 ---  Loss: 3.9694390520453453    Accuracy: 87.03125\n",
      "iter 187 ---  Loss: 2.7280851155519485    Accuracy: 87.34375\n",
      "iter 188 ---  Loss: 2.670622132718563    Accuracy: 88.59375\n",
      "iter 189 ---  Loss: 2.685545541346073    Accuracy: 87.1875\n",
      "iter 190 ---  Loss: 3.4010569006204605    Accuracy: 86.875\n",
      "iter 191 ---  Loss: 2.926855929195881    Accuracy: 86.5625\n",
      "iter 192 ---  Loss: 3.1086110696196556    Accuracy: 85.0\n",
      "iter 193 ---  Loss: 3.2202438563108444    Accuracy: 86.875\n",
      "iter 194 ---  Loss: 3.4066899344325066    Accuracy: 86.25\n",
      "iter 195 ---  Loss: 3.1087285429239273    Accuracy: 87.96875\n",
      "iter 196 ---  Loss: 3.673039674758911    Accuracy: 85.0\n",
      "iter 197 ---  Loss: 2.8694136291742325    Accuracy: 88.125\n",
      "iter 198 ---  Loss: 2.908614493906498    Accuracy: 86.25\n",
      "iter 199 ---  Loss: 3.4762828201055527    Accuracy: 84.6875\n",
      "iter 200 ---  Loss: 3.287271700799465    Accuracy: 86.25\n",
      "iter 201 ---  Loss: 3.459979571402073    Accuracy: 87.1875\n",
      "iter 202 ---  Loss: 3.1124768629670143    Accuracy: 85.9375\n",
      "iter 203 ---  Loss: 3.2943735867738724    Accuracy: 86.5625\n",
      "iter 204 ---  Loss: 3.4704411178827286    Accuracy: 87.34375\n",
      "iter 205 ---  Loss: 3.5165217891335487    Accuracy: 86.71875\n",
      "iter 206 ---  Loss: 3.456932321190834    Accuracy: 84.6875\n",
      "iter 207 ---  Loss: 2.9851538091897964    Accuracy: 88.90625\n",
      "iter 208 ---  Loss: 2.8106060549616814    Accuracy: 87.34375\n",
      "iter 209 ---  Loss: 3.202079489827156    Accuracy: 87.1875\n",
      "iter 210 ---  Loss: 2.967403084039688    Accuracy: 86.875\n",
      "iter 211 ---  Loss: 3.3336014673113823    Accuracy: 84.84375\n",
      "iter 212 ---  Loss: 2.8938460871577263    Accuracy: 87.03125\n",
      "iter 213 ---  Loss: 3.422464795410633    Accuracy: 84.53125\n",
      "iter 214 ---  Loss: 3.059390716254711    Accuracy: 85.78125\n",
      "iter 215 ---  Loss: 2.487607665359974    Accuracy: 87.03125\n",
      "iter 216 ---  Loss: 4.0627386495471    Accuracy: 86.40625\n",
      "iter 217 ---  Loss: 3.0335967913269997    Accuracy: 86.40625\n",
      "iter 218 ---  Loss: 3.101615995168686    Accuracy: 86.875\n",
      "iter 219 ---  Loss: 3.0597655922174454    Accuracy: 86.71875\n",
      "iter 220 ---  Loss: 3.9029130190610886    Accuracy: 87.34375\n",
      "iter 221 ---  Loss: 2.739443391561508    Accuracy: 86.5625\n",
      "iter 222 ---  Loss: 3.111016444861889    Accuracy: 86.875\n",
      "iter 223 ---  Loss: 2.79387716203928    Accuracy: 85.625\n",
      "iter 224 ---  Loss: 2.7640668153762817    Accuracy: 88.28125\n",
      "iter 225 ---  Loss: 2.721877761185169    Accuracy: 87.65625\n",
      "iter 226 ---  Loss: 3.1402033641934395    Accuracy: 86.875\n",
      "iter 227 ---  Loss: 2.69994392991066    Accuracy: 87.8125\n",
      "iter 228 ---  Loss: 3.298179470002651    Accuracy: 87.8125\n",
      "iter 229 ---  Loss: 2.9565512388944626    Accuracy: 87.03125\n",
      "iter 230 ---  Loss: 3.5096256136894226    Accuracy: 84.53125\n",
      "iter 231 ---  Loss: 3.1470178812742233    Accuracy: 86.09375\n",
      "iter 232 ---  Loss: 3.211766391992569    Accuracy: 85.9375\n",
      "iter 233 ---  Loss: 3.4249357283115387    Accuracy: 86.09375\n",
      "iter 234 ---  Loss: 2.823282852768898    Accuracy: 87.96875\n",
      "iter 235 ---  Loss: 3.0749377831816673    Accuracy: 87.5\n",
      "iter 236 ---  Loss: 2.5416018664836884    Accuracy: 88.75\n",
      "iter 237 ---  Loss: 2.6238598003983498    Accuracy: 87.1875\n",
      "iter 238 ---  Loss: 3.16525612026453    Accuracy: 84.6875\n",
      "iter 239 ---  Loss: 3.0223752930760384    Accuracy: 85.78125\n",
      "iter 240 ---  Loss: 2.8643670603632927    Accuracy: 86.09375\n",
      "iter 241 ---  Loss: 2.8572642356157303    Accuracy: 85.9375\n",
      "iter 242 ---  Loss: 2.7903468906879425    Accuracy: 87.34375\n",
      "iter 243 ---  Loss: 3.743877649307251    Accuracy: 85.78125\n",
      "iter 244 ---  Loss: 3.064142659306526    Accuracy: 88.28125\n",
      "iter 245 ---  Loss: 2.941428355872631    Accuracy: 87.5\n",
      "iter 246 ---  Loss: 3.2385861352086067    Accuracy: 85.78125\n",
      "iter 247 ---  Loss: 2.9938548132777214    Accuracy: 89.375\n",
      "iter 248 ---  Loss: 2.565184101462364    Accuracy: 88.28125\n",
      "iter 249 ---  Loss: 2.968518555164337    Accuracy: 87.96875\n",
      "iter 250 ---  Loss: 3.3208813816308975    Accuracy: 87.03125\n",
      "iter 251 ---  Loss: 3.1596999019384384    Accuracy: 85.15625\n",
      "iter 252 ---  Loss: 2.963428720831871    Accuracy: 89.53125\n",
      "iter 253 ---  Loss: 3.045513316988945    Accuracy: 87.5\n",
      "iter 254 ---  Loss: 2.956127107143402    Accuracy: 86.40625\n",
      "iter 255 ---  Loss: 2.6277386099100113    Accuracy: 87.5\n",
      "iter 256 ---  Loss: 3.072676122188568    Accuracy: 87.1875\n",
      "iter 257 ---  Loss: 2.8146847039461136    Accuracy: 85.46875\n",
      "iter 258 ---  Loss: 3.1297783702611923    Accuracy: 85.78125\n",
      "iter 259 ---  Loss: 3.6654229387640953    Accuracy: 84.6875\n",
      "iter 260 ---  Loss: 3.0461087450385094    Accuracy: 87.65625\n",
      "iter 261 ---  Loss: 2.980339042842388    Accuracy: 87.03125\n",
      "iter 262 ---  Loss: 2.889765314757824    Accuracy: 88.75\n",
      "iter 263 ---  Loss: 3.313325747847557    Accuracy: 85.9375\n",
      "iter 264 ---  Loss: 2.8355691581964493    Accuracy: 87.03125\n",
      "iter 265 ---  Loss: 3.06555612385273    Accuracy: 88.90625\n",
      "iter 266 ---  Loss: 3.176762267947197    Accuracy: 87.1875\n",
      "iter 267 ---  Loss: 2.8964700773358345    Accuracy: 87.8125\n",
      "iter 268 ---  Loss: 3.279472328722477    Accuracy: 85.9375\n",
      "iter 269 ---  Loss: 3.7933870404958725    Accuracy: 87.65625\n",
      "iter 270 ---  Loss: 3.1270489245653152    Accuracy: 83.90625\n",
      "iter 271 ---  Loss: 2.8982764780521393    Accuracy: 88.28125\n",
      "iter 272 ---  Loss: 3.1575215235352516    Accuracy: 87.65625\n",
      "iter 273 ---  Loss: 3.671413391828537    Accuracy: 86.40625\n",
      "iter 274 ---  Loss: 3.1205621510744095    Accuracy: 86.09375\n",
      "iter 275 ---  Loss: 2.8680184856057167    Accuracy: 87.1875\n",
      "iter 276 ---  Loss: 2.728432521224022    Accuracy: 87.03125\n",
      "iter 277 ---  Loss: 2.766652323305607    Accuracy: 88.59375\n",
      "iter 278 ---  Loss: 3.1612518206238747    Accuracy: 87.03125\n",
      "iter 279 ---  Loss: 3.087725892663002    Accuracy: 88.28125\n",
      "iter 280 ---  Loss: 2.514591544866562    Accuracy: 88.59375\n",
      "iter 281 ---  Loss: 3.2429599836468697    Accuracy: 86.40625\n",
      "iter 282 ---  Loss: 2.9869244545698166    Accuracy: 87.34375\n",
      "iter 283 ---  Loss: 2.8800636902451515    Accuracy: 87.65625\n",
      "iter 284 ---  Loss: 3.149420626461506    Accuracy: 86.5625\n",
      "iter 285 ---  Loss: 3.040999971330166    Accuracy: 89.21875\n",
      "iter 286 ---  Loss: 3.194983460009098    Accuracy: 87.03125\n",
      "iter 287 ---  Loss: 2.9692530930042267    Accuracy: 87.8125\n",
      "iter 288 ---  Loss: 2.824922375380993    Accuracy: 88.59375\n",
      "iter 289 ---  Loss: 2.733794003725052    Accuracy: 89.375\n",
      "iter 290 ---  Loss: 4.012878015637398    Accuracy: 84.84375\n",
      "iter 291 ---  Loss: 2.6732464507222176    Accuracy: 86.875\n",
      "iter 292 ---  Loss: 3.3169273659586906    Accuracy: 87.65625\n",
      "iter 293 ---  Loss: 3.414391368627548    Accuracy: 87.1875\n",
      "iter 294 ---  Loss: 2.8848682790994644    Accuracy: 89.0625\n",
      "iter 295 ---  Loss: 3.1984440982341766    Accuracy: 85.9375\n",
      "iter 296 ---  Loss: 3.40057809650898    Accuracy: 85.15625\n",
      "iter 297 ---  Loss: 3.524791866540909    Accuracy: 85.625\n",
      "iter 298 ---  Loss: 3.149829737842083    Accuracy: 86.5625\n",
      "iter 299 ---  Loss: 2.98137079924345    Accuracy: 86.09375\n",
      "iter 300 ---  Loss: 3.2795869410037994    Accuracy: 86.25\n",
      "iter 301 ---  Loss: 3.3842526972293854    Accuracy: 84.53125\n",
      "iter 302 ---  Loss: 2.8492868840694427    Accuracy: 87.03125\n",
      "iter 303 ---  Loss: 3.425468124449253    Accuracy: 85.46875\n",
      "iter 304 ---  Loss: 3.4633186012506485    Accuracy: 85.625\n",
      "iter 305 ---  Loss: 3.0567450523376465    Accuracy: 86.71875\n",
      "iter 306 ---  Loss: 3.2576488479971886    Accuracy: 87.5\n",
      "iter 307 ---  Loss: 3.0728224515914917    Accuracy: 88.59375\n",
      "iter 308 ---  Loss: 2.928454726934433    Accuracy: 88.28125\n",
      "iter 309 ---  Loss: 3.625361517071724    Accuracy: 85.3125\n",
      "iter 310 ---  Loss: 3.855000466108322    Accuracy: 87.03125\n",
      "iter 311 ---  Loss: 4.021072186529636    Accuracy: 86.09375\n",
      "iter 312 ---  Loss: 2.8777250349521637    Accuracy: 88.125\n",
      "iter 313 ---  Loss: 2.752021908760071    Accuracy: 87.8125\n",
      "iter 314 ---  Loss: 2.9916672706604004    Accuracy: 85.3125\n",
      "iter 315 ---  Loss: 3.400112546980381    Accuracy: 88.75\n",
      "iter 316 ---  Loss: 3.0274689942598343    Accuracy: 87.8125\n",
      "iter 317 ---  Loss: 3.1449491158127785    Accuracy: 87.8125\n",
      "iter 318 ---  Loss: 3.566309928894043    Accuracy: 84.53125\n",
      "iter 319 ---  Loss: 2.8086739778518677    Accuracy: 87.96875\n",
      "iter 320 ---  Loss: 3.2613841220736504    Accuracy: 86.09375\n",
      "iter 321 ---  Loss: 3.169112741947174    Accuracy: 86.09375\n",
      "iter 322 ---  Loss: 3.3043734580278397    Accuracy: 85.9375\n",
      "iter 323 ---  Loss: 2.9268506914377213    Accuracy: 86.875\n",
      "iter 324 ---  Loss: 3.771292343735695    Accuracy: 85.625\n",
      "iter 325 ---  Loss: 2.895345129072666    Accuracy: 86.5625\n",
      "iter 326 ---  Loss: 2.5653777346014977    Accuracy: 88.4375\n",
      "iter 327 ---  Loss: 2.5876305401325226    Accuracy: 88.125\n",
      "iter 328 ---  Loss: 3.4250388890504837    Accuracy: 86.25\n",
      "iter 329 ---  Loss: 3.12071879953146    Accuracy: 87.96875\n",
      "iter 330 ---  Loss: 3.391864627599716    Accuracy: 87.1875\n",
      "iter 331 ---  Loss: 3.8325387313961983    Accuracy: 85.625\n",
      "iter 332 ---  Loss: 3.1713081523776054    Accuracy: 87.1875\n",
      "iter 333 ---  Loss: 3.1097411662340164    Accuracy: 90.0\n",
      "iter 334 ---  Loss: 2.8435754030942917    Accuracy: 89.21875\n",
      "iter 335 ---  Loss: 3.5072492584586143    Accuracy: 87.96875\n",
      "iter 336 ---  Loss: 2.9900701120495796    Accuracy: 87.5\n",
      "iter 337 ---  Loss: 2.76287292689085    Accuracy: 87.8125\n",
      "iter 338 ---  Loss: 2.827185831964016    Accuracy: 88.28125\n",
      "iter 339 ---  Loss: 2.8665100932121277    Accuracy: 87.96875\n",
      "iter 340 ---  Loss: 2.7961036264896393    Accuracy: 87.65625\n",
      "iter 341 ---  Loss: 3.167423091828823    Accuracy: 88.4375\n",
      "iter 342 ---  Loss: 2.7234815284609795    Accuracy: 88.28125\n",
      "iter 343 ---  Loss: 2.816284231841564    Accuracy: 87.03125\n",
      "iter 344 ---  Loss: 3.329579681158066    Accuracy: 86.25\n",
      "iter 345 ---  Loss: 4.192184068262577    Accuracy: 83.90625\n",
      "iter 346 ---  Loss: 3.4031600654125214    Accuracy: 86.09375\n",
      "iter 347 ---  Loss: 3.225348509848118    Accuracy: 86.5625\n",
      "iter 348 ---  Loss: 2.5895945876836777    Accuracy: 87.5\n",
      "iter 349 ---  Loss: 2.978923939168453    Accuracy: 86.875\n",
      "iter 350 ---  Loss: 3.3480961695313454    Accuracy: 86.25\n",
      "iter 351 ---  Loss: 2.8091922476887703    Accuracy: 85.46875\n",
      "iter 352 ---  Loss: 2.98642710596323    Accuracy: 87.5\n",
      "iter 353 ---  Loss: 3.6295208483934402    Accuracy: 86.5625\n",
      "iter 354 ---  Loss: 3.126571848988533    Accuracy: 87.8125\n",
      "iter 355 ---  Loss: 2.778295949101448    Accuracy: 87.65625\n",
      "iter 356 ---  Loss: 3.1854508370161057    Accuracy: 86.40625\n",
      "iter 357 ---  Loss: 2.816544160246849    Accuracy: 87.96875\n",
      "iter 358 ---  Loss: 3.3127254396677017    Accuracy: 86.25\n",
      "iter 359 ---  Loss: 3.132289133965969    Accuracy: 88.75\n",
      "iter 360 ---  Loss: 3.5321846306324005    Accuracy: 85.625\n",
      "iter 361 ---  Loss: 2.810798227787018    Accuracy: 87.8125\n",
      "iter 362 ---  Loss: 3.192425586283207    Accuracy: 86.71875\n",
      "iter 363 ---  Loss: 3.4681850224733353    Accuracy: 85.3125\n",
      "iter 364 ---  Loss: 2.7355757132172585    Accuracy: 87.65625\n",
      "iter 365 ---  Loss: 3.103475861251354    Accuracy: 87.5\n",
      "iter 366 ---  Loss: 3.417332246899605    Accuracy: 87.03125\n",
      "iter 367 ---  Loss: 2.7475696355104446    Accuracy: 85.9375\n",
      "iter 368 ---  Loss: 2.8388332575559616    Accuracy: 88.90625\n",
      "iter 369 ---  Loss: 3.532464049756527    Accuracy: 87.03125\n",
      "iter 370 ---  Loss: 3.21947830170393    Accuracy: 86.5625\n",
      "iter 371 ---  Loss: 3.090710684657097    Accuracy: 88.125\n",
      "iter 372 ---  Loss: 3.4148849323391914    Accuracy: 87.65625\n",
      "iter 373 ---  Loss: 2.845573253929615    Accuracy: 86.71875\n",
      "iter 374 ---  Loss: 3.6193669512867928    Accuracy: 87.5\n",
      "iter 375 ---  Loss: 2.803778126835823    Accuracy: 87.34375\n",
      "iter 376 ---  Loss: 3.2893209233880043    Accuracy: 88.125\n",
      "iter 377 ---  Loss: 3.0726944133639336    Accuracy: 85.46875\n",
      "iter 378 ---  Loss: 2.9768516793847084    Accuracy: 86.875\n",
      "iter 379 ---  Loss: 3.1386692374944687    Accuracy: 86.71875\n",
      "iter 380 ---  Loss: 3.21607905626297    Accuracy: 87.65625\n",
      "iter 381 ---  Loss: 3.1712792739272118    Accuracy: 86.25\n",
      "iter 382 ---  Loss: 3.31641299277544    Accuracy: 87.03125\n",
      "iter 383 ---  Loss: 3.1406433507800102    Accuracy: 88.125\n",
      "iter 384 ---  Loss: 2.977013938128948    Accuracy: 87.34375\n",
      "iter 385 ---  Loss: 3.460306756198406    Accuracy: 87.03125\n",
      "iter 386 ---  Loss: 2.7388278171420097    Accuracy: 86.25\n",
      "iter 387 ---  Loss: 3.0103499814867973    Accuracy: 88.4375\n",
      "iter 388 ---  Loss: 2.6268563121557236    Accuracy: 89.375\n",
      "iter 389 ---  Loss: 3.3039250299334526    Accuracy: 88.59375\n",
      "iter 390 ---  Loss: 3.346874549984932    Accuracy: 86.71875\n",
      "iter 391 ---  Loss: 2.684796065092087    Accuracy: 89.21875\n",
      "iter 392 ---  Loss: 3.503607600927353    Accuracy: 87.34375\n",
      "iter 393 ---  Loss: 3.066472977399826    Accuracy: 85.9375\n",
      "iter 394 ---  Loss: 3.420431427657604    Accuracy: 87.1875\n",
      "iter 395 ---  Loss: 4.091738179326057    Accuracy: 84.21875\n",
      "iter 396 ---  Loss: 2.6633154824376106    Accuracy: 86.875\n",
      "iter 397 ---  Loss: 3.3811153173446655    Accuracy: 85.78125\n",
      "iter 398 ---  Loss: 3.186186783015728    Accuracy: 85.15625\n",
      "iter 399 ---  Loss: 3.02744597196579    Accuracy: 87.1875\n",
      "iter 400 ---  Loss: 2.8070278763771057    Accuracy: 87.1875\n",
      "iter 401 ---  Loss: 3.2174812480807304    Accuracy: 87.03125\n",
      "iter 402 ---  Loss: 2.821425035595894    Accuracy: 86.71875\n",
      "iter 403 ---  Loss: 2.932354584336281    Accuracy: 86.5625\n",
      "iter 404 ---  Loss: 2.681155890226364    Accuracy: 87.8125\n",
      "iter 405 ---  Loss: 2.654229238629341    Accuracy: 87.96875\n",
      "iter 406 ---  Loss: 3.377266839146614    Accuracy: 86.71875\n",
      "iter 407 ---  Loss: 2.67674857378006    Accuracy: 89.6875\n",
      "iter 408 ---  Loss: 2.790872484445572    Accuracy: 89.21875\n",
      "iter 409 ---  Loss: 2.984183683991432    Accuracy: 84.84375\n",
      "iter 410 ---  Loss: 3.5559211522340775    Accuracy: 85.3125\n",
      "iter 411 ---  Loss: 2.9502628296613693    Accuracy: 86.5625\n",
      "iter 412 ---  Loss: 2.730760157108307    Accuracy: 87.65625\n",
      "iter 413 ---  Loss: 2.6104030460119247    Accuracy: 87.5\n",
      "iter 414 ---  Loss: 3.0441459640860558    Accuracy: 87.03125\n",
      "iter 415 ---  Loss: 2.9470764100551605    Accuracy: 88.59375\n",
      "iter 416 ---  Loss: 3.2335018441081047    Accuracy: 87.1875\n",
      "iter 417 ---  Loss: 2.915022872388363    Accuracy: 87.1875\n",
      "iter 418 ---  Loss: 3.478704124689102    Accuracy: 85.15625\n",
      "iter 419 ---  Loss: 3.680395156145096    Accuracy: 84.53125\n",
      "iter 420 ---  Loss: 3.2610262036323547    Accuracy: 87.34375\n",
      "iter 421 ---  Loss: 3.2739576175808907    Accuracy: 88.4375\n",
      "iter 422 ---  Loss: 2.763025216758251    Accuracy: 86.40625\n",
      "iter 423 ---  Loss: 3.332821026444435    Accuracy: 88.90625\n",
      "iter 424 ---  Loss: 3.3485560417175293    Accuracy: 88.59375\n",
      "iter 425 ---  Loss: 3.2469973787665367    Accuracy: 87.1875\n",
      "iter 426 ---  Loss: 2.832523137331009    Accuracy: 87.5\n",
      "iter 427 ---  Loss: 2.83894269913435    Accuracy: 88.125\n",
      "iter 428 ---  Loss: 3.07138841599226    Accuracy: 88.4375\n",
      "iter 429 ---  Loss: 2.9268178418278694    Accuracy: 87.65625\n",
      "iter 430 ---  Loss: 3.641490802168846    Accuracy: 85.0\n",
      "iter 431 ---  Loss: 3.1322537288069725    Accuracy: 86.71875\n",
      "iter 432 ---  Loss: 3.52384103089571    Accuracy: 89.21875\n",
      "iter 433 ---  Loss: 3.0596378222107887    Accuracy: 87.96875\n",
      "iter 434 ---  Loss: 2.6316569223999977    Accuracy: 87.5\n",
      "iter 435 ---  Loss: 2.843069225549698    Accuracy: 88.59375\n",
      "iter 436 ---  Loss: 3.4791268184781075    Accuracy: 86.875\n",
      "iter 437 ---  Loss: 2.8515028208494186    Accuracy: 88.28125\n",
      "iter 438 ---  Loss: 2.568557657301426    Accuracy: 88.90625\n",
      "iter 439 ---  Loss: 3.6685143187642097    Accuracy: 87.5\n",
      "iter 440 ---  Loss: 2.5298767164349556    Accuracy: 87.96875\n",
      "iter 441 ---  Loss: 3.420798361301422    Accuracy: 85.3125\n",
      "iter 442 ---  Loss: 2.8908447921276093    Accuracy: 88.28125\n",
      "iter 443 ---  Loss: 3.0104164481163025    Accuracy: 87.8125\n",
      "iter 444 ---  Loss: 3.3842727839946747    Accuracy: 87.5\n",
      "iter 445 ---  Loss: 2.864988796412945    Accuracy: 86.875\n",
      "iter 446 ---  Loss: 2.7020081505179405    Accuracy: 91.09375\n",
      "iter 447 ---  Loss: 3.2276284769177437    Accuracy: 86.5625\n",
      "iter 448 ---  Loss: 3.03013414144516    Accuracy: 87.5\n",
      "iter 449 ---  Loss: 3.4317376986145973    Accuracy: 87.1875\n",
      "iter 450 ---  Loss: 3.0570774525403976    Accuracy: 86.875\n",
      "iter 451 ---  Loss: 3.909959316253662    Accuracy: 88.125\n",
      "iter 452 ---  Loss: 2.990175276994705    Accuracy: 87.65625\n",
      "iter 453 ---  Loss: 3.462929666042328    Accuracy: 86.875\n",
      "iter 454 ---  Loss: 3.347864620387554    Accuracy: 85.78125\n",
      "iter 455 ---  Loss: 2.839525394141674    Accuracy: 87.1875\n",
      "iter 456 ---  Loss: 3.173513613641262    Accuracy: 89.53125\n",
      "iter 457 ---  Loss: 2.54655259847641    Accuracy: 88.4375\n",
      "iter 458 ---  Loss: 3.9858796894550323    Accuracy: 87.34375\n",
      "iter 459 ---  Loss: 3.715303674340248    Accuracy: 86.71875\n",
      "iter 460 ---  Loss: 2.851066969335079    Accuracy: 88.59375\n",
      "iter 461 ---  Loss: 3.072890467941761    Accuracy: 89.375\n",
      "iter 462 ---  Loss: 3.2594932913780212    Accuracy: 87.03125\n",
      "iter 463 ---  Loss: 2.9579486325383186    Accuracy: 86.71875\n",
      "iter 464 ---  Loss: 3.0096457973122597    Accuracy: 85.46875\n",
      "iter 465 ---  Loss: 3.562922179698944    Accuracy: 86.875\n",
      "iter 466 ---  Loss: 3.9167717546224594    Accuracy: 85.46875\n",
      "iter 467 ---  Loss: 2.7838272601366043    Accuracy: 85.9375\n",
      "iter 468 ---  Loss: 3.1846967563033104    Accuracy: 87.65625\n",
      "iter 469 ---  Loss: 3.4708045795559883    Accuracy: 85.9375\n",
      "iter 470 ---  Loss: 2.939650386571884    Accuracy: 87.5\n",
      "iter 471 ---  Loss: 3.1904240921139717    Accuracy: 86.25\n",
      "iter 472 ---  Loss: 2.7232128605246544    Accuracy: 88.90625\n",
      "iter 473 ---  Loss: 2.701463036239147    Accuracy: 87.65625\n",
      "iter 474 ---  Loss: 2.5779983326792717    Accuracy: 87.96875\n",
      "iter 475 ---  Loss: 3.379143215715885    Accuracy: 86.40625\n",
      "iter 476 ---  Loss: 2.728211894631386    Accuracy: 86.40625\n",
      "iter 477 ---  Loss: 3.7220191657543182    Accuracy: 85.78125\n",
      "iter 478 ---  Loss: 3.7221151292324066    Accuracy: 86.71875\n",
      "iter 479 ---  Loss: 2.970295988023281    Accuracy: 86.875\n",
      "iter 480 ---  Loss: 2.939836338162422    Accuracy: 87.65625\n",
      "iter 481 ---  Loss: 3.1572385728359222    Accuracy: 85.15625\n",
      "iter 482 ---  Loss: 3.0343952998518944    Accuracy: 87.34375\n",
      "iter 483 ---  Loss: 3.0832754969596863    Accuracy: 86.875\n",
      "iter 484 ---  Loss: 2.604787826538086    Accuracy: 88.75\n",
      "iter 485 ---  Loss: 2.8669466972351074    Accuracy: 89.6875\n",
      "iter 486 ---  Loss: 3.145993396639824    Accuracy: 87.1875\n",
      "iter 487 ---  Loss: 2.6928685903549194    Accuracy: 88.75\n",
      "iter 488 ---  Loss: 3.085466280579567    Accuracy: 87.1875\n",
      "iter 489 ---  Loss: 3.5728203430771828    Accuracy: 86.09375\n",
      "iter 490 ---  Loss: 3.087833434343338    Accuracy: 87.03125\n",
      "iter 491 ---  Loss: 3.325294740498066    Accuracy: 87.34375\n",
      "iter 492 ---  Loss: 3.629199840128422    Accuracy: 87.65625\n",
      "iter 493 ---  Loss: 3.1396425291895866    Accuracy: 86.875\n",
      "iter 494 ---  Loss: 3.765307180583477    Accuracy: 88.4375\n",
      "iter 495 ---  Loss: 3.1534239649772644    Accuracy: 87.96875\n",
      "iter 496 ---  Loss: 3.064351126551628    Accuracy: 85.46875\n",
      "iter 497 ---  Loss: 2.987855412065983    Accuracy: 86.25\n",
      "iter 498 ---  Loss: 3.1696342527866364    Accuracy: 87.65625\n",
      "iter 499 ---  Loss: 3.402880847454071    Accuracy: 87.96875\n",
      "iter 500 ---  Loss: 2.915276475250721    Accuracy: 87.8125\n",
      "iter 501 ---  Loss: 2.64305267482996    Accuracy: 88.75\n",
      "iter 502 ---  Loss: 2.910308599472046    Accuracy: 86.5625\n",
      "iter 503 ---  Loss: 2.75581144541502    Accuracy: 87.8125\n",
      "iter 504 ---  Loss: 3.003879353404045    Accuracy: 87.5\n",
      "iter 505 ---  Loss: 2.589662402868271    Accuracy: 89.375\n",
      "iter 506 ---  Loss: 2.910180352628231    Accuracy: 86.875\n",
      "iter 507 ---  Loss: 3.4519804641604424    Accuracy: 87.5\n",
      "iter 508 ---  Loss: 2.9913884848356247    Accuracy: 88.75\n",
      "iter 509 ---  Loss: 2.818930007517338    Accuracy: 87.34375\n",
      "iter 510 ---  Loss: 3.085582509636879    Accuracy: 87.34375\n",
      "iter 511 ---  Loss: 3.1518162935972214    Accuracy: 86.09375\n",
      "iter 512 ---  Loss: 3.2549196258187294    Accuracy: 86.40625\n",
      "iter 513 ---  Loss: 3.320062078535557    Accuracy: 85.9375\n",
      "iter 514 ---  Loss: 3.2646324634552    Accuracy: 86.875\n",
      "iter 515 ---  Loss: 2.9424217119812965    Accuracy: 87.1875\n",
      "iter 516 ---  Loss: 2.9605037346482277    Accuracy: 88.59375\n",
      "iter 517 ---  Loss: 2.6541923955082893    Accuracy: 88.28125\n",
      "iter 518 ---  Loss: 3.0728665068745613    Accuracy: 86.5625\n",
      "iter 519 ---  Loss: 2.9351996406912804    Accuracy: 87.8125\n",
      "iter 520 ---  Loss: 2.437872715294361    Accuracy: 87.96875\n",
      "iter 521 ---  Loss: 3.223031312227249    Accuracy: 85.9375\n",
      "iter 522 ---  Loss: 2.633516065776348    Accuracy: 88.90625\n",
      "iter 523 ---  Loss: 3.4854273200035095    Accuracy: 86.875\n",
      "iter 524 ---  Loss: 2.7271306812763214    Accuracy: 88.75\n",
      "iter 525 ---  Loss: 3.3742630183696747    Accuracy: 85.625\n",
      "iter 526 ---  Loss: 3.367422878742218    Accuracy: 88.75\n",
      "iter 527 ---  Loss: 2.8679127171635628    Accuracy: 87.34375\n",
      "iter 528 ---  Loss: 2.9901921451091766    Accuracy: 87.1875\n",
      "iter 529 ---  Loss: 2.8077332824468613    Accuracy: 88.4375\n",
      "iter 530 ---  Loss: 3.0343617647886276    Accuracy: 87.65625\n",
      "iter 531 ---  Loss: 3.056006573140621    Accuracy: 87.5\n",
      "iter 532 ---  Loss: 2.4521902203559875    Accuracy: 88.59375\n",
      "iter 533 ---  Loss: 2.886180602014065    Accuracy: 89.375\n",
      "iter 534 ---  Loss: 3.024341680109501    Accuracy: 85.0\n",
      "iter 535 ---  Loss: 3.493076853454113    Accuracy: 88.125\n",
      "iter 536 ---  Loss: 2.893036015331745    Accuracy: 88.90625\n",
      "iter 537 ---  Loss: 2.3789385333657265    Accuracy: 88.125\n",
      "iter 538 ---  Loss: 2.7231488078832626    Accuracy: 87.65625\n",
      "iter 539 ---  Loss: 3.4188618138432503    Accuracy: 87.1875\n",
      "iter 540 ---  Loss: 2.8829337507486343    Accuracy: 87.65625\n",
      "iter 541 ---  Loss: 3.2407187670469284    Accuracy: 86.5625\n",
      "iter 542 ---  Loss: 3.2760540023446083    Accuracy: 88.59375\n",
      "iter 543 ---  Loss: 2.5524433106184006    Accuracy: 88.59375\n",
      "iter 544 ---  Loss: 3.350287437438965    Accuracy: 85.9375\n",
      "iter 545 ---  Loss: 2.7055495604872704    Accuracy: 87.34375\n",
      "iter 546 ---  Loss: 3.6014027670025826    Accuracy: 85.3125\n",
      "iter 547 ---  Loss: 3.6681252494454384    Accuracy: 85.0\n",
      "iter 548 ---  Loss: 2.916345924139023    Accuracy: 88.90625\n",
      "iter 549 ---  Loss: 3.3306827321648598    Accuracy: 87.65625\n",
      "iter 550 ---  Loss: 2.7697097584605217    Accuracy: 88.125\n",
      "iter 551 ---  Loss: 3.3024900183081627    Accuracy: 86.09375\n",
      "iter 552 ---  Loss: 2.7683183178305626    Accuracy: 87.65625\n",
      "iter 553 ---  Loss: 3.127254068851471    Accuracy: 87.65625\n",
      "iter 554 ---  Loss: 2.6152163222432137    Accuracy: 88.4375\n",
      "iter 555 ---  Loss: 2.691066525876522    Accuracy: 87.8125\n",
      "iter 556 ---  Loss: 2.5480510517954826    Accuracy: 88.59375\n",
      "iter 557 ---  Loss: 3.6890571266412735    Accuracy: 85.46875\n",
      "iter 558 ---  Loss: 3.129039227962494    Accuracy: 87.5\n",
      "iter 559 ---  Loss: 3.0962062999606133    Accuracy: 88.90625\n",
      "iter 560 ---  Loss: 3.1671029925346375    Accuracy: 87.5\n",
      "iter 561 ---  Loss: 3.1500810012221336    Accuracy: 87.5\n",
      "iter 562 ---  Loss: 3.1906216517090797    Accuracy: 85.78125\n",
      "iter 563 ---  Loss: 3.2053488940000534    Accuracy: 88.90625\n",
      "iter 564 ---  Loss: 2.984902396798134    Accuracy: 88.125\n",
      "iter 565 ---  Loss: 3.1661914363503456    Accuracy: 88.28125\n",
      "iter 566 ---  Loss: 3.0727884992957115    Accuracy: 88.75\n",
      "iter 567 ---  Loss: 2.953008994460106    Accuracy: 89.0625\n",
      "iter 568 ---  Loss: 3.430466115474701    Accuracy: 87.34375\n",
      "iter 569 ---  Loss: 2.701814115047455    Accuracy: 86.875\n",
      "iter 570 ---  Loss: 3.047745168209076    Accuracy: 87.5\n",
      "iter 571 ---  Loss: 3.2238103970885277    Accuracy: 88.59375\n",
      "iter 572 ---  Loss: 2.88048155605793    Accuracy: 87.8125\n",
      "iter 573 ---  Loss: 3.074260175228119    Accuracy: 87.1875\n",
      "iter 574 ---  Loss: 3.2223459258675575    Accuracy: 87.8125\n",
      "iter 575 ---  Loss: 2.904234766960144    Accuracy: 88.75\n",
      "iter 576 ---  Loss: 3.3267124965786934    Accuracy: 85.9375\n",
      "iter 577 ---  Loss: 2.6964560821652412    Accuracy: 87.1875\n",
      "iter 578 ---  Loss: 2.6646812558174133    Accuracy: 87.34375\n",
      "iter 579 ---  Loss: 3.6403164118528366    Accuracy: 86.5625\n",
      "iter 580 ---  Loss: 2.741747386753559    Accuracy: 89.0625\n",
      "iter 581 ---  Loss: 2.895738959312439    Accuracy: 87.1875\n",
      "iter 582 ---  Loss: 2.9376926198601723    Accuracy: 87.5\n",
      "iter 583 ---  Loss: 2.7473843917250633    Accuracy: 87.5\n",
      "iter 584 ---  Loss: 3.1604240983724594    Accuracy: 88.4375\n",
      "iter 585 ---  Loss: 3.760459579527378    Accuracy: 86.875\n",
      "iter 586 ---  Loss: 3.3151907101273537    Accuracy: 88.4375\n",
      "iter 587 ---  Loss: 2.6031946539878845    Accuracy: 88.125\n",
      "iter 588 ---  Loss: 2.7124449759721756    Accuracy: 87.1875\n",
      "iter 589 ---  Loss: 2.9646428897976875    Accuracy: 88.4375\n",
      "iter 590 ---  Loss: 2.9815635830163956    Accuracy: 88.4375\n",
      "iter 591 ---  Loss: 3.0071915835142136    Accuracy: 87.1875\n",
      "iter 592 ---  Loss: 3.1886087879538536    Accuracy: 89.21875\n",
      "iter 593 ---  Loss: 3.4871652647852898    Accuracy: 87.1875\n",
      "iter 594 ---  Loss: 2.8558249548077583    Accuracy: 89.53125\n",
      "iter 595 ---  Loss: 2.889797180891037    Accuracy: 87.1875\n",
      "iter 596 ---  Loss: 3.3201764598488808    Accuracy: 87.65625\n",
      "iter 597 ---  Loss: 3.056332588195801    Accuracy: 86.875\n",
      "iter 598 ---  Loss: 3.0015581995248795    Accuracy: 87.03125\n",
      "iter 599 ---  Loss: 2.981223486363888    Accuracy: 86.71875\n",
      "iter 600 ---  Loss: 2.9097754806280136    Accuracy: 87.03125\n",
      "iter 601 ---  Loss: 3.0332699939608574    Accuracy: 86.09375\n",
      "iter 602 ---  Loss: 3.4249751791357994    Accuracy: 86.875\n",
      "iter 603 ---  Loss: 2.814064159989357    Accuracy: 88.4375\n",
      "iter 604 ---  Loss: 2.569623425602913    Accuracy: 88.75\n",
      "iter 605 ---  Loss: 2.8380435183644295    Accuracy: 88.4375\n",
      "iter 606 ---  Loss: 3.228602297604084    Accuracy: 88.4375\n",
      "iter 607 ---  Loss: 3.1096087098121643    Accuracy: 88.59375\n",
      "iter 608 ---  Loss: 3.042392872273922    Accuracy: 86.25\n",
      "iter 609 ---  Loss: 2.807815797626972    Accuracy: 88.125\n",
      "iter 610 ---  Loss: 3.3319780752062798    Accuracy: 85.78125\n",
      "iter 611 ---  Loss: 3.0537132173776627    Accuracy: 89.21875\n",
      "iter 612 ---  Loss: 2.6647256538271904    Accuracy: 86.875\n",
      "iter 613 ---  Loss: 3.244392178952694    Accuracy: 85.625\n",
      "iter 614 ---  Loss: 3.709690235555172    Accuracy: 85.46875\n",
      "iter 615 ---  Loss: 3.12956266105175    Accuracy: 87.8125\n",
      "iter 616 ---  Loss: 2.7282889261841774    Accuracy: 86.875\n",
      "iter 617 ---  Loss: 2.8205159306526184    Accuracy: 86.5625\n",
      "iter 618 ---  Loss: 2.940489135682583    Accuracy: 88.59375\n",
      "iter 619 ---  Loss: 2.9975877851247787    Accuracy: 88.59375\n",
      "iter 620 ---  Loss: 2.7952299043536186    Accuracy: 89.0625\n",
      "iter 621 ---  Loss: 3.3636659383773804    Accuracy: 87.8125\n",
      "iter 622 ---  Loss: 2.786864474415779    Accuracy: 86.875\n",
      "iter 623 ---  Loss: 2.86289431899786    Accuracy: 86.5625\n",
      "iter 624 ---  Loss: 2.795386753976345    Accuracy: 88.125\n",
      "iter 625 ---  Loss: 3.1068204939365387    Accuracy: 87.03125\n",
      "iter 626 ---  Loss: 2.4623095095157623    Accuracy: 88.125\n",
      "iter 627 ---  Loss: 4.397479824721813    Accuracy: 83.90625\n",
      "iter 628 ---  Loss: 2.713162437081337    Accuracy: 88.4375\n",
      "iter 629 ---  Loss: 2.5907690599560738    Accuracy: 86.875\n",
      "iter 630 ---  Loss: 2.85452564060688    Accuracy: 87.1875\n",
      "iter 631 ---  Loss: 3.1891826018691063    Accuracy: 86.25\n",
      "iter 632 ---  Loss: 2.6408464685082436    Accuracy: 87.8125\n",
      "iter 633 ---  Loss: 2.866365186870098    Accuracy: 86.71875\n",
      "iter 634 ---  Loss: 3.1649200171232224    Accuracy: 88.125\n",
      "iter 635 ---  Loss: 3.0316425934433937    Accuracy: 86.875\n",
      "iter 636 ---  Loss: 2.626187965273857    Accuracy: 89.375\n",
      "iter 637 ---  Loss: 3.2706001549959183    Accuracy: 88.28125\n",
      "iter 638 ---  Loss: 3.5951428785920143    Accuracy: 86.71875\n",
      "iter 639 ---  Loss: 2.916204757988453    Accuracy: 86.40625\n",
      "iter 640 ---  Loss: 2.9736307486891747    Accuracy: 87.34375\n",
      "iter 641 ---  Loss: 3.248391628265381    Accuracy: 88.125\n",
      "iter 642 ---  Loss: 3.178285002708435    Accuracy: 87.34375\n",
      "iter 643 ---  Loss: 2.713673122227192    Accuracy: 89.53125\n",
      "iter 644 ---  Loss: 3.1565104350447655    Accuracy: 87.03125\n",
      "iter 645 ---  Loss: 3.9902801290154457    Accuracy: 87.1875\n",
      "iter 646 ---  Loss: 2.6371947899460793    Accuracy: 87.65625\n",
      "iter 647 ---  Loss: 3.0002820417284966    Accuracy: 89.84375\n",
      "iter 648 ---  Loss: 3.1223001703619957    Accuracy: 86.875\n",
      "iter 649 ---  Loss: 2.645026832818985    Accuracy: 87.65625\n",
      "iter 650 ---  Loss: 3.1230082139372826    Accuracy: 88.4375\n",
      "iter 651 ---  Loss: 3.2181326374411583    Accuracy: 87.03125\n",
      "iter 652 ---  Loss: 2.7106124460697174    Accuracy: 87.65625\n",
      "iter 653 ---  Loss: 2.6753498911857605    Accuracy: 87.1875\n",
      "iter 654 ---  Loss: 3.7932651564478874    Accuracy: 83.4375\n",
      "iter 655 ---  Loss: 3.0969429463148117    Accuracy: 87.5\n",
      "iter 656 ---  Loss: 3.674919232726097    Accuracy: 87.34375\n",
      "iter 657 ---  Loss: 2.7406247407197952    Accuracy: 88.90625\n",
      "iter 658 ---  Loss: 3.3035594448447227    Accuracy: 88.90625\n",
      "iter 659 ---  Loss: 2.7044665217399597    Accuracy: 87.65625\n",
      "iter 660 ---  Loss: 3.228804834187031    Accuracy: 85.78125\n",
      "iter 661 ---  Loss: 3.23875729739666    Accuracy: 84.53125\n",
      "iter 662 ---  Loss: 3.0571741238236427    Accuracy: 87.34375\n",
      "iter 663 ---  Loss: 3.204081304371357    Accuracy: 87.96875\n",
      "iter 664 ---  Loss: 2.8187143206596375    Accuracy: 87.96875\n",
      "iter 665 ---  Loss: 2.9030435532331467    Accuracy: 89.0625\n",
      "iter 666 ---  Loss: 2.8595692962408066    Accuracy: 87.5\n",
      "iter 667 ---  Loss: 3.686798073351383    Accuracy: 85.46875\n",
      "iter 668 ---  Loss: 3.2562964111566544    Accuracy: 86.875\n",
      "iter 669 ---  Loss: 2.6945842131972313    Accuracy: 87.8125\n",
      "iter 670 ---  Loss: 3.2136939018964767    Accuracy: 85.78125\n",
      "iter 671 ---  Loss: 2.9874677807092667    Accuracy: 87.1875\n",
      "iter 672 ---  Loss: 2.6886462792754173    Accuracy: 89.375\n",
      "iter 673 ---  Loss: 3.21212687343359    Accuracy: 87.8125\n",
      "iter 674 ---  Loss: 2.5007455199956894    Accuracy: 87.96875\n",
      "iter 675 ---  Loss: 2.803094521164894    Accuracy: 87.8125\n",
      "iter 676 ---  Loss: 2.837536498904228    Accuracy: 87.1875\n",
      "iter 677 ---  Loss: 3.1177419796586037    Accuracy: 86.25\n",
      "iter 678 ---  Loss: 3.2102307602763176    Accuracy: 85.78125\n",
      "iter 679 ---  Loss: 3.150333672761917    Accuracy: 87.03125\n",
      "iter 680 ---  Loss: 2.920689731836319    Accuracy: 87.03125\n",
      "iter 681 ---  Loss: 3.0153904855251312    Accuracy: 87.65625\n",
      "iter 682 ---  Loss: 3.0995098054409027    Accuracy: 87.8125\n",
      "iter 683 ---  Loss: 2.802384600043297    Accuracy: 87.8125\n",
      "iter 684 ---  Loss: 3.52254281938076    Accuracy: 87.34375\n",
      "iter 685 ---  Loss: 2.64103152602911    Accuracy: 87.96875\n",
      "iter 686 ---  Loss: 3.14217621833086    Accuracy: 89.0625\n",
      "iter 687 ---  Loss: 3.3239198103547096    Accuracy: 88.4375\n",
      "iter 688 ---  Loss: 3.0895559042692184    Accuracy: 89.21875\n",
      "iter 689 ---  Loss: 3.090306155383587    Accuracy: 86.5625\n",
      "iter 690 ---  Loss: 2.938243694603443    Accuracy: 90.0\n",
      "iter 691 ---  Loss: 3.1500251665711403    Accuracy: 86.25\n",
      "iter 692 ---  Loss: 3.073444627225399    Accuracy: 88.125\n",
      "iter 693 ---  Loss: 3.0717715844511986    Accuracy: 87.8125\n",
      "iter 694 ---  Loss: 3.091523304581642    Accuracy: 88.4375\n",
      "iter 695 ---  Loss: 3.161177970468998    Accuracy: 88.125\n",
      "iter 696 ---  Loss: 2.9448976144194603    Accuracy: 87.34375\n",
      "iter 697 ---  Loss: 2.9497178718447685    Accuracy: 88.125\n",
      "iter 698 ---  Loss: 3.1511308550834656    Accuracy: 87.65625\n",
      "iter 699 ---  Loss: 2.5925863534212112    Accuracy: 88.4375\n",
      "iter 700 ---  Loss: 3.3095606341958046    Accuracy: 87.8125\n",
      "iter 701 ---  Loss: 2.447552315890789    Accuracy: 88.59375\n",
      "iter 702 ---  Loss: 3.0616624504327774    Accuracy: 86.40625\n",
      "iter 703 ---  Loss: 3.4569465667009354    Accuracy: 86.40625\n",
      "iter 704 ---  Loss: 3.1206247210502625    Accuracy: 86.71875\n",
      "iter 705 ---  Loss: 3.258145347237587    Accuracy: 87.1875\n",
      "iter 706 ---  Loss: 3.4785499945282936    Accuracy: 85.78125\n",
      "iter 707 ---  Loss: 3.2685436233878136    Accuracy: 87.34375\n",
      "iter 708 ---  Loss: 3.1746253222227097    Accuracy: 87.96875\n",
      "iter 709 ---  Loss: 3.004820466041565    Accuracy: 87.5\n",
      "iter 710 ---  Loss: 3.373119667172432    Accuracy: 86.5625\n",
      "iter 711 ---  Loss: 2.594342067837715    Accuracy: 87.34375\n",
      "iter 712 ---  Loss: 3.333183228969574    Accuracy: 85.0\n",
      "iter 713 ---  Loss: 2.8531953394412994    Accuracy: 87.03125\n",
      "iter 714 ---  Loss: 3.5263591036200523    Accuracy: 85.3125\n",
      "iter 715 ---  Loss: 2.6099623441696167    Accuracy: 87.1875\n",
      "iter 716 ---  Loss: 3.013570636510849    Accuracy: 87.65625\n",
      "iter 717 ---  Loss: 3.139819048345089    Accuracy: 87.65625\n",
      "iter 718 ---  Loss: 2.550161838531494    Accuracy: 85.78125\n",
      "iter 719 ---  Loss: 3.265752352774143    Accuracy: 85.625\n",
      "iter 720 ---  Loss: 3.048617087304592    Accuracy: 88.4375\n",
      "iter 721 ---  Loss: 3.580008141696453    Accuracy: 87.5\n",
      "iter 722 ---  Loss: 2.9068723767995834    Accuracy: 88.4375\n",
      "iter 723 ---  Loss: 2.6599049866199493    Accuracy: 87.8125\n",
      "iter 724 ---  Loss: 2.8712152242660522    Accuracy: 89.53125\n",
      "iter 725 ---  Loss: 3.665433667600155    Accuracy: 86.25\n",
      "iter 726 ---  Loss: 3.0595681369304657    Accuracy: 87.5\n",
      "iter 727 ---  Loss: 3.327840216457844    Accuracy: 87.8125\n",
      "iter 728 ---  Loss: 3.134300246834755    Accuracy: 86.5625\n",
      "iter 729 ---  Loss: 2.9132895171642303    Accuracy: 86.71875\n",
      "iter 730 ---  Loss: 2.842415727674961    Accuracy: 89.0625\n",
      "iter 731 ---  Loss: 3.145701490342617    Accuracy: 87.96875\n",
      "iter 732 ---  Loss: 3.352049045264721    Accuracy: 85.78125\n",
      "iter 733 ---  Loss: 3.0999995917081833    Accuracy: 85.78125\n",
      "iter 734 ---  Loss: 2.708445779979229    Accuracy: 88.59375\n",
      "iter 735 ---  Loss: 3.3398142382502556    Accuracy: 87.65625\n",
      "iter 736 ---  Loss: 2.9718367978930473    Accuracy: 88.75\n",
      "iter 737 ---  Loss: 3.6911039873957634    Accuracy: 86.25\n",
      "iter 738 ---  Loss: 3.1614579409360886    Accuracy: 88.75\n",
      "iter 739 ---  Loss: 3.497003771364689    Accuracy: 85.9375\n",
      "iter 740 ---  Loss: 3.1035847291350365    Accuracy: 88.28125\n",
      "iter 741 ---  Loss: 2.8245243951678276    Accuracy: 86.5625\n",
      "iter 742 ---  Loss: 3.090264029800892    Accuracy: 86.875\n",
      "iter 743 ---  Loss: 3.1024575531482697    Accuracy: 86.71875\n",
      "iter 744 ---  Loss: 3.196152187883854    Accuracy: 87.34375\n",
      "iter 745 ---  Loss: 2.853074125945568    Accuracy: 87.5\n",
      "iter 746 ---  Loss: 3.0398212298750877    Accuracy: 88.75\n",
      "iter 747 ---  Loss: 3.2025883719325066    Accuracy: 86.875\n",
      "iter 748 ---  Loss: 3.039267621934414    Accuracy: 86.71875\n",
      "iter 749 ---  Loss: 2.924974136054516    Accuracy: 88.125\n",
      "iter 750 ---  Loss: 2.7701957002282143    Accuracy: 87.96875\n",
      "iter 751 ---  Loss: 2.976022109389305    Accuracy: 87.96875\n",
      "iter 752 ---  Loss: 2.696617156267166    Accuracy: 88.28125\n",
      "iter 753 ---  Loss: 3.023874245584011    Accuracy: 87.34375\n",
      "iter 754 ---  Loss: 3.185482919216156    Accuracy: 85.625\n",
      "iter 755 ---  Loss: 3.4282271414995193    Accuracy: 85.9375\n",
      "iter 756 ---  Loss: 2.8886465430259705    Accuracy: 88.28125\n",
      "iter 757 ---  Loss: 3.8127245754003525    Accuracy: 86.09375\n",
      "iter 758 ---  Loss: 3.3138934820890427    Accuracy: 86.5625\n",
      "iter 759 ---  Loss: 2.811541460454464    Accuracy: 87.1875\n",
      "iter 760 ---  Loss: 2.9750687330961227    Accuracy: 87.1875\n",
      "iter 761 ---  Loss: 3.643560014665127    Accuracy: 86.25\n",
      "iter 762 ---  Loss: 2.857293628156185    Accuracy: 85.0\n",
      "iter 763 ---  Loss: 3.194586805999279    Accuracy: 85.9375\n",
      "iter 764 ---  Loss: 2.9864673614501953    Accuracy: 88.125\n",
      "iter 765 ---  Loss: 2.9726471602916718    Accuracy: 87.1875\n",
      "iter 766 ---  Loss: 2.840104393661022    Accuracy: 87.65625\n",
      "iter 767 ---  Loss: 2.885066755115986    Accuracy: 87.03125\n",
      "iter 768 ---  Loss: 3.345135435461998    Accuracy: 87.96875\n",
      "iter 769 ---  Loss: 2.7036503329873085    Accuracy: 89.0625\n",
      "iter 770 ---  Loss: 2.932472087442875    Accuracy: 87.5\n",
      "iter 771 ---  Loss: 3.414587303996086    Accuracy: 85.625\n",
      "iter 772 ---  Loss: 2.8099526315927505    Accuracy: 87.65625\n",
      "iter 773 ---  Loss: 2.8738997355103493    Accuracy: 86.09375\n",
      "iter 774 ---  Loss: 2.9485263898968697    Accuracy: 86.875\n",
      "iter 775 ---  Loss: 3.4567922800779343    Accuracy: 87.5\n",
      "iter 776 ---  Loss: 3.2672614380717278    Accuracy: 87.03125\n",
      "iter 777 ---  Loss: 3.09470846503973    Accuracy: 85.625\n",
      "iter 778 ---  Loss: 3.5359465330839157    Accuracy: 85.78125\n",
      "iter 779 ---  Loss: 3.6988729014992714    Accuracy: 87.5\n",
      "iter 780 ---  Loss: 2.604960061609745    Accuracy: 87.65625\n",
      "iter 781 ---  Loss: 3.0264004692435265    Accuracy: 86.09375\n",
      "iter 782 ---  Loss: 3.645869791507721    Accuracy: 86.09375\n",
      "iter 783 ---  Loss: 3.0284880325198174    Accuracy: 86.25\n",
      "iter 784 ---  Loss: 3.0324898287653923    Accuracy: 86.875\n",
      "iter 785 ---  Loss: 2.5022951140999794    Accuracy: 88.125\n",
      "iter 786 ---  Loss: 3.4425472989678383    Accuracy: 85.15625\n",
      "iter 787 ---  Loss: 2.8449838161468506    Accuracy: 89.0625\n",
      "iter 788 ---  Loss: 2.784034013748169    Accuracy: 86.40625\n",
      "iter 789 ---  Loss: 3.0010983273386955    Accuracy: 88.125\n",
      "iter 790 ---  Loss: 3.0495937168598175    Accuracy: 84.375\n",
      "iter 791 ---  Loss: 3.153310149908066    Accuracy: 87.8125\n",
      "iter 792 ---  Loss: 3.1826726719737053    Accuracy: 87.65625\n",
      "iter 793 ---  Loss: 3.8306642174720764    Accuracy: 86.25\n",
      "iter 794 ---  Loss: 3.0250893384218216    Accuracy: 85.0\n",
      "iter 795 ---  Loss: 2.640988416969776    Accuracy: 87.8125\n",
      "iter 796 ---  Loss: 3.101038344204426    Accuracy: 86.71875\n",
      "iter 797 ---  Loss: 3.2999214231967926    Accuracy: 85.9375\n",
      "iter 798 ---  Loss: 3.0457023605704308    Accuracy: 85.78125\n",
      "iter 799 ---  Loss: 3.3099819868803024    Accuracy: 86.5625\n",
      "iter 800 ---  Loss: 3.2997986525297165    Accuracy: 85.9375\n",
      "iter 801 ---  Loss: 2.890814207494259    Accuracy: 86.875\n",
      "iter 802 ---  Loss: 3.352116219699383    Accuracy: 86.875\n",
      "iter 803 ---  Loss: 3.1864669173955917    Accuracy: 87.5\n",
      "iter 804 ---  Loss: 2.9498872235417366    Accuracy: 86.40625\n",
      "iter 805 ---  Loss: 3.269973486661911    Accuracy: 85.625\n",
      "iter 806 ---  Loss: 2.979714795947075    Accuracy: 86.875\n",
      "iter 807 ---  Loss: 3.017830066382885    Accuracy: 84.84375\n",
      "iter 808 ---  Loss: 3.1902851313352585    Accuracy: 87.65625\n",
      "iter 809 ---  Loss: 2.790775030851364    Accuracy: 87.8125\n",
      "iter 810 ---  Loss: 3.4711585491895676    Accuracy: 86.875\n",
      "iter 811 ---  Loss: 3.2331737503409386    Accuracy: 87.34375\n",
      "iter 812 ---  Loss: 2.828394465148449    Accuracy: 87.1875\n",
      "iter 813 ---  Loss: 3.0419212505221367    Accuracy: 87.65625\n",
      "iter 814 ---  Loss: 3.424428552389145    Accuracy: 86.71875\n",
      "iter 815 ---  Loss: 3.0442991852760315    Accuracy: 85.9375\n",
      "iter 816 ---  Loss: 3.045638881623745    Accuracy: 87.5\n",
      "iter 817 ---  Loss: 3.0605733320116997    Accuracy: 87.65625\n",
      "iter 818 ---  Loss: 3.194706328213215    Accuracy: 86.40625\n",
      "iter 819 ---  Loss: 2.60857143253088    Accuracy: 88.75\n",
      "iter 820 ---  Loss: 3.354882299900055    Accuracy: 86.875\n",
      "iter 821 ---  Loss: 2.6558580473065376    Accuracy: 87.5\n",
      "iter 822 ---  Loss: 2.539456367492676    Accuracy: 88.28125\n",
      "iter 823 ---  Loss: 2.7381479293107986    Accuracy: 89.6875\n",
      "iter 824 ---  Loss: 2.8288561776280403    Accuracy: 87.65625\n",
      "iter 825 ---  Loss: 2.876598760485649    Accuracy: 88.4375\n",
      "iter 826 ---  Loss: 3.926981784403324    Accuracy: 85.78125\n",
      "iter 827 ---  Loss: 3.2895891964435577    Accuracy: 87.34375\n",
      "iter 828 ---  Loss: 2.962426818907261    Accuracy: 88.4375\n",
      "iter 829 ---  Loss: 3.203888237476349    Accuracy: 88.75\n",
      "iter 830 ---  Loss: 3.1762651205062866    Accuracy: 87.34375\n",
      "iter 831 ---  Loss: 3.22090046107769    Accuracy: 85.625\n",
      "iter 832 ---  Loss: 3.4990877509117126    Accuracy: 85.625\n",
      "iter 833 ---  Loss: 3.1670925095677376    Accuracy: 84.6875\n",
      "iter 834 ---  Loss: 3.2501892149448395    Accuracy: 88.125\n",
      "iter 835 ---  Loss: 2.963039591908455    Accuracy: 88.4375\n",
      "iter 836 ---  Loss: 3.0627721026539803    Accuracy: 87.8125\n",
      "iter 837 ---  Loss: 2.442913919687271    Accuracy: 88.4375\n",
      "iter 838 ---  Loss: 2.884630925953388    Accuracy: 88.28125\n",
      "iter 839 ---  Loss: 2.7125192657113075    Accuracy: 86.875\n",
      "iter 840 ---  Loss: 3.2347133085131645    Accuracy: 87.5\n",
      "iter 841 ---  Loss: 3.0262362211942673    Accuracy: 86.71875\n",
      "iter 842 ---  Loss: 3.311038039624691    Accuracy: 86.71875\n",
      "iter 843 ---  Loss: 3.7232790514826775    Accuracy: 87.1875\n",
      "iter 844 ---  Loss: 3.0087644904851913    Accuracy: 88.28125\n",
      "iter 845 ---  Loss: 3.08371489495039    Accuracy: 87.65625\n",
      "iter 846 ---  Loss: 2.693211443722248    Accuracy: 87.5\n",
      "iter 847 ---  Loss: 3.381474457681179    Accuracy: 87.03125\n",
      "iter 848 ---  Loss: 3.1184315010905266    Accuracy: 86.40625\n",
      "iter 849 ---  Loss: 3.1573433354496956    Accuracy: 85.3125\n",
      "iter 850 ---  Loss: 2.5273390784859657    Accuracy: 88.59375\n",
      "iter 851 ---  Loss: 3.0124916806817055    Accuracy: 87.34375\n",
      "iter 852 ---  Loss: 2.7949820309877396    Accuracy: 87.03125\n",
      "iter 853 ---  Loss: 3.3642439544200897    Accuracy: 86.25\n",
      "iter 854 ---  Loss: 3.4693750515580177    Accuracy: 86.5625\n",
      "iter 855 ---  Loss: 3.2414847686886787    Accuracy: 86.09375\n",
      "iter 856 ---  Loss: 2.9609428718686104    Accuracy: 87.34375\n",
      "iter 857 ---  Loss: 2.7615499421954155    Accuracy: 88.4375\n",
      "iter 858 ---  Loss: 2.7389712408185005    Accuracy: 87.8125\n",
      "iter 859 ---  Loss: 3.426742762327194    Accuracy: 84.84375\n",
      "iter 860 ---  Loss: 3.182580329477787    Accuracy: 86.875\n",
      "iter 861 ---  Loss: 3.2137429118156433    Accuracy: 85.15625\n",
      "iter 862 ---  Loss: 2.811610147356987    Accuracy: 88.28125\n",
      "iter 863 ---  Loss: 2.9788287952542305    Accuracy: 88.4375\n",
      "iter 864 ---  Loss: 3.0100854113698006    Accuracy: 86.09375\n",
      "iter 865 ---  Loss: 3.1655333563685417    Accuracy: 86.5625\n",
      "iter 866 ---  Loss: 2.686547338962555    Accuracy: 87.8125\n",
      "iter 867 ---  Loss: 2.9484975934028625    Accuracy: 88.125\n",
      "iter 868 ---  Loss: 3.282757952809334    Accuracy: 85.78125\n",
      "iter 869 ---  Loss: 3.6552229449152946    Accuracy: 85.0\n",
      "iter 870 ---  Loss: 3.460363231599331    Accuracy: 89.375\n",
      "iter 871 ---  Loss: 2.994735263288021    Accuracy: 88.125\n",
      "iter 872 ---  Loss: 3.6323614940047264    Accuracy: 85.46875\n",
      "iter 873 ---  Loss: 3.605396181344986    Accuracy: 86.71875\n",
      "iter 874 ---  Loss: 3.250027157366276    Accuracy: 86.5625\n",
      "iter 875 ---  Loss: 3.2430786415934563    Accuracy: 87.65625\n",
      "iter 876 ---  Loss: 2.666728988289833    Accuracy: 87.03125\n",
      "iter 877 ---  Loss: 2.8449434861540794    Accuracy: 87.8125\n",
      "iter 878 ---  Loss: 3.360196925699711    Accuracy: 86.40625\n",
      "iter 879 ---  Loss: 2.9580783545970917    Accuracy: 87.96875\n",
      "iter 880 ---  Loss: 3.2325012013316154    Accuracy: 86.25\n",
      "iter 881 ---  Loss: 3.9780478850007057    Accuracy: 85.9375\n",
      "iter 882 ---  Loss: 3.4038410410284996    Accuracy: 88.75\n",
      "iter 883 ---  Loss: 3.0396459102630615    Accuracy: 87.96875\n",
      "iter 884 ---  Loss: 2.4838239550590515    Accuracy: 88.28125\n",
      "iter 885 ---  Loss: 2.64083082228899    Accuracy: 87.1875\n",
      "iter 886 ---  Loss: 2.8361934795975685    Accuracy: 85.3125\n",
      "iter 887 ---  Loss: 2.9206531196832657    Accuracy: 88.59375\n",
      "iter 888 ---  Loss: 3.1718121990561485    Accuracy: 87.34375\n",
      "iter 889 ---  Loss: 2.81365679949522    Accuracy: 87.65625\n",
      "iter 890 ---  Loss: 3.3394059911370277    Accuracy: 85.625\n",
      "iter 891 ---  Loss: 3.05352745950222    Accuracy: 87.96875\n",
      "iter 892 ---  Loss: 3.28020016849041    Accuracy: 86.25\n",
      "iter 893 ---  Loss: 2.6796719431877136    Accuracy: 87.65625\n",
      "iter 894 ---  Loss: 3.125521644949913    Accuracy: 87.5\n",
      "iter 895 ---  Loss: 2.940115861594677    Accuracy: 88.28125\n",
      "iter 896 ---  Loss: 2.9168656319379807    Accuracy: 87.03125\n",
      "iter 897 ---  Loss: 3.101407453417778    Accuracy: 85.625\n",
      "iter 898 ---  Loss: 2.848910130560398    Accuracy: 87.1875\n",
      "iter 899 ---  Loss: 2.657926931977272    Accuracy: 85.9375\n",
      "iter 900 ---  Loss: 3.6279402747750282    Accuracy: 85.15625\n",
      "iter 901 ---  Loss: 3.112444818019867    Accuracy: 87.34375\n",
      "iter 902 ---  Loss: 3.8681378290057182    Accuracy: 86.09375\n",
      "iter 903 ---  Loss: 2.773672565817833    Accuracy: 87.34375\n",
      "iter 904 ---  Loss: 2.6197107657790184    Accuracy: 88.28125\n",
      "iter 905 ---  Loss: 2.956113189458847    Accuracy: 88.4375\n",
      "iter 906 ---  Loss: 2.782193548977375    Accuracy: 87.03125\n",
      "iter 907 ---  Loss: 3.2127440869808197    Accuracy: 85.625\n",
      "iter 908 ---  Loss: 3.0997020453214645    Accuracy: 86.09375\n",
      "iter 909 ---  Loss: 2.81535005569458    Accuracy: 88.125\n",
      "iter 910 ---  Loss: 3.3114877343177795    Accuracy: 85.625\n",
      "iter 911 ---  Loss: 2.8808164596557617    Accuracy: 86.71875\n",
      "iter 912 ---  Loss: 3.1158841401338577    Accuracy: 88.125\n",
      "iter 913 ---  Loss: 3.5644179731607437    Accuracy: 85.3125\n",
      "iter 914 ---  Loss: 3.5054913759231567    Accuracy: 85.78125\n",
      "iter 915 ---  Loss: 2.8539794981479645    Accuracy: 86.5625\n",
      "iter 916 ---  Loss: 3.0628692507743835    Accuracy: 88.28125\n",
      "iter 917 ---  Loss: 3.130114644765854    Accuracy: 88.75\n",
      "iter 918 ---  Loss: 2.931792140007019    Accuracy: 87.8125\n",
      "iter 919 ---  Loss: 3.5680884793400764    Accuracy: 87.65625\n",
      "iter 920 ---  Loss: 3.081379160284996    Accuracy: 88.125\n",
      "iter 921 ---  Loss: 3.165166176855564    Accuracy: 86.25\n",
      "iter 922 ---  Loss: 3.136403411626816    Accuracy: 86.09375\n",
      "iter 923 ---  Loss: 3.5354088470339775    Accuracy: 87.8125\n",
      "iter 924 ---  Loss: 2.413896679878235    Accuracy: 89.375\n",
      "iter 925 ---  Loss: 2.568338192999363    Accuracy: 87.34375\n",
      "iter 926 ---  Loss: 2.823010392487049    Accuracy: 86.71875\n",
      "iter 927 ---  Loss: 3.1230649054050446    Accuracy: 87.34375\n",
      "iter 928 ---  Loss: 3.2413318306207657    Accuracy: 86.875\n",
      "iter 929 ---  Loss: 3.3494338616728783    Accuracy: 87.5\n",
      "iter 930 ---  Loss: 3.237293891608715    Accuracy: 85.0\n",
      "iter 931 ---  Loss: 3.7266282811760902    Accuracy: 84.21875\n",
      "iter 932 ---  Loss: 2.583919070661068    Accuracy: 87.34375\n",
      "iter 933 ---  Loss: 3.3631593734025955    Accuracy: 85.625\n",
      "iter 934 ---  Loss: 3.0840283632278442    Accuracy: 88.4375\n",
      "iter 935 ---  Loss: 3.2090001851320267    Accuracy: 87.65625\n",
      "iter 936 ---  Loss: 2.7107268422842026    Accuracy: 89.84375\n",
      "iter 937 ---  Loss: 3.3958673030138016    Accuracy: 85.78125\n",
      "iter 938 ---  Loss: 2.757248304784298    Accuracy: 87.03125\n",
      "iter 939 ---  Loss: 3.0337374806404114    Accuracy: 87.8125\n",
      "iter 940 ---  Loss: 3.0206594690680504    Accuracy: 87.34375\n",
      "iter 941 ---  Loss: 3.7237486243247986    Accuracy: 86.09375\n",
      "iter 942 ---  Loss: 3.0979244261980057    Accuracy: 87.03125\n",
      "iter 943 ---  Loss: 2.6035328060388565    Accuracy: 88.59375\n",
      "iter 944 ---  Loss: 2.762285530567169    Accuracy: 86.09375\n",
      "iter 945 ---  Loss: 2.6935528367757797    Accuracy: 87.65625\n",
      "iter 946 ---  Loss: 3.0335468128323555    Accuracy: 85.9375\n",
      "iter 947 ---  Loss: 3.1334970742464066    Accuracy: 87.03125\n",
      "iter 948 ---  Loss: 2.505853995680809    Accuracy: 89.53125\n",
      "iter 949 ---  Loss: 2.9607702046632767    Accuracy: 87.8125\n",
      "iter 950 ---  Loss: 2.6277852579951286    Accuracy: 86.875\n",
      "iter 951 ---  Loss: 2.9108907654881477    Accuracy: 87.5\n",
      "iter 952 ---  Loss: 3.1331401020288467    Accuracy: 87.34375\n",
      "iter 953 ---  Loss: 2.922121360898018    Accuracy: 87.96875\n",
      "iter 954 ---  Loss: 3.4261857718229294    Accuracy: 86.875\n",
      "iter 955 ---  Loss: 3.5974740982055664    Accuracy: 86.25\n",
      "iter 956 ---  Loss: 2.8363488912582397    Accuracy: 88.28125\n",
      "iter 957 ---  Loss: 2.9761014208197594    Accuracy: 89.6875\n",
      "iter 958 ---  Loss: 3.755565784871578    Accuracy: 87.03125\n",
      "iter 959 ---  Loss: 2.81318186968565    Accuracy: 88.90625\n",
      "iter 960 ---  Loss: 3.217130072414875    Accuracy: 87.96875\n",
      "iter 961 ---  Loss: 2.9665729254484177    Accuracy: 89.53125\n",
      "iter 962 ---  Loss: 2.6264679357409477    Accuracy: 89.375\n",
      "iter 963 ---  Loss: 3.007829986512661    Accuracy: 87.8125\n",
      "iter 964 ---  Loss: 3.158142603933811    Accuracy: 87.5\n",
      "iter 965 ---  Loss: 3.1651178747415543    Accuracy: 87.03125\n",
      "iter 966 ---  Loss: 2.7754297852516174    Accuracy: 87.96875\n",
      "iter 967 ---  Loss: 3.5779952108860016    Accuracy: 86.40625\n",
      "iter 968 ---  Loss: 2.7937388867139816    Accuracy: 87.5\n",
      "iter 969 ---  Loss: 2.7216858118772507    Accuracy: 89.6875\n",
      "iter 970 ---  Loss: 3.095558486878872    Accuracy: 86.25\n",
      "iter 971 ---  Loss: 2.970686547458172    Accuracy: 86.875\n",
      "iter 972 ---  Loss: 2.952424630522728    Accuracy: 86.09375\n",
      "iter 973 ---  Loss: 2.9237256720662117    Accuracy: 88.28125\n",
      "iter 974 ---  Loss: 2.677936889231205    Accuracy: 88.4375\n",
      "iter 975 ---  Loss: 3.4057430401444435    Accuracy: 87.03125\n",
      "iter 976 ---  Loss: 3.3984094485640526    Accuracy: 87.03125\n",
      "iter 977 ---  Loss: 3.3667885959148407    Accuracy: 85.625\n",
      "iter 978 ---  Loss: 2.845932327210903    Accuracy: 87.34375\n",
      "iter 979 ---  Loss: 2.872430697083473    Accuracy: 88.75\n",
      "iter 980 ---  Loss: 2.5825712382793427    Accuracy: 87.5\n",
      "iter 981 ---  Loss: 3.377254992723465    Accuracy: 86.40625\n",
      "iter 982 ---  Loss: 3.259237267076969    Accuracy: 87.03125\n",
      "iter 983 ---  Loss: 2.870039775967598    Accuracy: 88.4375\n",
      "iter 984 ---  Loss: 2.8013952001929283    Accuracy: 88.90625\n",
      "iter 985 ---  Loss: 3.0330068320035934    Accuracy: 88.59375\n",
      "iter 986 ---  Loss: 2.8794588148593903    Accuracy: 88.4375\n",
      "iter 987 ---  Loss: 3.075423553586006    Accuracy: 86.875\n",
      "iter 988 ---  Loss: 2.6921889036893845    Accuracy: 87.1875\n",
      "iter 989 ---  Loss: 3.220208689570427    Accuracy: 86.25\n",
      "iter 990 ---  Loss: 3.4193985760211945    Accuracy: 87.34375\n",
      "iter 991 ---  Loss: 2.5504360422492027    Accuracy: 89.84375\n",
      "iter 992 ---  Loss: 3.1024465784430504    Accuracy: 87.03125\n",
      "iter 993 ---  Loss: 2.8315602019429207    Accuracy: 89.21875\n",
      "iter 994 ---  Loss: 3.2693035900592804    Accuracy: 87.65625\n",
      "iter 995 ---  Loss: 3.0256232991814613    Accuracy: 87.03125\n",
      "iter 996 ---  Loss: 3.258094906806946    Accuracy: 87.03125\n",
      "iter 997 ---  Loss: 2.7917230799794197    Accuracy: 87.34375\n",
      "iter 998 ---  Loss: 2.959430567920208    Accuracy: 88.59375\n",
      "iter 999 ---  Loss: 3.061355099081993    Accuracy: 88.75\n",
      "iter 1000 ---  Loss: 3.345793880522251    Accuracy: 87.1875\n",
      "iter 1001 ---  Loss: 3.518453001976013    Accuracy: 83.75\n",
      "iter 1002 ---  Loss: 3.0922756716609    Accuracy: 89.21875\n",
      "iter 1003 ---  Loss: 2.6393661871552467    Accuracy: 88.125\n",
      "iter 1004 ---  Loss: 3.273578852415085    Accuracy: 87.03125\n",
      "iter 1005 ---  Loss: 3.308991402387619    Accuracy: 85.78125\n",
      "iter 1006 ---  Loss: 2.65507822483778    Accuracy: 89.375\n",
      "iter 1007 ---  Loss: 3.5631316006183624    Accuracy: 87.03125\n",
      "iter 1008 ---  Loss: 2.5188392996788025    Accuracy: 87.5\n",
      "iter 1009 ---  Loss: 2.965789444744587    Accuracy: 87.96875\n",
      "iter 1010 ---  Loss: 2.842945970594883    Accuracy: 87.96875\n",
      "iter 1011 ---  Loss: 3.653215229511261    Accuracy: 87.8125\n",
      "iter 1012 ---  Loss: 2.9890022352337837    Accuracy: 86.71875\n",
      "iter 1013 ---  Loss: 3.614410437643528    Accuracy: 84.375\n",
      "iter 1014 ---  Loss: 3.223865784704685    Accuracy: 89.21875\n",
      "iter 1015 ---  Loss: 3.2522731572389603    Accuracy: 85.9375\n",
      "iter 1016 ---  Loss: 3.660741202533245    Accuracy: 85.78125\n",
      "iter 1017 ---  Loss: 3.0180361568927765    Accuracy: 87.96875\n",
      "iter 1018 ---  Loss: 3.118582636117935    Accuracy: 89.375\n",
      "iter 1019 ---  Loss: 2.9716137498617172    Accuracy: 87.03125\n",
      "iter 1020 ---  Loss: 2.7467082664370537    Accuracy: 87.5\n",
      "iter 1021 ---  Loss: 2.9692418724298477    Accuracy: 88.125\n",
      "iter 1022 ---  Loss: 3.2907510176301003    Accuracy: 88.59375\n",
      "iter 1023 ---  Loss: 2.3802292495965958    Accuracy: 90.0\n",
      "iter 1024 ---  Loss: 2.8967524766921997    Accuracy: 87.65625\n",
      "iter 1025 ---  Loss: 3.6264191269874573    Accuracy: 86.5625\n",
      "iter 1026 ---  Loss: 3.3821630850434303    Accuracy: 87.03125\n",
      "iter 1027 ---  Loss: 3.5699003785848618    Accuracy: 85.9375\n",
      "iter 1028 ---  Loss: 2.8671886026859283    Accuracy: 87.65625\n",
      "iter 1029 ---  Loss: 2.9230932742357254    Accuracy: 88.75\n",
      "iter 1030 ---  Loss: 2.5174523144960403    Accuracy: 88.59375\n",
      "iter 1031 ---  Loss: 2.6439429745078087    Accuracy: 89.0625\n",
      "iter 1032 ---  Loss: 3.1608491390943527    Accuracy: 87.65625\n",
      "iter 1033 ---  Loss: 2.676059901714325    Accuracy: 89.21875\n",
      "iter 1034 ---  Loss: 2.6432563960552216    Accuracy: 89.53125\n",
      "iter 1035 ---  Loss: 3.2522155791521072    Accuracy: 86.875\n",
      "iter 1036 ---  Loss: 3.2158209532499313    Accuracy: 84.375\n",
      "iter 1037 ---  Loss: 2.6832109317183495    Accuracy: 87.03125\n",
      "iter 1038 ---  Loss: 2.961222752928734    Accuracy: 88.28125\n",
      "iter 1039 ---  Loss: 3.572761796414852    Accuracy: 85.625\n",
      "iter 1040 ---  Loss: 3.5056715980172157    Accuracy: 87.1875\n",
      "iter 1041 ---  Loss: 2.9966889694333076    Accuracy: 88.125\n",
      "iter 1042 ---  Loss: 3.2483547255396843    Accuracy: 85.9375\n",
      "iter 1043 ---  Loss: 3.2005296424031258    Accuracy: 88.75\n",
      "iter 1044 ---  Loss: 2.781445011496544    Accuracy: 89.53125\n",
      "iter 1045 ---  Loss: 3.157691702246666    Accuracy: 87.34375\n",
      "iter 1046 ---  Loss: 2.801944114267826    Accuracy: 89.6875\n",
      "iter 1047 ---  Loss: 2.7322391644120216    Accuracy: 88.75\n",
      "iter 1048 ---  Loss: 3.1216057166457176    Accuracy: 86.875\n",
      "iter 1049 ---  Loss: 2.8133629634976387    Accuracy: 88.59375\n",
      "iter 1050 ---  Loss: 3.296197071671486    Accuracy: 86.875\n",
      "iter 1051 ---  Loss: 2.7033256515860558    Accuracy: 88.75\n",
      "iter 1052 ---  Loss: 3.3699186593294144    Accuracy: 89.6875\n",
      "iter 1053 ---  Loss: 3.0046598464250565    Accuracy: 88.4375\n",
      "iter 1054 ---  Loss: 2.829897068440914    Accuracy: 88.90625\n",
      "iter 1055 ---  Loss: 2.8985331878066063    Accuracy: 88.28125\n",
      "iter 1056 ---  Loss: 3.3338056579232216    Accuracy: 86.40625\n",
      "iter 1057 ---  Loss: 3.3443554267287254    Accuracy: 87.5\n",
      "iter 1058 ---  Loss: 2.834104299545288    Accuracy: 89.84375\n",
      "iter 1059 ---  Loss: 3.569742329418659    Accuracy: 88.75\n",
      "iter 1060 ---  Loss: 2.8389693945646286    Accuracy: 87.03125\n",
      "iter 1061 ---  Loss: 3.003922760486603    Accuracy: 85.9375\n",
      "iter 1062 ---  Loss: 2.693226233124733    Accuracy: 87.96875\n",
      "iter 1063 ---  Loss: 3.436795487999916    Accuracy: 88.90625\n",
      "iter 1064 ---  Loss: 2.628969132900238    Accuracy: 87.8125\n",
      "iter 1065 ---  Loss: 2.973476156592369    Accuracy: 87.1875\n",
      "iter 1066 ---  Loss: 2.5077861323952675    Accuracy: 89.0625\n",
      "iter 1067 ---  Loss: 3.161659814417362    Accuracy: 88.75\n",
      "iter 1068 ---  Loss: 3.1424089893698692    Accuracy: 86.40625\n",
      "iter 1069 ---  Loss: 2.7931143790483475    Accuracy: 90.3125\n",
      "iter 1070 ---  Loss: 2.9788420498371124    Accuracy: 89.0625\n",
      "iter 1071 ---  Loss: 3.387105815112591    Accuracy: 87.34375\n",
      "iter 1072 ---  Loss: 3.099449962377548    Accuracy: 87.03125\n",
      "iter 1073 ---  Loss: 2.7518894746899605    Accuracy: 88.59375\n",
      "iter 1074 ---  Loss: 3.7920443937182426    Accuracy: 87.8125\n",
      "iter 1075 ---  Loss: 3.0142587646842003    Accuracy: 84.84375\n",
      "iter 1076 ---  Loss: 3.3579705953598022    Accuracy: 86.25\n",
      "iter 1077 ---  Loss: 3.720219314098358    Accuracy: 87.5\n",
      "iter 1078 ---  Loss: 2.846231184899807    Accuracy: 87.5\n",
      "iter 1079 ---  Loss: 3.4026451259851456    Accuracy: 86.875\n",
      "iter 1080 ---  Loss: 2.6581624671816826    Accuracy: 89.21875\n",
      "iter 1081 ---  Loss: 3.1856625080108643    Accuracy: 87.34375\n",
      "iter 1082 ---  Loss: 3.373536743223667    Accuracy: 87.8125\n",
      "iter 1083 ---  Loss: 3.009364143013954    Accuracy: 87.03125\n",
      "iter 1084 ---  Loss: 3.104214295744896    Accuracy: 88.59375\n",
      "iter 1085 ---  Loss: 3.4759355410933495    Accuracy: 86.875\n",
      "iter 1086 ---  Loss: 2.7708120942115784    Accuracy: 87.8125\n",
      "iter 1087 ---  Loss: 2.8213412389159203    Accuracy: 89.0625\n",
      "iter 1088 ---  Loss: 2.785616084933281    Accuracy: 87.96875\n",
      "iter 1089 ---  Loss: 2.997114509344101    Accuracy: 88.59375\n",
      "iter 1090 ---  Loss: 3.0426700189709663    Accuracy: 87.96875\n",
      "iter 1091 ---  Loss: 2.7715685293078423    Accuracy: 87.65625\n",
      "iter 1092 ---  Loss: 2.8846974819898605    Accuracy: 88.125\n",
      "iter 1093 ---  Loss: 3.5014439672231674    Accuracy: 88.125\n",
      "iter 1094 ---  Loss: 2.92228814214468    Accuracy: 89.53125\n",
      "iter 1095 ---  Loss: 3.173199273645878    Accuracy: 87.8125\n",
      "iter 1096 ---  Loss: 3.724054090678692    Accuracy: 87.1875\n",
      "iter 1097 ---  Loss: 3.1537521854043007    Accuracy: 87.65625\n",
      "iter 1098 ---  Loss: 2.7469785064458847    Accuracy: 88.28125\n",
      "iter 1099 ---  Loss: 3.25873139500618    Accuracy: 86.71875\n",
      "iter 1100 ---  Loss: 3.0592683032155037    Accuracy: 87.8125\n",
      "iter 1101 ---  Loss: 3.3901119381189346    Accuracy: 88.4375\n",
      "iter 1102 ---  Loss: 3.970321260392666    Accuracy: 87.5\n",
      "iter 1103 ---  Loss: 2.992184601724148    Accuracy: 88.59375\n",
      "iter 1104 ---  Loss: 3.9019026160240173    Accuracy: 86.5625\n",
      "iter 1105 ---  Loss: 2.9510251358151436    Accuracy: 88.4375\n",
      "iter 1106 ---  Loss: 3.8846040964126587    Accuracy: 86.40625\n",
      "iter 1107 ---  Loss: 3.3862929940223694    Accuracy: 86.40625\n",
      "iter 1108 ---  Loss: 2.7293509244918823    Accuracy: 88.125\n",
      "iter 1109 ---  Loss: 3.354514129459858    Accuracy: 88.28125\n",
      "iter 1110 ---  Loss: 3.0802688598632812    Accuracy: 86.875\n",
      "iter 1111 ---  Loss: 2.8496329337358475    Accuracy: 87.34375\n",
      "iter 1112 ---  Loss: 2.897087700664997    Accuracy: 87.03125\n",
      "iter 1113 ---  Loss: 2.9893999844789505    Accuracy: 88.4375\n",
      "iter 1114 ---  Loss: 3.5604912862181664    Accuracy: 87.8125\n",
      "iter 1115 ---  Loss: 2.656340278685093    Accuracy: 86.875\n",
      "iter 1116 ---  Loss: 3.042750023305416    Accuracy: 88.90625\n",
      "iter 1117 ---  Loss: 3.875459708273411    Accuracy: 85.46875\n",
      "iter 1118 ---  Loss: 2.580314613878727    Accuracy: 88.90625\n",
      "iter 1119 ---  Loss: 3.091303452849388    Accuracy: 86.25\n",
      "iter 1120 ---  Loss: 3.429783098399639    Accuracy: 85.625\n",
      "iter 1121 ---  Loss: 2.9563159719109535    Accuracy: 87.65625\n",
      "iter 1122 ---  Loss: 2.6604868173599243    Accuracy: 88.4375\n",
      "iter 1123 ---  Loss: 2.9816401228308678    Accuracy: 87.65625\n",
      "iter 1124 ---  Loss: 3.895623728632927    Accuracy: 86.09375\n",
      "iter 1125 ---  Loss: 2.9399976655840874    Accuracy: 86.71875\n",
      "iter 1126 ---  Loss: 2.716848038136959    Accuracy: 88.75\n",
      "iter 1127 ---  Loss: 3.1457399800419807    Accuracy: 87.03125\n",
      "iter 1128 ---  Loss: 3.2712949588894844    Accuracy: 85.3125\n",
      "iter 1129 ---  Loss: 3.140149064362049    Accuracy: 87.5\n",
      "iter 1130 ---  Loss: 2.974321164190769    Accuracy: 87.8125\n",
      "iter 1131 ---  Loss: 3.086062975227833    Accuracy: 87.96875\n",
      "iter 1132 ---  Loss: 3.455495834350586    Accuracy: 87.8125\n",
      "iter 1133 ---  Loss: 3.194834254682064    Accuracy: 87.65625\n",
      "iter 1134 ---  Loss: 2.6925826743245125    Accuracy: 88.75\n",
      "iter 1135 ---  Loss: 3.094294384121895    Accuracy: 85.9375\n",
      "iter 1136 ---  Loss: 2.8332777470350266    Accuracy: 86.40625\n",
      "iter 1137 ---  Loss: 3.1116963252425194    Accuracy: 86.5625\n",
      "iter 1138 ---  Loss: 3.0489648282527924    Accuracy: 86.5625\n",
      "iter 1139 ---  Loss: 3.316912107169628    Accuracy: 84.53125\n",
      "iter 1140 ---  Loss: 3.650781460106373    Accuracy: 86.09375\n",
      "iter 1141 ---  Loss: 2.9875459372997284    Accuracy: 88.125\n",
      "iter 1142 ---  Loss: 2.943234659731388    Accuracy: 88.28125\n",
      "iter 1143 ---  Loss: 3.015752613544464    Accuracy: 86.71875\n",
      "iter 1144 ---  Loss: 3.1106868982315063    Accuracy: 85.625\n",
      "iter 1145 ---  Loss: 3.263550043106079    Accuracy: 86.5625\n",
      "iter 1146 ---  Loss: 3.4179493710398674    Accuracy: 88.75\n",
      "iter 1147 ---  Loss: 3.146976262331009    Accuracy: 87.65625\n",
      "iter 1148 ---  Loss: 2.615011617541313    Accuracy: 89.0625\n",
      "iter 1149 ---  Loss: 3.243860214948654    Accuracy: 85.625\n",
      "iter 1150 ---  Loss: 2.790623441338539    Accuracy: 86.40625\n",
      "iter 1151 ---  Loss: 3.3816182166337967    Accuracy: 87.1875\n",
      "iter 1152 ---  Loss: 3.5588964745402336    Accuracy: 85.46875\n",
      "iter 1153 ---  Loss: 3.049548238515854    Accuracy: 85.15625\n",
      "iter 1154 ---  Loss: 3.430546335875988    Accuracy: 85.15625\n",
      "iter 1155 ---  Loss: 2.90843103826046    Accuracy: 87.65625\n",
      "iter 1156 ---  Loss: 3.3011434674263    Accuracy: 86.40625\n",
      "iter 1157 ---  Loss: 3.0806038975715637    Accuracy: 85.9375\n",
      "iter 1158 ---  Loss: 2.767795190215111    Accuracy: 87.8125\n",
      "iter 1159 ---  Loss: 3.8699499145150185    Accuracy: 86.25\n",
      "iter 1160 ---  Loss: 2.733318902552128    Accuracy: 90.0\n",
      "iter 1161 ---  Loss: 2.7763934955000877    Accuracy: 87.1875\n",
      "iter 1162 ---  Loss: 3.4168100878596306    Accuracy: 88.28125\n",
      "iter 1163 ---  Loss: 2.9698269218206406    Accuracy: 87.5\n",
      "iter 1164 ---  Loss: 2.9987522438168526    Accuracy: 85.9375\n",
      "iter 1165 ---  Loss: 3.035992495715618    Accuracy: 87.96875\n",
      "iter 1166 ---  Loss: 3.5673284009099007    Accuracy: 85.0\n",
      "iter 1167 ---  Loss: 3.248392105102539    Accuracy: 88.4375\n",
      "iter 1168 ---  Loss: 3.087416537106037    Accuracy: 86.5625\n",
      "iter 1169 ---  Loss: 2.7255137264728546    Accuracy: 88.125\n",
      "iter 1170 ---  Loss: 3.5202653408050537    Accuracy: 88.90625\n",
      "iter 1171 ---  Loss: 2.8091199696063995    Accuracy: 86.09375\n",
      "iter 1172 ---  Loss: 2.872928351163864    Accuracy: 88.4375\n",
      "iter 1173 ---  Loss: 3.0209703892469406    Accuracy: 87.03125\n",
      "iter 1174 ---  Loss: 2.824374407529831    Accuracy: 87.96875\n",
      "iter 1175 ---  Loss: 2.532362677156925    Accuracy: 87.8125\n",
      "iter 1176 ---  Loss: 2.7369407415390015    Accuracy: 86.40625\n",
      "iter 1177 ---  Loss: 2.4863387048244476    Accuracy: 87.1875\n",
      "iter 1178 ---  Loss: 3.1312192752957344    Accuracy: 86.40625\n",
      "iter 1179 ---  Loss: 3.034984812140465    Accuracy: 87.8125\n",
      "iter 1180 ---  Loss: 2.8816918060183525    Accuracy: 87.8125\n",
      "iter 1181 ---  Loss: 3.320786699652672    Accuracy: 87.03125\n",
      "iter 1182 ---  Loss: 2.6651118248701096    Accuracy: 89.21875\n",
      "iter 1183 ---  Loss: 3.335838757455349    Accuracy: 87.34375\n",
      "iter 1184 ---  Loss: 3.2578639537096024    Accuracy: 88.4375\n",
      "iter 1185 ---  Loss: 3.4708657562732697    Accuracy: 85.9375\n",
      "iter 1186 ---  Loss: 2.8964043483138084    Accuracy: 88.28125\n",
      "iter 1187 ---  Loss: 2.9279172345995903    Accuracy: 88.28125\n",
      "iter 1188 ---  Loss: 3.23463773727417    Accuracy: 87.03125\n",
      "iter 1189 ---  Loss: 2.7190292328596115    Accuracy: 86.25\n",
      "iter 1190 ---  Loss: 2.9182151556015015    Accuracy: 87.5\n",
      "iter 1191 ---  Loss: 3.2418595999479294    Accuracy: 88.28125\n",
      "iter 1192 ---  Loss: 3.5482999831438065    Accuracy: 85.3125\n",
      "iter 1193 ---  Loss: 2.690545193850994    Accuracy: 86.5625\n",
      "iter 1194 ---  Loss: 3.3275344744324684    Accuracy: 86.875\n",
      "iter 1195 ---  Loss: 2.805674970149994    Accuracy: 89.21875\n",
      "iter 1196 ---  Loss: 2.8245679661631584    Accuracy: 87.8125\n",
      "iter 1197 ---  Loss: 2.7688167318701744    Accuracy: 89.0625\n",
      "iter 1198 ---  Loss: 3.4359042048454285    Accuracy: 86.5625\n",
      "iter 1199 ---  Loss: 3.8217884078621864    Accuracy: 85.78125\n",
      "iter 1200 ---  Loss: 2.884459465742111    Accuracy: 87.96875\n",
      "iter 1201 ---  Loss: 3.348934605717659    Accuracy: 86.71875\n",
      "iter 1202 ---  Loss: 3.989458329975605    Accuracy: 87.34375\n",
      "iter 1203 ---  Loss: 2.9293414875864983    Accuracy: 86.25\n",
      "iter 1204 ---  Loss: 3.356072284281254    Accuracy: 87.34375\n",
      "iter 1205 ---  Loss: 3.303447797894478    Accuracy: 87.34375\n",
      "iter 1206 ---  Loss: 3.088937386870384    Accuracy: 88.75\n",
      "iter 1207 ---  Loss: 3.251212492585182    Accuracy: 86.40625\n",
      "iter 1208 ---  Loss: 2.591346763074398    Accuracy: 87.5\n",
      "iter 1209 ---  Loss: 3.8090693950653076    Accuracy: 84.84375\n",
      "iter 1210 ---  Loss: 2.704836383461952    Accuracy: 89.53125\n",
      "iter 1211 ---  Loss: 3.861021988093853    Accuracy: 86.09375\n",
      "iter 1212 ---  Loss: 3.4563405588269234    Accuracy: 87.5\n",
      "iter 1213 ---  Loss: 3.247745931148529    Accuracy: 86.40625\n",
      "iter 1214 ---  Loss: 2.8054477646946907    Accuracy: 87.96875\n",
      "iter 1215 ---  Loss: 2.9651789516210556    Accuracy: 87.03125\n",
      "iter 1216 ---  Loss: 2.8062324300408363    Accuracy: 88.4375\n",
      "iter 1217 ---  Loss: 3.083342991769314    Accuracy: 89.375\n",
      "iter 1218 ---  Loss: 3.0427453443408012    Accuracy: 86.40625\n",
      "iter 1219 ---  Loss: 2.9121826216578484    Accuracy: 87.1875\n",
      "iter 1220 ---  Loss: 3.1016607135534286    Accuracy: 87.34375\n",
      "iter 1221 ---  Loss: 2.7394943684339523    Accuracy: 87.8125\n",
      "iter 1222 ---  Loss: 2.3768466860055923    Accuracy: 88.75\n",
      "iter 1223 ---  Loss: 3.2787153869867325    Accuracy: 88.28125\n",
      "iter 1224 ---  Loss: 2.860745705664158    Accuracy: 87.8125\n",
      "iter 1225 ---  Loss: 2.9852210134267807    Accuracy: 87.96875\n",
      "iter 1226 ---  Loss: 3.145978681743145    Accuracy: 85.625\n",
      "iter 1227 ---  Loss: 2.634459286928177    Accuracy: 88.4375\n",
      "iter 1228 ---  Loss: 3.0714540109038353    Accuracy: 88.28125\n",
      "iter 1229 ---  Loss: 3.991193987429142    Accuracy: 85.0\n",
      "iter 1230 ---  Loss: 2.692631758749485    Accuracy: 89.0625\n",
      "iter 1231 ---  Loss: 2.713662877678871    Accuracy: 88.4375\n",
      "iter 1232 ---  Loss: 2.7698034793138504    Accuracy: 88.90625\n",
      "iter 1233 ---  Loss: 2.771059736609459    Accuracy: 87.34375\n",
      "iter 1234 ---  Loss: 2.5016261264681816    Accuracy: 87.96875\n",
      "iter 1235 ---  Loss: 3.0970708429813385    Accuracy: 86.71875\n",
      "iter 1236 ---  Loss: 2.9043419882655144    Accuracy: 86.71875\n",
      "iter 1237 ---  Loss: 3.151703543961048    Accuracy: 85.9375\n",
      "iter 1238 ---  Loss: 2.659642770886421    Accuracy: 90.0\n",
      "iter 1239 ---  Loss: 3.0927052423357964    Accuracy: 86.25\n",
      "iter 1240 ---  Loss: 2.969995141029358    Accuracy: 84.84375\n",
      "iter 1241 ---  Loss: 2.656003773212433    Accuracy: 87.34375\n",
      "iter 1242 ---  Loss: 2.6653627827763557    Accuracy: 88.75\n",
      "iter 1243 ---  Loss: 3.1001795828342438    Accuracy: 86.5625\n",
      "iter 1244 ---  Loss: 2.8967795595526695    Accuracy: 87.1875\n",
      "iter 1245 ---  Loss: 3.0913175493478775    Accuracy: 88.28125\n",
      "iter 1246 ---  Loss: 2.9973510578274727    Accuracy: 87.1875\n",
      "iter 1247 ---  Loss: 3.097239561378956    Accuracy: 87.8125\n",
      "iter 1248 ---  Loss: 2.9427802115678787    Accuracy: 87.5\n",
      "iter 1249 ---  Loss: 2.6948999240994453    Accuracy: 88.28125\n",
      "iter 1250 ---  Loss: 3.9340181052684784    Accuracy: 85.625\n",
      "iter 1251 ---  Loss: 2.648357279598713    Accuracy: 90.3125\n",
      "iter 1252 ---  Loss: 3.0233228355646133    Accuracy: 87.8125\n",
      "iter 1253 ---  Loss: 2.6049733459949493    Accuracy: 89.21875\n",
      "iter 1254 ---  Loss: 3.0107085779309273    Accuracy: 88.59375\n",
      "iter 1255 ---  Loss: 2.8574771359562874    Accuracy: 88.75\n",
      "iter 1256 ---  Loss: 3.201130546629429    Accuracy: 87.65625\n",
      "iter 1257 ---  Loss: 2.5024052932858467    Accuracy: 91.5625\n",
      "iter 1258 ---  Loss: 2.9540678337216377    Accuracy: 88.125\n",
      "iter 1259 ---  Loss: 2.8919407948851585    Accuracy: 87.8125\n",
      "iter 1260 ---  Loss: 3.4342937767505646    Accuracy: 89.6875\n",
      "iter 1261 ---  Loss: 2.870601534843445    Accuracy: 90.625\n",
      "iter 1262 ---  Loss: 2.98180965334177    Accuracy: 88.59375\n",
      "iter 1263 ---  Loss: 3.789894685149193    Accuracy: 87.8125\n",
      "iter 1264 ---  Loss: 3.322075366973877    Accuracy: 87.8125\n",
      "iter 1265 ---  Loss: 2.631514608860016    Accuracy: 89.84375\n",
      "iter 1266 ---  Loss: 3.008640728890896    Accuracy: 86.5625\n",
      "iter 1267 ---  Loss: 2.5352379083633423    Accuracy: 89.21875\n",
      "iter 1268 ---  Loss: 3.0854631438851357    Accuracy: 86.40625\n",
      "iter 1269 ---  Loss: 3.3532290384173393    Accuracy: 88.125\n",
      "iter 1270 ---  Loss: 3.0051488429307938    Accuracy: 87.96875\n",
      "iter 1271 ---  Loss: 2.653842404484749    Accuracy: 88.125\n",
      "iter 1272 ---  Loss: 2.941247783601284    Accuracy: 87.8125\n",
      "iter 1273 ---  Loss: 2.7746986225247383    Accuracy: 88.75\n",
      "iter 1274 ---  Loss: 2.8480874821543694    Accuracy: 87.96875\n",
      "iter 1275 ---  Loss: 3.120424173772335    Accuracy: 87.65625\n",
      "iter 1276 ---  Loss: 2.872940994799137    Accuracy: 87.8125\n",
      "iter 1277 ---  Loss: 2.9721821025013924    Accuracy: 88.28125\n",
      "iter 1278 ---  Loss: 2.6083685979247093    Accuracy: 87.96875\n",
      "iter 1279 ---  Loss: 2.5833695083856583    Accuracy: 90.78125\n",
      "iter 1280 ---  Loss: 2.662099964916706    Accuracy: 88.125\n",
      "iter 1281 ---  Loss: 3.2342055290937424    Accuracy: 86.09375\n",
      "iter 1282 ---  Loss: 3.069549836218357    Accuracy: 86.875\n",
      "iter 1283 ---  Loss: 3.0388099923729897    Accuracy: 87.8125\n",
      "iter 1284 ---  Loss: 2.509586103260517    Accuracy: 90.0\n",
      "iter 1285 ---  Loss: 2.748028948903084    Accuracy: 88.125\n",
      "iter 1286 ---  Loss: 3.231664724647999    Accuracy: 86.875\n",
      "iter 1287 ---  Loss: 3.5596135407686234    Accuracy: 86.40625\n",
      "iter 1288 ---  Loss: 3.1900561153888702    Accuracy: 86.5625\n",
      "iter 1289 ---  Loss: 3.0796127319335938    Accuracy: 87.5\n",
      "iter 1290 ---  Loss: 2.583854503929615    Accuracy: 87.03125\n",
      "iter 1291 ---  Loss: 3.388447865843773    Accuracy: 85.78125\n",
      "iter 1292 ---  Loss: 2.5723377987742424    Accuracy: 91.25\n",
      "iter 1293 ---  Loss: 2.9100825414061546    Accuracy: 87.1875\n",
      "iter 1294 ---  Loss: 2.976275958120823    Accuracy: 87.65625\n",
      "iter 1295 ---  Loss: 2.8231606259942055    Accuracy: 88.4375\n",
      "iter 1296 ---  Loss: 3.2056538686156273    Accuracy: 87.96875\n",
      "iter 1297 ---  Loss: 3.1410623118281364    Accuracy: 88.90625\n",
      "iter 1298 ---  Loss: 2.9629463478922844    Accuracy: 88.59375\n",
      "iter 1299 ---  Loss: 3.145167239010334    Accuracy: 88.75\n",
      "iter 1300 ---  Loss: 3.098369300365448    Accuracy: 88.28125\n",
      "iter 1301 ---  Loss: 2.9929531142115593    Accuracy: 87.1875\n",
      "iter 1302 ---  Loss: 2.723601222038269    Accuracy: 88.28125\n",
      "iter 1303 ---  Loss: 2.7394836992025375    Accuracy: 87.8125\n",
      "iter 1304 ---  Loss: 3.467928536236286    Accuracy: 87.5\n",
      "iter 1305 ---  Loss: 3.333330348134041    Accuracy: 87.65625\n",
      "iter 1306 ---  Loss: 2.781885303556919    Accuracy: 89.21875\n",
      "iter 1307 ---  Loss: 2.8469569236040115    Accuracy: 87.65625\n",
      "iter 1308 ---  Loss: 3.0833463445305824    Accuracy: 89.375\n",
      "iter 1309 ---  Loss: 2.6566640958189964    Accuracy: 90.3125\n",
      "iter 1310 ---  Loss: 3.4704494401812553    Accuracy: 86.875\n",
      "iter 1311 ---  Loss: 3.0528678223490715    Accuracy: 89.21875\n",
      "iter 1312 ---  Loss: 2.5389796420931816    Accuracy: 89.6875\n",
      "iter 1313 ---  Loss: 3.4351566657423973    Accuracy: 87.5\n",
      "iter 1314 ---  Loss: 3.415189877152443    Accuracy: 87.34375\n",
      "iter 1315 ---  Loss: 2.881962738931179    Accuracy: 88.28125\n",
      "iter 1316 ---  Loss: 3.3279701992869377    Accuracy: 86.09375\n",
      "iter 1317 ---  Loss: 3.0109953954815865    Accuracy: 87.34375\n",
      "iter 1318 ---  Loss: 2.5608150586485863    Accuracy: 89.53125\n",
      "iter 1319 ---  Loss: 2.7347137555480003    Accuracy: 88.28125\n",
      "iter 1320 ---  Loss: 2.7879302725195885    Accuracy: 89.6875\n",
      "iter 1321 ---  Loss: 2.6305984780192375    Accuracy: 89.53125\n",
      "iter 1322 ---  Loss: 2.919516183435917    Accuracy: 88.28125\n",
      "iter 1323 ---  Loss: 3.0211985260248184    Accuracy: 88.125\n",
      "iter 1324 ---  Loss: 3.0905193090438843    Accuracy: 86.40625\n",
      "iter 1325 ---  Loss: 2.928289219737053    Accuracy: 89.0625\n",
      "iter 1326 ---  Loss: 2.8877792805433273    Accuracy: 88.28125\n",
      "iter 1327 ---  Loss: 3.0780628323554993    Accuracy: 86.875\n",
      "iter 1328 ---  Loss: 2.402785785496235    Accuracy: 89.84375\n",
      "iter 1329 ---  Loss: 3.320511966943741    Accuracy: 86.71875\n",
      "iter 1330 ---  Loss: 3.047593019902706    Accuracy: 89.53125\n",
      "iter 1331 ---  Loss: 2.851313039660454    Accuracy: 87.1875\n",
      "iter 1332 ---  Loss: 2.442759521305561    Accuracy: 88.125\n",
      "iter 1333 ---  Loss: 2.903112716972828    Accuracy: 86.09375\n",
      "iter 1334 ---  Loss: 3.0067019760608673    Accuracy: 87.34375\n",
      "iter 1335 ---  Loss: 2.5850545167922974    Accuracy: 86.5625\n",
      "iter 1336 ---  Loss: 2.789264999330044    Accuracy: 88.90625\n",
      "iter 1337 ---  Loss: 2.7207674384117126    Accuracy: 90.15625\n",
      "iter 1338 ---  Loss: 2.694812871515751    Accuracy: 89.21875\n",
      "iter 1339 ---  Loss: 2.916417174041271    Accuracy: 89.84375\n",
      "iter 1340 ---  Loss: 3.4425275698304176    Accuracy: 87.34375\n",
      "iter 1341 ---  Loss: 2.6892613023519516    Accuracy: 89.0625\n",
      "iter 1342 ---  Loss: 3.1140344589948654    Accuracy: 87.8125\n",
      "iter 1343 ---  Loss: 3.4555517211556435    Accuracy: 87.96875\n",
      "iter 1344 ---  Loss: 3.2340476661920547    Accuracy: 87.1875\n",
      "iter 1345 ---  Loss: 2.988793693482876    Accuracy: 86.25\n",
      "iter 1346 ---  Loss: 3.4543662145733833    Accuracy: 86.71875\n",
      "iter 1347 ---  Loss: 3.0626513436436653    Accuracy: 89.375\n",
      "iter 1348 ---  Loss: 2.989794112741947    Accuracy: 87.34375\n",
      "iter 1349 ---  Loss: 3.1492560356855392    Accuracy: 88.125\n",
      "iter 1350 ---  Loss: 3.4525411278009415    Accuracy: 87.03125\n",
      "iter 1351 ---  Loss: 3.1337597891688347    Accuracy: 87.03125\n",
      "iter 1352 ---  Loss: 2.391152650117874    Accuracy: 90.78125\n",
      "iter 1353 ---  Loss: 2.6109623089432716    Accuracy: 89.6875\n",
      "iter 1354 ---  Loss: 3.218823581933975    Accuracy: 87.96875\n",
      "iter 1355 ---  Loss: 3.9732141569256783    Accuracy: 87.96875\n",
      "iter 1356 ---  Loss: 2.4048462510108948    Accuracy: 88.125\n",
      "iter 1357 ---  Loss: 3.000760979950428    Accuracy: 89.0625\n",
      "iter 1358 ---  Loss: 3.4692375361919403    Accuracy: 86.71875\n",
      "iter 1359 ---  Loss: 3.593082919716835    Accuracy: 86.71875\n",
      "iter 1360 ---  Loss: 3.2661171555519104    Accuracy: 87.34375\n",
      "iter 1361 ---  Loss: 3.322813756763935    Accuracy: 88.28125\n",
      "iter 1362 ---  Loss: 2.653567060828209    Accuracy: 89.53125\n",
      "iter 1363 ---  Loss: 3.186497114598751    Accuracy: 87.34375\n",
      "iter 1364 ---  Loss: 3.3752598762512207    Accuracy: 85.46875\n",
      "iter 1365 ---  Loss: 3.0177789628505707    Accuracy: 86.25\n",
      "iter 1366 ---  Loss: 2.9570629447698593    Accuracy: 87.96875\n",
      "iter 1367 ---  Loss: 2.8738573864102364    Accuracy: 88.4375\n",
      "iter 1368 ---  Loss: 3.35350701212883    Accuracy: 88.90625\n",
      "iter 1369 ---  Loss: 2.66665980219841    Accuracy: 87.65625\n",
      "iter 1370 ---  Loss: 2.470833733677864    Accuracy: 89.0625\n",
      "iter 1371 ---  Loss: 2.7488521188497543    Accuracy: 88.75\n",
      "iter 1372 ---  Loss: 3.558977946639061    Accuracy: 88.75\n",
      "iter 1373 ---  Loss: 3.6739427596330643    Accuracy: 85.9375\n",
      "iter 1374 ---  Loss: 3.3068892881274223    Accuracy: 87.8125\n",
      "iter 1375 ---  Loss: 2.8475416898727417    Accuracy: 89.0625\n",
      "iter 1376 ---  Loss: 2.7692755311727524    Accuracy: 88.4375\n",
      "iter 1377 ---  Loss: 3.139032781124115    Accuracy: 87.03125\n",
      "iter 1378 ---  Loss: 2.818636506795883    Accuracy: 87.8125\n",
      "iter 1379 ---  Loss: 3.672583468258381    Accuracy: 87.03125\n",
      "iter 1380 ---  Loss: 3.2339233234524727    Accuracy: 87.5\n",
      "iter 1381 ---  Loss: 2.9209785163402557    Accuracy: 87.5\n",
      "iter 1382 ---  Loss: 3.997245118021965    Accuracy: 85.9375\n",
      "iter 1383 ---  Loss: 2.9334234818816185    Accuracy: 87.96875\n",
      "iter 1384 ---  Loss: 3.411579467356205    Accuracy: 86.875\n",
      "iter 1385 ---  Loss: 2.77925556153059    Accuracy: 88.4375\n",
      "iter 1386 ---  Loss: 3.001782566308975    Accuracy: 87.34375\n",
      "iter 1387 ---  Loss: 2.903621144592762    Accuracy: 88.59375\n",
      "iter 1388 ---  Loss: 3.04916999489069    Accuracy: 89.375\n",
      "iter 1389 ---  Loss: 3.2963278219103813    Accuracy: 87.03125\n",
      "iter 1390 ---  Loss: 3.4175419583916664    Accuracy: 88.75\n",
      "iter 1391 ---  Loss: 2.8568681105971336    Accuracy: 89.0625\n",
      "iter 1392 ---  Loss: 3.2608108669519424    Accuracy: 87.34375\n",
      "iter 1393 ---  Loss: 3.4628448486328125    Accuracy: 86.25\n",
      "iter 1394 ---  Loss: 2.8767366632819176    Accuracy: 87.65625\n",
      "iter 1395 ---  Loss: 3.566189505159855    Accuracy: 88.125\n",
      "iter 1396 ---  Loss: 2.948274813592434    Accuracy: 89.53125\n",
      "iter 1397 ---  Loss: 2.8082659989595413    Accuracy: 87.65625\n",
      "iter 1398 ---  Loss: 2.8097741454839706    Accuracy: 87.34375\n",
      "iter 1399 ---  Loss: 3.065582402050495    Accuracy: 85.78125\n",
      "iter 1400 ---  Loss: 3.0226796120405197    Accuracy: 88.4375\n",
      "iter 1401 ---  Loss: 2.8423504307866096    Accuracy: 87.96875\n",
      "iter 1402 ---  Loss: 3.003784343600273    Accuracy: 86.875\n",
      "iter 1403 ---  Loss: 2.7982451021671295    Accuracy: 86.875\n",
      "iter 1404 ---  Loss: 2.7028911262750626    Accuracy: 88.59375\n",
      "iter 1405 ---  Loss: 3.057003431022167    Accuracy: 87.5\n",
      "iter 1406 ---  Loss: 3.7727271914482117    Accuracy: 86.5625\n",
      "iter 1407 ---  Loss: 2.69729333370924    Accuracy: 88.90625\n",
      "iter 1408 ---  Loss: 2.8045862540602684    Accuracy: 88.90625\n",
      "iter 1409 ---  Loss: 2.9330101162195206    Accuracy: 89.53125\n",
      "iter 1410 ---  Loss: 2.7118652686476707    Accuracy: 88.90625\n",
      "iter 1411 ---  Loss: 3.346756748855114    Accuracy: 87.1875\n",
      "iter 1412 ---  Loss: 3.371667169034481    Accuracy: 86.875\n",
      "iter 1413 ---  Loss: 2.7522611245512962    Accuracy: 87.1875\n",
      "iter 1414 ---  Loss: 2.782906658947468    Accuracy: 87.8125\n",
      "iter 1415 ---  Loss: 2.5297427028417587    Accuracy: 88.125\n",
      "iter 1416 ---  Loss: 3.4665270298719406    Accuracy: 88.59375\n",
      "iter 1417 ---  Loss: 2.9197419583797455    Accuracy: 87.5\n",
      "iter 1418 ---  Loss: 3.206339791417122    Accuracy: 86.875\n",
      "iter 1419 ---  Loss: 2.9512218832969666    Accuracy: 87.03125\n",
      "iter 1420 ---  Loss: 3.2380806133151054    Accuracy: 87.5\n",
      "iter 1421 ---  Loss: 3.1638411432504654    Accuracy: 86.875\n",
      "iter 1422 ---  Loss: 3.069866858422756    Accuracy: 87.34375\n",
      "iter 1423 ---  Loss: 2.762177996337414    Accuracy: 86.875\n",
      "iter 1424 ---  Loss: 2.7295532301068306    Accuracy: 87.8125\n",
      "iter 1425 ---  Loss: 3.3723893091082573    Accuracy: 88.125\n",
      "iter 1426 ---  Loss: 2.979061685502529    Accuracy: 88.125\n",
      "iter 1427 ---  Loss: 3.450201392173767    Accuracy: 86.71875\n",
      "iter 1428 ---  Loss: 2.8824644163250923    Accuracy: 88.90625\n",
      "iter 1429 ---  Loss: 2.626535803079605    Accuracy: 87.1875\n",
      "iter 1430 ---  Loss: 3.132944770157337    Accuracy: 87.65625\n",
      "iter 1431 ---  Loss: 3.2686013504862785    Accuracy: 88.28125\n",
      "iter 1432 ---  Loss: 2.687753714621067    Accuracy: 89.6875\n",
      "iter 1433 ---  Loss: 2.93437173217535    Accuracy: 88.4375\n",
      "iter 1434 ---  Loss: 3.324648939073086    Accuracy: 87.5\n",
      "iter 1435 ---  Loss: 3.3079981207847595    Accuracy: 89.84375\n",
      "iter 1436 ---  Loss: 3.239376410841942    Accuracy: 87.1875\n",
      "iter 1437 ---  Loss: 3.0737748071551323    Accuracy: 88.59375\n",
      "iter 1438 ---  Loss: 3.0494987964630127    Accuracy: 86.40625\n",
      "iter 1439 ---  Loss: 2.874732442200184    Accuracy: 86.875\n",
      "iter 1440 ---  Loss: 3.1746683418750763    Accuracy: 87.1875\n",
      "iter 1441 ---  Loss: 2.558360405266285    Accuracy: 90.625\n",
      "iter 1442 ---  Loss: 2.678521402180195    Accuracy: 87.8125\n",
      "iter 1443 ---  Loss: 2.6804848089814186    Accuracy: 88.28125\n",
      "iter 1444 ---  Loss: 2.9945994317531586    Accuracy: 88.4375\n",
      "iter 1445 ---  Loss: 3.1120820194482803    Accuracy: 86.5625\n",
      "iter 1446 ---  Loss: 3.1906909570097923    Accuracy: 86.40625\n",
      "iter 1447 ---  Loss: 2.924234628677368    Accuracy: 87.5\n",
      "iter 1448 ---  Loss: 2.73491607606411    Accuracy: 89.0625\n",
      "iter 1449 ---  Loss: 3.114104151725769    Accuracy: 87.03125\n",
      "iter 1450 ---  Loss: 3.181408502161503    Accuracy: 85.3125\n",
      "iter 1451 ---  Loss: 2.8265686482191086    Accuracy: 87.03125\n",
      "iter 1452 ---  Loss: 3.90942370146513    Accuracy: 87.1875\n",
      "iter 1453 ---  Loss: 2.8365728557109833    Accuracy: 89.21875\n",
      "iter 1454 ---  Loss: 2.943101830780506    Accuracy: 87.34375\n",
      "iter 1455 ---  Loss: 3.035388231277466    Accuracy: 86.09375\n",
      "iter 1456 ---  Loss: 2.636865980923176    Accuracy: 88.75\n",
      "iter 1457 ---  Loss: 2.808463469147682    Accuracy: 86.09375\n",
      "iter 1458 ---  Loss: 3.0066434741020203    Accuracy: 86.71875\n",
      "iter 1459 ---  Loss: 3.238344371318817    Accuracy: 85.0\n",
      "iter 1460 ---  Loss: 3.2964709103107452    Accuracy: 86.5625\n",
      "iter 1461 ---  Loss: 2.683726742863655    Accuracy: 87.8125\n",
      "iter 1462 ---  Loss: 3.200966604053974    Accuracy: 87.1875\n",
      "iter 1463 ---  Loss: 4.289270989596844    Accuracy: 87.1875\n",
      "iter 1464 ---  Loss: 3.4415387958288193    Accuracy: 86.875\n",
      "iter 1465 ---  Loss: 3.3677279502153397    Accuracy: 86.25\n",
      "iter 1466 ---  Loss: 3.2644308283925056    Accuracy: 86.5625\n",
      "iter 1467 ---  Loss: 3.3358061388134956    Accuracy: 86.25\n",
      "iter 1468 ---  Loss: 2.799354575574398    Accuracy: 88.59375\n",
      "iter 1469 ---  Loss: 2.953739680349827    Accuracy: 88.90625\n",
      "iter 1470 ---  Loss: 3.5683932304382324    Accuracy: 85.9375\n",
      "iter 1471 ---  Loss: 2.934992365539074    Accuracy: 87.8125\n",
      "iter 1472 ---  Loss: 3.7718648314476013    Accuracy: 85.3125\n",
      "iter 1473 ---  Loss: 3.32760538905859    Accuracy: 86.25\n",
      "iter 1474 ---  Loss: 3.1111893504858017    Accuracy: 87.1875\n",
      "iter 1475 ---  Loss: 2.9491618499159813    Accuracy: 87.5\n",
      "iter 1476 ---  Loss: 3.4769167080521584    Accuracy: 87.65625\n",
      "iter 1477 ---  Loss: 3.016714721918106    Accuracy: 88.4375\n",
      "iter 1478 ---  Loss: 2.619092158973217    Accuracy: 88.59375\n",
      "iter 1479 ---  Loss: 3.131630964577198    Accuracy: 87.5\n",
      "iter 1480 ---  Loss: 2.984136402606964    Accuracy: 87.1875\n",
      "iter 1481 ---  Loss: 3.42780239880085    Accuracy: 85.0\n",
      "iter 1482 ---  Loss: 3.2614185735583305    Accuracy: 87.1875\n",
      "iter 1483 ---  Loss: 3.281901590526104    Accuracy: 82.8125\n",
      "iter 1484 ---  Loss: 2.6665098667144775    Accuracy: 89.84375\n",
      "iter 1485 ---  Loss: 3.2259835973381996    Accuracy: 86.5625\n",
      "iter 1486 ---  Loss: 3.1969707012176514    Accuracy: 88.125\n",
      "iter 1487 ---  Loss: 3.021246075630188    Accuracy: 87.65625\n",
      "iter 1488 ---  Loss: 3.2843013927340508    Accuracy: 85.0\n",
      "iter 1489 ---  Loss: 2.7691989317536354    Accuracy: 87.1875\n",
      "iter 1490 ---  Loss: 2.7903911992907524    Accuracy: 87.65625\n",
      "iter 1491 ---  Loss: 2.7719888538122177    Accuracy: 86.5625\n",
      "iter 1492 ---  Loss: 3.1653716787695885    Accuracy: 85.3125\n",
      "iter 1493 ---  Loss: 3.951481521129608    Accuracy: 85.9375\n",
      "iter 1494 ---  Loss: 3.2025582268834114    Accuracy: 89.0625\n",
      "iter 1495 ---  Loss: 2.8770985081791878    Accuracy: 87.8125\n",
      "iter 1496 ---  Loss: 2.738557569682598    Accuracy: 86.875\n",
      "iter 1497 ---  Loss: 2.682073377072811    Accuracy: 89.21875\n",
      "iter 1498 ---  Loss: 4.10819198936224    Accuracy: 86.71875\n",
      "iter 1499 ---  Loss: 3.292291522026062    Accuracy: 86.875\n",
      "iter 1500 ---  Loss: 3.003686487674713    Accuracy: 85.78125\n",
      "iter 1501 ---  Loss: 3.270175889134407    Accuracy: 87.34375\n",
      "iter 1502 ---  Loss: 2.7945015877485275    Accuracy: 88.4375\n",
      "iter 1503 ---  Loss: 2.9615376070141792    Accuracy: 87.34375\n",
      "iter 1504 ---  Loss: 3.3123706728219986    Accuracy: 86.40625\n",
      "iter 1505 ---  Loss: 2.8977965116500854    Accuracy: 86.71875\n",
      "iter 1506 ---  Loss: 3.408174157142639    Accuracy: 85.3125\n",
      "iter 1507 ---  Loss: 3.236322619020939    Accuracy: 86.40625\n",
      "iter 1508 ---  Loss: 3.026435509324074    Accuracy: 86.875\n",
      "iter 1509 ---  Loss: 2.605137377977371    Accuracy: 89.21875\n",
      "iter 1510 ---  Loss: 2.9079245552420616    Accuracy: 86.71875\n",
      "iter 1511 ---  Loss: 3.336065337061882    Accuracy: 86.25\n",
      "iter 1512 ---  Loss: 3.772573508322239    Accuracy: 85.0\n",
      "iter 1513 ---  Loss: 2.6987105384469032    Accuracy: 88.125\n",
      "iter 1514 ---  Loss: 3.409072257578373    Accuracy: 85.9375\n",
      "iter 1515 ---  Loss: 2.8606878146529198    Accuracy: 87.96875\n",
      "iter 1516 ---  Loss: 3.1995843201875687    Accuracy: 86.25\n",
      "iter 1517 ---  Loss: 3.265179641544819    Accuracy: 87.65625\n",
      "iter 1518 ---  Loss: 2.512898288667202    Accuracy: 88.75\n",
      "iter 1519 ---  Loss: 3.33080143481493    Accuracy: 87.5\n",
      "iter 1520 ---  Loss: 3.2002884224057198    Accuracy: 87.65625\n",
      "iter 1521 ---  Loss: 3.795425698161125    Accuracy: 87.1875\n",
      "iter 1522 ---  Loss: 2.947648912668228    Accuracy: 88.28125\n",
      "iter 1523 ---  Loss: 3.114050976932049    Accuracy: 87.5\n",
      "iter 1524 ---  Loss: 2.794554591178894    Accuracy: 87.65625\n",
      "iter 1525 ---  Loss: 2.6548712998628616    Accuracy: 87.96875\n",
      "iter 1526 ---  Loss: 2.792783170938492    Accuracy: 89.6875\n",
      "iter 1527 ---  Loss: 2.8380445316433907    Accuracy: 87.34375\n",
      "iter 1528 ---  Loss: 2.824112981557846    Accuracy: 87.03125\n",
      "iter 1529 ---  Loss: 3.093769073486328    Accuracy: 87.8125\n",
      "iter 1530 ---  Loss: 2.4424117729067802    Accuracy: 89.84375\n",
      "iter 1531 ---  Loss: 3.2273268327116966    Accuracy: 86.09375\n",
      "iter 1532 ---  Loss: 3.5322080552577972    Accuracy: 87.8125\n",
      "iter 1533 ---  Loss: 3.0016011968255043    Accuracy: 88.28125\n",
      "iter 1534 ---  Loss: 3.083494372665882    Accuracy: 87.96875\n",
      "iter 1535 ---  Loss: 2.7709993347525597    Accuracy: 87.1875\n",
      "iter 1536 ---  Loss: 3.4252084717154503    Accuracy: 86.875\n",
      "iter 1537 ---  Loss: 3.173177309334278    Accuracy: 86.71875\n",
      "iter 1538 ---  Loss: 3.4890115186572075    Accuracy: 87.1875\n",
      "iter 1539 ---  Loss: 3.179431937634945    Accuracy: 87.8125\n",
      "iter 1540 ---  Loss: 2.733574040234089    Accuracy: 86.40625\n",
      "iter 1541 ---  Loss: 3.0513521805405617    Accuracy: 87.96875\n",
      "iter 1542 ---  Loss: 3.493761047720909    Accuracy: 87.5\n",
      "iter 1543 ---  Loss: 3.4151968136429787    Accuracy: 87.65625\n",
      "iter 1544 ---  Loss: 3.0409718677401543    Accuracy: 87.34375\n",
      "iter 1545 ---  Loss: 3.3588364496827126    Accuracy: 85.3125\n",
      "iter 1546 ---  Loss: 3.1502831280231476    Accuracy: 86.5625\n",
      "iter 1547 ---  Loss: 3.165328584611416    Accuracy: 86.25\n",
      "iter 1548 ---  Loss: 3.023746319115162    Accuracy: 88.90625\n",
      "iter 1549 ---  Loss: 3.848582871258259    Accuracy: 85.15625\n",
      "iter 1550 ---  Loss: 2.8644061759114265    Accuracy: 88.75\n",
      "iter 1551 ---  Loss: 2.9035115987062454    Accuracy: 86.875\n",
      "iter 1552 ---  Loss: 3.518101766705513    Accuracy: 86.25\n",
      "iter 1553 ---  Loss: 3.460621103644371    Accuracy: 87.03125\n",
      "iter 1554 ---  Loss: 2.8997903540730476    Accuracy: 87.96875\n",
      "iter 1555 ---  Loss: 2.9059661477804184    Accuracy: 86.09375\n",
      "iter 1556 ---  Loss: 3.3373043462634087    Accuracy: 87.5\n",
      "iter 1557 ---  Loss: 3.163995638489723    Accuracy: 85.625\n",
      "iter 1558 ---  Loss: 2.8007973209023476    Accuracy: 88.125\n",
      "iter 1559 ---  Loss: 3.200646288692951    Accuracy: 86.71875\n",
      "iter 1560 ---  Loss: 3.3373535498976707    Accuracy: 88.75\n",
      "iter 1561 ---  Loss: 2.7824529260396957    Accuracy: 86.71875\n",
      "iter 1562 ---  Loss: 2.800817094743252    Accuracy: 88.125\n",
      "iter 1563 ---  Loss: 2.693160928785801    Accuracy: 87.03125\n",
      "iter 1564 ---  Loss: 4.108404062688351    Accuracy: 85.46875\n",
      "iter 1565 ---  Loss: 3.1319063678383827    Accuracy: 87.65625\n",
      "iter 1566 ---  Loss: 4.090933129191399    Accuracy: 85.0\n",
      "iter 1567 ---  Loss: 2.6318712010979652    Accuracy: 88.125\n",
      "iter 1568 ---  Loss: 3.337058737874031    Accuracy: 85.78125\n",
      "iter 1569 ---  Loss: 2.9073592349886894    Accuracy: 88.125\n",
      "iter 1570 ---  Loss: 3.0966831371188164    Accuracy: 86.5625\n",
      "iter 1571 ---  Loss: 3.1603005081415176    Accuracy: 87.03125\n",
      "iter 1572 ---  Loss: 2.8021293580532074    Accuracy: 87.96875\n",
      "iter 1573 ---  Loss: 3.141775853931904    Accuracy: 85.3125\n",
      "iter 1574 ---  Loss: 3.388163775205612    Accuracy: 85.625\n",
      "iter 1575 ---  Loss: 3.0867456048727036    Accuracy: 85.625\n",
      "iter 1576 ---  Loss: 2.883721023797989    Accuracy: 87.34375\n",
      "iter 1577 ---  Loss: 2.6600476279854774    Accuracy: 87.5\n",
      "iter 1578 ---  Loss: 3.154952608048916    Accuracy: 87.1875\n",
      "iter 1579 ---  Loss: 3.664901554584503    Accuracy: 86.5625\n",
      "iter 1580 ---  Loss: 3.3426700830459595    Accuracy: 87.1875\n",
      "iter 1581 ---  Loss: 2.5771229192614555    Accuracy: 88.75\n",
      "iter 1582 ---  Loss: 2.8188235759735107    Accuracy: 87.65625\n",
      "iter 1583 ---  Loss: 2.8989691734313965    Accuracy: 88.59375\n",
      "iter 1584 ---  Loss: 3.134673923254013    Accuracy: 86.71875\n",
      "iter 1585 ---  Loss: 2.535599187016487    Accuracy: 88.59375\n",
      "iter 1586 ---  Loss: 3.424758158624172    Accuracy: 86.875\n",
      "iter 1587 ---  Loss: 3.1050151735544205    Accuracy: 86.25\n",
      "iter 1588 ---  Loss: 2.9023983627557755    Accuracy: 87.34375\n",
      "iter 1589 ---  Loss: 3.2491414174437523    Accuracy: 87.34375\n",
      "iter 1590 ---  Loss: 2.844318449497223    Accuracy: 87.5\n",
      "iter 1591 ---  Loss: 2.799045592546463    Accuracy: 86.40625\n",
      "iter 1592 ---  Loss: 2.7764495238661766    Accuracy: 86.875\n",
      "iter 1593 ---  Loss: 3.2852164581418037    Accuracy: 86.875\n",
      "iter 1594 ---  Loss: 2.953179217875004    Accuracy: 87.65625\n",
      "iter 1595 ---  Loss: 2.999969467520714    Accuracy: 87.5\n",
      "iter 1596 ---  Loss: 3.548314966261387    Accuracy: 85.15625\n",
      "iter 1597 ---  Loss: 3.128932885825634    Accuracy: 87.65625\n",
      "iter 1598 ---  Loss: 2.9797285199165344    Accuracy: 86.40625\n",
      "iter 1599 ---  Loss: 2.9992449805140495    Accuracy: 86.25\n",
      "iter 1600 ---  Loss: 2.8178479373455048    Accuracy: 88.28125\n",
      "iter 1601 ---  Loss: 3.678701102733612    Accuracy: 86.71875\n",
      "iter 1602 ---  Loss: 3.302312470972538    Accuracy: 87.96875\n",
      "iter 1603 ---  Loss: 2.5812694504857063    Accuracy: 90.15625\n",
      "iter 1604 ---  Loss: 3.199031725525856    Accuracy: 87.34375\n",
      "iter 1605 ---  Loss: 2.5534338280558586    Accuracy: 88.59375\n",
      "iter 1606 ---  Loss: 2.9478778690099716    Accuracy: 87.5\n",
      "iter 1607 ---  Loss: 3.0478096455335617    Accuracy: 88.28125\n",
      "iter 1608 ---  Loss: 3.1190233901143074    Accuracy: 86.25\n",
      "iter 1609 ---  Loss: 3.4720680713653564    Accuracy: 87.1875\n",
      "iter 1610 ---  Loss: 4.136953093111515    Accuracy: 83.75\n",
      "iter 1611 ---  Loss: 2.703846864402294    Accuracy: 89.53125\n",
      "iter 1612 ---  Loss: 3.000710092484951    Accuracy: 86.5625\n",
      "iter 1613 ---  Loss: 3.170818403363228    Accuracy: 87.5\n",
      "iter 1614 ---  Loss: 2.7887096107006073    Accuracy: 87.65625\n",
      "iter 1615 ---  Loss: 2.6479120329022408    Accuracy: 87.96875\n",
      "iter 1616 ---  Loss: 2.961421951651573    Accuracy: 87.5\n",
      "iter 1617 ---  Loss: 3.25592253357172    Accuracy: 86.71875\n",
      "iter 1618 ---  Loss: 2.954330287873745    Accuracy: 87.34375\n",
      "iter 1619 ---  Loss: 2.6777686178684235    Accuracy: 87.5\n",
      "iter 1620 ---  Loss: 3.401609383523464    Accuracy: 89.0625\n",
      "iter 1621 ---  Loss: 3.1637198328971863    Accuracy: 86.5625\n",
      "iter 1622 ---  Loss: 3.116889089345932    Accuracy: 88.125\n",
      "iter 1623 ---  Loss: 3.102375201880932    Accuracy: 87.96875\n",
      "iter 1624 ---  Loss: 3.5245384499430656    Accuracy: 87.03125\n",
      "iter 1625 ---  Loss: 2.726871833205223    Accuracy: 89.375\n",
      "iter 1626 ---  Loss: 2.983186759054661    Accuracy: 90.78125\n",
      "iter 1627 ---  Loss: 3.281696178019047    Accuracy: 85.3125\n",
      "iter 1628 ---  Loss: 3.0548745915293694    Accuracy: 87.96875\n",
      "iter 1629 ---  Loss: 3.182894356548786    Accuracy: 86.25\n",
      "iter 1630 ---  Loss: 3.1480650827288628    Accuracy: 86.09375\n",
      "iter 1631 ---  Loss: 2.6567942276597023    Accuracy: 88.59375\n",
      "iter 1632 ---  Loss: 2.9206473901867867    Accuracy: 86.71875\n",
      "iter 1633 ---  Loss: 3.6061143428087234    Accuracy: 85.3125\n",
      "iter 1634 ---  Loss: 2.7563290745019913    Accuracy: 89.21875\n",
      "iter 1635 ---  Loss: 2.8316192254424095    Accuracy: 88.75\n",
      "iter 1636 ---  Loss: 3.1171959787607193    Accuracy: 86.25\n",
      "iter 1637 ---  Loss: 2.853530928492546    Accuracy: 87.96875\n",
      "iter 1638 ---  Loss: 2.927202306687832    Accuracy: 85.9375\n",
      "iter 1639 ---  Loss: 3.1251993402838707    Accuracy: 86.40625\n",
      "iter 1640 ---  Loss: 3.0265855565667152    Accuracy: 87.34375\n",
      "iter 1641 ---  Loss: 2.890985295176506    Accuracy: 87.5\n",
      "iter 1642 ---  Loss: 3.431589089334011    Accuracy: 87.5\n",
      "iter 1643 ---  Loss: 3.0375912114977837    Accuracy: 88.4375\n",
      "iter 1644 ---  Loss: 3.2523809298872948    Accuracy: 86.40625\n",
      "iter 1645 ---  Loss: 3.506605215370655    Accuracy: 86.5625\n",
      "iter 1646 ---  Loss: 3.0694835409522057    Accuracy: 87.8125\n",
      "iter 1647 ---  Loss: 3.335874281823635    Accuracy: 87.96875\n",
      "iter 1648 ---  Loss: 3.921287402510643    Accuracy: 85.625\n",
      "iter 1649 ---  Loss: 3.8096999153494835    Accuracy: 84.21875\n",
      "iter 1650 ---  Loss: 3.1830589696764946    Accuracy: 87.65625\n",
      "iter 1651 ---  Loss: 3.9467623233795166    Accuracy: 84.21875\n",
      "iter 1652 ---  Loss: 3.2099673599004745    Accuracy: 84.84375\n",
      "iter 1653 ---  Loss: 3.0848085954785347    Accuracy: 86.5625\n",
      "iter 1654 ---  Loss: 3.407462626695633    Accuracy: 86.875\n",
      "iter 1655 ---  Loss: 2.828237049281597    Accuracy: 87.03125\n",
      "iter 1656 ---  Loss: 3.206030361354351    Accuracy: 85.9375\n",
      "iter 1657 ---  Loss: 3.2659627869725227    Accuracy: 87.1875\n",
      "iter 1658 ---  Loss: 2.8937943801283836    Accuracy: 90.3125\n",
      "iter 1659 ---  Loss: 3.427445225417614    Accuracy: 86.40625\n",
      "iter 1660 ---  Loss: 2.7104639410972595    Accuracy: 88.90625\n",
      "iter 1661 ---  Loss: 3.4934112206101418    Accuracy: 88.4375\n",
      "iter 1662 ---  Loss: 2.8729446828365326    Accuracy: 87.65625\n",
      "iter 1663 ---  Loss: 3.963393859565258    Accuracy: 86.5625\n",
      "iter 1664 ---  Loss: 2.7718667909502983    Accuracy: 89.0625\n",
      "iter 1665 ---  Loss: 2.772312209010124    Accuracy: 90.15625\n",
      "iter 1666 ---  Loss: 2.9638423696160316    Accuracy: 87.8125\n",
      "iter 1667 ---  Loss: 3.4580047875642776    Accuracy: 87.1875\n",
      "iter 1668 ---  Loss: 3.799714833498001    Accuracy: 87.65625\n",
      "iter 1669 ---  Loss: 2.5389316007494926    Accuracy: 89.0625\n",
      "iter 1670 ---  Loss: 3.1023228839039803    Accuracy: 87.65625\n",
      "iter 1671 ---  Loss: 2.733325369656086    Accuracy: 86.71875\n",
      "iter 1672 ---  Loss: 3.139995977282524    Accuracy: 87.1875\n",
      "iter 1673 ---  Loss: 2.887776091694832    Accuracy: 87.65625\n",
      "iter 1674 ---  Loss: 3.2708127349615097    Accuracy: 85.9375\n",
      "iter 1675 ---  Loss: 3.0160324722528458    Accuracy: 86.875\n",
      "iter 1676 ---  Loss: 2.7587477564811707    Accuracy: 88.59375\n",
      "iter 1677 ---  Loss: 3.267991192638874    Accuracy: 86.71875\n",
      "iter 1678 ---  Loss: 2.9571475759148598    Accuracy: 87.5\n",
      "iter 1679 ---  Loss: 3.131041832268238    Accuracy: 86.09375\n",
      "iter 1680 ---  Loss: 2.6760328337550163    Accuracy: 88.59375\n",
      "iter 1681 ---  Loss: 2.7501843944191933    Accuracy: 87.65625\n",
      "iter 1682 ---  Loss: 2.569273956120014    Accuracy: 89.6875\n",
      "iter 1683 ---  Loss: 3.452329993247986    Accuracy: 86.71875\n",
      "iter 1684 ---  Loss: 3.3114767745137215    Accuracy: 84.53125\n",
      "iter 1685 ---  Loss: 3.0318711027503014    Accuracy: 86.875\n",
      "iter 1686 ---  Loss: 2.97657423466444    Accuracy: 87.5\n",
      "iter 1687 ---  Loss: 3.0357774272561073    Accuracy: 87.1875\n",
      "iter 1688 ---  Loss: 3.257154516875744    Accuracy: 86.5625\n",
      "iter 1689 ---  Loss: 2.8817247822880745    Accuracy: 86.71875\n",
      "iter 1690 ---  Loss: 2.7749801948666573    Accuracy: 87.5\n",
      "iter 1691 ---  Loss: 3.371995784342289    Accuracy: 85.46875\n",
      "iter 1692 ---  Loss: 2.7925386279821396    Accuracy: 87.65625\n",
      "iter 1693 ---  Loss: 3.9436367750167847    Accuracy: 86.71875\n",
      "iter 1694 ---  Loss: 3.2767172008752823    Accuracy: 87.65625\n",
      "iter 1695 ---  Loss: 3.283129096031189    Accuracy: 86.71875\n",
      "iter 1696 ---  Loss: 3.188217855989933    Accuracy: 85.3125\n",
      "iter 1697 ---  Loss: 2.756494201719761    Accuracy: 86.25\n",
      "iter 1698 ---  Loss: 2.657910495996475    Accuracy: 87.96875\n",
      "iter 1699 ---  Loss: 3.1167199909687042    Accuracy: 86.40625\n",
      "iter 1700 ---  Loss: 2.8660211265087128    Accuracy: 88.28125\n",
      "iter 1701 ---  Loss: 3.1477822214365005    Accuracy: 84.84375\n",
      "iter 1702 ---  Loss: 2.7498203814029694    Accuracy: 89.0625\n",
      "iter 1703 ---  Loss: 2.6874468475580215    Accuracy: 88.28125\n",
      "iter 1704 ---  Loss: 3.6438647881150246    Accuracy: 85.625\n",
      "iter 1705 ---  Loss: 3.0515672117471695    Accuracy: 87.03125\n",
      "iter 1706 ---  Loss: 2.944329746067524    Accuracy: 86.875\n",
      "iter 1707 ---  Loss: 3.027544729411602    Accuracy: 87.65625\n",
      "iter 1708 ---  Loss: 3.4758364260196686    Accuracy: 86.5625\n",
      "iter 1709 ---  Loss: 3.033120408654213    Accuracy: 88.4375\n",
      "iter 1710 ---  Loss: 3.308193601667881    Accuracy: 87.5\n",
      "iter 1711 ---  Loss: 2.6080717369914055    Accuracy: 88.28125\n",
      "iter 1712 ---  Loss: 3.497208021581173    Accuracy: 86.5625\n",
      "iter 1713 ---  Loss: 3.1372846215963364    Accuracy: 88.125\n",
      "iter 1714 ---  Loss: 3.1631230413913727    Accuracy: 86.25\n",
      "iter 1715 ---  Loss: 3.1182100102305412    Accuracy: 87.1875\n",
      "iter 1716 ---  Loss: 2.847041867673397    Accuracy: 89.375\n",
      "iter 1717 ---  Loss: 3.1973761469125748    Accuracy: 86.71875\n",
      "iter 1718 ---  Loss: 2.805868975818157    Accuracy: 88.125\n",
      "iter 1719 ---  Loss: 3.2492274418473244    Accuracy: 88.28125\n",
      "iter 1720 ---  Loss: 3.3322927355766296    Accuracy: 83.90625\n",
      "iter 1721 ---  Loss: 2.7452533841133118    Accuracy: 87.5\n",
      "iter 1722 ---  Loss: 3.0363562628626823    Accuracy: 86.5625\n",
      "iter 1723 ---  Loss: 3.526168867945671    Accuracy: 86.71875\n",
      "iter 1724 ---  Loss: 2.9541027396917343    Accuracy: 86.25\n",
      "iter 1725 ---  Loss: 2.394085444509983    Accuracy: 90.0\n",
      "iter 1726 ---  Loss: 3.1235385313630104    Accuracy: 87.03125\n",
      "iter 1727 ---  Loss: 2.6100857704877853    Accuracy: 88.75\n",
      "iter 1728 ---  Loss: 2.6416475772857666    Accuracy: 90.0\n",
      "iter 1729 ---  Loss: 3.3642958253622055    Accuracy: 85.15625\n",
      "iter 1730 ---  Loss: 2.8165105506777763    Accuracy: 87.8125\n",
      "iter 1731 ---  Loss: 3.457302749156952    Accuracy: 87.03125\n",
      "iter 1732 ---  Loss: 2.9997864067554474    Accuracy: 88.90625\n",
      "iter 1733 ---  Loss: 2.849256731569767    Accuracy: 88.59375\n",
      "iter 1734 ---  Loss: 2.5532945469021797    Accuracy: 88.4375\n",
      "iter 1735 ---  Loss: 3.3741653859615326    Accuracy: 88.28125\n",
      "iter 1736 ---  Loss: 2.773705005645752    Accuracy: 88.4375\n",
      "iter 1737 ---  Loss: 3.2287029325962067    Accuracy: 86.875\n",
      "iter 1738 ---  Loss: 3.189218506217003    Accuracy: 87.65625\n",
      "iter 1739 ---  Loss: 2.8967534601688385    Accuracy: 88.125\n",
      "iter 1740 ---  Loss: 3.1413626074790955    Accuracy: 89.6875\n",
      "iter 1741 ---  Loss: 3.143505647778511    Accuracy: 88.90625\n",
      "iter 1742 ---  Loss: 2.9457694739103317    Accuracy: 88.4375\n",
      "iter 1743 ---  Loss: 3.186893939971924    Accuracy: 89.53125\n",
      "iter 1744 ---  Loss: 3.0327571257948875    Accuracy: 86.875\n",
      "iter 1745 ---  Loss: 3.037943236529827    Accuracy: 87.34375\n",
      "iter 1746 ---  Loss: 3.653774544596672    Accuracy: 88.4375\n",
      "iter 1747 ---  Loss: 3.1990992352366447    Accuracy: 85.15625\n",
      "iter 1748 ---  Loss: 2.50270214676857    Accuracy: 87.03125\n",
      "iter 1749 ---  Loss: 3.9844093173742294    Accuracy: 87.5\n",
      "iter 1750 ---  Loss: 3.1314497590065002    Accuracy: 86.25\n",
      "iter 1751 ---  Loss: 2.853894665837288    Accuracy: 85.625\n",
      "iter 1752 ---  Loss: 3.9399196729063988    Accuracy: 85.3125\n",
      "iter 1753 ---  Loss: 3.59855517745018    Accuracy: 85.78125\n",
      "iter 1754 ---  Loss: 3.4688984975218773    Accuracy: 86.25\n",
      "iter 1755 ---  Loss: 2.8228575959801674    Accuracy: 88.59375\n",
      "iter 1756 ---  Loss: 3.183679759502411    Accuracy: 86.09375\n",
      "iter 1757 ---  Loss: 2.9126692190766335    Accuracy: 87.65625\n",
      "iter 1758 ---  Loss: 3.1203042715787888    Accuracy: 88.28125\n",
      "iter 1759 ---  Loss: 2.9930772185325623    Accuracy: 87.96875\n",
      "iter 1760 ---  Loss: 2.712315745651722    Accuracy: 89.21875\n",
      "iter 1761 ---  Loss: 2.849418729543686    Accuracy: 86.40625\n",
      "iter 1762 ---  Loss: 3.883738823235035    Accuracy: 85.9375\n",
      "iter 1763 ---  Loss: 3.1085393205285072    Accuracy: 86.875\n",
      "iter 1764 ---  Loss: 2.6504041999578476    Accuracy: 88.90625\n",
      "iter 1765 ---  Loss: 3.7433554902672768    Accuracy: 86.25\n",
      "iter 1766 ---  Loss: 3.486046977341175    Accuracy: 87.34375\n",
      "iter 1767 ---  Loss: 2.892181597650051    Accuracy: 87.5\n",
      "iter 1768 ---  Loss: 3.377274051308632    Accuracy: 86.25\n",
      "iter 1769 ---  Loss: 3.032342813909054    Accuracy: 89.53125\n",
      "iter 1770 ---  Loss: 3.2879990562796593    Accuracy: 85.9375\n",
      "iter 1771 ---  Loss: 2.7860535606741905    Accuracy: 88.28125\n",
      "iter 1772 ---  Loss: 3.2818541154265404    Accuracy: 85.46875\n",
      "iter 1773 ---  Loss: 2.8180537968873978    Accuracy: 89.0625\n",
      "iter 1774 ---  Loss: 2.7843249142169952    Accuracy: 88.59375\n",
      "iter 1775 ---  Loss: 2.960656151175499    Accuracy: 88.125\n",
      "iter 1776 ---  Loss: 2.587403729557991    Accuracy: 89.53125\n",
      "iter 1777 ---  Loss: 2.7582175582647324    Accuracy: 87.65625\n",
      "iter 1778 ---  Loss: 3.113825000822544    Accuracy: 87.1875\n",
      "iter 1779 ---  Loss: 2.591636911034584    Accuracy: 89.0625\n",
      "iter 1780 ---  Loss: 3.1078773513436317    Accuracy: 87.8125\n",
      "iter 1781 ---  Loss: 2.8720590695738792    Accuracy: 86.5625\n",
      "iter 1782 ---  Loss: 3.2994726300239563    Accuracy: 86.25\n",
      "iter 1783 ---  Loss: 3.1848626509308815    Accuracy: 88.125\n",
      "iter 1784 ---  Loss: 3.028008669614792    Accuracy: 86.71875\n",
      "iter 1785 ---  Loss: 3.284811742603779    Accuracy: 87.03125\n",
      "iter 1786 ---  Loss: 3.055024243891239    Accuracy: 88.4375\n",
      "iter 1787 ---  Loss: 2.811554379761219    Accuracy: 87.96875\n",
      "iter 1788 ---  Loss: 3.056118071079254    Accuracy: 85.625\n",
      "iter 1789 ---  Loss: 2.9812309816479683    Accuracy: 87.34375\n",
      "iter 1790 ---  Loss: 3.540241874754429    Accuracy: 87.65625\n",
      "iter 1791 ---  Loss: 2.87037892639637    Accuracy: 87.34375\n",
      "iter 1792 ---  Loss: 2.980703555047512    Accuracy: 87.96875\n",
      "iter 1793 ---  Loss: 3.100007101893425    Accuracy: 87.03125\n",
      "iter 1794 ---  Loss: 3.096033990383148    Accuracy: 87.65625\n",
      "iter 1795 ---  Loss: 3.478003680706024    Accuracy: 87.96875\n",
      "iter 1796 ---  Loss: 2.7062839418649673    Accuracy: 87.65625\n",
      "iter 1797 ---  Loss: 3.1035549268126488    Accuracy: 87.65625\n",
      "iter 1798 ---  Loss: 2.4538577124476433    Accuracy: 89.375\n",
      "iter 1799 ---  Loss: 2.6397052481770515    Accuracy: 87.8125\n",
      "iter 1800 ---  Loss: 3.156265437602997    Accuracy: 86.09375\n",
      "iter 1801 ---  Loss: 3.1860342249274254    Accuracy: 88.28125\n",
      "iter 1802 ---  Loss: 3.357692688703537    Accuracy: 85.46875\n",
      "iter 1803 ---  Loss: 2.9134356305003166    Accuracy: 87.8125\n",
      "iter 1804 ---  Loss: 2.9185393527150154    Accuracy: 87.96875\n",
      "iter 1805 ---  Loss: 2.729933351278305    Accuracy: 89.21875\n",
      "iter 1806 ---  Loss: 2.998102083802223    Accuracy: 86.40625\n",
      "iter 1807 ---  Loss: 3.1752368360757828    Accuracy: 88.75\n",
      "iter 1808 ---  Loss: 2.7272405549883842    Accuracy: 89.53125\n",
      "iter 1809 ---  Loss: 3.734269604086876    Accuracy: 85.15625\n",
      "iter 1810 ---  Loss: 3.3471063375473022    Accuracy: 86.5625\n",
      "iter 1811 ---  Loss: 2.9944619312882423    Accuracy: 86.09375\n",
      "iter 1812 ---  Loss: 3.0398095697164536    Accuracy: 86.71875\n",
      "iter 1813 ---  Loss: 2.726643741130829    Accuracy: 87.34375\n",
      "iter 1814 ---  Loss: 2.5461577624082565    Accuracy: 90.3125\n",
      "iter 1815 ---  Loss: 2.951117515563965    Accuracy: 87.65625\n",
      "iter 1816 ---  Loss: 3.1228065341711044    Accuracy: 87.65625\n",
      "iter 1817 ---  Loss: 3.2882409542798996    Accuracy: 87.03125\n",
      "iter 1818 ---  Loss: 3.4804049655795097    Accuracy: 87.03125\n",
      "iter 1819 ---  Loss: 2.8790266662836075    Accuracy: 88.125\n",
      "iter 1820 ---  Loss: 2.893360011279583    Accuracy: 91.09375\n",
      "iter 1821 ---  Loss: 3.076750412583351    Accuracy: 86.25\n",
      "iter 1822 ---  Loss: 3.340211883187294    Accuracy: 86.875\n",
      "iter 1823 ---  Loss: 2.8852428197860718    Accuracy: 91.25\n",
      "iter 1824 ---  Loss: 3.2278479784727097    Accuracy: 87.34375\n",
      "iter 1825 ---  Loss: 2.867983363568783    Accuracy: 88.125\n",
      "iter 1826 ---  Loss: 3.0566254779696465    Accuracy: 87.65625\n",
      "iter 1827 ---  Loss: 2.7037215158343315    Accuracy: 88.59375\n",
      "iter 1828 ---  Loss: 3.5959893837571144    Accuracy: 85.9375\n",
      "iter 1829 ---  Loss: 3.219962500035763    Accuracy: 88.75\n",
      "iter 1830 ---  Loss: 2.715472899377346    Accuracy: 87.03125\n",
      "iter 1831 ---  Loss: 3.3000887259840965    Accuracy: 85.9375\n",
      "iter 1832 ---  Loss: 3.6907157003879547    Accuracy: 86.25\n",
      "iter 1833 ---  Loss: 3.721179775893688    Accuracy: 86.5625\n",
      "iter 1834 ---  Loss: 3.3923723474144936    Accuracy: 87.65625\n",
      "iter 1835 ---  Loss: 3.034575566649437    Accuracy: 87.5\n",
      "iter 1836 ---  Loss: 3.0157657116651535    Accuracy: 86.875\n",
      "iter 1837 ---  Loss: 3.281091630458832    Accuracy: 86.875\n",
      "iter 1838 ---  Loss: 3.8333839774131775    Accuracy: 85.78125\n",
      "iter 1839 ---  Loss: 2.8531265780329704    Accuracy: 88.4375\n",
      "iter 1840 ---  Loss: 3.7558148354291916    Accuracy: 84.84375\n",
      "iter 1841 ---  Loss: 3.1574660539627075    Accuracy: 88.28125\n",
      "iter 1842 ---  Loss: 3.2381403893232346    Accuracy: 87.5\n",
      "iter 1843 ---  Loss: 2.7572644352912903    Accuracy: 88.90625\n",
      "iter 1844 ---  Loss: 3.3115271031856537    Accuracy: 85.9375\n",
      "iter 1845 ---  Loss: 3.3247674331068993    Accuracy: 88.125\n",
      "iter 1846 ---  Loss: 3.1503851041197777    Accuracy: 88.4375\n",
      "iter 1847 ---  Loss: 3.6332830488681793    Accuracy: 85.3125\n",
      "iter 1848 ---  Loss: 2.6742323637008667    Accuracy: 88.28125\n",
      "iter 1849 ---  Loss: 2.737673707306385    Accuracy: 87.96875\n",
      "iter 1850 ---  Loss: 2.7890972271561623    Accuracy: 88.90625\n",
      "iter 1851 ---  Loss: 3.1464335545897484    Accuracy: 87.65625\n",
      "iter 1852 ---  Loss: 2.9055062159895897    Accuracy: 88.90625\n",
      "iter 1853 ---  Loss: 2.782262161374092    Accuracy: 87.03125\n",
      "iter 1854 ---  Loss: 3.268606923520565    Accuracy: 87.03125\n",
      "iter 1855 ---  Loss: 2.90607563406229    Accuracy: 87.8125\n",
      "iter 1856 ---  Loss: 3.254797510802746    Accuracy: 85.3125\n",
      "iter 1857 ---  Loss: 3.1513680443167686    Accuracy: 86.875\n",
      "iter 1858 ---  Loss: 2.581844724714756    Accuracy: 88.75\n",
      "iter 1859 ---  Loss: 3.6262468844652176    Accuracy: 86.875\n",
      "iter 1860 ---  Loss: 3.0651722475886345    Accuracy: 87.5\n",
      "iter 1861 ---  Loss: 3.3767905235290527    Accuracy: 86.09375\n",
      "iter 1862 ---  Loss: 2.5923635438084602    Accuracy: 90.78125\n",
      "iter 1863 ---  Loss: 3.7753724604845047    Accuracy: 85.15625\n",
      "iter 1864 ---  Loss: 2.895270086824894    Accuracy: 87.96875\n",
      "iter 1865 ---  Loss: 2.9791261181235313    Accuracy: 87.34375\n",
      "iter 1866 ---  Loss: 3.281790502369404    Accuracy: 86.25\n",
      "iter 1867 ---  Loss: 3.805251829326153    Accuracy: 85.9375\n",
      "iter 1868 ---  Loss: 3.4569961205124855    Accuracy: 86.875\n",
      "iter 1869 ---  Loss: 3.07350742071867    Accuracy: 86.40625\n",
      "iter 1870 ---  Loss: 2.7263526022434235    Accuracy: 88.75\n",
      "iter 1871 ---  Loss: 3.7670617550611496    Accuracy: 87.34375\n",
      "iter 1872 ---  Loss: 3.57588317245245    Accuracy: 85.3125\n",
      "iter 1873 ---  Loss: 2.9276716709136963    Accuracy: 89.53125\n",
      "iter 1874 ---  Loss: 2.4697027131915092    Accuracy: 90.3125\n",
      "iter 1875 ---  Loss: 3.096459738910198    Accuracy: 86.25\n",
      "iter 1876 ---  Loss: 2.57376591861248    Accuracy: 89.0625\n",
      "iter 1877 ---  Loss: 2.6205002069473267    Accuracy: 89.53125\n",
      "iter 1878 ---  Loss: 2.954252041876316    Accuracy: 88.4375\n",
      "iter 1879 ---  Loss: 3.0410522520542145    Accuracy: 87.1875\n",
      "iter 1880 ---  Loss: 3.0506651028990746    Accuracy: 88.28125\n",
      "iter 1881 ---  Loss: 3.556433454155922    Accuracy: 86.875\n",
      "iter 1882 ---  Loss: 2.909538894891739    Accuracy: 87.1875\n",
      "iter 1883 ---  Loss: 2.964923605322838    Accuracy: 86.5625\n",
      "iter 1884 ---  Loss: 3.1630758345127106    Accuracy: 89.375\n",
      "iter 1885 ---  Loss: 2.815338023006916    Accuracy: 88.28125\n",
      "iter 1886 ---  Loss: 2.7618686482310295    Accuracy: 85.625\n",
      "iter 1887 ---  Loss: 2.9745303094387054    Accuracy: 88.59375\n",
      "iter 1888 ---  Loss: 3.3928432688117027    Accuracy: 88.28125\n",
      "iter 1889 ---  Loss: 2.64664239436388    Accuracy: 88.90625\n",
      "iter 1890 ---  Loss: 2.9588046818971634    Accuracy: 88.75\n",
      "iter 1891 ---  Loss: 2.5518452301621437    Accuracy: 90.0\n",
      "iter 1892 ---  Loss: 2.8875977993011475    Accuracy: 89.0625\n",
      "iter 1893 ---  Loss: 3.1007972434163094    Accuracy: 87.5\n",
      "iter 1894 ---  Loss: 2.870760038495064    Accuracy: 88.75\n",
      "iter 1895 ---  Loss: 3.0037502124905586    Accuracy: 87.34375\n",
      "iter 1896 ---  Loss: 3.6129763796925545    Accuracy: 88.125\n",
      "iter 1897 ---  Loss: 2.546636678278446    Accuracy: 87.96875\n",
      "iter 1898 ---  Loss: 3.5593548491597176    Accuracy: 86.09375\n",
      "iter 1899 ---  Loss: 3.1975628286600113    Accuracy: 87.5\n",
      "iter 1900 ---  Loss: 3.4132059812545776    Accuracy: 87.1875\n",
      "iter 1901 ---  Loss: 3.2348276153206825    Accuracy: 87.34375\n",
      "iter 1902 ---  Loss: 2.6744871735572815    Accuracy: 87.96875\n",
      "iter 1903 ---  Loss: 2.9491836577653885    Accuracy: 88.59375\n",
      "iter 1904 ---  Loss: 2.373829521238804    Accuracy: 88.125\n",
      "iter 1905 ---  Loss: 3.027803972363472    Accuracy: 86.5625\n",
      "iter 1906 ---  Loss: 3.3193611055612564    Accuracy: 85.46875\n",
      "iter 1907 ---  Loss: 2.900277905166149    Accuracy: 88.90625\n",
      "iter 1908 ---  Loss: 3.3554137125611305    Accuracy: 86.71875\n",
      "iter 1909 ---  Loss: 3.3381255120038986    Accuracy: 87.34375\n",
      "iter 1910 ---  Loss: 2.8826521411538124    Accuracy: 87.65625\n",
      "iter 1911 ---  Loss: 3.347487449645996    Accuracy: 87.65625\n",
      "iter 1912 ---  Loss: 3.123826712369919    Accuracy: 86.25\n",
      "iter 1913 ---  Loss: 2.4852596819400787    Accuracy: 87.65625\n",
      "iter 1914 ---  Loss: 3.6016339734196663    Accuracy: 86.71875\n",
      "iter 1915 ---  Loss: 2.9493124037981033    Accuracy: 87.65625\n",
      "iter 1916 ---  Loss: 3.252363920211792    Accuracy: 85.46875\n",
      "iter 1917 ---  Loss: 3.085912622511387    Accuracy: 86.25\n",
      "iter 1918 ---  Loss: 3.2038980051875114    Accuracy: 85.625\n",
      "iter 1919 ---  Loss: 2.9435155391693115    Accuracy: 86.09375\n",
      "iter 1920 ---  Loss: 3.3810096457600594    Accuracy: 86.875\n",
      "iter 1921 ---  Loss: 3.1963857039809227    Accuracy: 84.21875\n",
      "iter 1922 ---  Loss: 2.7902968525886536    Accuracy: 87.65625\n",
      "iter 1923 ---  Loss: 2.4749784767627716    Accuracy: 87.96875\n",
      "iter 1924 ---  Loss: 2.6388100907206535    Accuracy: 86.875\n",
      "iter 1925 ---  Loss: 3.321374498307705    Accuracy: 86.71875\n",
      "iter 1926 ---  Loss: 3.1591405868530273    Accuracy: 88.4375\n",
      "iter 1927 ---  Loss: 2.481996551156044    Accuracy: 89.21875\n",
      "iter 1928 ---  Loss: 2.8149711191654205    Accuracy: 86.875\n",
      "iter 1929 ---  Loss: 3.0016056448221207    Accuracy: 87.8125\n",
      "iter 1930 ---  Loss: 3.616147182881832    Accuracy: 86.5625\n",
      "iter 1931 ---  Loss: 3.0755717754364014    Accuracy: 86.5625\n",
      "iter 1932 ---  Loss: 3.4074460715055466    Accuracy: 87.1875\n",
      "iter 1933 ---  Loss: 3.114430643618107    Accuracy: 89.0625\n",
      "iter 1934 ---  Loss: 3.0607951879501343    Accuracy: 86.71875\n",
      "iter 1935 ---  Loss: 3.2425056248903275    Accuracy: 87.34375\n",
      "iter 1936 ---  Loss: 2.9780337661504745    Accuracy: 86.5625\n",
      "iter 1937 ---  Loss: 2.7796593382954597    Accuracy: 90.0\n",
      "iter 1938 ---  Loss: 3.147222600877285    Accuracy: 87.03125\n",
      "iter 1939 ---  Loss: 3.317812703549862    Accuracy: 86.40625\n",
      "iter 1940 ---  Loss: 3.0699710696935654    Accuracy: 87.03125\n",
      "iter 1941 ---  Loss: 2.596032753586769    Accuracy: 87.03125\n",
      "iter 1942 ---  Loss: 3.0692567750811577    Accuracy: 86.09375\n",
      "iter 1943 ---  Loss: 3.825577676296234    Accuracy: 84.6875\n",
      "iter 1944 ---  Loss: 2.9978091418743134    Accuracy: 86.5625\n",
      "iter 1945 ---  Loss: 3.1521795466542244    Accuracy: 88.59375\n",
      "iter 1946 ---  Loss: 2.744428366422653    Accuracy: 89.53125\n",
      "iter 1947 ---  Loss: 3.1903355196118355    Accuracy: 86.40625\n",
      "iter 1948 ---  Loss: 3.237772226333618    Accuracy: 85.46875\n",
      "iter 1949 ---  Loss: 3.6512448489665985    Accuracy: 86.09375\n",
      "iter 1950 ---  Loss: 3.226256303489208    Accuracy: 87.96875\n",
      "iter 1951 ---  Loss: 2.9737309366464615    Accuracy: 87.1875\n",
      "iter 1952 ---  Loss: 3.1413836404681206    Accuracy: 85.9375\n",
      "iter 1953 ---  Loss: 2.873914249241352    Accuracy: 87.8125\n",
      "iter 1954 ---  Loss: 3.1185453683137894    Accuracy: 87.1875\n",
      "iter 1955 ---  Loss: 2.860269472002983    Accuracy: 89.375\n",
      "iter 1956 ---  Loss: 3.403542175889015    Accuracy: 86.875\n",
      "iter 1957 ---  Loss: 3.113712355494499    Accuracy: 86.71875\n",
      "iter 1958 ---  Loss: 4.2041434198617935    Accuracy: 85.46875\n",
      "iter 1959 ---  Loss: 3.6347269862890244    Accuracy: 85.625\n",
      "iter 1960 ---  Loss: 3.495340958237648    Accuracy: 85.15625\n",
      "iter 1961 ---  Loss: 3.1129107028245926    Accuracy: 86.40625\n",
      "iter 1962 ---  Loss: 2.9796718806028366    Accuracy: 86.40625\n",
      "iter 1963 ---  Loss: 2.544376663863659    Accuracy: 88.4375\n",
      "iter 1964 ---  Loss: 2.569425918161869    Accuracy: 89.375\n",
      "iter 1965 ---  Loss: 3.5614146292209625    Accuracy: 87.03125\n",
      "iter 1966 ---  Loss: 2.51168442517519    Accuracy: 90.3125\n",
      "iter 1967 ---  Loss: 3.0361704602837563    Accuracy: 87.03125\n",
      "iter 1968 ---  Loss: 3.193985491991043    Accuracy: 85.15625\n",
      "iter 1969 ---  Loss: 3.350989617407322    Accuracy: 87.65625\n",
      "iter 1970 ---  Loss: 3.0297986641526222    Accuracy: 88.125\n",
      "iter 1971 ---  Loss: 2.913249231874943    Accuracy: 87.34375\n",
      "iter 1972 ---  Loss: 2.8593000918626785    Accuracy: 87.5\n",
      "iter 1973 ---  Loss: 3.287428140640259    Accuracy: 86.71875\n",
      "iter 1974 ---  Loss: 2.5758605748414993    Accuracy: 88.125\n",
      "iter 1975 ---  Loss: 2.7948995903134346    Accuracy: 89.6875\n",
      "iter 1976 ---  Loss: 2.854163020849228    Accuracy: 88.75\n",
      "iter 1977 ---  Loss: 3.292437620460987    Accuracy: 85.625\n",
      "iter 1978 ---  Loss: 3.604195296764374    Accuracy: 88.90625\n",
      "iter 1979 ---  Loss: 3.2455461844801903    Accuracy: 86.09375\n",
      "iter 1980 ---  Loss: 3.5500095561146736    Accuracy: 87.8125\n",
      "iter 1981 ---  Loss: 3.2516534626483917    Accuracy: 88.125\n",
      "iter 1982 ---  Loss: 2.63590819388628    Accuracy: 88.59375\n",
      "iter 1983 ---  Loss: 3.334302879869938    Accuracy: 88.75\n",
      "iter 1984 ---  Loss: 3.421216204762459    Accuracy: 87.96875\n",
      "iter 1985 ---  Loss: 3.1264686062932014    Accuracy: 87.65625\n",
      "iter 1986 ---  Loss: 2.8001121655106544    Accuracy: 88.4375\n",
      "iter 1987 ---  Loss: 2.7779249250888824    Accuracy: 89.21875\n",
      "iter 1988 ---  Loss: 3.316509947180748    Accuracy: 87.65625\n",
      "iter 1989 ---  Loss: 3.486784264445305    Accuracy: 87.65625\n",
      "iter 1990 ---  Loss: 2.944128639996052    Accuracy: 85.9375\n",
      "iter 1991 ---  Loss: 2.906815752387047    Accuracy: 88.28125\n",
      "iter 1992 ---  Loss: 2.9415265396237373    Accuracy: 88.125\n",
      "iter 1993 ---  Loss: 2.83856787532568    Accuracy: 87.1875\n",
      "iter 1994 ---  Loss: 2.995796635746956    Accuracy: 88.4375\n",
      "iter 1995 ---  Loss: 3.4681826382875443    Accuracy: 86.09375\n",
      "iter 1996 ---  Loss: 3.1943031698465347    Accuracy: 87.34375\n",
      "iter 1997 ---  Loss: 3.680568590760231    Accuracy: 87.03125\n",
      "iter 1998 ---  Loss: 2.9539880231022835    Accuracy: 88.125\n",
      "iter 1999 ---  Loss: 2.8311685994267464    Accuracy: 89.0625\n",
      "iter 2000 ---  Loss: 2.73173189163208    Accuracy: 88.59375\n",
      "iter 2001 ---  Loss: 3.3248965442180634    Accuracy: 87.65625\n",
      "iter 2002 ---  Loss: 3.6920138522982597    Accuracy: 84.6875\n",
      "iter 2003 ---  Loss: 3.1971557065844536    Accuracy: 87.96875\n",
      "iter 2004 ---  Loss: 2.5269520357251167    Accuracy: 90.0\n",
      "iter 2005 ---  Loss: 2.9512432292103767    Accuracy: 87.1875\n",
      "iter 2006 ---  Loss: 3.747221551835537    Accuracy: 85.46875\n",
      "iter 2007 ---  Loss: 3.230422630906105    Accuracy: 86.5625\n",
      "iter 2008 ---  Loss: 3.0596643835306168    Accuracy: 87.96875\n",
      "iter 2009 ---  Loss: 3.0516712591052055    Accuracy: 87.1875\n",
      "iter 2010 ---  Loss: 3.5766994580626488    Accuracy: 86.71875\n",
      "iter 2011 ---  Loss: 2.8880193158984184    Accuracy: 87.03125\n",
      "iter 2012 ---  Loss: 3.1582353711128235    Accuracy: 87.8125\n",
      "iter 2013 ---  Loss: 2.929526388645172    Accuracy: 86.25\n",
      "iter 2014 ---  Loss: 3.228446625173092    Accuracy: 87.5\n",
      "iter 2015 ---  Loss: 3.0928521156311035    Accuracy: 88.125\n",
      "iter 2016 ---  Loss: 3.4866259172558784    Accuracy: 86.40625\n",
      "iter 2017 ---  Loss: 2.6648039296269417    Accuracy: 89.21875\n",
      "iter 2018 ---  Loss: 2.775075741112232    Accuracy: 89.53125\n",
      "iter 2019 ---  Loss: 2.701639272272587    Accuracy: 89.84375\n",
      "iter 2020 ---  Loss: 3.0684023052453995    Accuracy: 87.8125\n",
      "iter 2021 ---  Loss: 2.7685412392020226    Accuracy: 87.8125\n",
      "iter 2022 ---  Loss: 2.679853245615959    Accuracy: 88.90625\n",
      "iter 2023 ---  Loss: 3.3880786448717117    Accuracy: 86.71875\n",
      "iter 2024 ---  Loss: 2.9249142855405807    Accuracy: 88.4375\n",
      "iter 2025 ---  Loss: 2.9064669013023376    Accuracy: 86.71875\n",
      "iter 2026 ---  Loss: 3.2287239506840706    Accuracy: 87.65625\n",
      "iter 2027 ---  Loss: 3.517041400074959    Accuracy: 87.1875\n",
      "iter 2028 ---  Loss: 3.909429058432579    Accuracy: 85.3125\n",
      "iter 2029 ---  Loss: 3.5107400938868523    Accuracy: 89.21875\n",
      "iter 2030 ---  Loss: 4.034225940704346    Accuracy: 85.3125\n",
      "iter 2031 ---  Loss: 2.627674162387848    Accuracy: 88.28125\n",
      "iter 2032 ---  Loss: 2.763895019888878    Accuracy: 87.96875\n",
      "iter 2033 ---  Loss: 2.7121833860874176    Accuracy: 89.21875\n",
      "iter 2034 ---  Loss: 3.007445238530636    Accuracy: 87.1875\n",
      "iter 2035 ---  Loss: 3.3264706283807755    Accuracy: 86.5625\n",
      "iter 2036 ---  Loss: 2.7976568937301636    Accuracy: 87.03125\n",
      "iter 2037 ---  Loss: 3.0882380232214928    Accuracy: 86.875\n",
      "iter 2038 ---  Loss: 3.8960859328508377    Accuracy: 85.625\n",
      "iter 2039 ---  Loss: 2.717927500605583    Accuracy: 87.34375\n",
      "iter 2040 ---  Loss: 3.5561924427747726    Accuracy: 85.46875\n",
      "iter 2041 ---  Loss: 3.723442889750004    Accuracy: 84.6875\n",
      "iter 2042 ---  Loss: 2.7917953357100487    Accuracy: 88.28125\n",
      "iter 2043 ---  Loss: 3.2777549624443054    Accuracy: 86.09375\n",
      "iter 2044 ---  Loss: 3.404205895960331    Accuracy: 85.625\n",
      "iter 2045 ---  Loss: 2.842225782573223    Accuracy: 88.59375\n",
      "iter 2046 ---  Loss: 2.794524021446705    Accuracy: 89.0625\n",
      "iter 2047 ---  Loss: 3.1108269467949867    Accuracy: 89.6875\n",
      "iter 2048 ---  Loss: 2.7386069893836975    Accuracy: 88.28125\n",
      "iter 2049 ---  Loss: 3.139680027961731    Accuracy: 87.65625\n",
      "iter 2050 ---  Loss: 2.932699538767338    Accuracy: 86.71875\n",
      "iter 2051 ---  Loss: 3.635267361998558    Accuracy: 87.03125\n",
      "iter 2052 ---  Loss: 2.9913928508758545    Accuracy: 89.21875\n",
      "iter 2053 ---  Loss: 3.2856031358242035    Accuracy: 87.03125\n",
      "iter 2054 ---  Loss: 2.862787239253521    Accuracy: 85.15625\n",
      "iter 2055 ---  Loss: 2.6684787571430206    Accuracy: 88.75\n",
      "iter 2056 ---  Loss: 3.0297190472483635    Accuracy: 87.96875\n",
      "iter 2057 ---  Loss: 3.1397397965192795    Accuracy: 86.40625\n",
      "iter 2058 ---  Loss: 3.2630937919020653    Accuracy: 87.5\n",
      "iter 2059 ---  Loss: 2.405712217092514    Accuracy: 88.90625\n",
      "iter 2060 ---  Loss: 2.9519124627113342    Accuracy: 86.25\n",
      "iter 2061 ---  Loss: 3.053659752011299    Accuracy: 87.65625\n",
      "iter 2062 ---  Loss: 2.903047166764736    Accuracy: 87.34375\n",
      "iter 2063 ---  Loss: 2.777078755199909    Accuracy: 87.65625\n",
      "iter 2064 ---  Loss: 3.288008324801922    Accuracy: 88.125\n",
      "iter 2065 ---  Loss: 3.2807302698493004    Accuracy: 86.71875\n",
      "iter 2066 ---  Loss: 2.888695351779461    Accuracy: 87.65625\n",
      "iter 2067 ---  Loss: 2.8171317875385284    Accuracy: 86.875\n",
      "iter 2068 ---  Loss: 3.088370829820633    Accuracy: 87.8125\n",
      "iter 2069 ---  Loss: 3.467599131166935    Accuracy: 86.25\n",
      "iter 2070 ---  Loss: 3.045482151210308    Accuracy: 87.65625\n",
      "iter 2071 ---  Loss: 3.1386737376451492    Accuracy: 86.875\n",
      "iter 2072 ---  Loss: 3.3262359127402306    Accuracy: 88.125\n",
      "iter 2073 ---  Loss: 2.8931401446461678    Accuracy: 85.9375\n",
      "iter 2074 ---  Loss: 3.1233605965971947    Accuracy: 87.96875\n",
      "iter 2075 ---  Loss: 3.9517996832728386    Accuracy: 88.28125\n",
      "iter 2076 ---  Loss: 3.2700676023960114    Accuracy: 85.78125\n",
      "iter 2077 ---  Loss: 3.2976302951574326    Accuracy: 87.65625\n",
      "iter 2078 ---  Loss: 2.779422417283058    Accuracy: 89.375\n",
      "iter 2079 ---  Loss: 2.6214439049363136    Accuracy: 88.28125\n",
      "iter 2080 ---  Loss: 2.939736694097519    Accuracy: 87.5\n",
      "iter 2081 ---  Loss: 2.908794552087784    Accuracy: 86.71875\n",
      "iter 2082 ---  Loss: 3.339983180165291    Accuracy: 84.21875\n",
      "iter 2083 ---  Loss: 4.053069643676281    Accuracy: 87.03125\n",
      "iter 2084 ---  Loss: 3.0724214240908623    Accuracy: 87.34375\n",
      "iter 2085 ---  Loss: 2.8562263771891594    Accuracy: 86.71875\n",
      "iter 2086 ---  Loss: 2.997443325817585    Accuracy: 86.40625\n",
      "iter 2087 ---  Loss: 3.4623995795845985    Accuracy: 85.46875\n",
      "iter 2088 ---  Loss: 3.250590316951275    Accuracy: 86.40625\n",
      "iter 2089 ---  Loss: 3.0732354670763016    Accuracy: 88.59375\n",
      "iter 2090 ---  Loss: 3.029747523367405    Accuracy: 89.53125\n",
      "iter 2091 ---  Loss: 3.5221264958381653    Accuracy: 88.4375\n",
      "iter 2092 ---  Loss: 3.346591532230377    Accuracy: 86.71875\n",
      "iter 2093 ---  Loss: 2.8252067416906357    Accuracy: 88.59375\n",
      "iter 2094 ---  Loss: 3.273203209042549    Accuracy: 87.5\n",
      "iter 2095 ---  Loss: 3.3213858231902122    Accuracy: 86.40625\n",
      "iter 2096 ---  Loss: 2.967909947037697    Accuracy: 88.125\n",
      "iter 2097 ---  Loss: 3.552316427230835    Accuracy: 85.3125\n",
      "iter 2098 ---  Loss: 2.4714314863085747    Accuracy: 89.84375\n",
      "iter 2099 ---  Loss: 3.117757685482502    Accuracy: 87.03125\n",
      "iter 2100 ---  Loss: 3.0128635093569756    Accuracy: 87.96875\n",
      "iter 2101 ---  Loss: 3.2034850046038628    Accuracy: 86.875\n",
      "iter 2102 ---  Loss: 3.0580840185284615    Accuracy: 85.78125\n",
      "iter 2103 ---  Loss: 3.3141044229269028    Accuracy: 86.875\n",
      "iter 2104 ---  Loss: 2.8763984963297844    Accuracy: 88.4375\n",
      "iter 2105 ---  Loss: 2.8605805784463882    Accuracy: 87.65625\n",
      "iter 2106 ---  Loss: 3.4451903700828552    Accuracy: 86.09375\n",
      "iter 2107 ---  Loss: 3.0997311547398567    Accuracy: 88.4375\n",
      "iter 2108 ---  Loss: 3.0342165753245354    Accuracy: 86.5625\n",
      "iter 2109 ---  Loss: 3.1328464075922966    Accuracy: 87.1875\n",
      "iter 2110 ---  Loss: 3.1339510679244995    Accuracy: 87.8125\n",
      "iter 2111 ---  Loss: 2.8613294661045074    Accuracy: 88.59375\n",
      "iter 2112 ---  Loss: 2.6610953733325005    Accuracy: 89.84375\n",
      "iter 2113 ---  Loss: 3.4102881997823715    Accuracy: 85.9375\n",
      "iter 2114 ---  Loss: 3.509469762444496    Accuracy: 86.5625\n",
      "iter 2115 ---  Loss: 3.4293050691485405    Accuracy: 87.34375\n",
      "iter 2116 ---  Loss: 3.9252427220344543    Accuracy: 86.25\n",
      "iter 2117 ---  Loss: 3.6503836289048195    Accuracy: 86.5625\n",
      "iter 2118 ---  Loss: 2.989039868116379    Accuracy: 86.40625\n",
      "iter 2119 ---  Loss: 2.751331776380539    Accuracy: 89.0625\n",
      "iter 2120 ---  Loss: 3.2488967776298523    Accuracy: 85.78125\n",
      "iter 2121 ---  Loss: 2.651734910905361    Accuracy: 88.4375\n",
      "iter 2122 ---  Loss: 2.7455412596464157    Accuracy: 90.0\n",
      "iter 2123 ---  Loss: 2.804634168744087    Accuracy: 86.71875\n",
      "iter 2124 ---  Loss: 2.819032408297062    Accuracy: 87.65625\n",
      "iter 2125 ---  Loss: 3.0166813507676125    Accuracy: 87.34375\n",
      "iter 2126 ---  Loss: 3.027042530477047    Accuracy: 86.875\n",
      "iter 2127 ---  Loss: 2.777925379574299    Accuracy: 88.125\n",
      "iter 2128 ---  Loss: 3.025884672999382    Accuracy: 88.4375\n",
      "iter 2129 ---  Loss: 3.0706632137298584    Accuracy: 87.96875\n",
      "iter 2130 ---  Loss: 2.821940839290619    Accuracy: 89.21875\n",
      "iter 2131 ---  Loss: 3.3535335958004    Accuracy: 87.5\n",
      "iter 2132 ---  Loss: 3.0077659860253334    Accuracy: 86.875\n",
      "iter 2133 ---  Loss: 3.3519876450300217    Accuracy: 87.1875\n",
      "iter 2134 ---  Loss: 2.4659622609615326    Accuracy: 88.28125\n",
      "iter 2135 ---  Loss: 2.875492975115776    Accuracy: 88.59375\n",
      "iter 2136 ---  Loss: 2.5791087299585342    Accuracy: 88.90625\n",
      "iter 2137 ---  Loss: 2.6777771785855293    Accuracy: 88.125\n",
      "iter 2138 ---  Loss: 2.671341322362423    Accuracy: 88.59375\n",
      "iter 2139 ---  Loss: 2.912177190184593    Accuracy: 87.65625\n",
      "iter 2140 ---  Loss: 2.8432410657405853    Accuracy: 88.75\n",
      "iter 2141 ---  Loss: 3.018267199397087    Accuracy: 86.875\n",
      "iter 2142 ---  Loss: 3.66326030343771    Accuracy: 84.84375\n",
      "iter 2143 ---  Loss: 3.673612229526043    Accuracy: 87.1875\n",
      "iter 2144 ---  Loss: 3.1836947351694107    Accuracy: 86.71875\n",
      "iter 2145 ---  Loss: 3.220458894968033    Accuracy: 88.59375\n",
      "iter 2146 ---  Loss: 2.7003218308091164    Accuracy: 86.71875\n",
      "iter 2147 ---  Loss: 2.9022586047649384    Accuracy: 88.4375\n",
      "iter 2148 ---  Loss: 3.625316761434078    Accuracy: 87.34375\n",
      "iter 2149 ---  Loss: 2.770293675363064    Accuracy: 86.71875\n",
      "iter 2150 ---  Loss: 2.931847393512726    Accuracy: 88.59375\n",
      "iter 2151 ---  Loss: 2.9400743320584297    Accuracy: 87.03125\n",
      "iter 2152 ---  Loss: 3.0195897817611694    Accuracy: 86.875\n",
      "iter 2153 ---  Loss: 3.302855432033539    Accuracy: 86.875\n",
      "iter 2154 ---  Loss: 2.9868317171931267    Accuracy: 86.5625\n",
      "iter 2155 ---  Loss: 2.872824266552925    Accuracy: 88.75\n",
      "iter 2156 ---  Loss: 3.5017540007829666    Accuracy: 87.5\n",
      "iter 2157 ---  Loss: 2.6168862655758858    Accuracy: 90.625\n",
      "iter 2158 ---  Loss: 2.7266640290617943    Accuracy: 88.125\n",
      "iter 2159 ---  Loss: 2.8913838639855385    Accuracy: 87.5\n",
      "iter 2160 ---  Loss: 3.6465498358011246    Accuracy: 86.09375\n",
      "iter 2161 ---  Loss: 3.0607181563973427    Accuracy: 88.4375\n",
      "iter 2162 ---  Loss: 3.025036409497261    Accuracy: 85.9375\n",
      "iter 2163 ---  Loss: 2.8753186985850334    Accuracy: 86.875\n",
      "iter 2164 ---  Loss: 2.619163140654564    Accuracy: 88.28125\n",
      "iter 2165 ---  Loss: 2.9520063176751137    Accuracy: 85.9375\n",
      "iter 2166 ---  Loss: 3.2323875203728676    Accuracy: 86.875\n",
      "iter 2167 ---  Loss: 2.8880939185619354    Accuracy: 88.4375\n",
      "iter 2168 ---  Loss: 2.8802584558725357    Accuracy: 87.03125\n",
      "iter 2169 ---  Loss: 2.751404196023941    Accuracy: 85.46875\n",
      "iter 2170 ---  Loss: 3.2329805120825768    Accuracy: 87.34375\n",
      "iter 2171 ---  Loss: 3.142229288816452    Accuracy: 88.125\n",
      "iter 2172 ---  Loss: 2.9166941568255424    Accuracy: 87.65625\n",
      "iter 2173 ---  Loss: 3.69344162940979    Accuracy: 86.71875\n",
      "iter 2174 ---  Loss: 2.755251355469227    Accuracy: 87.8125\n",
      "iter 2175 ---  Loss: 3.013696849346161    Accuracy: 87.5\n",
      "iter 2176 ---  Loss: 3.2100339829921722    Accuracy: 87.96875\n",
      "iter 2177 ---  Loss: 3.16062244027853    Accuracy: 85.625\n",
      "iter 2178 ---  Loss: 2.459117114543915    Accuracy: 89.0625\n",
      "iter 2179 ---  Loss: 3.083452768623829    Accuracy: 87.96875\n",
      "iter 2180 ---  Loss: 3.065826825797558    Accuracy: 88.90625\n",
      "iter 2181 ---  Loss: 2.9025895595550537    Accuracy: 88.125\n",
      "iter 2182 ---  Loss: 2.856767900288105    Accuracy: 88.28125\n",
      "iter 2183 ---  Loss: 3.5773225128650665    Accuracy: 85.9375\n",
      "iter 2184 ---  Loss: 3.4590051770210266    Accuracy: 86.09375\n",
      "iter 2185 ---  Loss: 3.138770841062069    Accuracy: 90.15625\n",
      "iter 2186 ---  Loss: 3.2298229187726974    Accuracy: 88.75\n",
      "iter 2187 ---  Loss: 3.271046854555607    Accuracy: 87.03125\n",
      "iter 2188 ---  Loss: 3.1028293520212173    Accuracy: 88.90625\n",
      "iter 2189 ---  Loss: 2.849092647433281    Accuracy: 88.28125\n",
      "iter 2190 ---  Loss: 3.0509329363703728    Accuracy: 87.5\n",
      "iter 2191 ---  Loss: 3.435997523367405    Accuracy: 84.84375\n",
      "iter 2192 ---  Loss: 2.561151683330536    Accuracy: 87.5\n",
      "iter 2193 ---  Loss: 2.79204710572958    Accuracy: 86.09375\n",
      "iter 2194 ---  Loss: 3.1990073397755623    Accuracy: 87.65625\n",
      "iter 2195 ---  Loss: 3.218685545027256    Accuracy: 87.96875\n",
      "iter 2196 ---  Loss: 2.509100615978241    Accuracy: 88.90625\n",
      "iter 2197 ---  Loss: 3.188919350504875    Accuracy: 87.96875\n",
      "iter 2198 ---  Loss: 2.9650273621082306    Accuracy: 86.875\n",
      "iter 2199 ---  Loss: 3.0128197744488716    Accuracy: 87.1875\n",
      "iter 2200 ---  Loss: 2.8259226009249687    Accuracy: 89.6875\n",
      "iter 2201 ---  Loss: 4.09878134727478    Accuracy: 84.6875\n",
      "iter 2202 ---  Loss: 3.112822473049164    Accuracy: 86.5625\n",
      "iter 2203 ---  Loss: 3.2761018499732018    Accuracy: 88.4375\n",
      "iter 2204 ---  Loss: 3.188735991716385    Accuracy: 88.125\n",
      "iter 2205 ---  Loss: 3.415115363895893    Accuracy: 89.84375\n",
      "iter 2206 ---  Loss: 2.8180229291319847    Accuracy: 87.65625\n",
      "iter 2207 ---  Loss: 2.9182097762823105    Accuracy: 86.875\n",
      "iter 2208 ---  Loss: 2.759911172091961    Accuracy: 87.8125\n",
      "iter 2209 ---  Loss: 3.0732292905449867    Accuracy: 88.4375\n",
      "iter 2210 ---  Loss: 2.894261382520199    Accuracy: 88.59375\n",
      "iter 2211 ---  Loss: 4.189288608729839    Accuracy: 86.875\n",
      "iter 2212 ---  Loss: 3.74090888351202    Accuracy: 86.71875\n",
      "iter 2213 ---  Loss: 3.0667480006814003    Accuracy: 87.65625\n",
      "iter 2214 ---  Loss: 3.008204698562622    Accuracy: 88.28125\n",
      "iter 2215 ---  Loss: 2.5407692417502403    Accuracy: 88.75\n",
      "iter 2216 ---  Loss: 3.0793860405683517    Accuracy: 87.8125\n",
      "iter 2217 ---  Loss: 3.1256798654794693    Accuracy: 87.65625\n",
      "iter 2218 ---  Loss: 2.846735991537571    Accuracy: 87.34375\n",
      "iter 2219 ---  Loss: 2.931617744266987    Accuracy: 86.40625\n",
      "iter 2220 ---  Loss: 2.8972926288843155    Accuracy: 86.5625\n",
      "iter 2221 ---  Loss: 3.3176010847091675    Accuracy: 85.78125\n",
      "iter 2222 ---  Loss: 2.922264024615288    Accuracy: 86.40625\n",
      "iter 2223 ---  Loss: 3.236997626721859    Accuracy: 88.59375\n",
      "iter 2224 ---  Loss: 3.6993461698293686    Accuracy: 85.9375\n",
      "iter 2225 ---  Loss: 3.3952345848083496    Accuracy: 86.875\n",
      "iter 2226 ---  Loss: 3.2366765812039375    Accuracy: 87.5\n",
      "iter 2227 ---  Loss: 3.2695692032575607    Accuracy: 84.84375\n",
      "iter 2228 ---  Loss: 2.9805623218417168    Accuracy: 88.75\n",
      "iter 2229 ---  Loss: 3.20233141630888    Accuracy: 87.5\n",
      "iter 2230 ---  Loss: 2.9124611616134644    Accuracy: 87.8125\n",
      "iter 2231 ---  Loss: 2.723062589764595    Accuracy: 87.65625\n",
      "iter 2232 ---  Loss: 3.16793230175972    Accuracy: 87.5\n",
      "iter 2233 ---  Loss: 3.3737569749355316    Accuracy: 86.09375\n",
      "iter 2234 ---  Loss: 3.0276808068156242    Accuracy: 87.8125\n",
      "iter 2235 ---  Loss: 3.258957639336586    Accuracy: 87.1875\n",
      "iter 2236 ---  Loss: 3.3801071494817734    Accuracy: 86.5625\n",
      "iter 2237 ---  Loss: 3.5428872480988503    Accuracy: 86.09375\n",
      "iter 2238 ---  Loss: 2.9200305938720703    Accuracy: 87.34375\n",
      "iter 2239 ---  Loss: 2.985987439751625    Accuracy: 88.125\n",
      "iter 2240 ---  Loss: 2.7892547473311424    Accuracy: 89.53125\n",
      "iter 2241 ---  Loss: 3.0883808732032776    Accuracy: 87.03125\n",
      "iter 2242 ---  Loss: 3.294077105820179    Accuracy: 87.1875\n",
      "iter 2243 ---  Loss: 2.6997128427028656    Accuracy: 87.65625\n",
      "iter 2244 ---  Loss: 2.770139664411545    Accuracy: 87.5\n",
      "iter 2245 ---  Loss: 3.0672193616628647    Accuracy: 86.875\n",
      "iter 2246 ---  Loss: 3.2354692816734314    Accuracy: 89.0625\n",
      "iter 2247 ---  Loss: 2.345594808459282    Accuracy: 88.59375\n",
      "iter 2248 ---  Loss: 3.2993610501289368    Accuracy: 86.5625\n",
      "iter 2249 ---  Loss: 2.830682061612606    Accuracy: 86.5625\n",
      "iter 2250 ---  Loss: 2.925021268427372    Accuracy: 86.5625\n",
      "iter 2251 ---  Loss: 3.1096412986516953    Accuracy: 87.65625\n",
      "iter 2252 ---  Loss: 3.569926105439663    Accuracy: 84.84375\n",
      "iter 2253 ---  Loss: 3.77782791107893    Accuracy: 85.15625\n",
      "iter 2254 ---  Loss: 3.2841999009251595    Accuracy: 86.09375\n",
      "iter 2255 ---  Loss: 2.327868051826954    Accuracy: 88.28125\n",
      "iter 2256 ---  Loss: 2.644264355301857    Accuracy: 89.21875\n",
      "iter 2257 ---  Loss: 3.1239306703209877    Accuracy: 87.8125\n",
      "iter 2258 ---  Loss: 3.1331237852573395    Accuracy: 85.15625\n",
      "iter 2259 ---  Loss: 2.801162615418434    Accuracy: 88.28125\n",
      "iter 2260 ---  Loss: 3.344515100121498    Accuracy: 88.28125\n",
      "iter 2261 ---  Loss: 3.055276721715927    Accuracy: 88.28125\n",
      "iter 2262 ---  Loss: 3.0491738691926003    Accuracy: 87.34375\n",
      "iter 2263 ---  Loss: 3.2918511107563972    Accuracy: 87.03125\n",
      "iter 2264 ---  Loss: 2.6893282309174538    Accuracy: 86.5625\n",
      "iter 2265 ---  Loss: 2.506345883011818    Accuracy: 87.96875\n",
      "iter 2266 ---  Loss: 3.2642089650034904    Accuracy: 86.5625\n",
      "iter 2267 ---  Loss: 3.7664566412568092    Accuracy: 86.71875\n",
      "iter 2268 ---  Loss: 3.157588578760624    Accuracy: 87.03125\n",
      "iter 2269 ---  Loss: 3.302558735013008    Accuracy: 87.03125\n",
      "iter 2270 ---  Loss: 2.9103362262248993    Accuracy: 87.1875\n",
      "iter 2271 ---  Loss: 3.0126841738820076    Accuracy: 89.21875\n",
      "iter 2272 ---  Loss: 3.029355190694332    Accuracy: 86.5625\n",
      "iter 2273 ---  Loss: 2.808836340904236    Accuracy: 87.5\n",
      "iter 2274 ---  Loss: 3.6159474551677704    Accuracy: 86.09375\n",
      "iter 2275 ---  Loss: 2.4862191528081894    Accuracy: 89.6875\n",
      "iter 2276 ---  Loss: 3.48224825412035    Accuracy: 86.40625\n",
      "iter 2277 ---  Loss: 3.009688325226307    Accuracy: 88.125\n",
      "iter 2278 ---  Loss: 3.016628786921501    Accuracy: 86.25\n",
      "iter 2279 ---  Loss: 3.275270476937294    Accuracy: 87.34375\n",
      "iter 2280 ---  Loss: 3.2651124596595764    Accuracy: 87.5\n",
      "iter 2281 ---  Loss: 2.8278804421424866    Accuracy: 87.65625\n",
      "iter 2282 ---  Loss: 2.9087415859103203    Accuracy: 89.6875\n",
      "iter 2283 ---  Loss: 3.325536869466305    Accuracy: 87.8125\n",
      "iter 2284 ---  Loss: 2.4849461540579796    Accuracy: 90.3125\n",
      "iter 2285 ---  Loss: 3.3103095814585686    Accuracy: 84.21875\n",
      "iter 2286 ---  Loss: 2.697708398103714    Accuracy: 87.65625\n",
      "iter 2287 ---  Loss: 3.309702157974243    Accuracy: 86.875\n",
      "iter 2288 ---  Loss: 2.992793135344982    Accuracy: 90.3125\n",
      "iter 2289 ---  Loss: 2.632332004606724    Accuracy: 88.125\n",
      "iter 2290 ---  Loss: 2.5182007625699043    Accuracy: 88.90625\n",
      "iter 2291 ---  Loss: 2.6646039336919785    Accuracy: 88.90625\n",
      "iter 2292 ---  Loss: 3.21545522660017    Accuracy: 87.65625\n",
      "iter 2293 ---  Loss: 2.9945980235934258    Accuracy: 87.1875\n",
      "iter 2294 ---  Loss: 3.2542242258787155    Accuracy: 85.9375\n",
      "iter 2295 ---  Loss: 2.951898939907551    Accuracy: 87.96875\n",
      "iter 2296 ---  Loss: 2.905130073428154    Accuracy: 86.25\n",
      "iter 2297 ---  Loss: 2.898326024413109    Accuracy: 86.71875\n",
      "iter 2298 ---  Loss: 3.2180865705013275    Accuracy: 84.375\n",
      "iter 2299 ---  Loss: 3.843822456896305    Accuracy: 85.625\n",
      "iter 2300 ---  Loss: 3.1062518805265427    Accuracy: 85.78125\n",
      "iter 2301 ---  Loss: 3.528735063970089    Accuracy: 85.9375\n",
      "iter 2302 ---  Loss: 2.7467864602804184    Accuracy: 87.1875\n",
      "iter 2303 ---  Loss: 3.510101579129696    Accuracy: 86.5625\n",
      "iter 2304 ---  Loss: 2.5378202125430107    Accuracy: 89.53125\n",
      "iter 2305 ---  Loss: 3.7245219498872757    Accuracy: 86.25\n",
      "iter 2306 ---  Loss: 3.3368279933929443    Accuracy: 88.59375\n",
      "iter 2307 ---  Loss: 3.7022482827305794    Accuracy: 84.6875\n",
      "iter 2308 ---  Loss: 3.088969796895981    Accuracy: 88.28125\n",
      "iter 2309 ---  Loss: 3.7063744962215424    Accuracy: 85.15625\n",
      "iter 2310 ---  Loss: 3.017930433154106    Accuracy: 86.40625\n",
      "iter 2311 ---  Loss: 3.050939366221428    Accuracy: 86.5625\n",
      "iter 2312 ---  Loss: 3.095760256052017    Accuracy: 86.09375\n",
      "iter 2313 ---  Loss: 2.831695683300495    Accuracy: 87.1875\n",
      "iter 2314 ---  Loss: 2.8258545249700546    Accuracy: 88.28125\n",
      "iter 2315 ---  Loss: 3.3459579423069954    Accuracy: 87.1875\n",
      "iter 2316 ---  Loss: 3.5584088936448097    Accuracy: 86.40625\n",
      "iter 2317 ---  Loss: 2.830890379846096    Accuracy: 86.40625\n",
      "iter 2318 ---  Loss: 3.272857628762722    Accuracy: 85.625\n",
      "iter 2319 ---  Loss: 2.728879898786545    Accuracy: 87.1875\n",
      "iter 2320 ---  Loss: 3.3192789405584335    Accuracy: 85.78125\n",
      "iter 2321 ---  Loss: 2.6242610663175583    Accuracy: 89.21875\n",
      "iter 2322 ---  Loss: 2.825550325214863    Accuracy: 88.125\n",
      "iter 2323 ---  Loss: 2.480462372303009    Accuracy: 89.21875\n",
      "iter 2324 ---  Loss: 3.3531012684106827    Accuracy: 85.0\n",
      "iter 2325 ---  Loss: 2.7746097445487976    Accuracy: 87.96875\n",
      "iter 2326 ---  Loss: 3.3318302407860756    Accuracy: 87.65625\n",
      "iter 2327 ---  Loss: 3.3641083762049675    Accuracy: 85.9375\n",
      "iter 2328 ---  Loss: 3.4047626554965973    Accuracy: 86.5625\n",
      "iter 2329 ---  Loss: 2.791965253651142    Accuracy: 87.03125\n",
      "iter 2330 ---  Loss: 2.886135123670101    Accuracy: 85.625\n",
      "iter 2331 ---  Loss: 3.045343294739723    Accuracy: 88.59375\n",
      "iter 2332 ---  Loss: 3.397122025489807    Accuracy: 85.9375\n",
      "iter 2333 ---  Loss: 3.068327397108078    Accuracy: 86.5625\n",
      "iter 2334 ---  Loss: 2.7429729253053665    Accuracy: 88.90625\n",
      "iter 2335 ---  Loss: 2.5685474276542664    Accuracy: 87.34375\n",
      "iter 2336 ---  Loss: 2.9203931391239166    Accuracy: 88.4375\n",
      "iter 2337 ---  Loss: 2.4185340106487274    Accuracy: 89.84375\n",
      "iter 2338 ---  Loss: 2.706552818417549    Accuracy: 87.5\n",
      "iter 2339 ---  Loss: 2.9745806455612183    Accuracy: 85.78125\n",
      "iter 2340 ---  Loss: 3.2195833176374435    Accuracy: 86.09375\n",
      "iter 2341 ---  Loss: 3.0929073691368103    Accuracy: 86.40625\n",
      "iter 2342 ---  Loss: 3.3251893520355225    Accuracy: 85.46875\n",
      "iter 2343 ---  Loss: 2.7447785288095474    Accuracy: 86.875\n",
      "iter 2344 ---  Loss: 3.2755116149783134    Accuracy: 87.96875\n",
      "iter 2345 ---  Loss: 3.1184160709381104    Accuracy: 87.34375\n",
      "iter 2346 ---  Loss: 3.7525810077786446    Accuracy: 86.09375\n",
      "iter 2347 ---  Loss: 3.661898300051689    Accuracy: 87.03125\n",
      "iter 2348 ---  Loss: 3.562193773686886    Accuracy: 84.375\n",
      "iter 2349 ---  Loss: 3.4737567380070686    Accuracy: 86.09375\n",
      "iter 2350 ---  Loss: 3.021447032690048    Accuracy: 86.5625\n",
      "iter 2351 ---  Loss: 3.546032562851906    Accuracy: 86.25\n",
      "iter 2352 ---  Loss: 2.965414933860302    Accuracy: 85.3125\n",
      "iter 2353 ---  Loss: 2.900420494377613    Accuracy: 86.5625\n",
      "iter 2354 ---  Loss: 3.4004774689674377    Accuracy: 85.625\n",
      "iter 2355 ---  Loss: 2.777483619749546    Accuracy: 87.65625\n",
      "iter 2356 ---  Loss: 2.9209683761000633    Accuracy: 87.5\n",
      "iter 2357 ---  Loss: 3.2040198668837547    Accuracy: 86.5625\n",
      "iter 2358 ---  Loss: 3.319221831858158    Accuracy: 87.65625\n",
      "iter 2359 ---  Loss: 3.198803164064884    Accuracy: 89.53125\n",
      "iter 2360 ---  Loss: 2.74886304885149    Accuracy: 87.34375\n",
      "iter 2361 ---  Loss: 3.266671873629093    Accuracy: 86.875\n",
      "iter 2362 ---  Loss: 3.288230560719967    Accuracy: 87.03125\n",
      "iter 2363 ---  Loss: 3.347808964550495    Accuracy: 85.15625\n",
      "iter 2364 ---  Loss: 3.0258139446377754    Accuracy: 87.65625\n",
      "iter 2365 ---  Loss: 2.5608632788062096    Accuracy: 87.8125\n",
      "iter 2366 ---  Loss: 3.270871125161648    Accuracy: 84.6875\n",
      "iter 2367 ---  Loss: 3.671291097998619    Accuracy: 86.875\n",
      "iter 2368 ---  Loss: 3.3455039709806442    Accuracy: 86.09375\n",
      "iter 2369 ---  Loss: 3.087587483227253    Accuracy: 87.1875\n",
      "iter 2370 ---  Loss: 2.868757374584675    Accuracy: 88.4375\n",
      "iter 2371 ---  Loss: 3.5547173470258713    Accuracy: 86.71875\n",
      "iter 2372 ---  Loss: 3.3044889345765114    Accuracy: 87.1875\n",
      "iter 2373 ---  Loss: 3.0550117939710617    Accuracy: 86.25\n",
      "iter 2374 ---  Loss: 2.999972864985466    Accuracy: 89.21875\n",
      "iter 2375 ---  Loss: 3.1745212450623512    Accuracy: 86.25\n",
      "iter 2376 ---  Loss: 2.5369128212332726    Accuracy: 87.8125\n",
      "iter 2377 ---  Loss: 3.1306212693452835    Accuracy: 87.5\n",
      "iter 2378 ---  Loss: 3.1745871528983116    Accuracy: 86.875\n",
      "iter 2379 ---  Loss: 3.182723306119442    Accuracy: 87.03125\n",
      "iter 2380 ---  Loss: 2.8477462977170944    Accuracy: 87.96875\n",
      "iter 2381 ---  Loss: 3.247397802770138    Accuracy: 84.84375\n",
      "iter 2382 ---  Loss: 2.4614898562431335    Accuracy: 89.21875\n",
      "iter 2383 ---  Loss: 2.83380788564682    Accuracy: 85.9375\n",
      "iter 2384 ---  Loss: 2.898019663989544    Accuracy: 87.1875\n",
      "iter 2385 ---  Loss: 3.0071224868297577    Accuracy: 87.8125\n",
      "iter 2386 ---  Loss: 2.6622688099741936    Accuracy: 87.8125\n",
      "iter 2387 ---  Loss: 3.1518890112638474    Accuracy: 87.8125\n",
      "iter 2388 ---  Loss: 3.44091534614563    Accuracy: 86.5625\n",
      "iter 2389 ---  Loss: 3.0188580453395844    Accuracy: 85.78125\n",
      "iter 2390 ---  Loss: 2.4138132110238075    Accuracy: 89.53125\n",
      "iter 2391 ---  Loss: 3.321009114384651    Accuracy: 88.75\n",
      "iter 2392 ---  Loss: 3.2598762214183807    Accuracy: 88.28125\n",
      "iter 2393 ---  Loss: 2.8005892038345337    Accuracy: 88.28125\n",
      "iter 2394 ---  Loss: 3.4813523441553116    Accuracy: 84.84375\n",
      "iter 2395 ---  Loss: 2.7816819176077843    Accuracy: 87.34375\n",
      "iter 2396 ---  Loss: 3.0997489616274834    Accuracy: 87.96875\n",
      "iter 2397 ---  Loss: 3.2107257172465324    Accuracy: 89.21875\n",
      "iter 2398 ---  Loss: 2.856033392250538    Accuracy: 86.09375\n",
      "iter 2399 ---  Loss: 2.9370678812265396    Accuracy: 87.8125\n",
      "iter 2400 ---  Loss: 3.39923657476902    Accuracy: 85.78125\n",
      "iter 2401 ---  Loss: 3.067679814994335    Accuracy: 86.875\n",
      "iter 2402 ---  Loss: 2.655576467514038    Accuracy: 89.375\n",
      "iter 2403 ---  Loss: 2.86749716848135    Accuracy: 89.53125\n",
      "iter 2404 ---  Loss: 3.280514433979988    Accuracy: 85.625\n",
      "iter 2405 ---  Loss: 2.9057489782571793    Accuracy: 89.375\n",
      "iter 2406 ---  Loss: 3.854811415076256    Accuracy: 85.46875\n",
      "iter 2407 ---  Loss: 2.731349155306816    Accuracy: 89.6875\n",
      "iter 2408 ---  Loss: 3.0229816883802414    Accuracy: 85.9375\n",
      "iter 2409 ---  Loss: 3.2667617052793503    Accuracy: 85.625\n",
      "iter 2410 ---  Loss: 3.167126141488552    Accuracy: 86.40625\n",
      "iter 2411 ---  Loss: 3.008273661136627    Accuracy: 86.40625\n",
      "iter 2412 ---  Loss: 2.9766931012272835    Accuracy: 88.125\n",
      "iter 2413 ---  Loss: 3.4431625828146935    Accuracy: 87.5\n",
      "iter 2414 ---  Loss: 3.1020665019750595    Accuracy: 87.5\n",
      "iter 2415 ---  Loss: 2.936792239546776    Accuracy: 86.5625\n",
      "iter 2416 ---  Loss: 2.513600505888462    Accuracy: 88.28125\n",
      "iter 2417 ---  Loss: 3.355902224779129    Accuracy: 86.40625\n",
      "iter 2418 ---  Loss: 3.0090380385518074    Accuracy: 88.75\n",
      "iter 2419 ---  Loss: 3.4417819380760193    Accuracy: 85.78125\n",
      "iter 2420 ---  Loss: 3.6867354959249496    Accuracy: 87.5\n",
      "iter 2421 ---  Loss: 2.820637747645378    Accuracy: 87.65625\n",
      "iter 2422 ---  Loss: 3.224776789546013    Accuracy: 88.4375\n",
      "iter 2423 ---  Loss: 3.116918735206127    Accuracy: 88.4375\n",
      "iter 2424 ---  Loss: 2.5623570159077644    Accuracy: 87.65625\n",
      "iter 2425 ---  Loss: 3.2852514162659645    Accuracy: 87.03125\n",
      "iter 2426 ---  Loss: 2.6995189115405083    Accuracy: 87.65625\n",
      "iter 2427 ---  Loss: 3.083767108619213    Accuracy: 85.625\n",
      "iter 2428 ---  Loss: 2.8433568999171257    Accuracy: 87.1875\n",
      "iter 2429 ---  Loss: 2.9236913323402405    Accuracy: 87.8125\n",
      "iter 2430 ---  Loss: 2.6856904849410057    Accuracy: 87.34375\n",
      "iter 2431 ---  Loss: 2.8309714943170547    Accuracy: 89.0625\n",
      "iter 2432 ---  Loss: 3.1453183367848396    Accuracy: 87.34375\n",
      "iter 2433 ---  Loss: 2.9267460480332375    Accuracy: 87.1875\n",
      "iter 2434 ---  Loss: 2.77670656144619    Accuracy: 87.5\n",
      "iter 2435 ---  Loss: 3.1581515297293663    Accuracy: 86.25\n",
      "iter 2436 ---  Loss: 3.9462857991456985    Accuracy: 86.71875\n",
      "iter 2437 ---  Loss: 2.7942617908120155    Accuracy: 87.5\n",
      "iter 2438 ---  Loss: 3.0547982677817345    Accuracy: 86.09375\n",
      "iter 2439 ---  Loss: 2.9154344722628593    Accuracy: 88.90625\n",
      "iter 2440 ---  Loss: 3.6938472762703896    Accuracy: 86.71875\n",
      "iter 2441 ---  Loss: 3.2039412185549736    Accuracy: 87.03125\n",
      "iter 2442 ---  Loss: 3.4297634437680244    Accuracy: 85.0\n",
      "iter 2443 ---  Loss: 2.995815269649029    Accuracy: 87.1875\n",
      "iter 2444 ---  Loss: 3.0595075264573097    Accuracy: 85.9375\n",
      "iter 2445 ---  Loss: 2.9118098989129066    Accuracy: 87.34375\n",
      "iter 2446 ---  Loss: 3.2516977563500404    Accuracy: 87.1875\n",
      "iter 2447 ---  Loss: 3.0488748624920845    Accuracy: 87.65625\n",
      "iter 2448 ---  Loss: 3.3650178611278534    Accuracy: 85.78125\n",
      "iter 2449 ---  Loss: 2.7990113347768784    Accuracy: 86.40625\n",
      "iter 2450 ---  Loss: 2.795579142868519    Accuracy: 87.5\n",
      "iter 2451 ---  Loss: 3.1424474641680717    Accuracy: 86.875\n",
      "iter 2452 ---  Loss: 3.2708678394556046    Accuracy: 85.78125\n",
      "iter 2453 ---  Loss: 2.7923524141311646    Accuracy: 90.0\n",
      "Epoch 3/4\n",
      "-------------\n",
      "iter 0 ---  Loss: 3.1968797892332077    Accuracy: 87.65625\n",
      "iter 1 ---  Loss: 2.8903085440397263    Accuracy: 88.59375\n",
      "iter 2 ---  Loss: 2.753085993230343    Accuracy: 86.40625\n",
      "iter 3 ---  Loss: 3.7801807448267937    Accuracy: 86.875\n",
      "iter 4 ---  Loss: 2.840717062354088    Accuracy: 87.1875\n",
      "iter 5 ---  Loss: 2.9894991517066956    Accuracy: 87.8125\n",
      "iter 6 ---  Loss: 3.762220799922943    Accuracy: 86.875\n",
      "iter 7 ---  Loss: 3.0170890912413597    Accuracy: 85.625\n",
      "iter 8 ---  Loss: 3.048753723502159    Accuracy: 87.03125\n",
      "iter 9 ---  Loss: 3.249433532357216    Accuracy: 88.59375\n",
      "iter 10 ---  Loss: 3.2505525574088097    Accuracy: 86.40625\n",
      "iter 11 ---  Loss: 3.462873473763466    Accuracy: 86.25\n",
      "iter 12 ---  Loss: 3.163968786597252    Accuracy: 87.5\n",
      "iter 13 ---  Loss: 2.854920767247677    Accuracy: 85.46875\n",
      "iter 14 ---  Loss: 2.317752629518509    Accuracy: 88.28125\n",
      "iter 15 ---  Loss: 3.2407602295279503    Accuracy: 87.65625\n",
      "iter 16 ---  Loss: 2.7609873563051224    Accuracy: 88.4375\n",
      "iter 17 ---  Loss: 2.7274460047483444    Accuracy: 86.875\n",
      "iter 18 ---  Loss: 3.4778095558285713    Accuracy: 84.53125\n",
      "iter 19 ---  Loss: 2.737152762711048    Accuracy: 87.1875\n",
      "iter 20 ---  Loss: 3.055114895105362    Accuracy: 88.4375\n",
      "iter 21 ---  Loss: 3.1113918498158455    Accuracy: 85.15625\n",
      "iter 22 ---  Loss: 3.6887304484844208    Accuracy: 86.40625\n",
      "iter 23 ---  Loss: 2.5249442979693413    Accuracy: 87.34375\n",
      "iter 24 ---  Loss: 3.1645427346229553    Accuracy: 87.1875\n",
      "iter 25 ---  Loss: 2.977988615632057    Accuracy: 87.65625\n",
      "iter 26 ---  Loss: 3.2994246631860733    Accuracy: 87.03125\n",
      "iter 27 ---  Loss: 4.2886644676327705    Accuracy: 86.25\n",
      "iter 28 ---  Loss: 2.887984149158001    Accuracy: 87.1875\n",
      "iter 29 ---  Loss: 2.4847178012132645    Accuracy: 89.21875\n",
      "iter 30 ---  Loss: 3.765033856034279    Accuracy: 86.25\n",
      "iter 31 ---  Loss: 2.9801088124513626    Accuracy: 87.8125\n",
      "iter 32 ---  Loss: 3.550653353333473    Accuracy: 85.3125\n",
      "iter 33 ---  Loss: 3.2478145360946655    Accuracy: 86.40625\n",
      "iter 34 ---  Loss: 2.786852426826954    Accuracy: 88.75\n",
      "iter 35 ---  Loss: 2.9503864496946335    Accuracy: 86.09375\n",
      "iter 36 ---  Loss: 3.3479848578572273    Accuracy: 89.0625\n",
      "iter 37 ---  Loss: 2.9804433658719063    Accuracy: 88.59375\n",
      "iter 38 ---  Loss: 4.332085475325584    Accuracy: 83.90625\n",
      "iter 39 ---  Loss: 3.21297474950552    Accuracy: 86.25\n",
      "iter 40 ---  Loss: 3.129270501434803    Accuracy: 85.9375\n",
      "iter 41 ---  Loss: 3.1443420201539993    Accuracy: 86.875\n",
      "iter 42 ---  Loss: 2.786604717373848    Accuracy: 85.625\n",
      "iter 43 ---  Loss: 2.759012818336487    Accuracy: 88.28125\n",
      "iter 44 ---  Loss: 3.0682933926582336    Accuracy: 86.25\n",
      "iter 45 ---  Loss: 2.982049159705639    Accuracy: 88.125\n",
      "iter 46 ---  Loss: 3.182671181857586    Accuracy: 87.34375\n",
      "iter 47 ---  Loss: 3.510047160089016    Accuracy: 86.5625\n",
      "iter 48 ---  Loss: 3.029249869287014    Accuracy: 89.21875\n",
      "iter 49 ---  Loss: 3.0702471882104874    Accuracy: 88.125\n",
      "iter 50 ---  Loss: 3.1122449189424515    Accuracy: 86.25\n",
      "iter 51 ---  Loss: 3.59507454931736    Accuracy: 86.71875\n",
      "iter 52 ---  Loss: 2.6897982209920883    Accuracy: 87.34375\n",
      "iter 53 ---  Loss: 2.8707474172115326    Accuracy: 87.5\n",
      "iter 54 ---  Loss: 2.9612371623516083    Accuracy: 87.1875\n",
      "iter 55 ---  Loss: 2.712060958147049    Accuracy: 87.5\n",
      "iter 56 ---  Loss: 3.0704094767570496    Accuracy: 88.59375\n",
      "iter 57 ---  Loss: 3.6054967418313026    Accuracy: 84.84375\n",
      "iter 58 ---  Loss: 3.0053656920790672    Accuracy: 86.25\n",
      "iter 59 ---  Loss: 2.7377854809165    Accuracy: 87.96875\n",
      "iter 60 ---  Loss: 2.889297276735306    Accuracy: 88.75\n",
      "iter 61 ---  Loss: 2.7966964542865753    Accuracy: 85.9375\n",
      "iter 62 ---  Loss: 3.1088989078998566    Accuracy: 87.5\n",
      "iter 63 ---  Loss: 2.9797188118100166    Accuracy: 86.5625\n",
      "iter 64 ---  Loss: 2.941138006746769    Accuracy: 87.8125\n",
      "iter 65 ---  Loss: 3.0246058851480484    Accuracy: 87.8125\n",
      "iter 66 ---  Loss: 2.900921680033207    Accuracy: 86.5625\n",
      "iter 67 ---  Loss: 2.938305512070656    Accuracy: 86.25\n",
      "iter 68 ---  Loss: 3.409092701971531    Accuracy: 86.71875\n",
      "iter 69 ---  Loss: 4.029416486620903    Accuracy: 86.40625\n",
      "iter 70 ---  Loss: 2.9861646816134453    Accuracy: 88.28125\n",
      "iter 71 ---  Loss: 2.9861313477158546    Accuracy: 85.9375\n",
      "iter 72 ---  Loss: 2.6317697912454605    Accuracy: 87.34375\n",
      "iter 73 ---  Loss: 3.199839986860752    Accuracy: 89.375\n",
      "iter 74 ---  Loss: 3.725914977490902    Accuracy: 86.25\n",
      "iter 75 ---  Loss: 3.2641401514410973    Accuracy: 87.8125\n",
      "iter 76 ---  Loss: 2.9909209087491035    Accuracy: 87.65625\n",
      "iter 77 ---  Loss: 3.1441641747951508    Accuracy: 87.03125\n",
      "iter 78 ---  Loss: 3.580520585179329    Accuracy: 87.03125\n",
      "iter 79 ---  Loss: 3.1739946454763412    Accuracy: 86.875\n",
      "iter 80 ---  Loss: 2.637022517621517    Accuracy: 86.71875\n",
      "iter 81 ---  Loss: 3.4763344898819923    Accuracy: 86.25\n",
      "iter 82 ---  Loss: 3.1487507298588753    Accuracy: 87.1875\n",
      "iter 83 ---  Loss: 2.5488032773137093    Accuracy: 87.96875\n",
      "iter 84 ---  Loss: 3.511624999344349    Accuracy: 86.5625\n",
      "iter 85 ---  Loss: 2.5953160524368286    Accuracy: 89.6875\n",
      "iter 86 ---  Loss: 2.6722937375307083    Accuracy: 88.125\n",
      "iter 87 ---  Loss: 2.7574323415756226    Accuracy: 87.65625\n",
      "iter 88 ---  Loss: 2.815339133143425    Accuracy: 88.4375\n",
      "iter 89 ---  Loss: 3.0725795701146126    Accuracy: 88.28125\n",
      "iter 90 ---  Loss: 2.68188489228487    Accuracy: 87.1875\n",
      "iter 91 ---  Loss: 3.0400588884949684    Accuracy: 87.5\n",
      "iter 92 ---  Loss: 2.6864356994628906    Accuracy: 89.0625\n",
      "iter 93 ---  Loss: 3.5918114706873894    Accuracy: 85.9375\n",
      "iter 94 ---  Loss: 2.8468940183520317    Accuracy: 87.03125\n",
      "iter 95 ---  Loss: 2.809720128774643    Accuracy: 86.875\n",
      "iter 96 ---  Loss: 2.6578644812107086    Accuracy: 86.40625\n",
      "iter 97 ---  Loss: 3.2989114597439766    Accuracy: 88.4375\n",
      "iter 98 ---  Loss: 3.4387658834457397    Accuracy: 86.25\n",
      "iter 99 ---  Loss: 2.912128694355488    Accuracy: 88.59375\n",
      "iter 100 ---  Loss: 2.6749055311083794    Accuracy: 87.8125\n",
      "iter 101 ---  Loss: 3.1013423800468445    Accuracy: 86.875\n",
      "iter 102 ---  Loss: 3.2483553886413574    Accuracy: 85.9375\n",
      "iter 103 ---  Loss: 2.8005254939198494    Accuracy: 86.875\n",
      "iter 104 ---  Loss: 2.7134039849042892    Accuracy: 86.71875\n",
      "iter 105 ---  Loss: 3.182612366974354    Accuracy: 85.3125\n",
      "iter 106 ---  Loss: 2.5723433941602707    Accuracy: 89.0625\n",
      "iter 107 ---  Loss: 3.4685057997703552    Accuracy: 87.34375\n",
      "iter 108 ---  Loss: 3.032551556825638    Accuracy: 87.5\n",
      "iter 109 ---  Loss: 3.6541024148464203    Accuracy: 85.78125\n",
      "iter 110 ---  Loss: 3.498614065349102    Accuracy: 86.71875\n",
      "iter 111 ---  Loss: 2.4607312753796577    Accuracy: 88.59375\n",
      "iter 112 ---  Loss: 3.379487581551075    Accuracy: 87.34375\n",
      "iter 113 ---  Loss: 2.9382486045360565    Accuracy: 87.96875\n",
      "iter 114 ---  Loss: 3.0608595609664917    Accuracy: 87.8125\n",
      "iter 115 ---  Loss: 3.1174837350845337    Accuracy: 87.96875\n",
      "iter 116 ---  Loss: 3.0724339932203293    Accuracy: 89.6875\n",
      "iter 117 ---  Loss: 3.0792613178491592    Accuracy: 87.5\n",
      "iter 118 ---  Loss: 3.0058231577277184    Accuracy: 87.65625\n",
      "iter 119 ---  Loss: 3.0277467891573906    Accuracy: 89.0625\n",
      "iter 120 ---  Loss: 2.8842333927750587    Accuracy: 87.03125\n",
      "iter 121 ---  Loss: 2.7061177268624306    Accuracy: 87.34375\n",
      "iter 122 ---  Loss: 3.149319440126419    Accuracy: 87.03125\n",
      "iter 123 ---  Loss: 3.3579617887735367    Accuracy: 87.96875\n",
      "iter 124 ---  Loss: 2.82469529658556    Accuracy: 88.59375\n",
      "iter 125 ---  Loss: 3.2580696195364    Accuracy: 86.875\n",
      "iter 126 ---  Loss: 2.875041648745537    Accuracy: 87.96875\n",
      "iter 127 ---  Loss: 3.3591190725564957    Accuracy: 88.28125\n",
      "iter 128 ---  Loss: 3.0431337133049965    Accuracy: 90.3125\n",
      "iter 129 ---  Loss: 3.050742417573929    Accuracy: 87.65625\n",
      "iter 130 ---  Loss: 2.9572132900357246    Accuracy: 87.03125\n",
      "iter 131 ---  Loss: 2.778809078037739    Accuracy: 87.96875\n",
      "iter 132 ---  Loss: 2.9769905358552933    Accuracy: 90.0\n",
      "iter 133 ---  Loss: 3.5331823229789734    Accuracy: 85.15625\n",
      "iter 134 ---  Loss: 3.0847357138991356    Accuracy: 87.8125\n",
      "iter 135 ---  Loss: 2.6587687209248543    Accuracy: 88.75\n",
      "iter 136 ---  Loss: 3.9579387605190277    Accuracy: 86.71875\n",
      "iter 137 ---  Loss: 3.0701052397489548    Accuracy: 87.1875\n",
      "iter 138 ---  Loss: 2.8152036890387535    Accuracy: 89.6875\n",
      "iter 139 ---  Loss: 2.834609068930149    Accuracy: 87.1875\n",
      "iter 140 ---  Loss: 3.186901666224003    Accuracy: 87.96875\n",
      "iter 141 ---  Loss: 3.422014370560646    Accuracy: 86.25\n",
      "iter 142 ---  Loss: 3.3151522055268288    Accuracy: 86.875\n",
      "iter 143 ---  Loss: 3.460674576461315    Accuracy: 86.40625\n",
      "iter 144 ---  Loss: 3.1121349930763245    Accuracy: 88.28125\n",
      "iter 145 ---  Loss: 2.8761903271079063    Accuracy: 88.90625\n",
      "iter 146 ---  Loss: 3.0125583186745644    Accuracy: 88.4375\n",
      "iter 147 ---  Loss: 3.1294113397598267    Accuracy: 86.5625\n",
      "iter 148 ---  Loss: 2.9199119731783867    Accuracy: 90.0\n",
      "iter 149 ---  Loss: 2.9166603684425354    Accuracy: 88.75\n",
      "iter 150 ---  Loss: 2.683206118643284    Accuracy: 87.96875\n",
      "iter 151 ---  Loss: 3.1778968274593353    Accuracy: 87.5\n",
      "iter 152 ---  Loss: 2.83603872358799    Accuracy: 88.4375\n",
      "iter 153 ---  Loss: 3.193813979625702    Accuracy: 86.5625\n",
      "iter 154 ---  Loss: 2.844671919941902    Accuracy: 88.28125\n",
      "iter 155 ---  Loss: 3.4773812890052795    Accuracy: 87.65625\n",
      "iter 156 ---  Loss: 3.9440502375364304    Accuracy: 87.03125\n",
      "iter 157 ---  Loss: 2.8906602934002876    Accuracy: 87.5\n",
      "iter 158 ---  Loss: 3.4147605150938034    Accuracy: 86.09375\n",
      "iter 159 ---  Loss: 3.5769815295934677    Accuracy: 85.78125\n",
      "iter 160 ---  Loss: 2.5830460265278816    Accuracy: 87.1875\n",
      "iter 161 ---  Loss: 3.144565299153328    Accuracy: 87.34375\n",
      "iter 162 ---  Loss: 3.0204736292362213    Accuracy: 86.25\n",
      "iter 163 ---  Loss: 3.5622561275959015    Accuracy: 86.25\n",
      "iter 164 ---  Loss: 2.643035374581814    Accuracy: 87.65625\n",
      "iter 165 ---  Loss: 3.27331480383873    Accuracy: 85.15625\n",
      "iter 166 ---  Loss: 3.011548735201359    Accuracy: 89.21875\n",
      "iter 167 ---  Loss: 3.0885220244526863    Accuracy: 86.40625\n",
      "iter 168 ---  Loss: 3.255210317671299    Accuracy: 87.96875\n",
      "iter 169 ---  Loss: 3.4944155514240265    Accuracy: 88.28125\n",
      "iter 170 ---  Loss: 3.350647807121277    Accuracy: 87.1875\n",
      "iter 171 ---  Loss: 2.4197574332356453    Accuracy: 90.0\n",
      "iter 172 ---  Loss: 3.1596672236919403    Accuracy: 86.71875\n",
      "iter 173 ---  Loss: 2.772695355117321    Accuracy: 87.03125\n",
      "iter 174 ---  Loss: 3.0816802456974983    Accuracy: 87.96875\n",
      "iter 175 ---  Loss: 2.9886935725808144    Accuracy: 87.1875\n",
      "iter 176 ---  Loss: 3.7026967629790306    Accuracy: 85.0\n",
      "iter 177 ---  Loss: 3.2414087131619453    Accuracy: 86.40625\n",
      "iter 178 ---  Loss: 2.8105974942445755    Accuracy: 88.28125\n",
      "iter 179 ---  Loss: 2.839710868895054    Accuracy: 88.90625\n",
      "iter 180 ---  Loss: 3.3278934955596924    Accuracy: 88.59375\n",
      "iter 181 ---  Loss: 3.848224639892578    Accuracy: 84.375\n",
      "iter 182 ---  Loss: 2.704752616584301    Accuracy: 87.5\n",
      "iter 183 ---  Loss: 3.5575607866048813    Accuracy: 87.65625\n",
      "iter 184 ---  Loss: 2.8732572942972183    Accuracy: 86.5625\n",
      "iter 185 ---  Loss: 3.0958023741841316    Accuracy: 88.4375\n",
      "iter 186 ---  Loss: 2.9777523428201675    Accuracy: 87.65625\n",
      "iter 187 ---  Loss: 3.236725613474846    Accuracy: 86.25\n",
      "iter 188 ---  Loss: 3.628097288310528    Accuracy: 86.40625\n",
      "iter 189 ---  Loss: 3.36364071816206    Accuracy: 85.78125\n",
      "iter 190 ---  Loss: 3.014456056058407    Accuracy: 88.125\n",
      "iter 191 ---  Loss: 3.0230471342802048    Accuracy: 86.71875\n",
      "iter 192 ---  Loss: 3.2399496287107468    Accuracy: 86.875\n",
      "iter 193 ---  Loss: 2.5204359963536263    Accuracy: 88.59375\n",
      "iter 194 ---  Loss: 3.0085103064775467    Accuracy: 86.5625\n",
      "iter 195 ---  Loss: 2.8987232446670532    Accuracy: 88.75\n",
      "iter 196 ---  Loss: 3.8888950273394585    Accuracy: 86.5625\n",
      "iter 197 ---  Loss: 2.8125964924693108    Accuracy: 91.40625\n",
      "iter 198 ---  Loss: 2.597068667411804    Accuracy: 86.5625\n",
      "iter 199 ---  Loss: 3.244170367717743    Accuracy: 86.71875\n",
      "iter 200 ---  Loss: 3.391985073685646    Accuracy: 87.8125\n",
      "iter 201 ---  Loss: 3.5522612631320953    Accuracy: 84.375\n",
      "iter 202 ---  Loss: 3.546053886413574    Accuracy: 84.375\n",
      "iter 203 ---  Loss: 3.19675100594759    Accuracy: 87.65625\n",
      "iter 204 ---  Loss: 3.0980354696512222    Accuracy: 85.9375\n",
      "iter 205 ---  Loss: 2.6426667496562004    Accuracy: 86.71875\n",
      "iter 206 ---  Loss: 3.167841076850891    Accuracy: 86.25\n",
      "iter 207 ---  Loss: 2.6794961020350456    Accuracy: 86.40625\n",
      "iter 208 ---  Loss: 2.911936931312084    Accuracy: 88.59375\n",
      "iter 209 ---  Loss: 3.4654319062829018    Accuracy: 86.25\n",
      "iter 210 ---  Loss: 3.2445137798786163    Accuracy: 86.5625\n",
      "iter 211 ---  Loss: 3.0890808179974556    Accuracy: 86.71875\n",
      "iter 212 ---  Loss: 2.830408990383148    Accuracy: 89.21875\n",
      "iter 213 ---  Loss: 2.9658139497041702    Accuracy: 87.03125\n",
      "iter 214 ---  Loss: 3.3297566697001457    Accuracy: 85.15625\n",
      "iter 215 ---  Loss: 2.959210030734539    Accuracy: 87.65625\n",
      "iter 216 ---  Loss: 3.3204138427972794    Accuracy: 86.875\n",
      "iter 217 ---  Loss: 3.06413484364748    Accuracy: 85.9375\n",
      "iter 218 ---  Loss: 3.118643529713154    Accuracy: 87.1875\n",
      "iter 219 ---  Loss: 2.764724239706993    Accuracy: 86.71875\n",
      "iter 220 ---  Loss: 2.8491251319646835    Accuracy: 85.9375\n",
      "iter 221 ---  Loss: 3.073046162724495    Accuracy: 87.5\n",
      "iter 222 ---  Loss: 3.2208748385310173    Accuracy: 87.03125\n",
      "iter 223 ---  Loss: 3.6290534511208534    Accuracy: 84.53125\n",
      "iter 224 ---  Loss: 2.91865211725235    Accuracy: 86.25\n",
      "iter 225 ---  Loss: 3.162918336689472    Accuracy: 85.9375\n",
      "iter 226 ---  Loss: 3.000252403318882    Accuracy: 87.1875\n",
      "iter 227 ---  Loss: 2.846994072198868    Accuracy: 89.0625\n",
      "iter 228 ---  Loss: 3.2221770137548447    Accuracy: 86.71875\n",
      "iter 229 ---  Loss: 3.021008253097534    Accuracy: 86.875\n",
      "iter 230 ---  Loss: 3.1863845586776733    Accuracy: 88.125\n",
      "iter 231 ---  Loss: 3.015626721084118    Accuracy: 87.96875\n",
      "iter 232 ---  Loss: 3.1966831609606743    Accuracy: 87.8125\n",
      "iter 233 ---  Loss: 2.5190067440271378    Accuracy: 89.53125\n",
      "iter 234 ---  Loss: 2.971211791038513    Accuracy: 88.28125\n",
      "iter 235 ---  Loss: 3.5887222215533257    Accuracy: 85.625\n",
      "iter 236 ---  Loss: 3.2554820850491524    Accuracy: 87.1875\n",
      "iter 237 ---  Loss: 3.4327851980924606    Accuracy: 86.5625\n",
      "iter 238 ---  Loss: 3.348780281841755    Accuracy: 87.03125\n",
      "iter 239 ---  Loss: 2.474264681339264    Accuracy: 87.96875\n",
      "iter 240 ---  Loss: 3.3449051827192307    Accuracy: 88.28125\n",
      "iter 241 ---  Loss: 3.274356208741665    Accuracy: 87.65625\n",
      "iter 242 ---  Loss: 2.6958821415901184    Accuracy: 88.28125\n",
      "iter 243 ---  Loss: 3.253156654536724    Accuracy: 87.03125\n",
      "iter 244 ---  Loss: 3.1031136363744736    Accuracy: 86.5625\n",
      "iter 245 ---  Loss: 3.2418750151991844    Accuracy: 86.09375\n",
      "iter 246 ---  Loss: 3.333811305463314    Accuracy: 87.5\n",
      "iter 247 ---  Loss: 2.560106858611107    Accuracy: 87.8125\n",
      "iter 248 ---  Loss: 2.974710151553154    Accuracy: 86.875\n",
      "iter 249 ---  Loss: 2.9152250587940216    Accuracy: 88.90625\n",
      "iter 250 ---  Loss: 2.7129931151866913    Accuracy: 88.75\n",
      "iter 251 ---  Loss: 3.0814076885581017    Accuracy: 85.9375\n",
      "iter 252 ---  Loss: 3.8249580338597298    Accuracy: 86.875\n",
      "iter 253 ---  Loss: 2.9940522611141205    Accuracy: 87.65625\n",
      "iter 254 ---  Loss: 3.1329547837376595    Accuracy: 86.5625\n",
      "iter 255 ---  Loss: 3.1751923635601997    Accuracy: 86.09375\n",
      "iter 256 ---  Loss: 3.2797048836946487    Accuracy: 86.5625\n",
      "iter 257 ---  Loss: 3.13990119099617    Accuracy: 87.65625\n",
      "iter 258 ---  Loss: 3.9874931946396828    Accuracy: 86.875\n",
      "iter 259 ---  Loss: 3.173194244503975    Accuracy: 88.28125\n",
      "iter 260 ---  Loss: 3.074268713593483    Accuracy: 86.5625\n",
      "iter 261 ---  Loss: 3.0396377965807915    Accuracy: 86.71875\n",
      "iter 262 ---  Loss: 2.708686374127865    Accuracy: 87.8125\n",
      "iter 263 ---  Loss: 2.848685637116432    Accuracy: 86.25\n",
      "iter 264 ---  Loss: 3.12651526927948    Accuracy: 87.65625\n",
      "iter 265 ---  Loss: 2.7257604226469994    Accuracy: 88.59375\n",
      "iter 266 ---  Loss: 3.059768669307232    Accuracy: 87.34375\n",
      "iter 267 ---  Loss: 3.6072431430220604    Accuracy: 87.34375\n",
      "iter 268 ---  Loss: 2.984882205724716    Accuracy: 87.96875\n",
      "iter 269 ---  Loss: 3.3127218186855316    Accuracy: 86.5625\n",
      "iter 270 ---  Loss: 3.483767345547676    Accuracy: 85.625\n",
      "iter 271 ---  Loss: 2.9188034012913704    Accuracy: 86.40625\n",
      "iter 272 ---  Loss: 2.8772181794047356    Accuracy: 87.8125\n",
      "iter 273 ---  Loss: 3.1643762290477753    Accuracy: 85.9375\n",
      "iter 274 ---  Loss: 3.0074602589011192    Accuracy: 85.9375\n",
      "iter 275 ---  Loss: 2.883294127881527    Accuracy: 87.65625\n",
      "iter 276 ---  Loss: 3.0909710079431534    Accuracy: 87.65625\n",
      "iter 277 ---  Loss: 2.7195787876844406    Accuracy: 90.0\n",
      "iter 278 ---  Loss: 3.17535687237978    Accuracy: 87.96875\n",
      "iter 279 ---  Loss: 3.1434450075030327    Accuracy: 87.34375\n",
      "iter 280 ---  Loss: 3.237886093556881    Accuracy: 88.28125\n",
      "iter 281 ---  Loss: 3.3408184200525284    Accuracy: 87.03125\n",
      "iter 282 ---  Loss: 3.5924753174185753    Accuracy: 86.25\n",
      "iter 283 ---  Loss: 3.108515612781048    Accuracy: 86.25\n",
      "iter 284 ---  Loss: 3.0130985006690025    Accuracy: 88.28125\n",
      "iter 285 ---  Loss: 3.529767982661724    Accuracy: 86.5625\n",
      "iter 286 ---  Loss: 2.9072470664978027    Accuracy: 87.1875\n",
      "iter 287 ---  Loss: 3.626184366643429    Accuracy: 87.34375\n",
      "iter 288 ---  Loss: 2.9106666669249535    Accuracy: 87.65625\n",
      "iter 289 ---  Loss: 3.191689647734165    Accuracy: 85.46875\n",
      "iter 290 ---  Loss: 3.0643840804696083    Accuracy: 86.5625\n",
      "iter 291 ---  Loss: 2.9405240640044212    Accuracy: 87.65625\n",
      "iter 292 ---  Loss: 2.7370903193950653    Accuracy: 88.90625\n",
      "iter 293 ---  Loss: 3.033020868897438    Accuracy: 88.28125\n",
      "iter 294 ---  Loss: 3.102066606283188    Accuracy: 85.15625\n",
      "iter 295 ---  Loss: 2.3175110518932343    Accuracy: 89.6875\n",
      "iter 296 ---  Loss: 2.9119378849864006    Accuracy: 86.71875\n",
      "iter 297 ---  Loss: 2.672332637012005    Accuracy: 88.90625\n",
      "iter 298 ---  Loss: 2.5449870079755783    Accuracy: 89.53125\n",
      "iter 299 ---  Loss: 3.2198427096009254    Accuracy: 87.1875\n",
      "iter 300 ---  Loss: 3.36562842130661    Accuracy: 85.3125\n",
      "iter 301 ---  Loss: 2.8144607543945312    Accuracy: 88.4375\n",
      "iter 302 ---  Loss: 3.8984164893627167    Accuracy: 85.46875\n",
      "iter 303 ---  Loss: 3.4838364869356155    Accuracy: 86.09375\n",
      "iter 304 ---  Loss: 3.4539372473955154    Accuracy: 87.65625\n",
      "iter 305 ---  Loss: 2.4685481637716293    Accuracy: 88.75\n",
      "iter 306 ---  Loss: 3.4972785264253616    Accuracy: 85.9375\n",
      "iter 307 ---  Loss: 2.686833828687668    Accuracy: 87.5\n",
      "iter 308 ---  Loss: 3.360417351126671    Accuracy: 87.5\n",
      "iter 309 ---  Loss: 2.769669160246849    Accuracy: 88.90625\n",
      "iter 310 ---  Loss: 2.934046119451523    Accuracy: 86.5625\n",
      "iter 311 ---  Loss: 2.611423932015896    Accuracy: 89.84375\n",
      "iter 312 ---  Loss: 3.4699217304587364    Accuracy: 87.96875\n",
      "iter 313 ---  Loss: 2.764951452612877    Accuracy: 89.6875\n",
      "iter 314 ---  Loss: 3.323735259473324    Accuracy: 85.625\n",
      "iter 315 ---  Loss: 2.963802970945835    Accuracy: 85.625\n",
      "iter 316 ---  Loss: 2.8548217564821243    Accuracy: 87.8125\n",
      "iter 317 ---  Loss: 2.88529971241951    Accuracy: 88.75\n",
      "iter 318 ---  Loss: 2.8826156929135323    Accuracy: 87.03125\n",
      "iter 319 ---  Loss: 2.8697982281446457    Accuracy: 88.59375\n",
      "iter 320 ---  Loss: 3.0163813456892967    Accuracy: 88.75\n",
      "iter 321 ---  Loss: 3.7073996663093567    Accuracy: 87.65625\n",
      "iter 322 ---  Loss: 3.0447222888469696    Accuracy: 87.5\n",
      "iter 323 ---  Loss: 3.3888204619288445    Accuracy: 86.71875\n",
      "iter 324 ---  Loss: 2.9448949843645096    Accuracy: 88.4375\n",
      "iter 325 ---  Loss: 2.816831737756729    Accuracy: 85.3125\n",
      "iter 326 ---  Loss: 3.5375080183148384    Accuracy: 86.5625\n",
      "iter 327 ---  Loss: 2.3905382081866264    Accuracy: 90.15625\n",
      "iter 328 ---  Loss: 3.2426322996616364    Accuracy: 87.96875\n",
      "iter 329 ---  Loss: 3.183992587029934    Accuracy: 87.1875\n",
      "iter 330 ---  Loss: 2.918844550848007    Accuracy: 88.125\n",
      "iter 331 ---  Loss: 2.887118674814701    Accuracy: 88.125\n",
      "iter 332 ---  Loss: 2.854290820658207    Accuracy: 89.375\n",
      "iter 333 ---  Loss: 3.14370459318161    Accuracy: 87.34375\n",
      "iter 334 ---  Loss: 3.28825856000185    Accuracy: 87.96875\n",
      "iter 335 ---  Loss: 3.5261776447296143    Accuracy: 87.1875\n",
      "iter 336 ---  Loss: 3.140365391969681    Accuracy: 87.03125\n",
      "iter 337 ---  Loss: 3.490994445979595    Accuracy: 87.65625\n",
      "iter 338 ---  Loss: 3.3934672847390175    Accuracy: 86.875\n",
      "iter 339 ---  Loss: 2.757687933743    Accuracy: 86.25\n",
      "iter 340 ---  Loss: 3.0739070400595665    Accuracy: 89.0625\n",
      "iter 341 ---  Loss: 2.984954245388508    Accuracy: 86.875\n",
      "iter 342 ---  Loss: 3.028092287480831    Accuracy: 88.75\n",
      "iter 343 ---  Loss: 2.8477123975753784    Accuracy: 87.5\n",
      "iter 344 ---  Loss: 3.638924553990364    Accuracy: 85.625\n",
      "iter 345 ---  Loss: 2.907904788851738    Accuracy: 87.65625\n",
      "iter 346 ---  Loss: 2.6631311029195786    Accuracy: 88.125\n",
      "iter 347 ---  Loss: 2.5568840727210045    Accuracy: 88.28125\n",
      "iter 348 ---  Loss: 3.666384384036064    Accuracy: 85.0\n",
      "iter 349 ---  Loss: 2.5696144104003906    Accuracy: 88.4375\n",
      "iter 350 ---  Loss: 2.38652690500021    Accuracy: 88.125\n",
      "iter 351 ---  Loss: 2.563847728073597    Accuracy: 87.5\n",
      "iter 352 ---  Loss: 2.880067713558674    Accuracy: 89.21875\n",
      "iter 353 ---  Loss: 3.0299196392297745    Accuracy: 87.1875\n",
      "iter 354 ---  Loss: 3.1230614706873894    Accuracy: 87.34375\n",
      "iter 355 ---  Loss: 3.031694211065769    Accuracy: 86.71875\n",
      "iter 356 ---  Loss: 3.1843083053827286    Accuracy: 86.40625\n",
      "iter 357 ---  Loss: 3.0445068180561066    Accuracy: 89.0625\n",
      "iter 358 ---  Loss: 2.8898186162114143    Accuracy: 86.25\n",
      "iter 359 ---  Loss: 2.9271258860826492    Accuracy: 88.75\n",
      "iter 360 ---  Loss: 3.159389577805996    Accuracy: 86.875\n",
      "iter 361 ---  Loss: 3.622869163751602    Accuracy: 86.875\n",
      "iter 362 ---  Loss: 2.921727456152439    Accuracy: 88.28125\n",
      "iter 363 ---  Loss: 3.419807456433773    Accuracy: 86.5625\n",
      "iter 364 ---  Loss: 3.21558478474617    Accuracy: 86.25\n",
      "iter 365 ---  Loss: 3.609171576797962    Accuracy: 88.4375\n",
      "iter 366 ---  Loss: 3.3425934612751007    Accuracy: 85.0\n",
      "iter 367 ---  Loss: 3.2197370529174805    Accuracy: 85.3125\n",
      "iter 368 ---  Loss: 3.757482312619686    Accuracy: 85.3125\n",
      "iter 369 ---  Loss: 3.2648839578032494    Accuracy: 87.5\n",
      "iter 370 ---  Loss: 2.704551748931408    Accuracy: 88.59375\n",
      "iter 371 ---  Loss: 3.2780580818653107    Accuracy: 87.5\n",
      "iter 372 ---  Loss: 3.29980755597353    Accuracy: 85.9375\n",
      "iter 373 ---  Loss: 2.9573424383997917    Accuracy: 87.5\n",
      "iter 374 ---  Loss: 3.170772075653076    Accuracy: 87.65625\n",
      "iter 375 ---  Loss: 3.6964587196707726    Accuracy: 84.84375\n",
      "iter 376 ---  Loss: 3.076659567654133    Accuracy: 86.09375\n",
      "iter 377 ---  Loss: 3.3289476707577705    Accuracy: 86.25\n",
      "iter 378 ---  Loss: 3.0523290038108826    Accuracy: 85.625\n",
      "iter 379 ---  Loss: 3.509576693177223    Accuracy: 86.40625\n",
      "iter 380 ---  Loss: 2.824419930577278    Accuracy: 87.5\n",
      "iter 381 ---  Loss: 2.737253248691559    Accuracy: 87.5\n",
      "iter 382 ---  Loss: 3.1346136704087257    Accuracy: 87.1875\n",
      "iter 383 ---  Loss: 3.6181557029485703    Accuracy: 86.5625\n",
      "iter 384 ---  Loss: 3.594893626868725    Accuracy: 86.40625\n",
      "iter 385 ---  Loss: 3.3714338913559914    Accuracy: 86.71875\n",
      "iter 386 ---  Loss: 3.1008091494441032    Accuracy: 89.21875\n",
      "iter 387 ---  Loss: 2.4582493901252747    Accuracy: 89.84375\n",
      "iter 388 ---  Loss: 3.572540558874607    Accuracy: 86.875\n",
      "iter 389 ---  Loss: 3.2048624232411385    Accuracy: 86.40625\n",
      "iter 390 ---  Loss: 3.3736822977662086    Accuracy: 86.40625\n",
      "iter 391 ---  Loss: 3.5525718480348587    Accuracy: 86.875\n",
      "iter 392 ---  Loss: 3.2308817580342293    Accuracy: 85.9375\n",
      "iter 393 ---  Loss: 3.1123828664422035    Accuracy: 86.25\n",
      "iter 394 ---  Loss: 3.951797127723694    Accuracy: 86.5625\n",
      "iter 395 ---  Loss: 2.9146830663084984    Accuracy: 87.34375\n",
      "iter 396 ---  Loss: 3.5118482932448387    Accuracy: 87.65625\n",
      "iter 397 ---  Loss: 3.2808966785669327    Accuracy: 87.34375\n",
      "iter 398 ---  Loss: 3.3378180414438248    Accuracy: 87.5\n",
      "iter 399 ---  Loss: 3.0204428508877754    Accuracy: 85.15625\n",
      "iter 400 ---  Loss: 2.961336128413677    Accuracy: 86.875\n",
      "iter 401 ---  Loss: 3.78989315032959    Accuracy: 86.09375\n",
      "iter 402 ---  Loss: 2.9438823089003563    Accuracy: 86.40625\n",
      "iter 403 ---  Loss: 2.9506599828600883    Accuracy: 86.71875\n",
      "iter 404 ---  Loss: 2.8836270794272423    Accuracy: 87.8125\n",
      "iter 405 ---  Loss: 2.8973670676350594    Accuracy: 87.5\n",
      "iter 406 ---  Loss: 2.6844256073236465    Accuracy: 88.59375\n",
      "iter 407 ---  Loss: 3.2855413034558296    Accuracy: 87.03125\n",
      "iter 408 ---  Loss: 2.9595103561878204    Accuracy: 87.96875\n",
      "iter 409 ---  Loss: 2.8841357454657555    Accuracy: 87.5\n",
      "iter 410 ---  Loss: 2.8200181871652603    Accuracy: 86.40625\n",
      "iter 411 ---  Loss: 3.0918692648410797    Accuracy: 87.1875\n",
      "iter 412 ---  Loss: 3.3106267005205154    Accuracy: 87.03125\n",
      "iter 413 ---  Loss: 2.785967469215393    Accuracy: 87.34375\n",
      "iter 414 ---  Loss: 3.081568643450737    Accuracy: 86.25\n",
      "iter 415 ---  Loss: 3.85994091629982    Accuracy: 83.75\n",
      "iter 416 ---  Loss: 3.198805831372738    Accuracy: 87.96875\n",
      "iter 417 ---  Loss: 2.678426079452038    Accuracy: 86.875\n",
      "iter 418 ---  Loss: 3.557437591254711    Accuracy: 86.875\n",
      "iter 419 ---  Loss: 2.746927924454212    Accuracy: 87.96875\n",
      "iter 420 ---  Loss: 3.2136919051408768    Accuracy: 87.1875\n",
      "iter 421 ---  Loss: 3.051021173596382    Accuracy: 85.3125\n",
      "iter 422 ---  Loss: 2.750741995871067    Accuracy: 86.40625\n",
      "iter 423 ---  Loss: 2.8902049213647842    Accuracy: 87.03125\n",
      "iter 424 ---  Loss: 3.0635864660143852    Accuracy: 87.1875\n",
      "iter 425 ---  Loss: 3.3695263490080833    Accuracy: 87.5\n",
      "iter 426 ---  Loss: 2.8880493342876434    Accuracy: 86.40625\n",
      "iter 427 ---  Loss: 3.5444116964936256    Accuracy: 85.625\n",
      "iter 428 ---  Loss: 3.138865403831005    Accuracy: 86.40625\n",
      "iter 429 ---  Loss: 3.965053766965866    Accuracy: 87.65625\n",
      "iter 430 ---  Loss: 3.8500551134347916    Accuracy: 86.5625\n",
      "iter 431 ---  Loss: 3.4745185151696205    Accuracy: 86.40625\n",
      "iter 432 ---  Loss: 2.7904849275946617    Accuracy: 86.71875\n",
      "iter 433 ---  Loss: 3.1911919191479683    Accuracy: 86.5625\n",
      "iter 434 ---  Loss: 2.5034753158688545    Accuracy: 88.125\n",
      "iter 435 ---  Loss: 2.6937813758850098    Accuracy: 88.59375\n",
      "iter 436 ---  Loss: 2.498613953590393    Accuracy: 88.28125\n",
      "iter 437 ---  Loss: 3.0876502618193626    Accuracy: 85.15625\n",
      "iter 438 ---  Loss: 2.9087398052215576    Accuracy: 87.5\n",
      "iter 439 ---  Loss: 2.903960667550564    Accuracy: 85.46875\n",
      "iter 440 ---  Loss: 3.0169108137488365    Accuracy: 87.5\n",
      "iter 441 ---  Loss: 2.8690552040934563    Accuracy: 88.125\n",
      "iter 442 ---  Loss: 2.831974782049656    Accuracy: 86.71875\n",
      "iter 443 ---  Loss: 3.142669230699539    Accuracy: 86.5625\n",
      "iter 444 ---  Loss: 3.334518514573574    Accuracy: 86.71875\n",
      "iter 445 ---  Loss: 3.4932513758540154    Accuracy: 83.75\n",
      "iter 446 ---  Loss: 3.551728278398514    Accuracy: 86.25\n",
      "iter 447 ---  Loss: 3.1727317571640015    Accuracy: 86.875\n",
      "iter 448 ---  Loss: 3.259044535458088    Accuracy: 85.46875\n",
      "iter 449 ---  Loss: 3.483160823583603    Accuracy: 87.1875\n",
      "iter 450 ---  Loss: 3.501081421971321    Accuracy: 87.1875\n",
      "iter 451 ---  Loss: 2.72245229780674    Accuracy: 89.53125\n",
      "iter 452 ---  Loss: 3.065472550690174    Accuracy: 86.25\n",
      "iter 453 ---  Loss: 3.356188043951988    Accuracy: 86.09375\n",
      "iter 454 ---  Loss: 2.8689829781651497    Accuracy: 87.65625\n",
      "iter 455 ---  Loss: 2.7865982055664062    Accuracy: 87.8125\n",
      "iter 456 ---  Loss: 3.0864904522895813    Accuracy: 86.40625\n",
      "iter 457 ---  Loss: 2.973729021847248    Accuracy: 87.5\n",
      "iter 458 ---  Loss: 2.866217479109764    Accuracy: 84.84375\n",
      "iter 459 ---  Loss: 2.860885977745056    Accuracy: 88.4375\n",
      "iter 460 ---  Loss: 3.321357384324074    Accuracy: 86.09375\n",
      "iter 461 ---  Loss: 3.091335356235504    Accuracy: 85.9375\n",
      "iter 462 ---  Loss: 3.305517539381981    Accuracy: 84.84375\n",
      "iter 463 ---  Loss: 2.497545048594475    Accuracy: 88.4375\n",
      "iter 464 ---  Loss: 3.339196152985096    Accuracy: 87.8125\n",
      "iter 465 ---  Loss: 2.6662476137280464    Accuracy: 87.5\n",
      "iter 466 ---  Loss: 2.6197862029075623    Accuracy: 88.59375\n",
      "iter 467 ---  Loss: 3.093028500676155    Accuracy: 85.46875\n",
      "iter 468 ---  Loss: 3.1120072454214096    Accuracy: 86.875\n",
      "iter 469 ---  Loss: 3.112728789448738    Accuracy: 87.1875\n",
      "iter 470 ---  Loss: 3.24784068018198    Accuracy: 87.96875\n",
      "iter 471 ---  Loss: 3.3889069706201553    Accuracy: 84.84375\n",
      "iter 472 ---  Loss: 2.519069291651249    Accuracy: 87.5\n",
      "iter 473 ---  Loss: 2.954250395298004    Accuracy: 88.125\n",
      "iter 474 ---  Loss: 3.4112409949302673    Accuracy: 87.65625\n",
      "iter 475 ---  Loss: 3.110124461352825    Accuracy: 87.1875\n",
      "iter 476 ---  Loss: 2.7796942070126534    Accuracy: 86.71875\n",
      "iter 477 ---  Loss: 3.0888221114873886    Accuracy: 86.40625\n",
      "iter 478 ---  Loss: 2.8496641740202904    Accuracy: 87.1875\n",
      "iter 479 ---  Loss: 3.4814333245158195    Accuracy: 84.0625\n",
      "iter 480 ---  Loss: 3.460757978260517    Accuracy: 86.5625\n",
      "iter 481 ---  Loss: 2.970195099711418    Accuracy: 86.25\n",
      "iter 482 ---  Loss: 3.3997478783130646    Accuracy: 87.5\n",
      "iter 483 ---  Loss: 2.728365980088711    Accuracy: 88.75\n",
      "iter 484 ---  Loss: 2.776519149541855    Accuracy: 86.5625\n",
      "iter 485 ---  Loss: 3.188912972807884    Accuracy: 87.8125\n",
      "iter 486 ---  Loss: 3.620186135172844    Accuracy: 85.78125\n",
      "iter 487 ---  Loss: 2.7731343507766724    Accuracy: 88.28125\n",
      "iter 488 ---  Loss: 2.8356223851442337    Accuracy: 87.8125\n",
      "iter 489 ---  Loss: 3.0339003652334213    Accuracy: 86.40625\n",
      "iter 490 ---  Loss: 2.956105276942253    Accuracy: 87.1875\n",
      "iter 491 ---  Loss: 2.5779944136738777    Accuracy: 88.4375\n",
      "iter 492 ---  Loss: 3.089998207986355    Accuracy: 87.03125\n",
      "iter 493 ---  Loss: 2.7925442829728127    Accuracy: 87.8125\n",
      "iter 494 ---  Loss: 3.0150880366563797    Accuracy: 86.71875\n",
      "iter 495 ---  Loss: 4.043978974223137    Accuracy: 85.625\n",
      "iter 496 ---  Loss: 2.9673177152872086    Accuracy: 87.5\n",
      "iter 497 ---  Loss: 2.4910097867250443    Accuracy: 88.59375\n",
      "iter 498 ---  Loss: 2.8923177421092987    Accuracy: 89.375\n",
      "iter 499 ---  Loss: 3.084286220371723    Accuracy: 86.25\n",
      "iter 500 ---  Loss: 2.711357392370701    Accuracy: 86.40625\n",
      "iter 501 ---  Loss: 3.40964138507843    Accuracy: 87.34375\n",
      "iter 502 ---  Loss: 3.2595141902565956    Accuracy: 86.25\n",
      "iter 503 ---  Loss: 3.120357923209667    Accuracy: 87.65625\n",
      "iter 504 ---  Loss: 3.3493959680199623    Accuracy: 85.9375\n",
      "iter 505 ---  Loss: 3.293019615113735    Accuracy: 87.34375\n",
      "iter 506 ---  Loss: 2.6046533808112144    Accuracy: 88.75\n",
      "iter 507 ---  Loss: 2.887239657342434    Accuracy: 87.96875\n",
      "iter 508 ---  Loss: 2.8427523896098137    Accuracy: 88.90625\n",
      "iter 509 ---  Loss: 2.8007283955812454    Accuracy: 88.125\n",
      "iter 510 ---  Loss: 3.676530137658119    Accuracy: 85.46875\n",
      "iter 511 ---  Loss: 3.337123140692711    Accuracy: 87.8125\n",
      "iter 512 ---  Loss: 2.9440237060189247    Accuracy: 86.875\n",
      "iter 513 ---  Loss: 3.139903649687767    Accuracy: 87.65625\n",
      "iter 514 ---  Loss: 3.006776675581932    Accuracy: 89.0625\n",
      "iter 515 ---  Loss: 3.374236576259136    Accuracy: 87.34375\n",
      "iter 516 ---  Loss: 3.0832242742180824    Accuracy: 87.5\n",
      "iter 517 ---  Loss: 2.9941980838775635    Accuracy: 88.28125\n",
      "iter 518 ---  Loss: 2.706747643649578    Accuracy: 87.1875\n",
      "iter 519 ---  Loss: 3.2680819928646088    Accuracy: 86.25\n",
      "iter 520 ---  Loss: 2.8812781646847725    Accuracy: 87.65625\n",
      "iter 521 ---  Loss: 2.8447635248303413    Accuracy: 88.125\n",
      "iter 522 ---  Loss: 2.9171075597405434    Accuracy: 88.28125\n",
      "iter 523 ---  Loss: 3.0509365499019623    Accuracy: 87.03125\n",
      "iter 524 ---  Loss: 2.6888883113861084    Accuracy: 88.28125\n",
      "iter 525 ---  Loss: 3.1085692569613457    Accuracy: 84.375\n",
      "iter 526 ---  Loss: 2.7910756319761276    Accuracy: 88.75\n",
      "iter 527 ---  Loss: 3.2463148534297943    Accuracy: 87.96875\n",
      "iter 528 ---  Loss: 3.1568156480789185    Accuracy: 88.28125\n",
      "iter 529 ---  Loss: 2.801670454442501    Accuracy: 88.75\n",
      "iter 530 ---  Loss: 3.220964267849922    Accuracy: 87.65625\n",
      "iter 531 ---  Loss: 2.9839727953076363    Accuracy: 87.8125\n",
      "iter 532 ---  Loss: 2.9000037387013435    Accuracy: 87.65625\n",
      "iter 533 ---  Loss: 2.531524695456028    Accuracy: 87.8125\n",
      "iter 534 ---  Loss: 3.1126521453261375    Accuracy: 87.34375\n",
      "iter 535 ---  Loss: 3.4732581675052643    Accuracy: 87.8125\n",
      "iter 536 ---  Loss: 2.6883683279156685    Accuracy: 88.125\n",
      "iter 537 ---  Loss: 3.353350304067135    Accuracy: 87.1875\n",
      "iter 538 ---  Loss: 2.9880253598093987    Accuracy: 87.8125\n",
      "iter 539 ---  Loss: 3.09513808041811    Accuracy: 87.1875\n",
      "iter 540 ---  Loss: 2.7807926312088966    Accuracy: 86.09375\n",
      "iter 541 ---  Loss: 2.939574860036373    Accuracy: 87.5\n",
      "iter 542 ---  Loss: 2.940155379474163    Accuracy: 87.03125\n",
      "iter 543 ---  Loss: 2.6651098802685738    Accuracy: 87.65625\n",
      "iter 544 ---  Loss: 2.8927010372281075    Accuracy: 88.125\n",
      "iter 545 ---  Loss: 3.47131534665823    Accuracy: 85.78125\n",
      "iter 546 ---  Loss: 4.072438299655914    Accuracy: 85.78125\n",
      "iter 547 ---  Loss: 2.9091343209147453    Accuracy: 87.1875\n",
      "iter 548 ---  Loss: 3.134265772998333    Accuracy: 86.09375\n",
      "iter 549 ---  Loss: 2.8597672805190086    Accuracy: 86.71875\n",
      "iter 550 ---  Loss: 2.481279693543911    Accuracy: 87.65625\n",
      "iter 551 ---  Loss: 3.0227804854512215    Accuracy: 86.875\n",
      "iter 552 ---  Loss: 2.6767671033740044    Accuracy: 86.40625\n",
      "iter 553 ---  Loss: 3.0158939212560654    Accuracy: 86.71875\n",
      "iter 554 ---  Loss: 2.4623642563819885    Accuracy: 88.28125\n",
      "iter 555 ---  Loss: 3.3617162704467773    Accuracy: 86.71875\n",
      "iter 556 ---  Loss: 2.8508185148239136    Accuracy: 87.34375\n",
      "iter 557 ---  Loss: 3.3073173835873604    Accuracy: 86.5625\n",
      "iter 558 ---  Loss: 2.876965656876564    Accuracy: 87.65625\n",
      "iter 559 ---  Loss: 2.908790946006775    Accuracy: 88.125\n",
      "iter 560 ---  Loss: 3.1423974707722664    Accuracy: 86.40625\n",
      "iter 561 ---  Loss: 2.785358779132366    Accuracy: 87.8125\n",
      "iter 562 ---  Loss: 2.8203319758176804    Accuracy: 87.8125\n",
      "iter 563 ---  Loss: 2.7472679540514946    Accuracy: 87.5\n",
      "iter 564 ---  Loss: 2.7681180983781815    Accuracy: 89.0625\n",
      "iter 565 ---  Loss: 2.7057525739073753    Accuracy: 87.8125\n",
      "iter 566 ---  Loss: 3.1881390288472176    Accuracy: 88.125\n",
      "iter 567 ---  Loss: 2.8502323031425476    Accuracy: 87.34375\n",
      "iter 568 ---  Loss: 3.4342762157320976    Accuracy: 86.25\n",
      "iter 569 ---  Loss: 3.240702949464321    Accuracy: 87.65625\n",
      "iter 570 ---  Loss: 2.6556985825300217    Accuracy: 87.5\n",
      "iter 571 ---  Loss: 3.4076367914676666    Accuracy: 87.1875\n",
      "iter 572 ---  Loss: 2.857213132083416    Accuracy: 88.4375\n",
      "iter 573 ---  Loss: 2.8283653780817986    Accuracy: 87.1875\n",
      "iter 574 ---  Loss: 3.4566207826137543    Accuracy: 85.78125\n",
      "iter 575 ---  Loss: 3.0223889276385307    Accuracy: 88.59375\n",
      "iter 576 ---  Loss: 3.070980355143547    Accuracy: 86.5625\n",
      "iter 577 ---  Loss: 2.9577794671058655    Accuracy: 87.34375\n",
      "iter 578 ---  Loss: 3.5511594340205193    Accuracy: 86.71875\n",
      "iter 579 ---  Loss: 3.0936309248209    Accuracy: 86.5625\n",
      "iter 580 ---  Loss: 2.6831091940402985    Accuracy: 89.53125\n",
      "iter 581 ---  Loss: 2.7909035608172417    Accuracy: 88.125\n",
      "iter 582 ---  Loss: 3.099254220724106    Accuracy: 86.40625\n",
      "iter 583 ---  Loss: 3.046985886991024    Accuracy: 86.40625\n",
      "iter 584 ---  Loss: 3.138806529343128    Accuracy: 86.875\n",
      "iter 585 ---  Loss: 3.1718561723828316    Accuracy: 88.90625\n",
      "iter 586 ---  Loss: 3.2723133116960526    Accuracy: 87.1875\n",
      "iter 587 ---  Loss: 2.905336707830429    Accuracy: 86.40625\n",
      "iter 588 ---  Loss: 2.9681162238121033    Accuracy: 88.125\n",
      "iter 589 ---  Loss: 3.0452136993408203    Accuracy: 85.46875\n",
      "iter 590 ---  Loss: 2.8660956993699074    Accuracy: 89.53125\n",
      "iter 591 ---  Loss: 2.5822370126843452    Accuracy: 89.84375\n",
      "iter 592 ---  Loss: 3.5154756158590317    Accuracy: 85.625\n",
      "iter 593 ---  Loss: 3.3038314133882523    Accuracy: 86.25\n",
      "iter 594 ---  Loss: 3.308110848069191    Accuracy: 85.0\n",
      "iter 595 ---  Loss: 3.129285864531994    Accuracy: 86.71875\n",
      "iter 596 ---  Loss: 3.0932460874319077    Accuracy: 87.03125\n",
      "iter 597 ---  Loss: 3.1401008889079094    Accuracy: 86.5625\n",
      "iter 598 ---  Loss: 3.09571772813797    Accuracy: 87.8125\n",
      "iter 599 ---  Loss: 2.745633617043495    Accuracy: 86.25\n",
      "iter 600 ---  Loss: 3.316951259970665    Accuracy: 87.1875\n",
      "iter 601 ---  Loss: 2.797789916396141    Accuracy: 87.5\n",
      "iter 602 ---  Loss: 3.2966133505105972    Accuracy: 87.8125\n",
      "iter 603 ---  Loss: 3.381216362118721    Accuracy: 87.65625\n",
      "iter 604 ---  Loss: 2.695043705403805    Accuracy: 87.96875\n",
      "iter 605 ---  Loss: 2.7318570613861084    Accuracy: 87.03125\n",
      "iter 606 ---  Loss: 3.5204344540834427    Accuracy: 87.65625\n",
      "iter 607 ---  Loss: 3.015860043466091    Accuracy: 87.03125\n",
      "iter 608 ---  Loss: 2.8483649492263794    Accuracy: 88.125\n",
      "iter 609 ---  Loss: 2.7106164321303368    Accuracy: 89.21875\n",
      "iter 610 ---  Loss: 2.567091129720211    Accuracy: 88.59375\n",
      "iter 611 ---  Loss: 2.9956065490841866    Accuracy: 88.125\n",
      "iter 612 ---  Loss: 2.373531334102154    Accuracy: 88.28125\n",
      "iter 613 ---  Loss: 3.0843020603060722    Accuracy: 88.125\n",
      "iter 614 ---  Loss: 2.7702038288116455    Accuracy: 87.1875\n",
      "iter 615 ---  Loss: 3.5236286520957947    Accuracy: 85.9375\n",
      "iter 616 ---  Loss: 2.9443503096699715    Accuracy: 85.625\n",
      "iter 617 ---  Loss: 3.6023113057017326    Accuracy: 84.6875\n",
      "iter 618 ---  Loss: 3.261842302978039    Accuracy: 87.5\n",
      "iter 619 ---  Loss: 3.0145222023129463    Accuracy: 87.65625\n",
      "iter 620 ---  Loss: 2.75728876888752    Accuracy: 88.75\n",
      "iter 621 ---  Loss: 3.871180385351181    Accuracy: 86.25\n",
      "iter 622 ---  Loss: 2.741243064403534    Accuracy: 87.1875\n",
      "iter 623 ---  Loss: 2.707066088914871    Accuracy: 87.8125\n",
      "iter 624 ---  Loss: 2.8138777166604996    Accuracy: 88.28125\n",
      "iter 625 ---  Loss: 3.1813594922423363    Accuracy: 87.1875\n",
      "iter 626 ---  Loss: 2.379759691655636    Accuracy: 88.125\n",
      "iter 627 ---  Loss: 2.8992253467440605    Accuracy: 87.96875\n",
      "iter 628 ---  Loss: 3.305582381784916    Accuracy: 87.34375\n",
      "iter 629 ---  Loss: 3.378647655248642    Accuracy: 86.09375\n",
      "iter 630 ---  Loss: 3.4222351983189583    Accuracy: 87.03125\n",
      "iter 631 ---  Loss: 2.7669680938124657    Accuracy: 88.75\n",
      "iter 632 ---  Loss: 3.308403618633747    Accuracy: 86.25\n",
      "iter 633 ---  Loss: 2.786628931760788    Accuracy: 87.5\n",
      "iter 634 ---  Loss: 3.0686239153146744    Accuracy: 87.1875\n",
      "iter 635 ---  Loss: 3.102728173136711    Accuracy: 87.8125\n",
      "iter 636 ---  Loss: 3.1447758898139    Accuracy: 86.09375\n",
      "iter 637 ---  Loss: 3.381400629878044    Accuracy: 85.78125\n",
      "iter 638 ---  Loss: 3.103206105530262    Accuracy: 86.5625\n",
      "iter 639 ---  Loss: 3.3084867149591446    Accuracy: 87.65625\n",
      "iter 640 ---  Loss: 2.8918310031294823    Accuracy: 87.1875\n",
      "iter 641 ---  Loss: 3.0216929018497467    Accuracy: 87.5\n",
      "iter 642 ---  Loss: 2.791675180196762    Accuracy: 88.4375\n",
      "iter 643 ---  Loss: 3.750785507261753    Accuracy: 85.46875\n",
      "iter 644 ---  Loss: 3.4829361960291862    Accuracy: 86.5625\n",
      "iter 645 ---  Loss: 3.4659385457634926    Accuracy: 85.9375\n",
      "iter 646 ---  Loss: 3.232299044728279    Accuracy: 87.65625\n",
      "iter 647 ---  Loss: 2.65297120064497    Accuracy: 87.96875\n",
      "iter 648 ---  Loss: 3.3572165071964264    Accuracy: 85.46875\n",
      "iter 649 ---  Loss: 2.89851938188076    Accuracy: 87.1875\n",
      "iter 650 ---  Loss: 3.156500428915024    Accuracy: 87.03125\n",
      "iter 651 ---  Loss: 3.1577697470784187    Accuracy: 86.25\n",
      "iter 652 ---  Loss: 3.737638898193836    Accuracy: 85.0\n",
      "iter 653 ---  Loss: 2.997585617005825    Accuracy: 88.28125\n",
      "iter 654 ---  Loss: 3.0250584930181503    Accuracy: 87.8125\n",
      "iter 655 ---  Loss: 2.851665161550045    Accuracy: 89.84375\n",
      "iter 656 ---  Loss: 2.5427858754992485    Accuracy: 88.125\n",
      "iter 657 ---  Loss: 2.6534808054566383    Accuracy: 87.8125\n",
      "iter 658 ---  Loss: 3.283873274922371    Accuracy: 87.03125\n",
      "iter 659 ---  Loss: 3.0408852323889732    Accuracy: 87.65625\n",
      "iter 660 ---  Loss: 2.8092084154486656    Accuracy: 89.375\n",
      "iter 661 ---  Loss: 3.1791475862264633    Accuracy: 87.8125\n",
      "iter 662 ---  Loss: 2.996392384171486    Accuracy: 87.1875\n",
      "iter 663 ---  Loss: 3.309890568256378    Accuracy: 86.71875\n",
      "iter 664 ---  Loss: 2.7449024319648743    Accuracy: 88.28125\n",
      "iter 665 ---  Loss: 2.7543479651212692    Accuracy: 87.03125\n",
      "iter 666 ---  Loss: 3.1117533445358276    Accuracy: 86.5625\n",
      "iter 667 ---  Loss: 2.9121659845113754    Accuracy: 88.28125\n",
      "iter 668 ---  Loss: 2.807547114789486    Accuracy: 87.5\n",
      "iter 669 ---  Loss: 3.5238268077373505    Accuracy: 86.5625\n",
      "iter 670 ---  Loss: 2.9453009516000748    Accuracy: 88.75\n",
      "iter 671 ---  Loss: 3.336878575384617    Accuracy: 87.65625\n",
      "iter 672 ---  Loss: 3.114995114505291    Accuracy: 87.03125\n",
      "iter 673 ---  Loss: 2.8042261824011803    Accuracy: 86.40625\n",
      "iter 674 ---  Loss: 3.0375883132219315    Accuracy: 87.65625\n",
      "iter 675 ---  Loss: 2.6868246272206306    Accuracy: 87.65625\n",
      "iter 676 ---  Loss: 2.877055339515209    Accuracy: 86.5625\n",
      "iter 677 ---  Loss: 3.2064210772514343    Accuracy: 87.5\n",
      "iter 678 ---  Loss: 2.645771734416485    Accuracy: 87.1875\n",
      "iter 679 ---  Loss: 2.928172640502453    Accuracy: 86.875\n",
      "iter 680 ---  Loss: 3.979519709944725    Accuracy: 84.0625\n",
      "iter 681 ---  Loss: 3.324980966746807    Accuracy: 88.75\n",
      "iter 682 ---  Loss: 2.831615276634693    Accuracy: 89.53125\n",
      "iter 683 ---  Loss: 3.2669467478990555    Accuracy: 88.125\n",
      "iter 684 ---  Loss: 3.1387389600276947    Accuracy: 88.28125\n",
      "iter 685 ---  Loss: 3.3005225509405136    Accuracy: 87.1875\n",
      "iter 686 ---  Loss: 3.0869095996022224    Accuracy: 87.5\n",
      "iter 687 ---  Loss: 3.109830252826214    Accuracy: 86.25\n",
      "iter 688 ---  Loss: 3.5115600526332855    Accuracy: 87.1875\n",
      "iter 689 ---  Loss: 2.910874180495739    Accuracy: 90.0\n",
      "iter 690 ---  Loss: 2.8546745479106903    Accuracy: 87.1875\n",
      "iter 691 ---  Loss: 2.955227516591549    Accuracy: 87.96875\n",
      "iter 692 ---  Loss: 2.9169546961784363    Accuracy: 87.5\n",
      "iter 693 ---  Loss: 3.561521403491497    Accuracy: 86.40625\n",
      "iter 694 ---  Loss: 3.4368385300040245    Accuracy: 87.65625\n",
      "iter 695 ---  Loss: 2.772531233727932    Accuracy: 89.0625\n",
      "iter 696 ---  Loss: 3.266751378774643    Accuracy: 85.9375\n",
      "iter 697 ---  Loss: 3.0272824242711067    Accuracy: 87.65625\n",
      "iter 698 ---  Loss: 2.9426034688949585    Accuracy: 86.25\n",
      "iter 699 ---  Loss: 2.918512061238289    Accuracy: 87.96875\n",
      "iter 700 ---  Loss: 2.781414695084095    Accuracy: 87.34375\n",
      "iter 701 ---  Loss: 3.8665218576788902    Accuracy: 84.53125\n",
      "iter 702 ---  Loss: 3.197965182363987    Accuracy: 86.25\n",
      "iter 703 ---  Loss: 2.7573544681072235    Accuracy: 85.9375\n",
      "iter 704 ---  Loss: 2.7255804464221    Accuracy: 87.5\n",
      "iter 705 ---  Loss: 3.1274207532405853    Accuracy: 87.1875\n",
      "iter 706 ---  Loss: 3.216734506189823    Accuracy: 87.1875\n",
      "iter 707 ---  Loss: 3.063291974365711    Accuracy: 86.5625\n",
      "iter 708 ---  Loss: 2.849249117076397    Accuracy: 87.65625\n",
      "iter 709 ---  Loss: 3.294423386454582    Accuracy: 87.96875\n",
      "iter 710 ---  Loss: 2.9075446650385857    Accuracy: 87.8125\n",
      "iter 711 ---  Loss: 2.91993061453104    Accuracy: 86.71875\n",
      "iter 712 ---  Loss: 2.937317878007889    Accuracy: 89.6875\n",
      "iter 713 ---  Loss: 2.5534659549593925    Accuracy: 88.90625\n",
      "iter 714 ---  Loss: 3.378247380256653    Accuracy: 86.875\n",
      "iter 715 ---  Loss: 2.7408240139484406    Accuracy: 87.1875\n",
      "iter 716 ---  Loss: 3.297234423458576    Accuracy: 89.375\n",
      "iter 717 ---  Loss: 3.614029660820961    Accuracy: 85.3125\n",
      "iter 718 ---  Loss: 3.4715666472911835    Accuracy: 89.0625\n",
      "iter 719 ---  Loss: 2.6198122277855873    Accuracy: 88.90625\n",
      "iter 720 ---  Loss: 3.0011178851127625    Accuracy: 85.9375\n",
      "iter 721 ---  Loss: 3.4892411902546883    Accuracy: 87.03125\n",
      "iter 722 ---  Loss: 3.053611509501934    Accuracy: 85.15625\n",
      "iter 723 ---  Loss: 2.855290673673153    Accuracy: 87.5\n",
      "iter 724 ---  Loss: 2.875975050032139    Accuracy: 86.25\n",
      "iter 725 ---  Loss: 3.494304783642292    Accuracy: 85.9375\n",
      "iter 726 ---  Loss: 3.8168113380670547    Accuracy: 84.84375\n",
      "iter 727 ---  Loss: 3.6380678340792656    Accuracy: 85.625\n",
      "iter 728 ---  Loss: 2.4302833154797554    Accuracy: 87.65625\n",
      "iter 729 ---  Loss: 3.760938473045826    Accuracy: 85.46875\n",
      "iter 730 ---  Loss: 2.8905774131417274    Accuracy: 86.5625\n",
      "iter 731 ---  Loss: 2.802156411111355    Accuracy: 87.65625\n",
      "iter 732 ---  Loss: 3.0902355387806892    Accuracy: 87.03125\n",
      "iter 733 ---  Loss: 2.453943759202957    Accuracy: 88.125\n",
      "iter 734 ---  Loss: 3.9003666937351227    Accuracy: 85.625\n",
      "iter 735 ---  Loss: 3.2443531155586243    Accuracy: 86.09375\n",
      "iter 736 ---  Loss: 2.981961876153946    Accuracy: 87.8125\n",
      "iter 737 ---  Loss: 2.6740583702921867    Accuracy: 88.59375\n",
      "iter 738 ---  Loss: 3.2869131937623024    Accuracy: 85.78125\n",
      "iter 739 ---  Loss: 3.0293008983135223    Accuracy: 85.3125\n",
      "iter 740 ---  Loss: 2.891132175922394    Accuracy: 88.4375\n",
      "iter 741 ---  Loss: 3.0782253816723824    Accuracy: 86.875\n",
      "iter 742 ---  Loss: 3.530794106423855    Accuracy: 86.25\n",
      "iter 743 ---  Loss: 3.905000887811184    Accuracy: 85.625\n",
      "iter 744 ---  Loss: 3.005419857800007    Accuracy: 86.40625\n",
      "iter 745 ---  Loss: 3.0385616794228554    Accuracy: 87.5\n",
      "iter 746 ---  Loss: 3.0623220950365067    Accuracy: 87.03125\n",
      "iter 747 ---  Loss: 2.604154996573925    Accuracy: 89.0625\n",
      "iter 748 ---  Loss: 3.321258306503296    Accuracy: 87.5\n",
      "iter 749 ---  Loss: 3.5691042244434357    Accuracy: 84.53125\n",
      "iter 750 ---  Loss: 3.098676383495331    Accuracy: 87.1875\n",
      "iter 751 ---  Loss: 3.073603890836239    Accuracy: 86.71875\n",
      "iter 752 ---  Loss: 2.9220017343759537    Accuracy: 88.75\n",
      "iter 753 ---  Loss: 3.7017243579030037    Accuracy: 85.46875\n",
      "iter 754 ---  Loss: 2.8582800328731537    Accuracy: 87.1875\n",
      "iter 755 ---  Loss: 3.2454619705677032    Accuracy: 86.71875\n",
      "iter 756 ---  Loss: 2.835281625390053    Accuracy: 88.59375\n",
      "iter 757 ---  Loss: 2.744843654334545    Accuracy: 87.65625\n",
      "iter 758 ---  Loss: 2.6109958812594414    Accuracy: 87.8125\n",
      "iter 759 ---  Loss: 3.2551875934004784    Accuracy: 87.65625\n",
      "iter 760 ---  Loss: 2.852484367787838    Accuracy: 87.03125\n",
      "iter 761 ---  Loss: 3.0486070215702057    Accuracy: 87.1875\n",
      "iter 762 ---  Loss: 3.0322337672114372    Accuracy: 88.59375\n",
      "iter 763 ---  Loss: 3.3997455462813377    Accuracy: 86.5625\n",
      "iter 764 ---  Loss: 3.530560903251171    Accuracy: 87.8125\n",
      "iter 765 ---  Loss: 3.1883108392357826    Accuracy: 88.59375\n",
      "iter 766 ---  Loss: 3.2110829055309296    Accuracy: 85.78125\n",
      "iter 767 ---  Loss: 3.016521602869034    Accuracy: 86.40625\n",
      "iter 768 ---  Loss: 2.945913888514042    Accuracy: 89.6875\n",
      "iter 769 ---  Loss: 2.7280232459306717    Accuracy: 85.9375\n",
      "iter 770 ---  Loss: 2.836634151637554    Accuracy: 87.5\n",
      "iter 771 ---  Loss: 2.5927321016788483    Accuracy: 89.0625\n",
      "iter 772 ---  Loss: 3.063066489994526    Accuracy: 85.0\n",
      "iter 773 ---  Loss: 3.1946710273623466    Accuracy: 88.4375\n",
      "iter 774 ---  Loss: 2.983187660574913    Accuracy: 87.65625\n",
      "iter 775 ---  Loss: 3.2192355766892433    Accuracy: 87.03125\n",
      "iter 776 ---  Loss: 3.1499501317739487    Accuracy: 87.1875\n",
      "iter 777 ---  Loss: 3.4552792459726334    Accuracy: 86.09375\n",
      "iter 778 ---  Loss: 2.5653159990906715    Accuracy: 88.90625\n",
      "iter 779 ---  Loss: 2.7426678463816643    Accuracy: 86.875\n",
      "iter 780 ---  Loss: 3.6715381667017937    Accuracy: 85.9375\n",
      "iter 781 ---  Loss: 2.9531580209732056    Accuracy: 86.25\n",
      "iter 782 ---  Loss: 3.6354424953460693    Accuracy: 86.5625\n",
      "iter 783 ---  Loss: 2.907663494348526    Accuracy: 86.25\n",
      "iter 784 ---  Loss: 3.4586206451058388    Accuracy: 87.1875\n",
      "iter 785 ---  Loss: 2.5746551752090454    Accuracy: 87.34375\n",
      "iter 786 ---  Loss: 3.171941429376602    Accuracy: 87.34375\n",
      "iter 787 ---  Loss: 3.1796990633010864    Accuracy: 87.03125\n",
      "iter 788 ---  Loss: 2.7426630780100822    Accuracy: 87.03125\n",
      "iter 789 ---  Loss: 3.2345675453543663    Accuracy: 85.625\n",
      "iter 790 ---  Loss: 3.0945141911506653    Accuracy: 87.65625\n",
      "iter 791 ---  Loss: 2.824717067182064    Accuracy: 86.40625\n",
      "iter 792 ---  Loss: 2.747314192354679    Accuracy: 87.65625\n",
      "iter 793 ---  Loss: 3.2043632864952087    Accuracy: 85.9375\n",
      "iter 794 ---  Loss: 2.8411486595869064    Accuracy: 85.9375\n",
      "iter 795 ---  Loss: 3.197344072163105    Accuracy: 87.96875\n",
      "iter 796 ---  Loss: 2.7772281244397163    Accuracy: 88.90625\n",
      "iter 797 ---  Loss: 3.2272372990846634    Accuracy: 89.375\n",
      "iter 798 ---  Loss: 2.9441767185926437    Accuracy: 86.40625\n",
      "iter 799 ---  Loss: 3.077583387494087    Accuracy: 87.8125\n",
      "iter 800 ---  Loss: 3.2279664054512978    Accuracy: 86.71875\n",
      "iter 801 ---  Loss: 2.7810236737132072    Accuracy: 90.15625\n",
      "iter 802 ---  Loss: 2.910766303539276    Accuracy: 86.25\n",
      "iter 803 ---  Loss: 2.56914996355772    Accuracy: 89.6875\n",
      "iter 804 ---  Loss: 3.292137250304222    Accuracy: 87.96875\n",
      "iter 805 ---  Loss: 3.041185677051544    Accuracy: 86.25\n",
      "iter 806 ---  Loss: 2.6648859828710556    Accuracy: 87.03125\n",
      "iter 807 ---  Loss: 3.0030191019177437    Accuracy: 87.65625\n",
      "iter 808 ---  Loss: 3.236216716468334    Accuracy: 85.9375\n",
      "iter 809 ---  Loss: 3.583115242421627    Accuracy: 86.25\n",
      "iter 810 ---  Loss: 3.54360331594944    Accuracy: 85.3125\n",
      "iter 811 ---  Loss: 3.0580523014068604    Accuracy: 88.28125\n",
      "iter 812 ---  Loss: 3.3876133039593697    Accuracy: 85.78125\n",
      "iter 813 ---  Loss: 2.7179237604141235    Accuracy: 90.46875\n",
      "iter 814 ---  Loss: 3.1567903012037277    Accuracy: 88.90625\n",
      "iter 815 ---  Loss: 3.4047478064894676    Accuracy: 87.65625\n",
      "iter 816 ---  Loss: 2.9411693289875984    Accuracy: 88.75\n",
      "iter 817 ---  Loss: 3.487605594098568    Accuracy: 87.65625\n",
      "iter 818 ---  Loss: 3.1824359968304634    Accuracy: 86.71875\n",
      "iter 819 ---  Loss: 3.5989260375499725    Accuracy: 86.40625\n",
      "iter 820 ---  Loss: 3.516166754066944    Accuracy: 87.5\n",
      "iter 821 ---  Loss: 2.8169552981853485    Accuracy: 87.96875\n",
      "iter 822 ---  Loss: 2.9997904747724533    Accuracy: 87.5\n",
      "iter 823 ---  Loss: 2.4893202036619186    Accuracy: 87.65625\n",
      "iter 824 ---  Loss: 2.9206275641918182    Accuracy: 85.9375\n",
      "iter 825 ---  Loss: 3.493637576699257    Accuracy: 88.4375\n",
      "iter 826 ---  Loss: 3.1598233804106712    Accuracy: 85.625\n",
      "iter 827 ---  Loss: 2.656033478677273    Accuracy: 87.96875\n",
      "iter 828 ---  Loss: 2.585411213338375    Accuracy: 87.34375\n",
      "iter 829 ---  Loss: 3.4216310009360313    Accuracy: 86.875\n",
      "iter 830 ---  Loss: 2.5106351897120476    Accuracy: 88.75\n",
      "iter 831 ---  Loss: 3.3418505489826202    Accuracy: 86.09375\n",
      "iter 832 ---  Loss: 3.319030284881592    Accuracy: 86.40625\n",
      "iter 833 ---  Loss: 2.9512816220521927    Accuracy: 88.75\n",
      "iter 834 ---  Loss: 3.552554175257683    Accuracy: 87.1875\n",
      "iter 835 ---  Loss: 3.1267470121383667    Accuracy: 87.34375\n",
      "iter 836 ---  Loss: 3.25932876765728    Accuracy: 87.5\n",
      "iter 837 ---  Loss: 3.1241309717297554    Accuracy: 87.65625\n",
      "iter 838 ---  Loss: 3.052736297249794    Accuracy: 86.09375\n",
      "iter 839 ---  Loss: 3.068910129368305    Accuracy: 86.5625\n",
      "iter 840 ---  Loss: 2.9883176907896996    Accuracy: 89.21875\n",
      "iter 841 ---  Loss: 3.092711426317692    Accuracy: 87.03125\n",
      "iter 842 ---  Loss: 3.1098172068595886    Accuracy: 87.1875\n",
      "iter 843 ---  Loss: 3.4181025624275208    Accuracy: 87.1875\n",
      "iter 844 ---  Loss: 2.868553638458252    Accuracy: 87.65625\n",
      "iter 845 ---  Loss: 3.0858250185847282    Accuracy: 86.40625\n",
      "iter 846 ---  Loss: 2.674747809767723    Accuracy: 88.125\n",
      "iter 847 ---  Loss: 2.570112057030201    Accuracy: 87.34375\n",
      "iter 848 ---  Loss: 3.2482621744275093    Accuracy: 88.75\n",
      "iter 849 ---  Loss: 3.369380958378315    Accuracy: 85.9375\n",
      "iter 850 ---  Loss: 4.133301831781864    Accuracy: 87.5\n",
      "iter 851 ---  Loss: 2.688129723072052    Accuracy: 89.21875\n",
      "iter 852 ---  Loss: 3.093928024172783    Accuracy: 86.71875\n",
      "iter 853 ---  Loss: 2.9456507712602615    Accuracy: 88.75\n",
      "iter 854 ---  Loss: 3.136659637093544    Accuracy: 87.65625\n",
      "iter 855 ---  Loss: 2.833054408431053    Accuracy: 87.8125\n",
      "iter 856 ---  Loss: 3.146511986851692    Accuracy: 87.34375\n",
      "iter 857 ---  Loss: 4.01588512212038    Accuracy: 85.3125\n",
      "iter 858 ---  Loss: 3.477241702377796    Accuracy: 87.5\n",
      "iter 859 ---  Loss: 3.0456929355859756    Accuracy: 86.25\n",
      "iter 860 ---  Loss: 2.3412210568785667    Accuracy: 89.375\n",
      "iter 861 ---  Loss: 3.441951207816601    Accuracy: 87.03125\n",
      "iter 862 ---  Loss: 4.124647356569767    Accuracy: 85.3125\n",
      "iter 863 ---  Loss: 3.1217421889305115    Accuracy: 85.78125\n",
      "iter 864 ---  Loss: 2.9645451605319977    Accuracy: 86.25\n",
      "iter 865 ---  Loss: 2.954183392226696    Accuracy: 88.125\n",
      "iter 866 ---  Loss: 2.633371151983738    Accuracy: 87.65625\n",
      "iter 867 ---  Loss: 3.0383877903223038    Accuracy: 86.25\n",
      "iter 868 ---  Loss: 3.192611999809742    Accuracy: 85.78125\n",
      "iter 869 ---  Loss: 3.256684236228466    Accuracy: 86.5625\n",
      "iter 870 ---  Loss: 2.9448821023106575    Accuracy: 85.9375\n",
      "iter 871 ---  Loss: 4.162938147783279    Accuracy: 85.0\n",
      "iter 872 ---  Loss: 3.3449434712529182    Accuracy: 87.65625\n",
      "iter 873 ---  Loss: 2.9100835770368576    Accuracy: 86.09375\n",
      "iter 874 ---  Loss: 3.898217134177685    Accuracy: 86.875\n",
      "iter 875 ---  Loss: 3.937205731868744    Accuracy: 87.96875\n",
      "iter 876 ---  Loss: 3.3504294380545616    Accuracy: 88.28125\n",
      "iter 877 ---  Loss: 2.9767958000302315    Accuracy: 89.53125\n",
      "iter 878 ---  Loss: 3.024375669658184    Accuracy: 87.96875\n",
      "iter 879 ---  Loss: 2.6741322055459023    Accuracy: 88.28125\n",
      "iter 880 ---  Loss: 2.6015272364020348    Accuracy: 88.59375\n",
      "iter 881 ---  Loss: 3.025195799767971    Accuracy: 87.34375\n",
      "iter 882 ---  Loss: 2.925855152308941    Accuracy: 87.8125\n",
      "iter 883 ---  Loss: 2.768427185714245    Accuracy: 89.6875\n",
      "iter 884 ---  Loss: 3.0797427594661713    Accuracy: 86.5625\n",
      "iter 885 ---  Loss: 3.5318817794322968    Accuracy: 86.71875\n",
      "iter 886 ---  Loss: 2.528708703815937    Accuracy: 88.75\n",
      "iter 887 ---  Loss: 3.2226719930768013    Accuracy: 86.71875\n",
      "iter 888 ---  Loss: 2.670526161789894    Accuracy: 87.1875\n",
      "iter 889 ---  Loss: 3.4879600033164024    Accuracy: 87.8125\n",
      "iter 890 ---  Loss: 3.677734926342964    Accuracy: 88.125\n",
      "iter 891 ---  Loss: 3.270008370280266    Accuracy: 85.3125\n",
      "iter 892 ---  Loss: 3.25237700343132    Accuracy: 87.1875\n",
      "iter 893 ---  Loss: 3.124142646789551    Accuracy: 87.8125\n",
      "iter 894 ---  Loss: 3.3049814850091934    Accuracy: 87.5\n",
      "iter 895 ---  Loss: 2.824550971388817    Accuracy: 89.0625\n",
      "iter 896 ---  Loss: 2.67053734511137    Accuracy: 88.90625\n",
      "iter 897 ---  Loss: 2.7682594060897827    Accuracy: 88.59375\n",
      "iter 898 ---  Loss: 2.6630382016301155    Accuracy: 88.90625\n",
      "iter 899 ---  Loss: 3.6277346909046173    Accuracy: 86.40625\n",
      "iter 900 ---  Loss: 3.2137112244963646    Accuracy: 87.34375\n",
      "iter 901 ---  Loss: 2.633143797516823    Accuracy: 89.0625\n",
      "iter 902 ---  Loss: 3.2068036943674088    Accuracy: 86.71875\n",
      "iter 903 ---  Loss: 3.3746172934770584    Accuracy: 85.78125\n",
      "iter 904 ---  Loss: 3.2666211128234863    Accuracy: 86.71875\n",
      "iter 905 ---  Loss: 3.3010480254888535    Accuracy: 86.40625\n",
      "iter 906 ---  Loss: 2.914353407919407    Accuracy: 87.34375\n",
      "iter 907 ---  Loss: 2.969901666045189    Accuracy: 85.78125\n",
      "iter 908 ---  Loss: 3.5030489340424538    Accuracy: 86.09375\n",
      "iter 909 ---  Loss: 2.9169740974903107    Accuracy: 86.71875\n",
      "iter 910 ---  Loss: 2.9962661415338516    Accuracy: 88.4375\n",
      "iter 911 ---  Loss: 3.516178220510483    Accuracy: 87.5\n",
      "iter 912 ---  Loss: 3.298772193491459    Accuracy: 85.15625\n",
      "iter 913 ---  Loss: 3.242149844765663    Accuracy: 88.4375\n",
      "iter 914 ---  Loss: 3.0929167196154594    Accuracy: 87.96875\n",
      "iter 915 ---  Loss: 3.0784204229712486    Accuracy: 85.625\n",
      "iter 916 ---  Loss: 2.6024032160639763    Accuracy: 89.375\n",
      "iter 917 ---  Loss: 2.9097120612859726    Accuracy: 87.65625\n",
      "iter 918 ---  Loss: 2.788188010454178    Accuracy: 89.21875\n",
      "iter 919 ---  Loss: 3.008779101073742    Accuracy: 86.71875\n",
      "iter 920 ---  Loss: 3.102143779397011    Accuracy: 87.5\n",
      "iter 921 ---  Loss: 2.9236176535487175    Accuracy: 88.125\n",
      "iter 922 ---  Loss: 2.982371725142002    Accuracy: 87.65625\n",
      "iter 923 ---  Loss: 2.709830805659294    Accuracy: 88.4375\n",
      "iter 924 ---  Loss: 2.7202598974108696    Accuracy: 88.75\n",
      "iter 925 ---  Loss: 3.341622270643711    Accuracy: 86.25\n",
      "iter 926 ---  Loss: 2.8622497096657753    Accuracy: 88.75\n",
      "iter 927 ---  Loss: 3.6160146594047546    Accuracy: 87.1875\n",
      "iter 928 ---  Loss: 3.2245104014873505    Accuracy: 87.03125\n",
      "iter 929 ---  Loss: 4.225647523999214    Accuracy: 85.3125\n",
      "iter 930 ---  Loss: 3.450767010450363    Accuracy: 85.0\n",
      "iter 931 ---  Loss: 3.375181309878826    Accuracy: 86.5625\n",
      "iter 932 ---  Loss: 2.8820317164063454    Accuracy: 88.90625\n",
      "iter 933 ---  Loss: 3.0222374573349953    Accuracy: 88.4375\n",
      "iter 934 ---  Loss: 2.9335406199097633    Accuracy: 88.90625\n",
      "iter 935 ---  Loss: 3.1858187317848206    Accuracy: 89.21875\n",
      "iter 936 ---  Loss: 2.9112012535333633    Accuracy: 87.5\n",
      "iter 937 ---  Loss: 2.5436829328536987    Accuracy: 88.75\n",
      "iter 938 ---  Loss: 2.9682702124118805    Accuracy: 87.1875\n",
      "iter 939 ---  Loss: 3.4280330762267113    Accuracy: 86.25\n",
      "iter 940 ---  Loss: 2.846685364842415    Accuracy: 87.8125\n",
      "iter 941 ---  Loss: 2.73522075265646    Accuracy: 87.34375\n",
      "iter 942 ---  Loss: 2.6943581104278564    Accuracy: 89.0625\n",
      "iter 943 ---  Loss: 3.0410298258066177    Accuracy: 87.96875\n",
      "iter 944 ---  Loss: 3.044311784207821    Accuracy: 88.28125\n",
      "iter 945 ---  Loss: 3.2977011650800705    Accuracy: 87.34375\n",
      "iter 946 ---  Loss: 2.92450213432312    Accuracy: 87.65625\n",
      "iter 947 ---  Loss: 3.719606526196003    Accuracy: 86.875\n",
      "iter 948 ---  Loss: 2.6987558379769325    Accuracy: 88.125\n",
      "iter 949 ---  Loss: 3.4006889536976814    Accuracy: 87.8125\n",
      "iter 950 ---  Loss: 3.088015541434288    Accuracy: 87.96875\n",
      "iter 951 ---  Loss: 3.0958331003785133    Accuracy: 89.21875\n",
      "iter 952 ---  Loss: 3.064862944185734    Accuracy: 88.28125\n",
      "iter 953 ---  Loss: 3.709074303507805    Accuracy: 85.78125\n",
      "iter 954 ---  Loss: 2.9647646248340607    Accuracy: 88.90625\n",
      "iter 955 ---  Loss: 3.2392918094992638    Accuracy: 88.75\n",
      "iter 956 ---  Loss: 3.8505687564611435    Accuracy: 87.5\n",
      "iter 957 ---  Loss: 3.1969446167349815    Accuracy: 87.8125\n",
      "iter 958 ---  Loss: 4.115997605025768    Accuracy: 85.9375\n",
      "iter 959 ---  Loss: 3.4912010356783867    Accuracy: 85.78125\n",
      "iter 960 ---  Loss: 2.7852312698960304    Accuracy: 85.46875\n",
      "iter 961 ---  Loss: 2.942593716084957    Accuracy: 87.8125\n",
      "iter 962 ---  Loss: 3.453230880200863    Accuracy: 86.09375\n",
      "iter 963 ---  Loss: 3.6832796037197113    Accuracy: 85.9375\n",
      "iter 964 ---  Loss: 3.049353614449501    Accuracy: 86.5625\n",
      "iter 965 ---  Loss: 3.318362183868885    Accuracy: 87.1875\n",
      "iter 966 ---  Loss: 3.122711308300495    Accuracy: 88.28125\n",
      "iter 967 ---  Loss: 3.252599313855171    Accuracy: 87.34375\n",
      "iter 968 ---  Loss: 2.8379577547311783    Accuracy: 88.4375\n",
      "iter 969 ---  Loss: 3.1642883718013763    Accuracy: 86.25\n",
      "iter 970 ---  Loss: 3.024208687245846    Accuracy: 88.75\n",
      "iter 971 ---  Loss: 2.5848482474684715    Accuracy: 87.5\n",
      "iter 972 ---  Loss: 2.954731337726116    Accuracy: 86.5625\n",
      "iter 973 ---  Loss: 3.260040432214737    Accuracy: 88.125\n",
      "iter 974 ---  Loss: 3.092373140156269    Accuracy: 86.25\n",
      "iter 975 ---  Loss: 3.345679059624672    Accuracy: 85.0\n",
      "iter 976 ---  Loss: 2.6707432940602303    Accuracy: 88.90625\n",
      "iter 977 ---  Loss: 3.03633338958025    Accuracy: 87.03125\n",
      "iter 978 ---  Loss: 3.263650707900524    Accuracy: 87.03125\n",
      "iter 979 ---  Loss: 2.727027155458927    Accuracy: 86.71875\n",
      "iter 980 ---  Loss: 3.1284148022532463    Accuracy: 86.40625\n",
      "iter 981 ---  Loss: 3.2753072679042816    Accuracy: 87.8125\n",
      "iter 982 ---  Loss: 3.152907021343708    Accuracy: 88.125\n",
      "iter 983 ---  Loss: 2.685126319527626    Accuracy: 87.8125\n",
      "iter 984 ---  Loss: 3.344002701342106    Accuracy: 87.03125\n",
      "iter 985 ---  Loss: 3.2357201352715492    Accuracy: 87.34375\n",
      "iter 986 ---  Loss: 2.9899777695536613    Accuracy: 85.625\n",
      "iter 987 ---  Loss: 2.682142496109009    Accuracy: 87.34375\n",
      "iter 988 ---  Loss: 2.5331137403845787    Accuracy: 88.4375\n",
      "iter 989 ---  Loss: 2.9875775575637817    Accuracy: 89.0625\n",
      "iter 990 ---  Loss: 2.763428494334221    Accuracy: 87.03125\n",
      "iter 991 ---  Loss: 3.1276139467954636    Accuracy: 87.65625\n",
      "iter 992 ---  Loss: 3.1474788412451744    Accuracy: 87.03125\n",
      "iter 993 ---  Loss: 3.129591427743435    Accuracy: 88.125\n",
      "iter 994 ---  Loss: 3.590327635407448    Accuracy: 87.96875\n",
      "iter 995 ---  Loss: 2.815773569047451    Accuracy: 88.28125\n",
      "iter 996 ---  Loss: 3.0686174035072327    Accuracy: 88.125\n",
      "iter 997 ---  Loss: 2.7385621145367622    Accuracy: 88.75\n",
      "iter 998 ---  Loss: 3.1193931475281715    Accuracy: 87.34375\n",
      "iter 999 ---  Loss: 3.381211094558239    Accuracy: 87.1875\n",
      "iter 1000 ---  Loss: 3.351740963757038    Accuracy: 86.40625\n",
      "iter 1001 ---  Loss: 3.345878966152668    Accuracy: 86.875\n",
      "iter 1002 ---  Loss: 3.7598905116319656    Accuracy: 84.84375\n",
      "iter 1003 ---  Loss: 2.8538348376750946    Accuracy: 88.125\n",
      "iter 1004 ---  Loss: 3.2378545850515366    Accuracy: 88.28125\n",
      "iter 1005 ---  Loss: 2.802661180496216    Accuracy: 89.6875\n",
      "iter 1006 ---  Loss: 2.989333339035511    Accuracy: 89.375\n",
      "iter 1007 ---  Loss: 2.7118387520313263    Accuracy: 88.125\n",
      "iter 1008 ---  Loss: 2.6717845052480698    Accuracy: 88.90625\n",
      "iter 1009 ---  Loss: 3.055449165403843    Accuracy: 88.59375\n",
      "iter 1010 ---  Loss: 2.8226355761289597    Accuracy: 86.40625\n",
      "iter 1011 ---  Loss: 3.441439665853977    Accuracy: 85.9375\n",
      "iter 1012 ---  Loss: 3.9201224967837334    Accuracy: 87.96875\n",
      "iter 1013 ---  Loss: 2.745715983211994    Accuracy: 86.875\n",
      "iter 1014 ---  Loss: 3.0328708440065384    Accuracy: 89.53125\n",
      "iter 1015 ---  Loss: 2.6413246244192123    Accuracy: 87.5\n",
      "iter 1016 ---  Loss: 3.356782488524914    Accuracy: 87.65625\n",
      "iter 1017 ---  Loss: 3.50986098498106    Accuracy: 86.09375\n",
      "iter 1018 ---  Loss: 2.947010040283203    Accuracy: 86.40625\n",
      "iter 1019 ---  Loss: 2.8559314981102943    Accuracy: 87.34375\n",
      "iter 1020 ---  Loss: 2.762920118868351    Accuracy: 87.8125\n",
      "iter 1021 ---  Loss: 2.7680031284689903    Accuracy: 87.8125\n",
      "iter 1022 ---  Loss: 3.291627898812294    Accuracy: 88.90625\n",
      "iter 1023 ---  Loss: 3.818970575928688    Accuracy: 86.5625\n",
      "iter 1024 ---  Loss: 2.7474530190229416    Accuracy: 87.34375\n",
      "iter 1025 ---  Loss: 2.7622865363955498    Accuracy: 86.40625\n",
      "iter 1026 ---  Loss: 2.7853947803378105    Accuracy: 88.59375\n",
      "iter 1027 ---  Loss: 3.414421483874321    Accuracy: 85.625\n",
      "iter 1028 ---  Loss: 3.598599024116993    Accuracy: 85.78125\n",
      "iter 1029 ---  Loss: 3.2705687507987022    Accuracy: 86.71875\n",
      "iter 1030 ---  Loss: 2.6613636389374733    Accuracy: 87.03125\n",
      "iter 1031 ---  Loss: 3.3530196473002434    Accuracy: 87.5\n",
      "iter 1032 ---  Loss: 3.223173603415489    Accuracy: 86.25\n",
      "iter 1033 ---  Loss: 2.8972318693995476    Accuracy: 89.6875\n",
      "iter 1034 ---  Loss: 2.807322435081005    Accuracy: 85.3125\n",
      "iter 1035 ---  Loss: 3.0658532455563545    Accuracy: 87.34375\n",
      "iter 1036 ---  Loss: 3.1941308304667473    Accuracy: 87.34375\n",
      "iter 1037 ---  Loss: 3.1823973432183266    Accuracy: 89.0625\n",
      "iter 1038 ---  Loss: 2.964646555483341    Accuracy: 87.03125\n",
      "iter 1039 ---  Loss: 3.3653066977858543    Accuracy: 85.3125\n",
      "iter 1040 ---  Loss: 3.215970292687416    Accuracy: 86.5625\n",
      "iter 1041 ---  Loss: 2.575333632528782    Accuracy: 87.96875\n",
      "iter 1042 ---  Loss: 2.7165996357798576    Accuracy: 87.8125\n",
      "iter 1043 ---  Loss: 3.274523191154003    Accuracy: 86.5625\n",
      "iter 1044 ---  Loss: 3.5366757810115814    Accuracy: 84.84375\n",
      "iter 1045 ---  Loss: 2.974253475666046    Accuracy: 86.875\n",
      "iter 1046 ---  Loss: 2.747275747358799    Accuracy: 86.40625\n",
      "iter 1047 ---  Loss: 3.1231697276234627    Accuracy: 86.71875\n",
      "iter 1048 ---  Loss: 3.3564981669187546    Accuracy: 86.25\n",
      "iter 1049 ---  Loss: 3.062447026371956    Accuracy: 86.25\n",
      "iter 1050 ---  Loss: 3.3002241104841232    Accuracy: 86.5625\n",
      "iter 1051 ---  Loss: 3.097921095788479    Accuracy: 86.875\n",
      "iter 1052 ---  Loss: 3.0032483711838722    Accuracy: 87.65625\n",
      "iter 1053 ---  Loss: 3.0401139557361603    Accuracy: 87.1875\n",
      "iter 1054 ---  Loss: 3.1945539116859436    Accuracy: 86.09375\n",
      "iter 1055 ---  Loss: 3.3517380133271217    Accuracy: 86.5625\n",
      "iter 1056 ---  Loss: 3.561372935771942    Accuracy: 85.46875\n",
      "iter 1057 ---  Loss: 2.8300317600369453    Accuracy: 88.125\n",
      "iter 1058 ---  Loss: 3.6157072633504868    Accuracy: 87.03125\n",
      "iter 1059 ---  Loss: 3.491381660103798    Accuracy: 86.09375\n",
      "iter 1060 ---  Loss: 2.9175992757081985    Accuracy: 86.40625\n",
      "iter 1061 ---  Loss: 3.3292456790804863    Accuracy: 85.9375\n",
      "iter 1062 ---  Loss: 2.7899818643927574    Accuracy: 88.4375\n",
      "iter 1063 ---  Loss: 3.9342868700623512    Accuracy: 86.25\n",
      "iter 1064 ---  Loss: 3.371129237115383    Accuracy: 86.875\n",
      "iter 1065 ---  Loss: 3.2334105148911476    Accuracy: 85.625\n",
      "iter 1066 ---  Loss: 3.0414080768823624    Accuracy: 86.09375\n",
      "iter 1067 ---  Loss: 4.022693790495396    Accuracy: 85.9375\n",
      "iter 1068 ---  Loss: 3.8153571859002113    Accuracy: 84.53125\n",
      "iter 1069 ---  Loss: 2.6900793612003326    Accuracy: 87.8125\n",
      "iter 1070 ---  Loss: 2.788025453686714    Accuracy: 86.71875\n",
      "iter 1071 ---  Loss: 3.563635252416134    Accuracy: 86.5625\n",
      "iter 1072 ---  Loss: 3.2537955939769745    Accuracy: 87.03125\n",
      "iter 1073 ---  Loss: 3.343974843621254    Accuracy: 88.125\n",
      "iter 1074 ---  Loss: 3.0633251890540123    Accuracy: 86.40625\n",
      "iter 1075 ---  Loss: 3.855004832148552    Accuracy: 85.3125\n",
      "iter 1076 ---  Loss: 3.438565008342266    Accuracy: 85.15625\n",
      "iter 1077 ---  Loss: 3.227986216545105    Accuracy: 85.46875\n",
      "iter 1078 ---  Loss: 2.653040438890457    Accuracy: 87.65625\n",
      "iter 1079 ---  Loss: 2.8657674565911293    Accuracy: 87.5\n",
      "iter 1080 ---  Loss: 2.7863577231764793    Accuracy: 87.65625\n",
      "iter 1081 ---  Loss: 2.9370474442839622    Accuracy: 85.625\n",
      "iter 1082 ---  Loss: 2.958266645669937    Accuracy: 86.71875\n",
      "iter 1083 ---  Loss: 2.8750962242484093    Accuracy: 87.96875\n",
      "iter 1084 ---  Loss: 2.457388259470463    Accuracy: 89.375\n",
      "iter 1085 ---  Loss: 3.009374111890793    Accuracy: 88.28125\n",
      "iter 1086 ---  Loss: 3.0123299956321716    Accuracy: 86.71875\n",
      "iter 1087 ---  Loss: 3.301527038216591    Accuracy: 85.9375\n",
      "iter 1088 ---  Loss: 2.7779651507735252    Accuracy: 85.9375\n",
      "iter 1089 ---  Loss: 2.72984129935503    Accuracy: 86.875\n",
      "iter 1090 ---  Loss: 2.8104778081178665    Accuracy: 87.96875\n",
      "iter 1091 ---  Loss: 3.835891716182232    Accuracy: 85.15625\n",
      "iter 1092 ---  Loss: 3.133986659348011    Accuracy: 86.875\n",
      "iter 1093 ---  Loss: 3.06037724763155    Accuracy: 87.5\n",
      "iter 1094 ---  Loss: 3.0432024598121643    Accuracy: 86.09375\n",
      "iter 1095 ---  Loss: 3.1218995973467827    Accuracy: 86.71875\n",
      "iter 1096 ---  Loss: 3.0357017517089844    Accuracy: 85.9375\n",
      "iter 1097 ---  Loss: 3.0092922374606133    Accuracy: 87.34375\n",
      "iter 1098 ---  Loss: 3.507289841771126    Accuracy: 87.5\n",
      "iter 1099 ---  Loss: 3.263632245361805    Accuracy: 85.15625\n",
      "iter 1100 ---  Loss: 2.950837418437004    Accuracy: 87.03125\n",
      "iter 1101 ---  Loss: 3.0520446226000786    Accuracy: 86.09375\n",
      "iter 1102 ---  Loss: 2.9302863702178    Accuracy: 87.8125\n",
      "iter 1103 ---  Loss: 2.8221077769994736    Accuracy: 85.78125\n",
      "iter 1104 ---  Loss: 3.0954270362854004    Accuracy: 86.875\n",
      "iter 1105 ---  Loss: 3.3172559440135956    Accuracy: 85.3125\n",
      "iter 1106 ---  Loss: 2.620420418679714    Accuracy: 86.09375\n",
      "iter 1107 ---  Loss: 2.794928565621376    Accuracy: 89.53125\n",
      "iter 1108 ---  Loss: 3.2879693582654    Accuracy: 86.09375\n",
      "iter 1109 ---  Loss: 3.243183769285679    Accuracy: 86.5625\n",
      "iter 1110 ---  Loss: 2.8475627824664116    Accuracy: 86.875\n",
      "iter 1111 ---  Loss: 2.626851551234722    Accuracy: 88.125\n",
      "iter 1112 ---  Loss: 3.014154613018036    Accuracy: 86.09375\n",
      "iter 1113 ---  Loss: 3.0554119870066643    Accuracy: 88.28125\n",
      "iter 1114 ---  Loss: 3.401285022497177    Accuracy: 85.9375\n",
      "iter 1115 ---  Loss: 3.5435751006007195    Accuracy: 85.625\n",
      "iter 1116 ---  Loss: 3.5323130264878273    Accuracy: 85.9375\n",
      "iter 1117 ---  Loss: 3.3859586343169212    Accuracy: 87.8125\n",
      "iter 1118 ---  Loss: 2.714674472808838    Accuracy: 88.28125\n",
      "iter 1119 ---  Loss: 3.1162312999367714    Accuracy: 86.09375\n",
      "iter 1120 ---  Loss: 2.9695411026477814    Accuracy: 86.875\n",
      "iter 1121 ---  Loss: 3.4575231224298477    Accuracy: 87.1875\n",
      "iter 1122 ---  Loss: 2.6156294718384743    Accuracy: 89.0625\n",
      "iter 1123 ---  Loss: 2.8343706876039505    Accuracy: 87.96875\n",
      "iter 1124 ---  Loss: 2.503274030983448    Accuracy: 88.75\n",
      "iter 1125 ---  Loss: 2.915767841041088    Accuracy: 87.1875\n",
      "iter 1126 ---  Loss: 3.25353541970253    Accuracy: 88.90625\n",
      "iter 1127 ---  Loss: 2.75167802721262    Accuracy: 86.5625\n",
      "iter 1128 ---  Loss: 3.7360313162207603    Accuracy: 84.84375\n",
      "iter 1129 ---  Loss: 2.5180803537368774    Accuracy: 88.59375\n",
      "iter 1130 ---  Loss: 3.100864015519619    Accuracy: 87.65625\n",
      "iter 1131 ---  Loss: 2.6834573820233345    Accuracy: 87.65625\n",
      "iter 1132 ---  Loss: 2.8659146204590797    Accuracy: 88.59375\n",
      "iter 1133 ---  Loss: 3.1852299496531487    Accuracy: 87.03125\n",
      "iter 1134 ---  Loss: 2.680740140378475    Accuracy: 87.1875\n",
      "iter 1135 ---  Loss: 3.2237282544374466    Accuracy: 87.03125\n",
      "iter 1136 ---  Loss: 3.242263086140156    Accuracy: 86.09375\n",
      "iter 1137 ---  Loss: 3.763213962316513    Accuracy: 87.1875\n",
      "iter 1138 ---  Loss: 3.1786432936787605    Accuracy: 84.21875\n",
      "iter 1139 ---  Loss: 3.0627490803599358    Accuracy: 86.5625\n",
      "iter 1140 ---  Loss: 2.7006001695990562    Accuracy: 87.03125\n",
      "iter 1141 ---  Loss: 3.1762520372867584    Accuracy: 85.625\n",
      "iter 1142 ---  Loss: 3.1291653513908386    Accuracy: 86.875\n",
      "iter 1143 ---  Loss: 3.5367204025387764    Accuracy: 85.0\n",
      "iter 1144 ---  Loss: 2.747307650744915    Accuracy: 88.75\n",
      "iter 1145 ---  Loss: 3.5974573120474815    Accuracy: 83.59375\n",
      "iter 1146 ---  Loss: 2.60881320387125    Accuracy: 87.96875\n",
      "iter 1147 ---  Loss: 2.9654618352651596    Accuracy: 86.40625\n",
      "iter 1148 ---  Loss: 3.2397924065589905    Accuracy: 87.96875\n",
      "iter 1149 ---  Loss: 3.160471148788929    Accuracy: 88.4375\n",
      "iter 1150 ---  Loss: 3.1683816835284233    Accuracy: 86.71875\n",
      "iter 1151 ---  Loss: 3.396563969552517    Accuracy: 88.75\n",
      "iter 1152 ---  Loss: 3.3469952791929245    Accuracy: 86.40625\n",
      "iter 1153 ---  Loss: 2.7837496399879456    Accuracy: 87.1875\n",
      "iter 1154 ---  Loss: 3.492250479757786    Accuracy: 87.34375\n",
      "iter 1155 ---  Loss: 2.9992961063981056    Accuracy: 86.71875\n",
      "iter 1156 ---  Loss: 3.214136078953743    Accuracy: 85.46875\n",
      "iter 1157 ---  Loss: 2.693945847451687    Accuracy: 88.4375\n",
      "iter 1158 ---  Loss: 3.1649710908532143    Accuracy: 84.6875\n",
      "iter 1159 ---  Loss: 3.4070850908756256    Accuracy: 86.09375\n",
      "iter 1160 ---  Loss: 3.1718015372753143    Accuracy: 85.78125\n",
      "iter 1161 ---  Loss: 3.4574483409523964    Accuracy: 85.78125\n",
      "iter 1162 ---  Loss: 3.0894063115119934    Accuracy: 84.53125\n",
      "iter 1163 ---  Loss: 3.4933322817087173    Accuracy: 85.9375\n",
      "iter 1164 ---  Loss: 3.042367711663246    Accuracy: 88.59375\n",
      "iter 1165 ---  Loss: 3.062996193766594    Accuracy: 87.5\n",
      "iter 1166 ---  Loss: 3.1024581640958786    Accuracy: 88.125\n",
      "iter 1167 ---  Loss: 3.0173081159591675    Accuracy: 85.78125\n",
      "iter 1168 ---  Loss: 2.928489550948143    Accuracy: 88.90625\n",
      "iter 1169 ---  Loss: 3.430709943175316    Accuracy: 87.5\n",
      "iter 1170 ---  Loss: 3.0019746348261833    Accuracy: 88.4375\n",
      "iter 1171 ---  Loss: 3.0527994707226753    Accuracy: 87.34375\n",
      "iter 1172 ---  Loss: 2.73164252191782    Accuracy: 89.375\n",
      "iter 1173 ---  Loss: 2.8954396918416023    Accuracy: 89.21875\n",
      "iter 1174 ---  Loss: 2.928450420498848    Accuracy: 86.71875\n",
      "iter 1175 ---  Loss: 3.0789037868380547    Accuracy: 88.125\n",
      "iter 1176 ---  Loss: 2.473193846642971    Accuracy: 91.09375\n",
      "iter 1177 ---  Loss: 3.47618555277586    Accuracy: 85.9375\n",
      "iter 1178 ---  Loss: 3.3160410448908806    Accuracy: 87.03125\n",
      "iter 1179 ---  Loss: 3.0086295381188393    Accuracy: 87.96875\n",
      "iter 1180 ---  Loss: 3.124494180083275    Accuracy: 88.28125\n",
      "iter 1181 ---  Loss: 3.1872656047344208    Accuracy: 86.40625\n",
      "iter 1182 ---  Loss: 2.7913673594594    Accuracy: 87.03125\n",
      "iter 1183 ---  Loss: 2.979800522327423    Accuracy: 87.5\n",
      "iter 1184 ---  Loss: 3.0359546169638634    Accuracy: 87.34375\n",
      "iter 1185 ---  Loss: 2.8430302664637566    Accuracy: 88.28125\n",
      "iter 1186 ---  Loss: 2.9144382029771805    Accuracy: 86.40625\n",
      "iter 1187 ---  Loss: 2.3832870945334435    Accuracy: 87.03125\n",
      "iter 1188 ---  Loss: 3.563419245183468    Accuracy: 85.78125\n",
      "iter 1189 ---  Loss: 3.4602415785193443    Accuracy: 87.5\n",
      "iter 1190 ---  Loss: 2.8491156697273254    Accuracy: 87.5\n",
      "iter 1191 ---  Loss: 2.6102355867624283    Accuracy: 87.5\n",
      "iter 1192 ---  Loss: 3.1652541011571884    Accuracy: 87.65625\n",
      "iter 1193 ---  Loss: 2.6175877675414085    Accuracy: 87.5\n",
      "iter 1194 ---  Loss: 4.007951147854328    Accuracy: 86.09375\n",
      "iter 1195 ---  Loss: 2.852057531476021    Accuracy: 88.4375\n",
      "iter 1196 ---  Loss: 3.178635209798813    Accuracy: 88.125\n",
      "iter 1197 ---  Loss: 3.030463859438896    Accuracy: 87.34375\n",
      "iter 1198 ---  Loss: 3.08267755061388    Accuracy: 87.5\n",
      "iter 1199 ---  Loss: 3.214617356657982    Accuracy: 87.34375\n",
      "iter 1200 ---  Loss: 2.7711943835020065    Accuracy: 88.125\n",
      "iter 1201 ---  Loss: 3.16262998431921    Accuracy: 88.125\n",
      "iter 1202 ---  Loss: 3.2987319827079773    Accuracy: 86.5625\n",
      "iter 1203 ---  Loss: 2.8904385790228844    Accuracy: 88.59375\n",
      "iter 1204 ---  Loss: 3.3062715232372284    Accuracy: 87.34375\n",
      "iter 1205 ---  Loss: 3.043719321489334    Accuracy: 86.71875\n",
      "iter 1206 ---  Loss: 3.347356230020523    Accuracy: 87.5\n",
      "iter 1207 ---  Loss: 3.362569712102413    Accuracy: 86.71875\n",
      "iter 1208 ---  Loss: 2.999745763838291    Accuracy: 86.875\n",
      "iter 1209 ---  Loss: 2.9681254476308823    Accuracy: 86.875\n",
      "iter 1210 ---  Loss: 3.0249854251742363    Accuracy: 87.8125\n",
      "iter 1211 ---  Loss: 3.3006520941853523    Accuracy: 85.3125\n",
      "iter 1212 ---  Loss: 3.2783907651901245    Accuracy: 87.8125\n",
      "iter 1213 ---  Loss: 2.7718342319130898    Accuracy: 87.8125\n",
      "iter 1214 ---  Loss: 2.9279638826847076    Accuracy: 88.59375\n",
      "iter 1215 ---  Loss: 3.504376195371151    Accuracy: 87.34375\n",
      "iter 1216 ---  Loss: 3.04296512901783    Accuracy: 89.375\n",
      "iter 1217 ---  Loss: 3.1863179430365562    Accuracy: 88.4375\n",
      "iter 1218 ---  Loss: 3.136251263320446    Accuracy: 86.875\n",
      "iter 1219 ---  Loss: 2.929657392203808    Accuracy: 89.21875\n",
      "iter 1220 ---  Loss: 3.264844238758087    Accuracy: 88.4375\n",
      "iter 1221 ---  Loss: 3.1158642172813416    Accuracy: 87.8125\n",
      "iter 1222 ---  Loss: 3.0058414191007614    Accuracy: 87.5\n",
      "iter 1223 ---  Loss: 2.9977017268538475    Accuracy: 88.4375\n",
      "iter 1224 ---  Loss: 3.323440246284008    Accuracy: 87.03125\n",
      "iter 1225 ---  Loss: 3.040085159242153    Accuracy: 88.59375\n",
      "iter 1226 ---  Loss: 2.903658837080002    Accuracy: 86.5625\n",
      "iter 1227 ---  Loss: 3.0507393777370453    Accuracy: 87.96875\n",
      "iter 1228 ---  Loss: 2.6868570894002914    Accuracy: 89.53125\n",
      "iter 1229 ---  Loss: 3.022179551422596    Accuracy: 85.9375\n",
      "iter 1230 ---  Loss: 2.9948989003896713    Accuracy: 89.21875\n",
      "iter 1231 ---  Loss: 2.8216489031910896    Accuracy: 86.875\n",
      "iter 1232 ---  Loss: 3.0784570202231407    Accuracy: 87.03125\n",
      "iter 1233 ---  Loss: 2.5713266283273697    Accuracy: 88.28125\n",
      "iter 1234 ---  Loss: 2.606086388230324    Accuracy: 89.21875\n",
      "iter 1235 ---  Loss: 3.443850353360176    Accuracy: 87.96875\n",
      "iter 1236 ---  Loss: 3.4914617836475372    Accuracy: 87.65625\n",
      "iter 1237 ---  Loss: 3.2146990075707436    Accuracy: 85.46875\n",
      "iter 1238 ---  Loss: 3.5336116924881935    Accuracy: 86.40625\n",
      "iter 1239 ---  Loss: 3.5537014231085777    Accuracy: 87.5\n",
      "iter 1240 ---  Loss: 2.715996563434601    Accuracy: 88.59375\n",
      "iter 1241 ---  Loss: 3.182356283068657    Accuracy: 87.65625\n",
      "iter 1242 ---  Loss: 2.666526585817337    Accuracy: 87.8125\n",
      "iter 1243 ---  Loss: 2.872696243226528    Accuracy: 89.0625\n",
      "iter 1244 ---  Loss: 3.425019793212414    Accuracy: 87.5\n",
      "iter 1245 ---  Loss: 3.1773832961916924    Accuracy: 88.4375\n",
      "iter 1246 ---  Loss: 4.009717226028442    Accuracy: 86.40625\n",
      "iter 1247 ---  Loss: 3.2910220846533775    Accuracy: 87.8125\n",
      "iter 1248 ---  Loss: 2.955998107790947    Accuracy: 86.40625\n",
      "iter 1249 ---  Loss: 2.7281947135925293    Accuracy: 88.59375\n",
      "iter 1250 ---  Loss: 2.872053898870945    Accuracy: 88.75\n",
      "iter 1251 ---  Loss: 3.063968248665333    Accuracy: 87.96875\n",
      "iter 1252 ---  Loss: 3.2180294543504715    Accuracy: 86.5625\n",
      "iter 1253 ---  Loss: 3.008556939661503    Accuracy: 88.28125\n",
      "iter 1254 ---  Loss: 2.8979602009058    Accuracy: 88.125\n",
      "iter 1255 ---  Loss: 3.098005026578903    Accuracy: 87.65625\n",
      "iter 1256 ---  Loss: 3.326202243566513    Accuracy: 87.5\n",
      "iter 1257 ---  Loss: 3.19267825037241    Accuracy: 85.9375\n",
      "iter 1258 ---  Loss: 2.738875351846218    Accuracy: 89.6875\n",
      "iter 1259 ---  Loss: 2.7614935487508774    Accuracy: 87.34375\n",
      "iter 1260 ---  Loss: 2.713556259870529    Accuracy: 87.8125\n",
      "iter 1261 ---  Loss: 2.887130558490753    Accuracy: 86.5625\n",
      "iter 1262 ---  Loss: 3.2544888630509377    Accuracy: 86.40625\n",
      "iter 1263 ---  Loss: 3.297402501106262    Accuracy: 86.25\n",
      "iter 1264 ---  Loss: 2.9185858368873596    Accuracy: 88.75\n",
      "iter 1265 ---  Loss: 3.2517416402697563    Accuracy: 86.5625\n",
      "iter 1266 ---  Loss: 2.8217277601361275    Accuracy: 88.90625\n",
      "iter 1267 ---  Loss: 3.26168791949749    Accuracy: 87.5\n",
      "iter 1268 ---  Loss: 3.443823628127575    Accuracy: 86.25\n",
      "iter 1269 ---  Loss: 2.783925123512745    Accuracy: 88.75\n",
      "iter 1270 ---  Loss: 3.436260111629963    Accuracy: 86.71875\n",
      "iter 1271 ---  Loss: 2.578777067363262    Accuracy: 88.75\n",
      "iter 1272 ---  Loss: 3.64712306112051    Accuracy: 87.1875\n",
      "iter 1273 ---  Loss: 3.3053876981139183    Accuracy: 87.1875\n",
      "iter 1274 ---  Loss: 3.257837951183319    Accuracy: 87.1875\n",
      "iter 1275 ---  Loss: 3.6536432057619095    Accuracy: 87.65625\n",
      "iter 1276 ---  Loss: 2.9791756942868233    Accuracy: 87.8125\n",
      "iter 1277 ---  Loss: 2.8356624841690063    Accuracy: 88.90625\n",
      "iter 1278 ---  Loss: 2.649924658238888    Accuracy: 88.4375\n",
      "iter 1279 ---  Loss: 2.7581914216279984    Accuracy: 90.9375\n",
      "iter 1280 ---  Loss: 2.720780722796917    Accuracy: 89.84375\n",
      "iter 1281 ---  Loss: 3.0292526707053185    Accuracy: 88.4375\n",
      "iter 1282 ---  Loss: 3.5621123537421227    Accuracy: 88.75\n",
      "iter 1283 ---  Loss: 3.167001061141491    Accuracy: 87.34375\n",
      "iter 1284 ---  Loss: 2.8218255415558815    Accuracy: 88.59375\n",
      "iter 1285 ---  Loss: 3.2473908215761185    Accuracy: 87.34375\n",
      "iter 1286 ---  Loss: 2.896642416715622    Accuracy: 90.9375\n",
      "iter 1287 ---  Loss: 3.251173675060272    Accuracy: 87.5\n",
      "iter 1288 ---  Loss: 2.920320361852646    Accuracy: 87.65625\n",
      "iter 1289 ---  Loss: 3.0261822044849396    Accuracy: 87.96875\n",
      "iter 1290 ---  Loss: 3.2187197357416153    Accuracy: 88.75\n",
      "iter 1291 ---  Loss: 3.0468027740716934    Accuracy: 85.15625\n",
      "iter 1292 ---  Loss: 3.0490257665514946    Accuracy: 88.125\n",
      "iter 1293 ---  Loss: 3.7903685867786407    Accuracy: 86.71875\n",
      "iter 1294 ---  Loss: 2.821028970181942    Accuracy: 87.96875\n",
      "iter 1295 ---  Loss: 2.860676981508732    Accuracy: 88.4375\n",
      "iter 1296 ---  Loss: 3.355160489678383    Accuracy: 85.9375\n",
      "iter 1297 ---  Loss: 3.6948623061180115    Accuracy: 87.8125\n",
      "iter 1298 ---  Loss: 2.6089555993676186    Accuracy: 88.75\n",
      "iter 1299 ---  Loss: 3.374602772295475    Accuracy: 87.5\n",
      "iter 1300 ---  Loss: 3.6512119844555855    Accuracy: 85.3125\n",
      "iter 1301 ---  Loss: 2.707685522735119    Accuracy: 87.65625\n",
      "iter 1302 ---  Loss: 2.830134779214859    Accuracy: 87.8125\n",
      "iter 1303 ---  Loss: 3.574807919561863    Accuracy: 86.71875\n",
      "iter 1304 ---  Loss: 3.01613686978817    Accuracy: 88.59375\n",
      "iter 1305 ---  Loss: 2.989089258015156    Accuracy: 87.96875\n",
      "iter 1306 ---  Loss: 2.8887171372771263    Accuracy: 88.28125\n",
      "iter 1307 ---  Loss: 2.996753551065922    Accuracy: 89.53125\n",
      "iter 1308 ---  Loss: 3.151352643966675    Accuracy: 88.4375\n",
      "iter 1309 ---  Loss: 2.5904205590486526    Accuracy: 89.21875\n",
      "iter 1310 ---  Loss: 2.832134924829006    Accuracy: 87.8125\n",
      "iter 1311 ---  Loss: 3.083498403429985    Accuracy: 86.875\n",
      "iter 1312 ---  Loss: 2.972047232091427    Accuracy: 87.5\n",
      "iter 1313 ---  Loss: 2.5719502046704292    Accuracy: 88.4375\n",
      "iter 1314 ---  Loss: 3.2796530798077583    Accuracy: 87.96875\n",
      "iter 1315 ---  Loss: 2.7189904153347015    Accuracy: 86.25\n",
      "iter 1316 ---  Loss: 3.0288793742656708    Accuracy: 87.1875\n",
      "iter 1317 ---  Loss: 2.7529580742120743    Accuracy: 89.0625\n",
      "iter 1318 ---  Loss: 3.135771833360195    Accuracy: 85.78125\n",
      "iter 1319 ---  Loss: 2.81839831918478    Accuracy: 87.96875\n",
      "iter 1320 ---  Loss: 2.8577356413006783    Accuracy: 87.03125\n",
      "iter 1321 ---  Loss: 2.6817242577672005    Accuracy: 90.0\n",
      "iter 1322 ---  Loss: 3.242070786654949    Accuracy: 87.03125\n",
      "iter 1323 ---  Loss: 3.1361372843384743    Accuracy: 86.25\n",
      "iter 1324 ---  Loss: 2.569712959229946    Accuracy: 89.6875\n",
      "iter 1325 ---  Loss: 3.1298268362879753    Accuracy: 87.34375\n",
      "iter 1326 ---  Loss: 3.4645997509360313    Accuracy: 85.9375\n",
      "iter 1327 ---  Loss: 3.050728350877762    Accuracy: 88.4375\n",
      "iter 1328 ---  Loss: 2.663016028702259    Accuracy: 88.125\n",
      "iter 1329 ---  Loss: 3.0330202654004097    Accuracy: 88.75\n",
      "iter 1330 ---  Loss: 3.34991305321455    Accuracy: 86.71875\n",
      "iter 1331 ---  Loss: 2.9106614515185356    Accuracy: 86.5625\n",
      "iter 1332 ---  Loss: 2.750838063657284    Accuracy: 87.1875\n",
      "iter 1333 ---  Loss: 3.1585567593574524    Accuracy: 87.1875\n",
      "iter 1334 ---  Loss: 2.954702563583851    Accuracy: 88.59375\n",
      "iter 1335 ---  Loss: 2.9256055057048798    Accuracy: 86.875\n",
      "iter 1336 ---  Loss: 2.9383464753627777    Accuracy: 88.59375\n",
      "iter 1337 ---  Loss: 3.1458631083369255    Accuracy: 87.03125\n",
      "iter 1338 ---  Loss: 2.7941169515252113    Accuracy: 88.4375\n",
      "iter 1339 ---  Loss: 3.346333362162113    Accuracy: 88.28125\n",
      "iter 1340 ---  Loss: 3.1373888701200485    Accuracy: 87.5\n",
      "iter 1341 ---  Loss: 2.6184215992689133    Accuracy: 88.75\n",
      "iter 1342 ---  Loss: 2.946912758052349    Accuracy: 87.5\n",
      "iter 1343 ---  Loss: 3.349636748433113    Accuracy: 87.96875\n",
      "iter 1344 ---  Loss: 3.0259188562631607    Accuracy: 87.8125\n",
      "iter 1345 ---  Loss: 2.5724302232265472    Accuracy: 88.125\n",
      "iter 1346 ---  Loss: 3.6332884207367897    Accuracy: 86.875\n",
      "iter 1347 ---  Loss: 2.7662321999669075    Accuracy: 88.28125\n",
      "iter 1348 ---  Loss: 3.1383007541298866    Accuracy: 85.15625\n",
      "iter 1349 ---  Loss: 3.4529331624507904    Accuracy: 86.71875\n",
      "iter 1350 ---  Loss: 2.839075982570648    Accuracy: 87.03125\n",
      "iter 1351 ---  Loss: 3.330686569213867    Accuracy: 86.71875\n",
      "iter 1352 ---  Loss: 2.581259436905384    Accuracy: 88.75\n",
      "iter 1353 ---  Loss: 2.6489393413066864    Accuracy: 87.96875\n",
      "iter 1354 ---  Loss: 2.8240028470754623    Accuracy: 89.375\n",
      "iter 1355 ---  Loss: 2.771286502480507    Accuracy: 88.4375\n",
      "iter 1356 ---  Loss: 3.115891233086586    Accuracy: 85.9375\n",
      "iter 1357 ---  Loss: 3.0995568335056305    Accuracy: 87.8125\n",
      "iter 1358 ---  Loss: 2.875102572143078    Accuracy: 88.59375\n",
      "iter 1359 ---  Loss: 2.8414218351244926    Accuracy: 88.4375\n",
      "iter 1360 ---  Loss: 3.171463869512081    Accuracy: 88.59375\n",
      "iter 1361 ---  Loss: 3.814700774848461    Accuracy: 86.875\n",
      "iter 1362 ---  Loss: 2.9810665994882584    Accuracy: 87.1875\n",
      "iter 1363 ---  Loss: 2.743624299764633    Accuracy: 89.21875\n",
      "iter 1364 ---  Loss: 3.306068331003189    Accuracy: 88.125\n",
      "iter 1365 ---  Loss: 3.2612382993102074    Accuracy: 87.8125\n",
      "iter 1366 ---  Loss: 2.791763924062252    Accuracy: 87.8125\n",
      "iter 1367 ---  Loss: 2.7793906405568123    Accuracy: 89.0625\n",
      "iter 1368 ---  Loss: 2.7367356568574905    Accuracy: 88.75\n",
      "iter 1369 ---  Loss: 3.2407932355999947    Accuracy: 86.40625\n",
      "iter 1370 ---  Loss: 3.3211329579353333    Accuracy: 86.40625\n",
      "iter 1371 ---  Loss: 2.914188914000988    Accuracy: 87.1875\n",
      "iter 1372 ---  Loss: 3.2283487766981125    Accuracy: 87.03125\n",
      "iter 1373 ---  Loss: 2.7201919108629227    Accuracy: 88.75\n",
      "iter 1374 ---  Loss: 2.741929091513157    Accuracy: 88.90625\n",
      "iter 1375 ---  Loss: 2.863946869969368    Accuracy: 88.28125\n",
      "iter 1376 ---  Loss: 2.823960117995739    Accuracy: 89.375\n",
      "iter 1377 ---  Loss: 3.2910543233156204    Accuracy: 87.1875\n",
      "iter 1378 ---  Loss: 3.774924099445343    Accuracy: 85.9375\n",
      "iter 1379 ---  Loss: 2.6556031182408333    Accuracy: 87.65625\n",
      "iter 1380 ---  Loss: 2.5952860713005066    Accuracy: 90.0\n",
      "iter 1381 ---  Loss: 2.9077454432845116    Accuracy: 88.75\n",
      "iter 1382 ---  Loss: 2.9991308972239494    Accuracy: 87.96875\n",
      "iter 1383 ---  Loss: 3.236057184636593    Accuracy: 87.65625\n",
      "iter 1384 ---  Loss: 3.1818980649113655    Accuracy: 86.875\n",
      "iter 1385 ---  Loss: 2.899900957942009    Accuracy: 88.59375\n",
      "iter 1386 ---  Loss: 2.7565570026636124    Accuracy: 89.0625\n",
      "iter 1387 ---  Loss: 2.917707897722721    Accuracy: 88.59375\n",
      "iter 1388 ---  Loss: 3.11306481808424    Accuracy: 88.59375\n",
      "iter 1389 ---  Loss: 2.9154635071754456    Accuracy: 89.375\n",
      "iter 1390 ---  Loss: 3.051491789519787    Accuracy: 85.625\n",
      "iter 1391 ---  Loss: 2.5579310581088066    Accuracy: 88.59375\n",
      "iter 1392 ---  Loss: 3.728480316698551    Accuracy: 87.34375\n",
      "iter 1393 ---  Loss: 3.080226704478264    Accuracy: 87.96875\n",
      "iter 1394 ---  Loss: 2.375653274357319    Accuracy: 89.6875\n",
      "iter 1395 ---  Loss: 3.0940213799476624    Accuracy: 88.4375\n",
      "iter 1396 ---  Loss: 2.6831301748752594    Accuracy: 88.75\n",
      "iter 1397 ---  Loss: 3.042429529130459    Accuracy: 88.125\n",
      "iter 1398 ---  Loss: 3.072498433291912    Accuracy: 87.1875\n",
      "iter 1399 ---  Loss: 2.970355622470379    Accuracy: 88.59375\n",
      "iter 1400 ---  Loss: 3.2436546459794044    Accuracy: 87.03125\n",
      "iter 1401 ---  Loss: 3.3188348188996315    Accuracy: 86.71875\n",
      "iter 1402 ---  Loss: 3.3707543164491653    Accuracy: 87.03125\n",
      "iter 1403 ---  Loss: 3.006517358124256    Accuracy: 86.40625\n",
      "iter 1404 ---  Loss: 4.115120127797127    Accuracy: 86.5625\n",
      "iter 1405 ---  Loss: 2.766273096203804    Accuracy: 87.1875\n",
      "iter 1406 ---  Loss: 3.617420472204685    Accuracy: 88.4375\n",
      "iter 1407 ---  Loss: 2.867237851023674    Accuracy: 88.59375\n",
      "iter 1408 ---  Loss: 3.278297282755375    Accuracy: 87.96875\n",
      "iter 1409 ---  Loss: 3.159227192401886    Accuracy: 87.5\n",
      "iter 1410 ---  Loss: 3.432164281606674    Accuracy: 85.0\n",
      "iter 1411 ---  Loss: 3.878596618771553    Accuracy: 84.0625\n",
      "iter 1412 ---  Loss: 3.532974489033222    Accuracy: 87.34375\n",
      "iter 1413 ---  Loss: 2.8600782081484795    Accuracy: 90.15625\n",
      "iter 1414 ---  Loss: 3.3503369614481926    Accuracy: 87.5\n",
      "iter 1415 ---  Loss: 2.7157150954008102    Accuracy: 88.75\n",
      "iter 1416 ---  Loss: 3.119321256875992    Accuracy: 87.8125\n",
      "iter 1417 ---  Loss: 2.8304419964551926    Accuracy: 87.03125\n",
      "iter 1418 ---  Loss: 3.0717528983950615    Accuracy: 87.03125\n",
      "iter 1419 ---  Loss: 2.727685570716858    Accuracy: 86.40625\n",
      "iter 1420 ---  Loss: 2.722089998424053    Accuracy: 88.75\n",
      "iter 1421 ---  Loss: 2.9752273857593536    Accuracy: 89.0625\n",
      "iter 1422 ---  Loss: 2.748484767973423    Accuracy: 87.96875\n",
      "iter 1423 ---  Loss: 2.8194394037127495    Accuracy: 86.71875\n",
      "iter 1424 ---  Loss: 2.932998940348625    Accuracy: 86.25\n",
      "iter 1425 ---  Loss: 2.7349940836429596    Accuracy: 87.34375\n",
      "iter 1426 ---  Loss: 3.1367692202329636    Accuracy: 87.03125\n",
      "iter 1427 ---  Loss: 3.2811281085014343    Accuracy: 87.96875\n",
      "iter 1428 ---  Loss: 2.8551403880119324    Accuracy: 88.28125\n",
      "iter 1429 ---  Loss: 2.94476767629385    Accuracy: 87.8125\n",
      "iter 1430 ---  Loss: 2.9064939618110657    Accuracy: 86.40625\n",
      "iter 1431 ---  Loss: 2.69948148727417    Accuracy: 90.15625\n",
      "iter 1432 ---  Loss: 3.24755572527647    Accuracy: 86.25\n",
      "iter 1433 ---  Loss: 2.822790615260601    Accuracy: 89.84375\n",
      "iter 1434 ---  Loss: 2.867983654141426    Accuracy: 88.125\n",
      "iter 1435 ---  Loss: 2.7447886243462563    Accuracy: 87.65625\n",
      "iter 1436 ---  Loss: 3.1834164187312126    Accuracy: 87.03125\n",
      "iter 1437 ---  Loss: 3.58554270863533    Accuracy: 85.78125\n",
      "iter 1438 ---  Loss: 3.040253296494484    Accuracy: 89.0625\n",
      "iter 1439 ---  Loss: 2.8220961689949036    Accuracy: 88.59375\n",
      "iter 1440 ---  Loss: 3.013736844062805    Accuracy: 87.96875\n",
      "iter 1441 ---  Loss: 3.031075432896614    Accuracy: 88.75\n",
      "iter 1442 ---  Loss: 3.013272762298584    Accuracy: 89.375\n",
      "iter 1443 ---  Loss: 3.399543382227421    Accuracy: 86.71875\n",
      "iter 1444 ---  Loss: 2.640789158642292    Accuracy: 89.0625\n",
      "iter 1445 ---  Loss: 2.7944108471274376    Accuracy: 87.5\n",
      "iter 1446 ---  Loss: 3.116822399199009    Accuracy: 88.75\n",
      "iter 1447 ---  Loss: 3.340929836034775    Accuracy: 86.09375\n",
      "iter 1448 ---  Loss: 3.3261100202798843    Accuracy: 85.78125\n",
      "iter 1449 ---  Loss: 3.3668858855962753    Accuracy: 88.125\n",
      "iter 1450 ---  Loss: 3.6303515136241913    Accuracy: 86.875\n",
      "iter 1451 ---  Loss: 3.853467620909214    Accuracy: 85.3125\n",
      "iter 1452 ---  Loss: 3.570752777159214    Accuracy: 87.8125\n",
      "iter 1453 ---  Loss: 3.1923196390271187    Accuracy: 88.4375\n",
      "iter 1454 ---  Loss: 2.824691243469715    Accuracy: 85.3125\n",
      "iter 1455 ---  Loss: 3.3664273619651794    Accuracy: 85.9375\n",
      "iter 1456 ---  Loss: 3.758468449115753    Accuracy: 87.65625\n",
      "iter 1457 ---  Loss: 3.5064914748072624    Accuracy: 88.125\n",
      "iter 1458 ---  Loss: 2.6724111288785934    Accuracy: 88.75\n",
      "iter 1459 ---  Loss: 3.0185558050870895    Accuracy: 87.34375\n",
      "iter 1460 ---  Loss: 2.9281091690063477    Accuracy: 87.96875\n",
      "iter 1461 ---  Loss: 3.1025286093354225    Accuracy: 86.40625\n",
      "iter 1462 ---  Loss: 2.991279810667038    Accuracy: 87.5\n",
      "iter 1463 ---  Loss: 3.25360619276762    Accuracy: 89.84375\n",
      "iter 1464 ---  Loss: 3.0893192291259766    Accuracy: 87.65625\n",
      "iter 1465 ---  Loss: 3.202234908938408    Accuracy: 87.8125\n",
      "iter 1466 ---  Loss: 2.643496073782444    Accuracy: 87.34375\n",
      "iter 1467 ---  Loss: 3.5461779683828354    Accuracy: 88.28125\n",
      "iter 1468 ---  Loss: 3.186710000038147    Accuracy: 86.5625\n",
      "iter 1469 ---  Loss: 3.257865585386753    Accuracy: 87.65625\n",
      "iter 1470 ---  Loss: 3.3190834894776344    Accuracy: 85.0\n",
      "iter 1471 ---  Loss: 2.8724773973226547    Accuracy: 87.34375\n",
      "iter 1472 ---  Loss: 2.8803039714694023    Accuracy: 86.40625\n",
      "iter 1473 ---  Loss: 2.9733590111136436    Accuracy: 87.03125\n",
      "iter 1474 ---  Loss: 2.9836362451314926    Accuracy: 87.03125\n",
      "iter 1475 ---  Loss: 3.029313772916794    Accuracy: 88.59375\n",
      "iter 1476 ---  Loss: 2.6057533621788025    Accuracy: 89.6875\n",
      "iter 1477 ---  Loss: 3.678419180214405    Accuracy: 85.3125\n",
      "iter 1478 ---  Loss: 3.1787470504641533    Accuracy: 89.6875\n",
      "iter 1479 ---  Loss: 3.1287717819213867    Accuracy: 86.71875\n",
      "iter 1480 ---  Loss: 3.277362622320652    Accuracy: 86.875\n",
      "iter 1481 ---  Loss: 2.70800269395113    Accuracy: 88.59375\n",
      "iter 1482 ---  Loss: 3.533926285803318    Accuracy: 86.40625\n",
      "iter 1483 ---  Loss: 2.7585230469703674    Accuracy: 87.96875\n",
      "iter 1484 ---  Loss: 3.6095291674137115    Accuracy: 86.5625\n",
      "iter 1485 ---  Loss: 3.5334947258234024    Accuracy: 87.8125\n",
      "iter 1486 ---  Loss: 2.950445532798767    Accuracy: 86.875\n",
      "iter 1487 ---  Loss: 3.2932960465550423    Accuracy: 87.1875\n",
      "iter 1488 ---  Loss: 3.1572043523192406    Accuracy: 86.40625\n",
      "iter 1489 ---  Loss: 2.83175390958786    Accuracy: 85.78125\n",
      "iter 1490 ---  Loss: 2.600359171628952    Accuracy: 88.125\n",
      "iter 1491 ---  Loss: 3.040203407406807    Accuracy: 88.90625\n",
      "iter 1492 ---  Loss: 2.837103821337223    Accuracy: 87.96875\n",
      "iter 1493 ---  Loss: 3.1766199097037315    Accuracy: 86.875\n",
      "iter 1494 ---  Loss: 3.6128902286291122    Accuracy: 86.09375\n",
      "iter 1495 ---  Loss: 3.090712323784828    Accuracy: 87.03125\n",
      "iter 1496 ---  Loss: 2.5902077555656433    Accuracy: 89.375\n",
      "iter 1497 ---  Loss: 2.5982464402914047    Accuracy: 89.375\n",
      "iter 1498 ---  Loss: 2.938495434820652    Accuracy: 89.375\n",
      "iter 1499 ---  Loss: 2.7266079634428024    Accuracy: 87.8125\n",
      "iter 1500 ---  Loss: 2.6747542545199394    Accuracy: 88.28125\n",
      "iter 1501 ---  Loss: 2.8704045489430428    Accuracy: 87.03125\n",
      "iter 1502 ---  Loss: 2.831269159913063    Accuracy: 90.0\n",
      "iter 1503 ---  Loss: 2.681541368365288    Accuracy: 87.8125\n",
      "iter 1504 ---  Loss: 2.898125357925892    Accuracy: 88.90625\n",
      "iter 1505 ---  Loss: 2.4617945179343224    Accuracy: 88.125\n",
      "iter 1506 ---  Loss: 2.8877847492694855    Accuracy: 89.21875\n",
      "iter 1507 ---  Loss: 3.41397912055254    Accuracy: 86.40625\n",
      "iter 1508 ---  Loss: 3.1735001504421234    Accuracy: 89.21875\n",
      "iter 1509 ---  Loss: 2.733421988785267    Accuracy: 89.0625\n",
      "iter 1510 ---  Loss: 2.8917335271835327    Accuracy: 87.65625\n",
      "iter 1511 ---  Loss: 3.2814912497997284    Accuracy: 85.0\n",
      "iter 1512 ---  Loss: 2.8988984301686287    Accuracy: 88.28125\n",
      "iter 1513 ---  Loss: 3.454898439347744    Accuracy: 86.71875\n",
      "iter 1514 ---  Loss: 2.5294420570135117    Accuracy: 88.4375\n",
      "iter 1515 ---  Loss: 3.407213844358921    Accuracy: 85.9375\n",
      "iter 1516 ---  Loss: 3.3054689839482307    Accuracy: 88.125\n",
      "iter 1517 ---  Loss: 3.657105065882206    Accuracy: 87.03125\n",
      "iter 1518 ---  Loss: 3.220745511353016    Accuracy: 87.1875\n",
      "iter 1519 ---  Loss: 2.471291959285736    Accuracy: 89.0625\n",
      "iter 1520 ---  Loss: 2.9508113265037537    Accuracy: 88.90625\n",
      "iter 1521 ---  Loss: 3.3138472735881805    Accuracy: 85.9375\n",
      "iter 1522 ---  Loss: 3.9001793041825294    Accuracy: 87.5\n",
      "iter 1523 ---  Loss: 3.426325425505638    Accuracy: 86.875\n",
      "iter 1524 ---  Loss: 4.080670513212681    Accuracy: 87.1875\n",
      "iter 1525 ---  Loss: 3.0286934450268745    Accuracy: 88.125\n",
      "iter 1526 ---  Loss: 3.2093764916062355    Accuracy: 85.625\n",
      "iter 1527 ---  Loss: 3.1474763825535774    Accuracy: 87.8125\n",
      "iter 1528 ---  Loss: 2.8525436595082283    Accuracy: 86.875\n",
      "iter 1529 ---  Loss: 3.338345445692539    Accuracy: 87.34375\n",
      "iter 1530 ---  Loss: 3.24815334379673    Accuracy: 87.8125\n",
      "iter 1531 ---  Loss: 2.7128412276506424    Accuracy: 87.03125\n",
      "iter 1532 ---  Loss: 2.6584219709038734    Accuracy: 87.96875\n",
      "iter 1533 ---  Loss: 2.8327560126781464    Accuracy: 88.75\n",
      "iter 1534 ---  Loss: 2.542517304420471    Accuracy: 88.125\n",
      "iter 1535 ---  Loss: 3.0569045916199684    Accuracy: 87.8125\n",
      "iter 1536 ---  Loss: 3.1846930608153343    Accuracy: 87.65625\n",
      "iter 1537 ---  Loss: 3.7413337752223015    Accuracy: 87.1875\n",
      "iter 1538 ---  Loss: 3.355165958404541    Accuracy: 86.5625\n",
      "iter 1539 ---  Loss: 3.1881873682141304    Accuracy: 90.15625\n",
      "iter 1540 ---  Loss: 3.230863928794861    Accuracy: 85.46875\n",
      "iter 1541 ---  Loss: 3.895756110548973    Accuracy: 87.65625\n",
      "iter 1542 ---  Loss: 3.2432645186781883    Accuracy: 85.9375\n",
      "iter 1543 ---  Loss: 2.9678845703601837    Accuracy: 87.03125\n",
      "iter 1544 ---  Loss: 2.8906047344207764    Accuracy: 88.90625\n",
      "iter 1545 ---  Loss: 2.944490283727646    Accuracy: 87.96875\n",
      "iter 1546 ---  Loss: 2.807621121406555    Accuracy: 89.21875\n",
      "iter 1547 ---  Loss: 3.1196029260754585    Accuracy: 87.96875\n",
      "iter 1548 ---  Loss: 2.7126810997724533    Accuracy: 89.53125\n",
      "iter 1549 ---  Loss: 2.894459992647171    Accuracy: 88.4375\n",
      "iter 1550 ---  Loss: 3.5956626683473587    Accuracy: 86.875\n",
      "iter 1551 ---  Loss: 3.193495959043503    Accuracy: 87.34375\n",
      "iter 1552 ---  Loss: 3.1621163561940193    Accuracy: 88.125\n",
      "iter 1553 ---  Loss: 2.9522441402077675    Accuracy: 85.9375\n",
      "iter 1554 ---  Loss: 2.8125670477747917    Accuracy: 88.4375\n",
      "iter 1555 ---  Loss: 3.242453061044216    Accuracy: 87.8125\n",
      "iter 1556 ---  Loss: 2.6221979707479477    Accuracy: 88.75\n",
      "iter 1557 ---  Loss: 2.53744126111269    Accuracy: 88.28125\n",
      "iter 1558 ---  Loss: 2.4313825890421867    Accuracy: 91.09375\n",
      "iter 1559 ---  Loss: 3.1720350980758667    Accuracy: 87.8125\n",
      "iter 1560 ---  Loss: 3.223199002444744    Accuracy: 86.5625\n",
      "iter 1561 ---  Loss: 2.74173341691494    Accuracy: 87.8125\n",
      "iter 1562 ---  Loss: 2.732583038508892    Accuracy: 87.5\n",
      "iter 1563 ---  Loss: 2.6601568683981895    Accuracy: 87.34375\n",
      "iter 1564 ---  Loss: 3.630905658006668    Accuracy: 85.78125\n",
      "iter 1565 ---  Loss: 2.621885769069195    Accuracy: 89.6875\n",
      "iter 1566 ---  Loss: 3.0533440187573433    Accuracy: 86.40625\n",
      "iter 1567 ---  Loss: 2.635597102344036    Accuracy: 88.4375\n",
      "iter 1568 ---  Loss: 3.2250000536441803    Accuracy: 89.84375\n",
      "iter 1569 ---  Loss: 3.1476901322603226    Accuracy: 88.59375\n",
      "iter 1570 ---  Loss: 2.978322744369507    Accuracy: 87.34375\n",
      "iter 1571 ---  Loss: 2.6705911606550217    Accuracy: 89.53125\n",
      "iter 1572 ---  Loss: 2.8437319844961166    Accuracy: 89.53125\n",
      "iter 1573 ---  Loss: 2.7354485243558884    Accuracy: 88.90625\n",
      "iter 1574 ---  Loss: 2.458234876394272    Accuracy: 90.15625\n",
      "iter 1575 ---  Loss: 3.0177263244986534    Accuracy: 88.28125\n",
      "iter 1576 ---  Loss: 3.0671366527676582    Accuracy: 88.125\n",
      "iter 1577 ---  Loss: 2.909654386341572    Accuracy: 90.0\n",
      "iter 1578 ---  Loss: 3.460138224065304    Accuracy: 85.9375\n",
      "iter 1579 ---  Loss: 2.93989035487175    Accuracy: 87.8125\n",
      "iter 1580 ---  Loss: 2.5673868730664253    Accuracy: 87.65625\n",
      "iter 1581 ---  Loss: 3.5521847382187843    Accuracy: 86.875\n",
      "iter 1582 ---  Loss: 3.5033289790153503    Accuracy: 87.34375\n",
      "iter 1583 ---  Loss: 3.25131181627512    Accuracy: 84.84375\n",
      "iter 1584 ---  Loss: 3.014816500246525    Accuracy: 86.25\n",
      "iter 1585 ---  Loss: 2.967638596892357    Accuracy: 87.5\n",
      "iter 1586 ---  Loss: 2.7764083966612816    Accuracy: 88.28125\n",
      "iter 1587 ---  Loss: 3.664749041199684    Accuracy: 87.34375\n",
      "iter 1588 ---  Loss: 3.6322695910930634    Accuracy: 85.625\n",
      "iter 1589 ---  Loss: 3.270883895456791    Accuracy: 88.125\n",
      "iter 1590 ---  Loss: 3.0191649720072746    Accuracy: 87.96875\n",
      "iter 1591 ---  Loss: 3.2889359146356583    Accuracy: 85.3125\n",
      "iter 1592 ---  Loss: 3.3466246351599693    Accuracy: 88.125\n",
      "iter 1593 ---  Loss: 2.6274146884679794    Accuracy: 87.5\n",
      "iter 1594 ---  Loss: 3.5688739269971848    Accuracy: 86.09375\n",
      "iter 1595 ---  Loss: 2.792982041835785    Accuracy: 86.25\n",
      "iter 1596 ---  Loss: 2.8028342947363853    Accuracy: 89.0625\n",
      "iter 1597 ---  Loss: 3.532844841480255    Accuracy: 86.71875\n",
      "iter 1598 ---  Loss: 3.3842977061867714    Accuracy: 86.71875\n",
      "iter 1599 ---  Loss: 3.345161460340023    Accuracy: 88.90625\n",
      "iter 1600 ---  Loss: 2.9293870478868484    Accuracy: 87.96875\n",
      "iter 1601 ---  Loss: 2.3201799243688583    Accuracy: 88.75\n",
      "iter 1602 ---  Loss: 2.7008248642086983    Accuracy: 89.53125\n",
      "iter 1603 ---  Loss: 2.8950421437621117    Accuracy: 88.125\n",
      "iter 1604 ---  Loss: 3.1041540130972862    Accuracy: 87.03125\n",
      "iter 1605 ---  Loss: 3.080283410847187    Accuracy: 89.6875\n",
      "iter 1606 ---  Loss: 3.1887386441230774    Accuracy: 86.875\n",
      "iter 1607 ---  Loss: 3.05025315284729    Accuracy: 87.65625\n",
      "iter 1608 ---  Loss: 2.65069343149662    Accuracy: 87.65625\n",
      "iter 1609 ---  Loss: 2.926717907190323    Accuracy: 87.65625\n",
      "iter 1610 ---  Loss: 3.488289996981621    Accuracy: 87.34375\n",
      "iter 1611 ---  Loss: 3.285726025700569    Accuracy: 87.65625\n",
      "iter 1612 ---  Loss: 2.673195354640484    Accuracy: 88.28125\n",
      "iter 1613 ---  Loss: 3.127886213362217    Accuracy: 85.3125\n",
      "iter 1614 ---  Loss: 2.990850232541561    Accuracy: 90.625\n",
      "iter 1615 ---  Loss: 3.2872970923781395    Accuracy: 86.25\n",
      "iter 1616 ---  Loss: 3.2443924248218536    Accuracy: 84.0625\n",
      "iter 1617 ---  Loss: 2.6739868447184563    Accuracy: 88.75\n",
      "iter 1618 ---  Loss: 2.6904511228203773    Accuracy: 88.59375\n",
      "iter 1619 ---  Loss: 3.0456748083233833    Accuracy: 88.125\n",
      "iter 1620 ---  Loss: 3.2789693623781204    Accuracy: 87.96875\n",
      "iter 1621 ---  Loss: 3.645399384200573    Accuracy: 85.78125\n",
      "iter 1622 ---  Loss: 2.81744647026062    Accuracy: 88.59375\n",
      "iter 1623 ---  Loss: 2.9875325188040733    Accuracy: 88.90625\n",
      "iter 1624 ---  Loss: 2.715342231094837    Accuracy: 89.53125\n",
      "iter 1625 ---  Loss: 3.6648387014865875    Accuracy: 85.46875\n",
      "iter 1626 ---  Loss: 2.5908924862742424    Accuracy: 89.6875\n",
      "iter 1627 ---  Loss: 3.0514136403799057    Accuracy: 87.8125\n",
      "iter 1628 ---  Loss: 2.78067734092474    Accuracy: 88.59375\n",
      "iter 1629 ---  Loss: 2.798026330769062    Accuracy: 87.65625\n",
      "iter 1630 ---  Loss: 3.291936218738556    Accuracy: 86.875\n",
      "iter 1631 ---  Loss: 3.4926546663045883    Accuracy: 85.9375\n",
      "iter 1632 ---  Loss: 3.5840028524398804    Accuracy: 87.8125\n",
      "iter 1633 ---  Loss: 3.178858682513237    Accuracy: 86.875\n",
      "iter 1634 ---  Loss: 2.789660483598709    Accuracy: 88.4375\n",
      "iter 1635 ---  Loss: 3.273114889860153    Accuracy: 86.25\n",
      "iter 1636 ---  Loss: 3.2796769216656685    Accuracy: 87.03125\n",
      "iter 1637 ---  Loss: 3.7980778589844704    Accuracy: 86.71875\n",
      "iter 1638 ---  Loss: 2.6930198967456818    Accuracy: 87.34375\n",
      "iter 1639 ---  Loss: 3.1488106548786163    Accuracy: 86.40625\n",
      "iter 1640 ---  Loss: 3.244310073554516    Accuracy: 87.96875\n",
      "iter 1641 ---  Loss: 3.0167108327150345    Accuracy: 87.03125\n",
      "iter 1642 ---  Loss: 2.731782950460911    Accuracy: 88.75\n",
      "iter 1643 ---  Loss: 3.224787950515747    Accuracy: 87.8125\n",
      "iter 1644 ---  Loss: 3.7068176865577698    Accuracy: 87.5\n",
      "iter 1645 ---  Loss: 3.4482146352529526    Accuracy: 85.78125\n",
      "iter 1646 ---  Loss: 2.8806321173906326    Accuracy: 87.8125\n",
      "iter 1647 ---  Loss: 2.826487675309181    Accuracy: 88.125\n",
      "iter 1648 ---  Loss: 2.587037906050682    Accuracy: 88.75\n",
      "iter 1649 ---  Loss: 2.767690360546112    Accuracy: 86.25\n",
      "iter 1650 ---  Loss: 2.77543044090271    Accuracy: 87.34375\n",
      "iter 1651 ---  Loss: 2.866370625793934    Accuracy: 90.0\n",
      "iter 1652 ---  Loss: 2.853777974843979    Accuracy: 87.5\n",
      "iter 1653 ---  Loss: 2.594459444284439    Accuracy: 89.53125\n",
      "iter 1654 ---  Loss: 3.0057200491428375    Accuracy: 88.59375\n",
      "iter 1655 ---  Loss: 3.5058612897992134    Accuracy: 87.5\n",
      "iter 1656 ---  Loss: 3.2460227981209755    Accuracy: 87.8125\n",
      "iter 1657 ---  Loss: 2.8917101100087166    Accuracy: 87.34375\n",
      "iter 1658 ---  Loss: 2.79441087692976    Accuracy: 87.34375\n",
      "iter 1659 ---  Loss: 2.6945043057203293    Accuracy: 88.59375\n",
      "iter 1660 ---  Loss: 3.072091370820999    Accuracy: 87.65625\n",
      "iter 1661 ---  Loss: 3.6751814112067223    Accuracy: 86.71875\n",
      "iter 1662 ---  Loss: 2.746054619550705    Accuracy: 88.59375\n",
      "iter 1663 ---  Loss: 2.594527281820774    Accuracy: 90.15625\n",
      "iter 1664 ---  Loss: 2.739404931664467    Accuracy: 88.75\n",
      "iter 1665 ---  Loss: 2.8755182325839996    Accuracy: 88.90625\n",
      "iter 1666 ---  Loss: 2.625194564461708    Accuracy: 89.375\n",
      "iter 1667 ---  Loss: 3.0303674712777138    Accuracy: 86.40625\n",
      "iter 1668 ---  Loss: 2.795135587453842    Accuracy: 86.875\n",
      "iter 1669 ---  Loss: 3.1603181287646294    Accuracy: 86.25\n",
      "iter 1670 ---  Loss: 3.18551155179739    Accuracy: 87.8125\n",
      "iter 1671 ---  Loss: 2.7833024859428406    Accuracy: 88.4375\n",
      "iter 1672 ---  Loss: 2.5237101688981056    Accuracy: 88.59375\n",
      "iter 1673 ---  Loss: 3.514952801167965    Accuracy: 88.75\n",
      "iter 1674 ---  Loss: 3.1900250986218452    Accuracy: 87.1875\n",
      "iter 1675 ---  Loss: 3.3885303512215614    Accuracy: 87.65625\n",
      "iter 1676 ---  Loss: 3.0648288503289223    Accuracy: 88.90625\n",
      "iter 1677 ---  Loss: 3.030396819114685    Accuracy: 88.125\n",
      "iter 1678 ---  Loss: 2.309870272874832    Accuracy: 90.3125\n",
      "iter 1679 ---  Loss: 2.922503724694252    Accuracy: 87.34375\n",
      "iter 1680 ---  Loss: 2.965872623026371    Accuracy: 88.125\n",
      "iter 1681 ---  Loss: 3.111025683581829    Accuracy: 85.46875\n",
      "iter 1682 ---  Loss: 3.351401761174202    Accuracy: 86.875\n",
      "iter 1683 ---  Loss: 3.181662440299988    Accuracy: 87.65625\n",
      "iter 1684 ---  Loss: 3.186999522149563    Accuracy: 88.75\n",
      "iter 1685 ---  Loss: 3.3362378999590874    Accuracy: 86.875\n",
      "iter 1686 ---  Loss: 2.532724529504776    Accuracy: 87.96875\n",
      "iter 1687 ---  Loss: 2.876621074974537    Accuracy: 88.75\n",
      "iter 1688 ---  Loss: 3.0025187730789185    Accuracy: 89.375\n",
      "iter 1689 ---  Loss: 2.822107471525669    Accuracy: 86.25\n",
      "iter 1690 ---  Loss: 2.97020360827446    Accuracy: 88.125\n",
      "iter 1691 ---  Loss: 2.7704729586839676    Accuracy: 87.8125\n",
      "iter 1692 ---  Loss: 2.8950552493333817    Accuracy: 88.59375\n",
      "iter 1693 ---  Loss: 2.7490814328193665    Accuracy: 88.90625\n",
      "iter 1694 ---  Loss: 3.1168431863188744    Accuracy: 89.21875\n",
      "iter 1695 ---  Loss: 3.4513411968946457    Accuracy: 87.65625\n",
      "iter 1696 ---  Loss: 3.3883836790919304    Accuracy: 87.8125\n",
      "iter 1697 ---  Loss: 2.9331724867224693    Accuracy: 87.96875\n",
      "iter 1698 ---  Loss: 2.524666242301464    Accuracy: 89.6875\n",
      "iter 1699 ---  Loss: 2.952585034072399    Accuracy: 85.625\n",
      "iter 1700 ---  Loss: 3.2036192789673805    Accuracy: 86.875\n",
      "iter 1701 ---  Loss: 2.7803419455885887    Accuracy: 87.8125\n",
      "iter 1702 ---  Loss: 3.019657716155052    Accuracy: 88.75\n",
      "iter 1703 ---  Loss: 2.8940048664808273    Accuracy: 88.90625\n",
      "iter 1704 ---  Loss: 2.9575396552681923    Accuracy: 87.8125\n",
      "iter 1705 ---  Loss: 3.0516628101468086    Accuracy: 86.25\n",
      "iter 1706 ---  Loss: 3.2574099972844124    Accuracy: 85.625\n",
      "iter 1707 ---  Loss: 2.8966036960482597    Accuracy: 89.375\n",
      "iter 1708 ---  Loss: 2.9721746742725372    Accuracy: 86.875\n",
      "iter 1709 ---  Loss: 3.170820787549019    Accuracy: 87.96875\n",
      "iter 1710 ---  Loss: 3.0700452476739883    Accuracy: 87.5\n",
      "iter 1711 ---  Loss: 3.2783923894166946    Accuracy: 87.1875\n",
      "iter 1712 ---  Loss: 2.89738392829895    Accuracy: 87.34375\n",
      "iter 1713 ---  Loss: 3.208929568529129    Accuracy: 86.5625\n",
      "iter 1714 ---  Loss: 2.980439968407154    Accuracy: 86.71875\n",
      "iter 1715 ---  Loss: 2.616289995610714    Accuracy: 88.59375\n",
      "iter 1716 ---  Loss: 3.3201506212353706    Accuracy: 87.1875\n",
      "iter 1717 ---  Loss: 3.1639543399214745    Accuracy: 87.03125\n",
      "iter 1718 ---  Loss: 3.1760900616645813    Accuracy: 86.09375\n",
      "iter 1719 ---  Loss: 2.8338929414749146    Accuracy: 89.84375\n",
      "iter 1720 ---  Loss: 3.096687614917755    Accuracy: 87.65625\n",
      "iter 1721 ---  Loss: 3.4611887112259865    Accuracy: 87.8125\n",
      "iter 1722 ---  Loss: 2.9938330575823784    Accuracy: 86.09375\n",
      "iter 1723 ---  Loss: 3.087765410542488    Accuracy: 88.4375\n",
      "iter 1724 ---  Loss: 2.89261557161808    Accuracy: 88.28125\n",
      "iter 1725 ---  Loss: 3.5875346437096596    Accuracy: 86.25\n",
      "iter 1726 ---  Loss: 3.035800226032734    Accuracy: 85.9375\n",
      "iter 1727 ---  Loss: 2.880072608590126    Accuracy: 86.71875\n",
      "iter 1728 ---  Loss: 2.626754902303219    Accuracy: 87.5\n",
      "iter 1729 ---  Loss: 2.877539038658142    Accuracy: 87.5\n",
      "iter 1730 ---  Loss: 2.840408094227314    Accuracy: 88.4375\n",
      "iter 1731 ---  Loss: 2.9029176980257034    Accuracy: 90.0\n",
      "iter 1732 ---  Loss: 3.3509457036852837    Accuracy: 87.96875\n",
      "iter 1733 ---  Loss: 3.1796822994947433    Accuracy: 85.3125\n",
      "iter 1734 ---  Loss: 3.543058954179287    Accuracy: 87.65625\n",
      "iter 1735 ---  Loss: 3.296339899301529    Accuracy: 86.25\n",
      "iter 1736 ---  Loss: 3.1699133217334747    Accuracy: 88.4375\n",
      "iter 1737 ---  Loss: 3.0698845833539963    Accuracy: 86.71875\n",
      "iter 1738 ---  Loss: 3.926726348698139    Accuracy: 86.09375\n",
      "iter 1739 ---  Loss: 2.9370964616537094    Accuracy: 87.5\n",
      "iter 1740 ---  Loss: 2.604433983564377    Accuracy: 88.90625\n",
      "iter 1741 ---  Loss: 3.484949879348278    Accuracy: 87.65625\n",
      "iter 1742 ---  Loss: 2.9774142131209373    Accuracy: 88.75\n",
      "iter 1743 ---  Loss: 3.320549212396145    Accuracy: 86.5625\n",
      "iter 1744 ---  Loss: 2.732058085501194    Accuracy: 87.96875\n",
      "iter 1745 ---  Loss: 3.2807008400559425    Accuracy: 86.5625\n",
      "iter 1746 ---  Loss: 3.2994353994727135    Accuracy: 87.65625\n",
      "iter 1747 ---  Loss: 3.0902492627501488    Accuracy: 88.4375\n",
      "iter 1748 ---  Loss: 4.261540845036507    Accuracy: 84.84375\n",
      "iter 1749 ---  Loss: 2.9909547716379166    Accuracy: 88.125\n",
      "iter 1750 ---  Loss: 2.9858135655522346    Accuracy: 88.125\n",
      "iter 1751 ---  Loss: 3.215726263821125    Accuracy: 88.4375\n",
      "iter 1752 ---  Loss: 3.028237968683243    Accuracy: 87.5\n",
      "iter 1753 ---  Loss: 3.347223863005638    Accuracy: 87.96875\n",
      "iter 1754 ---  Loss: 3.0582977011799812    Accuracy: 85.9375\n",
      "iter 1755 ---  Loss: 3.179494872689247    Accuracy: 87.5\n",
      "iter 1756 ---  Loss: 2.9402681291103363    Accuracy: 89.6875\n",
      "iter 1757 ---  Loss: 2.804496757686138    Accuracy: 87.96875\n",
      "iter 1758 ---  Loss: 3.3879815489053726    Accuracy: 84.53125\n",
      "iter 1759 ---  Loss: 3.040837600827217    Accuracy: 87.5\n",
      "iter 1760 ---  Loss: 2.980341337621212    Accuracy: 87.5\n",
      "iter 1761 ---  Loss: 3.19768238812685    Accuracy: 86.875\n",
      "iter 1762 ---  Loss: 3.40487602353096    Accuracy: 87.96875\n",
      "iter 1763 ---  Loss: 2.6542434319853783    Accuracy: 88.90625\n",
      "iter 1764 ---  Loss: 3.155529648065567    Accuracy: 86.5625\n",
      "iter 1765 ---  Loss: 2.8218971863389015    Accuracy: 89.53125\n",
      "iter 1766 ---  Loss: 2.8718686997890472    Accuracy: 87.5\n",
      "iter 1767 ---  Loss: 3.505738817155361    Accuracy: 86.71875\n",
      "iter 1768 ---  Loss: 2.8311014026403427    Accuracy: 89.375\n",
      "iter 1769 ---  Loss: 3.266884855926037    Accuracy: 88.59375\n",
      "iter 1770 ---  Loss: 2.949159651994705    Accuracy: 87.34375\n",
      "iter 1771 ---  Loss: 3.453687384724617    Accuracy: 87.96875\n",
      "iter 1772 ---  Loss: 3.7393363788723946    Accuracy: 86.09375\n",
      "iter 1773 ---  Loss: 2.9619122594594955    Accuracy: 88.59375\n",
      "iter 1774 ---  Loss: 2.7860813066363335    Accuracy: 88.4375\n",
      "iter 1775 ---  Loss: 2.696123093366623    Accuracy: 87.96875\n",
      "iter 1776 ---  Loss: 2.916089065372944    Accuracy: 87.8125\n",
      "iter 1777 ---  Loss: 3.0981061309576035    Accuracy: 86.875\n",
      "iter 1778 ---  Loss: 2.511522963643074    Accuracy: 88.28125\n",
      "iter 1779 ---  Loss: 2.896046906709671    Accuracy: 87.96875\n",
      "iter 1780 ---  Loss: 2.8294426575303078    Accuracy: 87.96875\n",
      "iter 1781 ---  Loss: 3.2986867651343346    Accuracy: 87.5\n",
      "iter 1782 ---  Loss: 3.2906774058938026    Accuracy: 87.96875\n",
      "iter 1783 ---  Loss: 3.4858802556991577    Accuracy: 86.875\n",
      "iter 1784 ---  Loss: 2.832348011434078    Accuracy: 87.8125\n",
      "iter 1785 ---  Loss: 4.097468413412571    Accuracy: 85.15625\n",
      "iter 1786 ---  Loss: 2.6084866672754288    Accuracy: 88.28125\n",
      "iter 1787 ---  Loss: 2.743351362645626    Accuracy: 88.125\n",
      "iter 1788 ---  Loss: 3.086939714848995    Accuracy: 87.1875\n",
      "iter 1789 ---  Loss: 2.708565004169941    Accuracy: 87.96875\n",
      "iter 1790 ---  Loss: 3.1470699682831764    Accuracy: 86.5625\n",
      "iter 1791 ---  Loss: 3.1697665750980377    Accuracy: 86.875\n",
      "iter 1792 ---  Loss: 3.448111914098263    Accuracy: 85.625\n",
      "iter 1793 ---  Loss: 2.834575057029724    Accuracy: 87.03125\n",
      "iter 1794 ---  Loss: 3.2476330623030663    Accuracy: 86.71875\n",
      "iter 1795 ---  Loss: 2.8174807652831078    Accuracy: 87.8125\n",
      "iter 1796 ---  Loss: 3.353670097887516    Accuracy: 86.71875\n",
      "iter 1797 ---  Loss: 2.548479124903679    Accuracy: 89.0625\n",
      "iter 1798 ---  Loss: 2.5495545491576195    Accuracy: 88.90625\n",
      "iter 1799 ---  Loss: 2.44348856061697    Accuracy: 88.4375\n",
      "iter 1800 ---  Loss: 3.593777820467949    Accuracy: 85.9375\n",
      "iter 1801 ---  Loss: 3.255326919257641    Accuracy: 86.875\n",
      "iter 1802 ---  Loss: 3.8749494701623917    Accuracy: 85.3125\n",
      "iter 1803 ---  Loss: 2.8837712854146957    Accuracy: 86.875\n",
      "iter 1804 ---  Loss: 2.9994622841477394    Accuracy: 86.09375\n",
      "iter 1805 ---  Loss: 3.4874810948967934    Accuracy: 83.75\n",
      "iter 1806 ---  Loss: 3.438904248178005    Accuracy: 88.4375\n",
      "iter 1807 ---  Loss: 3.0766905769705772    Accuracy: 87.96875\n",
      "iter 1808 ---  Loss: 3.631146401166916    Accuracy: 86.40625\n",
      "iter 1809 ---  Loss: 3.046916224062443    Accuracy: 87.65625\n",
      "iter 1810 ---  Loss: 3.3023699894547462    Accuracy: 86.09375\n",
      "iter 1811 ---  Loss: 2.8912544921040535    Accuracy: 87.8125\n",
      "iter 1812 ---  Loss: 3.479874365031719    Accuracy: 85.46875\n",
      "iter 1813 ---  Loss: 3.37996394187212    Accuracy: 85.3125\n",
      "iter 1814 ---  Loss: 2.907353773713112    Accuracy: 88.4375\n",
      "iter 1815 ---  Loss: 2.701980195939541    Accuracy: 88.59375\n",
      "iter 1816 ---  Loss: 3.4403055533766747    Accuracy: 85.625\n",
      "iter 1817 ---  Loss: 2.6635003238916397    Accuracy: 87.96875\n",
      "iter 1818 ---  Loss: 2.755737505853176    Accuracy: 87.8125\n",
      "iter 1819 ---  Loss: 2.8747415021061897    Accuracy: 85.78125\n",
      "iter 1820 ---  Loss: 2.9187623783946037    Accuracy: 87.1875\n",
      "iter 1821 ---  Loss: 3.3787555396556854    Accuracy: 85.46875\n",
      "iter 1822 ---  Loss: 3.1748534217476845    Accuracy: 87.96875\n",
      "iter 1823 ---  Loss: 3.0805767253041267    Accuracy: 87.8125\n",
      "iter 1824 ---  Loss: 2.5498957484960556    Accuracy: 87.5\n",
      "iter 1825 ---  Loss: 2.6615976244211197    Accuracy: 87.5\n",
      "iter 1826 ---  Loss: 2.9002451822161674    Accuracy: 87.5\n",
      "iter 1827 ---  Loss: 2.930878736078739    Accuracy: 87.5\n",
      "iter 1828 ---  Loss: 2.885685443878174    Accuracy: 87.8125\n",
      "iter 1829 ---  Loss: 3.274173744022846    Accuracy: 86.09375\n",
      "iter 1830 ---  Loss: 2.9175087958574295    Accuracy: 87.03125\n",
      "iter 1831 ---  Loss: 2.798027202486992    Accuracy: 88.125\n",
      "iter 1832 ---  Loss: 2.4447243362665176    Accuracy: 89.375\n",
      "iter 1833 ---  Loss: 3.0707521811127663    Accuracy: 86.875\n",
      "iter 1834 ---  Loss: 3.0080703273415565    Accuracy: 85.9375\n",
      "iter 1835 ---  Loss: 3.138120971620083    Accuracy: 86.09375\n",
      "iter 1836 ---  Loss: 2.904878184199333    Accuracy: 86.40625\n",
      "iter 1837 ---  Loss: 2.7494573891162872    Accuracy: 88.4375\n",
      "iter 1838 ---  Loss: 2.9177652820944786    Accuracy: 87.1875\n",
      "iter 1839 ---  Loss: 2.6869626715779305    Accuracy: 87.5\n",
      "iter 1840 ---  Loss: 3.2077233269810677    Accuracy: 86.875\n",
      "iter 1841 ---  Loss: 2.576596699655056    Accuracy: 87.1875\n",
      "iter 1842 ---  Loss: 2.8811666816473007    Accuracy: 88.28125\n",
      "iter 1843 ---  Loss: 3.3650812953710556    Accuracy: 86.09375\n",
      "iter 1844 ---  Loss: 2.5263321846723557    Accuracy: 87.34375\n",
      "iter 1845 ---  Loss: 2.7074512764811516    Accuracy: 88.75\n",
      "iter 1846 ---  Loss: 2.7099331468343735    Accuracy: 89.6875\n",
      "iter 1847 ---  Loss: 3.385315366089344    Accuracy: 85.9375\n",
      "iter 1848 ---  Loss: 3.3824887946248055    Accuracy: 86.25\n",
      "iter 1849 ---  Loss: 2.8067572861909866    Accuracy: 87.34375\n",
      "iter 1850 ---  Loss: 3.0249749198555946    Accuracy: 85.3125\n",
      "iter 1851 ---  Loss: 2.9529140293598175    Accuracy: 89.375\n",
      "iter 1852 ---  Loss: 3.07872923463583    Accuracy: 85.3125\n",
      "iter 1853 ---  Loss: 2.7120633125305176    Accuracy: 88.125\n",
      "iter 1854 ---  Loss: 2.7375483363866806    Accuracy: 87.96875\n",
      "iter 1855 ---  Loss: 2.9529262632131577    Accuracy: 88.59375\n",
      "iter 1856 ---  Loss: 3.2302409261465073    Accuracy: 86.71875\n",
      "iter 1857 ---  Loss: 2.8490832075476646    Accuracy: 88.28125\n",
      "iter 1858 ---  Loss: 2.9981915205717087    Accuracy: 87.1875\n",
      "iter 1859 ---  Loss: 3.549626663327217    Accuracy: 84.84375\n",
      "iter 1860 ---  Loss: 2.919029861688614    Accuracy: 87.65625\n",
      "iter 1861 ---  Loss: 3.089912988245487    Accuracy: 86.40625\n",
      "iter 1862 ---  Loss: 2.801688827574253    Accuracy: 87.5\n",
      "iter 1863 ---  Loss: 2.8655727431178093    Accuracy: 86.875\n",
      "iter 1864 ---  Loss: 3.4995006918907166    Accuracy: 86.71875\n",
      "iter 1865 ---  Loss: 3.2280482798814774    Accuracy: 87.8125\n",
      "iter 1866 ---  Loss: 3.335527151823044    Accuracy: 86.875\n",
      "iter 1867 ---  Loss: 3.3421286270022392    Accuracy: 84.375\n",
      "iter 1868 ---  Loss: 3.660403832793236    Accuracy: 85.0\n",
      "iter 1869 ---  Loss: 2.8395270854234695    Accuracy: 88.28125\n",
      "iter 1870 ---  Loss: 2.8227268680930138    Accuracy: 87.03125\n",
      "iter 1871 ---  Loss: 2.826136976480484    Accuracy: 88.125\n",
      "iter 1872 ---  Loss: 3.2854404598474503    Accuracy: 86.875\n",
      "iter 1873 ---  Loss: 2.55081557482481    Accuracy: 87.5\n",
      "iter 1874 ---  Loss: 2.937050797045231    Accuracy: 87.96875\n",
      "iter 1875 ---  Loss: 3.4664000496268272    Accuracy: 86.25\n",
      "iter 1876 ---  Loss: 2.832256980240345    Accuracy: 88.75\n",
      "iter 1877 ---  Loss: 2.869151495397091    Accuracy: 85.0\n",
      "iter 1878 ---  Loss: 3.1281088069081306    Accuracy: 84.6875\n",
      "iter 1879 ---  Loss: 3.1670438647270203    Accuracy: 86.5625\n",
      "iter 1880 ---  Loss: 4.595347687602043    Accuracy: 85.78125\n",
      "iter 1881 ---  Loss: 2.9244064539670944    Accuracy: 85.46875\n",
      "iter 1882 ---  Loss: 2.8582873195409775    Accuracy: 86.875\n",
      "iter 1883 ---  Loss: 2.3944314643740654    Accuracy: 89.6875\n",
      "iter 1884 ---  Loss: 2.8421793803572655    Accuracy: 86.09375\n",
      "iter 1885 ---  Loss: 3.2047221958637238    Accuracy: 87.8125\n",
      "iter 1886 ---  Loss: 3.473289743065834    Accuracy: 85.15625\n",
      "iter 1887 ---  Loss: 3.2773944810032845    Accuracy: 86.71875\n",
      "iter 1888 ---  Loss: 3.0904256999492645    Accuracy: 85.46875\n",
      "iter 1889 ---  Loss: 2.873622663319111    Accuracy: 87.5\n",
      "iter 1890 ---  Loss: 3.11052293330431    Accuracy: 88.4375\n",
      "iter 1891 ---  Loss: 2.8437626138329506    Accuracy: 86.5625\n",
      "iter 1892 ---  Loss: 3.642094612121582    Accuracy: 86.71875\n",
      "iter 1893 ---  Loss: 3.0461818277835846    Accuracy: 86.5625\n",
      "iter 1894 ---  Loss: 3.5075677931308746    Accuracy: 86.71875\n",
      "iter 1895 ---  Loss: 2.962471053004265    Accuracy: 89.0625\n",
      "iter 1896 ---  Loss: 3.270853742957115    Accuracy: 87.65625\n",
      "iter 1897 ---  Loss: 2.85288917273283    Accuracy: 89.0625\n",
      "iter 1898 ---  Loss: 2.8362342417240143    Accuracy: 87.65625\n",
      "iter 1899 ---  Loss: 3.1017671525478363    Accuracy: 86.71875\n",
      "iter 1900 ---  Loss: 2.41773883998394    Accuracy: 88.90625\n",
      "iter 1901 ---  Loss: 2.7601059079170227    Accuracy: 86.09375\n",
      "iter 1902 ---  Loss: 2.683573380112648    Accuracy: 89.0625\n",
      "iter 1903 ---  Loss: 3.229552671313286    Accuracy: 84.6875\n",
      "iter 1904 ---  Loss: 3.0270696729421616    Accuracy: 87.96875\n",
      "iter 1905 ---  Loss: 3.1264148727059364    Accuracy: 85.78125\n",
      "iter 1906 ---  Loss: 2.8948866203427315    Accuracy: 87.8125\n",
      "iter 1907 ---  Loss: 3.022249758243561    Accuracy: 87.03125\n",
      "iter 1908 ---  Loss: 3.1743193566799164    Accuracy: 86.71875\n",
      "iter 1909 ---  Loss: 3.3098631873726845    Accuracy: 86.40625\n",
      "iter 1910 ---  Loss: 2.813902497291565    Accuracy: 87.65625\n",
      "iter 1911 ---  Loss: 2.517556369304657    Accuracy: 87.8125\n",
      "iter 1912 ---  Loss: 2.7407622933387756    Accuracy: 87.1875\n",
      "iter 1913 ---  Loss: 2.836888775229454    Accuracy: 85.3125\n",
      "iter 1914 ---  Loss: 3.3468230441212654    Accuracy: 87.65625\n",
      "iter 1915 ---  Loss: 3.4273915216326714    Accuracy: 87.65625\n",
      "iter 1916 ---  Loss: 2.715359978377819    Accuracy: 87.5\n",
      "iter 1917 ---  Loss: 2.8255460783839226    Accuracy: 85.625\n",
      "iter 1918 ---  Loss: 2.859971985220909    Accuracy: 90.0\n",
      "iter 1919 ---  Loss: 2.72803408652544    Accuracy: 88.75\n",
      "iter 1920 ---  Loss: 3.793933294713497    Accuracy: 84.375\n",
      "iter 1921 ---  Loss: 2.7579536885023117    Accuracy: 86.875\n",
      "iter 1922 ---  Loss: 2.643373616039753    Accuracy: 87.96875\n",
      "iter 1923 ---  Loss: 3.0100613608956337    Accuracy: 87.5\n",
      "iter 1924 ---  Loss: 2.9547927379608154    Accuracy: 87.96875\n",
      "iter 1925 ---  Loss: 3.3916481882333755    Accuracy: 85.3125\n",
      "iter 1926 ---  Loss: 3.164331927895546    Accuracy: 87.5\n",
      "iter 1927 ---  Loss: 3.33639570325613    Accuracy: 85.9375\n",
      "iter 1928 ---  Loss: 2.8975509479641914    Accuracy: 85.46875\n",
      "iter 1929 ---  Loss: 2.6827367916703224    Accuracy: 89.0625\n",
      "iter 1930 ---  Loss: 3.4148689433932304    Accuracy: 87.1875\n",
      "iter 1931 ---  Loss: 3.2404874116182327    Accuracy: 86.5625\n",
      "iter 1932 ---  Loss: 2.8823808059096336    Accuracy: 87.5\n",
      "iter 1933 ---  Loss: 4.070624276995659    Accuracy: 84.84375\n",
      "iter 1934 ---  Loss: 3.6801972314715385    Accuracy: 84.0625\n",
      "iter 1935 ---  Loss: 3.314352996647358    Accuracy: 86.5625\n",
      "iter 1936 ---  Loss: 2.8042423129081726    Accuracy: 88.125\n",
      "iter 1937 ---  Loss: 3.461086079478264    Accuracy: 86.875\n",
      "iter 1938 ---  Loss: 2.8893770277500153    Accuracy: 86.875\n",
      "iter 1939 ---  Loss: 3.3205072432756424    Accuracy: 85.625\n",
      "iter 1940 ---  Loss: 2.9355356320738792    Accuracy: 87.96875\n",
      "iter 1941 ---  Loss: 2.743553303182125    Accuracy: 89.6875\n",
      "iter 1942 ---  Loss: 3.24886441975832    Accuracy: 86.09375\n",
      "iter 1943 ---  Loss: 2.973613165318966    Accuracy: 86.71875\n",
      "iter 1944 ---  Loss: 3.4143418446183205    Accuracy: 84.0625\n",
      "iter 1945 ---  Loss: 2.8032236844301224    Accuracy: 87.96875\n",
      "iter 1946 ---  Loss: 3.024972192943096    Accuracy: 86.09375\n",
      "iter 1947 ---  Loss: 3.6016856729984283    Accuracy: 87.65625\n",
      "iter 1948 ---  Loss: 2.5929379984736443    Accuracy: 88.75\n",
      "iter 1949 ---  Loss: 3.391185462474823    Accuracy: 87.34375\n",
      "iter 1950 ---  Loss: 2.793111689388752    Accuracy: 87.1875\n",
      "iter 1951 ---  Loss: 2.971415586769581    Accuracy: 86.5625\n",
      "iter 1952 ---  Loss: 2.5233111530542374    Accuracy: 88.125\n",
      "iter 1953 ---  Loss: 3.256908230483532    Accuracy: 87.96875\n",
      "iter 1954 ---  Loss: 2.742280565202236    Accuracy: 87.8125\n",
      "iter 1955 ---  Loss: 2.9558828100562096    Accuracy: 87.34375\n",
      "iter 1956 ---  Loss: 2.948214404284954    Accuracy: 87.34375\n",
      "iter 1957 ---  Loss: 3.233737029135227    Accuracy: 87.65625\n",
      "iter 1958 ---  Loss: 2.835248254239559    Accuracy: 86.40625\n",
      "iter 1959 ---  Loss: 3.2714428529143333    Accuracy: 86.25\n",
      "iter 1960 ---  Loss: 2.820461690425873    Accuracy: 89.0625\n",
      "iter 1961 ---  Loss: 2.5896172374486923    Accuracy: 87.34375\n",
      "iter 1962 ---  Loss: 3.465745210647583    Accuracy: 85.625\n",
      "iter 1963 ---  Loss: 3.125010848045349    Accuracy: 87.1875\n",
      "iter 1964 ---  Loss: 3.470090389251709    Accuracy: 86.40625\n",
      "iter 1965 ---  Loss: 3.4036410823464394    Accuracy: 87.1875\n",
      "iter 1966 ---  Loss: 3.234310507774353    Accuracy: 88.90625\n",
      "iter 1967 ---  Loss: 3.1961095705628395    Accuracy: 86.71875\n",
      "iter 1968 ---  Loss: 3.1676919534802437    Accuracy: 86.09375\n",
      "iter 1969 ---  Loss: 3.58618076890707    Accuracy: 88.90625\n",
      "iter 1970 ---  Loss: 3.0670583322644234    Accuracy: 88.4375\n",
      "iter 1971 ---  Loss: 2.7805723771452904    Accuracy: 86.875\n",
      "iter 1972 ---  Loss: 3.634764850139618    Accuracy: 87.34375\n",
      "iter 1973 ---  Loss: 3.4082634896039963    Accuracy: 86.40625\n",
      "iter 1974 ---  Loss: 3.748792052268982    Accuracy: 85.46875\n",
      "iter 1975 ---  Loss: 3.3296458944678307    Accuracy: 87.65625\n",
      "iter 1976 ---  Loss: 3.2243523746728897    Accuracy: 89.0625\n",
      "iter 1977 ---  Loss: 3.3128363490104675    Accuracy: 88.28125\n",
      "iter 1978 ---  Loss: 3.0697426572442055    Accuracy: 87.96875\n",
      "iter 1979 ---  Loss: 3.2657177299261093    Accuracy: 87.03125\n",
      "iter 1980 ---  Loss: 2.7852419018745422    Accuracy: 88.59375\n",
      "iter 1981 ---  Loss: 2.7336013838648796    Accuracy: 87.03125\n",
      "iter 1982 ---  Loss: 3.1733695194125175    Accuracy: 87.96875\n",
      "iter 1983 ---  Loss: 2.709976486861706    Accuracy: 87.5\n",
      "iter 1984 ---  Loss: 3.474830314517021    Accuracy: 85.15625\n",
      "iter 1985 ---  Loss: 3.0043186843395233    Accuracy: 85.625\n",
      "iter 1986 ---  Loss: 3.2100590020418167    Accuracy: 87.1875\n",
      "iter 1987 ---  Loss: 2.990311250090599    Accuracy: 85.78125\n",
      "iter 1988 ---  Loss: 3.2512030974030495    Accuracy: 87.34375\n",
      "iter 1989 ---  Loss: 2.8661182671785355    Accuracy: 87.65625\n",
      "iter 1990 ---  Loss: 3.338441714644432    Accuracy: 87.5\n",
      "iter 1991 ---  Loss: 3.68362520635128    Accuracy: 88.90625\n",
      "iter 1992 ---  Loss: 3.566720701754093    Accuracy: 87.65625\n",
      "iter 1993 ---  Loss: 2.8955524787306786    Accuracy: 87.34375\n",
      "iter 1994 ---  Loss: 2.9140058010816574    Accuracy: 89.375\n",
      "iter 1995 ---  Loss: 2.8552761375904083    Accuracy: 85.3125\n",
      "iter 1996 ---  Loss: 2.9495320692658424    Accuracy: 87.03125\n",
      "iter 1997 ---  Loss: 2.6949141025543213    Accuracy: 87.34375\n",
      "iter 1998 ---  Loss: 2.850613720715046    Accuracy: 87.03125\n",
      "iter 1999 ---  Loss: 3.0733375921845436    Accuracy: 87.1875\n",
      "iter 2000 ---  Loss: 2.9172649160027504    Accuracy: 86.875\n",
      "iter 2001 ---  Loss: 3.261839799582958    Accuracy: 85.0\n",
      "iter 2002 ---  Loss: 3.4254996106028557    Accuracy: 88.28125\n",
      "iter 2003 ---  Loss: 3.3411227613687515    Accuracy: 86.09375\n",
      "iter 2004 ---  Loss: 2.7066273391246796    Accuracy: 86.5625\n",
      "iter 2005 ---  Loss: 3.3132316544651985    Accuracy: 86.09375\n",
      "iter 2006 ---  Loss: 2.8990769386291504    Accuracy: 86.875\n",
      "iter 2007 ---  Loss: 3.1391819939017296    Accuracy: 86.71875\n",
      "iter 2008 ---  Loss: 2.4936664029955864    Accuracy: 87.34375\n",
      "iter 2009 ---  Loss: 2.9473372027277946    Accuracy: 87.1875\n",
      "iter 2010 ---  Loss: 3.00439939647913    Accuracy: 88.28125\n",
      "iter 2011 ---  Loss: 2.7500513941049576    Accuracy: 88.28125\n",
      "iter 2012 ---  Loss: 2.89412459731102    Accuracy: 87.5\n",
      "iter 2013 ---  Loss: 3.1324756741523743    Accuracy: 88.75\n",
      "iter 2014 ---  Loss: 3.608236312866211    Accuracy: 86.71875\n",
      "iter 2015 ---  Loss: 3.344900958240032    Accuracy: 86.71875\n",
      "iter 2016 ---  Loss: 3.0070922449231148    Accuracy: 86.40625\n",
      "iter 2017 ---  Loss: 3.611609272658825    Accuracy: 87.34375\n",
      "iter 2018 ---  Loss: 3.0852572172880173    Accuracy: 87.1875\n",
      "iter 2019 ---  Loss: 2.9660219699144363    Accuracy: 87.03125\n",
      "iter 2020 ---  Loss: 3.4121467396616936    Accuracy: 85.9375\n",
      "iter 2021 ---  Loss: 3.0742333829402924    Accuracy: 86.40625\n",
      "iter 2022 ---  Loss: 2.7820352911949158    Accuracy: 87.03125\n",
      "iter 2023 ---  Loss: 3.223802827298641    Accuracy: 86.875\n",
      "iter 2024 ---  Loss: 2.8028538674116135    Accuracy: 86.5625\n",
      "iter 2025 ---  Loss: 3.1633150950074196    Accuracy: 86.875\n",
      "iter 2026 ---  Loss: 3.1716946586966515    Accuracy: 88.4375\n",
      "iter 2027 ---  Loss: 3.426692560315132    Accuracy: 87.65625\n",
      "iter 2028 ---  Loss: 3.513821341097355    Accuracy: 84.84375\n",
      "iter 2029 ---  Loss: 3.280549943447113    Accuracy: 89.0625\n",
      "iter 2030 ---  Loss: 3.0762557089328766    Accuracy: 87.5\n",
      "iter 2031 ---  Loss: 2.8391982465982437    Accuracy: 87.34375\n",
      "iter 2032 ---  Loss: 2.7023472785949707    Accuracy: 87.96875\n",
      "iter 2033 ---  Loss: 2.768203377723694    Accuracy: 89.21875\n",
      "iter 2034 ---  Loss: 3.220467299222946    Accuracy: 86.09375\n",
      "iter 2035 ---  Loss: 2.7996454685926437    Accuracy: 86.71875\n",
      "iter 2036 ---  Loss: 2.7624356150627136    Accuracy: 88.4375\n",
      "iter 2037 ---  Loss: 2.773764729499817    Accuracy: 88.90625\n",
      "iter 2038 ---  Loss: 3.223859131336212    Accuracy: 87.65625\n",
      "iter 2039 ---  Loss: 3.067317083477974    Accuracy: 87.65625\n",
      "iter 2040 ---  Loss: 3.1036113798618317    Accuracy: 87.34375\n",
      "iter 2041 ---  Loss: 3.111595280468464    Accuracy: 86.40625\n",
      "iter 2042 ---  Loss: 2.9965917468070984    Accuracy: 87.8125\n",
      "iter 2043 ---  Loss: 3.1557866632938385    Accuracy: 86.71875\n",
      "iter 2044 ---  Loss: 3.0001733899116516    Accuracy: 88.59375\n",
      "iter 2045 ---  Loss: 3.1769888773560524    Accuracy: 88.125\n",
      "iter 2046 ---  Loss: 2.9013972878456116    Accuracy: 86.40625\n",
      "iter 2047 ---  Loss: 3.255741275846958    Accuracy: 86.875\n",
      "iter 2048 ---  Loss: 2.9793141037225723    Accuracy: 85.15625\n",
      "iter 2049 ---  Loss: 3.4320558309555054    Accuracy: 86.25\n",
      "iter 2050 ---  Loss: 2.998535469174385    Accuracy: 86.71875\n",
      "iter 2051 ---  Loss: 3.1207622289657593    Accuracy: 86.25\n",
      "iter 2052 ---  Loss: 3.250068351626396    Accuracy: 87.8125\n",
      "iter 2053 ---  Loss: 3.5897828117012978    Accuracy: 86.875\n",
      "iter 2054 ---  Loss: 2.733262062072754    Accuracy: 88.4375\n",
      "iter 2055 ---  Loss: 3.083160847425461    Accuracy: 87.03125\n",
      "iter 2056 ---  Loss: 3.0376337319612503    Accuracy: 86.25\n",
      "iter 2057 ---  Loss: 2.80804081261158    Accuracy: 87.8125\n",
      "iter 2058 ---  Loss: 3.1797820031642914    Accuracy: 87.1875\n",
      "iter 2059 ---  Loss: 3.127619542181492    Accuracy: 87.65625\n",
      "iter 2060 ---  Loss: 3.331459119915962    Accuracy: 88.28125\n",
      "iter 2061 ---  Loss: 2.6105426400899887    Accuracy: 86.875\n",
      "iter 2062 ---  Loss: 2.644925966858864    Accuracy: 88.59375\n",
      "iter 2063 ---  Loss: 2.9830446392297745    Accuracy: 87.5\n",
      "iter 2064 ---  Loss: 2.842695541679859    Accuracy: 86.875\n",
      "iter 2065 ---  Loss: 3.155205249786377    Accuracy: 86.5625\n",
      "iter 2066 ---  Loss: 2.8278603181242943    Accuracy: 88.28125\n",
      "iter 2067 ---  Loss: 3.931009918451309    Accuracy: 83.4375\n",
      "iter 2068 ---  Loss: 2.9185702726244926    Accuracy: 88.90625\n",
      "iter 2069 ---  Loss: 3.2343654111027718    Accuracy: 86.25\n",
      "iter 2070 ---  Loss: 2.97017353028059    Accuracy: 87.1875\n",
      "iter 2071 ---  Loss: 3.129803791642189    Accuracy: 88.28125\n",
      "iter 2072 ---  Loss: 3.4877718165516853    Accuracy: 86.71875\n",
      "iter 2073 ---  Loss: 3.1582684963941574    Accuracy: 87.03125\n",
      "iter 2074 ---  Loss: 2.9339683651924133    Accuracy: 85.625\n",
      "iter 2075 ---  Loss: 2.79786579310894    Accuracy: 87.96875\n",
      "iter 2076 ---  Loss: 2.659441478550434    Accuracy: 87.65625\n",
      "iter 2077 ---  Loss: 2.878023162484169    Accuracy: 86.71875\n",
      "iter 2078 ---  Loss: 3.265707165002823    Accuracy: 87.5\n",
      "iter 2079 ---  Loss: 3.6660574451088905    Accuracy: 84.53125\n",
      "iter 2080 ---  Loss: 2.7663797959685326    Accuracy: 87.96875\n",
      "iter 2081 ---  Loss: 2.9651209488511086    Accuracy: 87.1875\n",
      "iter 2082 ---  Loss: 3.190319314599037    Accuracy: 85.9375\n",
      "iter 2083 ---  Loss: 2.78742615878582    Accuracy: 87.1875\n",
      "iter 2084 ---  Loss: 2.7932850047945976    Accuracy: 85.9375\n",
      "iter 2085 ---  Loss: 2.428743600845337    Accuracy: 88.4375\n",
      "iter 2086 ---  Loss: 2.8818525299429893    Accuracy: 88.125\n",
      "iter 2087 ---  Loss: 3.2344229966402054    Accuracy: 85.78125\n",
      "iter 2088 ---  Loss: 2.6503106132149696    Accuracy: 87.96875\n",
      "iter 2089 ---  Loss: 2.7920625507831573    Accuracy: 88.59375\n",
      "iter 2090 ---  Loss: 2.948217287659645    Accuracy: 87.03125\n",
      "iter 2091 ---  Loss: 3.276718743145466    Accuracy: 86.5625\n",
      "iter 2092 ---  Loss: 2.7415896579623222    Accuracy: 87.96875\n",
      "iter 2093 ---  Loss: 2.8585938587784767    Accuracy: 89.0625\n",
      "iter 2094 ---  Loss: 2.9819656163454056    Accuracy: 85.3125\n",
      "iter 2095 ---  Loss: 4.077426396310329    Accuracy: 86.25\n",
      "iter 2096 ---  Loss: 2.57512067258358    Accuracy: 88.59375\n",
      "iter 2097 ---  Loss: 2.907953731715679    Accuracy: 87.34375\n",
      "iter 2098 ---  Loss: 3.2875395491719246    Accuracy: 87.1875\n",
      "iter 2099 ---  Loss: 3.143758811056614    Accuracy: 87.1875\n",
      "iter 2100 ---  Loss: 3.047274649143219    Accuracy: 86.875\n",
      "iter 2101 ---  Loss: 2.850790783762932    Accuracy: 89.6875\n",
      "iter 2102 ---  Loss: 3.331368736922741    Accuracy: 87.1875\n",
      "iter 2103 ---  Loss: 2.8374127745628357    Accuracy: 86.875\n",
      "iter 2104 ---  Loss: 3.4970774427056313    Accuracy: 87.96875\n",
      "iter 2105 ---  Loss: 2.7756438180804253    Accuracy: 88.90625\n",
      "iter 2106 ---  Loss: 3.6494368463754654    Accuracy: 86.40625\n",
      "iter 2107 ---  Loss: 2.7462671399116516    Accuracy: 88.75\n",
      "iter 2108 ---  Loss: 3.0925502479076385    Accuracy: 85.9375\n",
      "iter 2109 ---  Loss: 3.1801643148064613    Accuracy: 88.125\n",
      "iter 2110 ---  Loss: 3.829950213432312    Accuracy: 85.9375\n",
      "iter 2111 ---  Loss: 2.9811674430966377    Accuracy: 86.09375\n",
      "iter 2112 ---  Loss: 2.8944025337696075    Accuracy: 86.5625\n",
      "iter 2113 ---  Loss: 3.592330038547516    Accuracy: 85.9375\n",
      "iter 2114 ---  Loss: 3.5249853879213333    Accuracy: 86.09375\n",
      "iter 2115 ---  Loss: 2.8598699793219566    Accuracy: 85.9375\n",
      "iter 2116 ---  Loss: 2.9644897058606148    Accuracy: 88.59375\n",
      "iter 2117 ---  Loss: 3.1291908770799637    Accuracy: 86.71875\n",
      "iter 2118 ---  Loss: 3.6258454844355583    Accuracy: 87.5\n",
      "iter 2119 ---  Loss: 3.047277197241783    Accuracy: 86.875\n",
      "iter 2120 ---  Loss: 2.884767770767212    Accuracy: 85.78125\n",
      "iter 2121 ---  Loss: 2.822829060256481    Accuracy: 84.375\n",
      "iter 2122 ---  Loss: 3.4212567880749702    Accuracy: 88.90625\n",
      "iter 2123 ---  Loss: 2.7493947967886925    Accuracy: 86.875\n",
      "iter 2124 ---  Loss: 3.05308186262846    Accuracy: 85.78125\n",
      "iter 2125 ---  Loss: 2.7050277069211006    Accuracy: 87.65625\n",
      "iter 2126 ---  Loss: 3.235590770840645    Accuracy: 85.15625\n",
      "iter 2127 ---  Loss: 2.5377634093165398    Accuracy: 88.125\n",
      "iter 2128 ---  Loss: 3.5673947632312775    Accuracy: 87.65625\n",
      "iter 2129 ---  Loss: 4.193011820316315    Accuracy: 85.3125\n",
      "iter 2130 ---  Loss: 3.265417568385601    Accuracy: 87.03125\n",
      "iter 2131 ---  Loss: 2.9578200429677963    Accuracy: 84.6875\n",
      "iter 2132 ---  Loss: 2.9596075415611267    Accuracy: 86.875\n",
      "iter 2133 ---  Loss: 3.1177372485399246    Accuracy: 86.40625\n",
      "iter 2134 ---  Loss: 2.797270782291889    Accuracy: 87.03125\n",
      "iter 2135 ---  Loss: 2.6722518131136894    Accuracy: 87.1875\n",
      "iter 2136 ---  Loss: 3.3965936452150345    Accuracy: 86.40625\n",
      "iter 2137 ---  Loss: 3.0581747964024544    Accuracy: 88.28125\n",
      "iter 2138 ---  Loss: 3.023516595363617    Accuracy: 87.5\n",
      "iter 2139 ---  Loss: 3.5299028530716896    Accuracy: 87.1875\n",
      "iter 2140 ---  Loss: 3.173491023480892    Accuracy: 86.40625\n",
      "iter 2141 ---  Loss: 3.008755385875702    Accuracy: 86.875\n",
      "iter 2142 ---  Loss: 3.2124130576848984    Accuracy: 87.96875\n",
      "iter 2143 ---  Loss: 2.7336229011416435    Accuracy: 88.125\n",
      "iter 2144 ---  Loss: 3.113379545509815    Accuracy: 89.21875\n",
      "iter 2145 ---  Loss: 3.2865685001015663    Accuracy: 87.03125\n",
      "iter 2146 ---  Loss: 3.1625235974788666    Accuracy: 86.71875\n",
      "iter 2147 ---  Loss: 3.978276789188385    Accuracy: 86.09375\n",
      "iter 2148 ---  Loss: 3.0028061494231224    Accuracy: 87.65625\n",
      "iter 2149 ---  Loss: 3.0119915828108788    Accuracy: 87.03125\n",
      "iter 2150 ---  Loss: 2.5355693623423576    Accuracy: 88.125\n",
      "iter 2151 ---  Loss: 3.0006678104400635    Accuracy: 86.09375\n",
      "iter 2152 ---  Loss: 2.802343226969242    Accuracy: 88.125\n",
      "iter 2153 ---  Loss: 3.1239202097058296    Accuracy: 87.1875\n",
      "iter 2154 ---  Loss: 3.3729833364486694    Accuracy: 87.65625\n",
      "iter 2155 ---  Loss: 2.6270035579800606    Accuracy: 88.59375\n",
      "iter 2156 ---  Loss: 3.7794209122657776    Accuracy: 84.6875\n",
      "iter 2157 ---  Loss: 2.8599007800221443    Accuracy: 87.65625\n",
      "iter 2158 ---  Loss: 2.736373156309128    Accuracy: 88.90625\n",
      "iter 2159 ---  Loss: 3.453047998249531    Accuracy: 87.03125\n",
      "iter 2160 ---  Loss: 2.816278226673603    Accuracy: 87.03125\n",
      "iter 2161 ---  Loss: 3.077329270541668    Accuracy: 86.40625\n",
      "iter 2162 ---  Loss: 3.0735416933894157    Accuracy: 88.125\n",
      "iter 2163 ---  Loss: 2.8166754990816116    Accuracy: 87.03125\n",
      "iter 2164 ---  Loss: 3.423252947628498    Accuracy: 86.5625\n",
      "iter 2165 ---  Loss: 2.9178505539894104    Accuracy: 88.28125\n",
      "iter 2166 ---  Loss: 2.6582494601607323    Accuracy: 87.1875\n",
      "iter 2167 ---  Loss: 3.455201230943203    Accuracy: 84.0625\n",
      "iter 2168 ---  Loss: 2.7334913462400436    Accuracy: 87.1875\n",
      "iter 2169 ---  Loss: 2.985998824238777    Accuracy: 87.1875\n",
      "iter 2170 ---  Loss: 2.5248808413743973    Accuracy: 88.59375\n",
      "iter 2171 ---  Loss: 3.291082412004471    Accuracy: 86.875\n",
      "iter 2172 ---  Loss: 2.584365375339985    Accuracy: 88.59375\n",
      "iter 2173 ---  Loss: 2.894510693848133    Accuracy: 89.21875\n",
      "iter 2174 ---  Loss: 3.006052643060684    Accuracy: 88.4375\n",
      "iter 2175 ---  Loss: 3.5132976099848747    Accuracy: 86.25\n",
      "iter 2176 ---  Loss: 3.5305405631661415    Accuracy: 85.625\n",
      "iter 2177 ---  Loss: 3.048214390873909    Accuracy: 86.5625\n",
      "iter 2178 ---  Loss: 2.8825254067778587    Accuracy: 88.75\n",
      "iter 2179 ---  Loss: 2.8464221730828285    Accuracy: 88.125\n",
      "iter 2180 ---  Loss: 3.649603508412838    Accuracy: 85.9375\n",
      "iter 2181 ---  Loss: 3.3950872123241425    Accuracy: 87.34375\n",
      "iter 2182 ---  Loss: 2.973129190504551    Accuracy: 86.71875\n",
      "iter 2183 ---  Loss: 3.642526865005493    Accuracy: 87.5\n",
      "iter 2184 ---  Loss: 2.978436402976513    Accuracy: 86.5625\n",
      "iter 2185 ---  Loss: 3.1036462485790253    Accuracy: 89.84375\n",
      "iter 2186 ---  Loss: 3.451073542237282    Accuracy: 87.5\n",
      "iter 2187 ---  Loss: 3.2705840542912483    Accuracy: 86.25\n",
      "iter 2188 ---  Loss: 3.4711184352636337    Accuracy: 86.71875\n",
      "iter 2189 ---  Loss: 3.084502026438713    Accuracy: 89.21875\n",
      "iter 2190 ---  Loss: 2.735269397497177    Accuracy: 85.9375\n",
      "iter 2191 ---  Loss: 2.8870568200945854    Accuracy: 88.28125\n",
      "iter 2192 ---  Loss: 2.676042787730694    Accuracy: 88.28125\n",
      "iter 2193 ---  Loss: 3.893359988927841    Accuracy: 86.09375\n",
      "iter 2194 ---  Loss: 3.221339799463749    Accuracy: 87.96875\n",
      "iter 2195 ---  Loss: 3.2073068991303444    Accuracy: 86.71875\n",
      "iter 2196 ---  Loss: 3.2375656738877296    Accuracy: 87.03125\n",
      "iter 2197 ---  Loss: 3.106199190020561    Accuracy: 87.34375\n",
      "iter 2198 ---  Loss: 2.86429213732481    Accuracy: 89.375\n",
      "iter 2199 ---  Loss: 2.658323273062706    Accuracy: 90.0\n",
      "iter 2200 ---  Loss: 2.923272579908371    Accuracy: 87.65625\n",
      "iter 2201 ---  Loss: 3.132611282169819    Accuracy: 88.125\n",
      "iter 2202 ---  Loss: 3.784824103116989    Accuracy: 86.40625\n",
      "iter 2203 ---  Loss: 2.9494234323501587    Accuracy: 86.09375\n",
      "iter 2204 ---  Loss: 2.7568457201123238    Accuracy: 87.96875\n",
      "iter 2205 ---  Loss: 2.955800861120224    Accuracy: 89.375\n",
      "iter 2206 ---  Loss: 3.1722407191991806    Accuracy: 87.5\n",
      "iter 2207 ---  Loss: 3.2448342218995094    Accuracy: 87.34375\n",
      "iter 2208 ---  Loss: 3.4497430995106697    Accuracy: 87.8125\n",
      "iter 2209 ---  Loss: 3.3682034239172935    Accuracy: 87.03125\n",
      "iter 2210 ---  Loss: 2.8824614733457565    Accuracy: 88.28125\n",
      "iter 2211 ---  Loss: 3.014578878879547    Accuracy: 86.71875\n",
      "iter 2212 ---  Loss: 3.1945765763521194    Accuracy: 85.9375\n",
      "iter 2213 ---  Loss: 2.71216406673193    Accuracy: 89.21875\n",
      "iter 2214 ---  Loss: 2.578514665365219    Accuracy: 88.4375\n",
      "iter 2215 ---  Loss: 3.401063486933708    Accuracy: 87.65625\n",
      "iter 2216 ---  Loss: 2.5907789394259453    Accuracy: 89.6875\n",
      "iter 2217 ---  Loss: 3.2325798347592354    Accuracy: 87.03125\n",
      "iter 2218 ---  Loss: 3.0494890809059143    Accuracy: 86.5625\n",
      "iter 2219 ---  Loss: 3.2946579828858376    Accuracy: 86.40625\n",
      "iter 2220 ---  Loss: 3.212428517639637    Accuracy: 86.09375\n",
      "iter 2221 ---  Loss: 2.6116926819086075    Accuracy: 88.90625\n",
      "iter 2222 ---  Loss: 3.6934348568320274    Accuracy: 87.65625\n",
      "iter 2223 ---  Loss: 3.1649421378970146    Accuracy: 88.28125\n",
      "iter 2224 ---  Loss: 3.2285969629883766    Accuracy: 86.71875\n",
      "iter 2225 ---  Loss: 3.12523702532053    Accuracy: 88.59375\n",
      "iter 2226 ---  Loss: 2.478026255965233    Accuracy: 88.59375\n",
      "iter 2227 ---  Loss: 2.4597703143954277    Accuracy: 90.0\n",
      "iter 2228 ---  Loss: 2.742752283811569    Accuracy: 86.40625\n",
      "iter 2229 ---  Loss: 3.1429938226938248    Accuracy: 87.5\n",
      "iter 2230 ---  Loss: 3.0845588222146034    Accuracy: 88.4375\n",
      "iter 2231 ---  Loss: 3.1626201272010803    Accuracy: 89.21875\n",
      "iter 2232 ---  Loss: 2.9937679544091225    Accuracy: 85.625\n",
      "iter 2233 ---  Loss: 2.6246329694986343    Accuracy: 88.4375\n",
      "iter 2234 ---  Loss: 2.541497990489006    Accuracy: 88.59375\n",
      "iter 2235 ---  Loss: 3.163339354097843    Accuracy: 87.5\n",
      "iter 2236 ---  Loss: 3.3106984347105026    Accuracy: 88.125\n",
      "iter 2237 ---  Loss: 2.8305790424346924    Accuracy: 87.8125\n",
      "iter 2238 ---  Loss: 3.0485304594039917    Accuracy: 87.5\n",
      "iter 2239 ---  Loss: 3.5879353880882263    Accuracy: 87.5\n",
      "iter 2240 ---  Loss: 3.0578295961022377    Accuracy: 88.59375\n",
      "iter 2241 ---  Loss: 3.40683227032423    Accuracy: 87.34375\n",
      "iter 2242 ---  Loss: 2.4625351950526237    Accuracy: 89.375\n",
      "iter 2243 ---  Loss: 3.713779293000698    Accuracy: 87.65625\n",
      "iter 2244 ---  Loss: 3.2020291164517403    Accuracy: 87.96875\n",
      "iter 2245 ---  Loss: 3.0431323051452637    Accuracy: 86.40625\n",
      "iter 2246 ---  Loss: 2.6970661357045174    Accuracy: 87.1875\n",
      "iter 2247 ---  Loss: 2.767704375088215    Accuracy: 88.28125\n",
      "iter 2248 ---  Loss: 2.981234550476074    Accuracy: 87.1875\n",
      "iter 2249 ---  Loss: 3.7958434149622917    Accuracy: 85.9375\n",
      "iter 2250 ---  Loss: 2.690323829650879    Accuracy: 88.75\n",
      "iter 2251 ---  Loss: 3.179658003151417    Accuracy: 88.28125\n",
      "iter 2252 ---  Loss: 3.27928813546896    Accuracy: 86.71875\n",
      "iter 2253 ---  Loss: 2.8809896036982536    Accuracy: 88.4375\n",
      "iter 2254 ---  Loss: 2.693886198103428    Accuracy: 86.5625\n",
      "iter 2255 ---  Loss: 3.3091308549046516    Accuracy: 86.25\n",
      "iter 2256 ---  Loss: 3.3201784193515778    Accuracy: 85.9375\n",
      "iter 2257 ---  Loss: 3.4383353888988495    Accuracy: 86.875\n",
      "iter 2258 ---  Loss: 3.86247967928648    Accuracy: 86.09375\n",
      "iter 2259 ---  Loss: 3.625485509634018    Accuracy: 87.1875\n",
      "iter 2260 ---  Loss: 2.7417635768651962    Accuracy: 88.125\n",
      "iter 2261 ---  Loss: 2.74354500323534    Accuracy: 88.28125\n",
      "iter 2262 ---  Loss: 2.8291973546147346    Accuracy: 89.0625\n",
      "iter 2263 ---  Loss: 2.5107166469097137    Accuracy: 88.4375\n",
      "iter 2264 ---  Loss: 3.6512562707066536    Accuracy: 86.09375\n",
      "iter 2265 ---  Loss: 2.6934353038668633    Accuracy: 88.28125\n",
      "iter 2266 ---  Loss: 3.6543350890278816    Accuracy: 84.84375\n",
      "iter 2267 ---  Loss: 3.5793496295809746    Accuracy: 86.09375\n",
      "iter 2268 ---  Loss: 2.592805437743664    Accuracy: 88.75\n",
      "iter 2269 ---  Loss: 3.062834031879902    Accuracy: 87.65625\n",
      "iter 2270 ---  Loss: 3.0557381585240364    Accuracy: 88.125\n",
      "iter 2271 ---  Loss: 3.4709989726543427    Accuracy: 86.09375\n",
      "iter 2272 ---  Loss: 3.392102934420109    Accuracy: 88.125\n",
      "iter 2273 ---  Loss: 2.500904396176338    Accuracy: 88.4375\n",
      "iter 2274 ---  Loss: 3.052424505352974    Accuracy: 88.59375\n",
      "iter 2275 ---  Loss: 2.914428763091564    Accuracy: 86.875\n",
      "iter 2276 ---  Loss: 3.801699176430702    Accuracy: 87.03125\n",
      "iter 2277 ---  Loss: 2.9382744431495667    Accuracy: 86.25\n",
      "iter 2278 ---  Loss: 3.4857925102114677    Accuracy: 86.71875\n",
      "iter 2279 ---  Loss: 2.707790933549404    Accuracy: 88.28125\n",
      "iter 2280 ---  Loss: 3.2980183884501457    Accuracy: 85.46875\n",
      "iter 2281 ---  Loss: 2.9200348779559135    Accuracy: 87.65625\n",
      "iter 2282 ---  Loss: 3.4303916171193123    Accuracy: 86.71875\n",
      "iter 2283 ---  Loss: 3.5790714472532272    Accuracy: 85.0\n",
      "iter 2284 ---  Loss: 2.970383144915104    Accuracy: 87.1875\n",
      "iter 2285 ---  Loss: 3.9376995489001274    Accuracy: 89.0625\n",
      "iter 2286 ---  Loss: 2.7895890548825264    Accuracy: 87.65625\n",
      "iter 2287 ---  Loss: 3.214893661439419    Accuracy: 87.1875\n",
      "iter 2288 ---  Loss: 2.487868048250675    Accuracy: 90.3125\n",
      "iter 2289 ---  Loss: 2.875088095664978    Accuracy: 88.59375\n",
      "iter 2290 ---  Loss: 2.6415380015969276    Accuracy: 86.875\n",
      "iter 2291 ---  Loss: 3.1329199820756912    Accuracy: 88.4375\n",
      "iter 2292 ---  Loss: 3.376861199736595    Accuracy: 88.28125\n",
      "iter 2293 ---  Loss: 3.120637521147728    Accuracy: 87.65625\n",
      "iter 2294 ---  Loss: 2.605628378689289    Accuracy: 87.96875\n",
      "iter 2295 ---  Loss: 3.051946148276329    Accuracy: 89.53125\n",
      "iter 2296 ---  Loss: 2.850595586001873    Accuracy: 87.65625\n",
      "iter 2297 ---  Loss: 2.7968664839863777    Accuracy: 88.4375\n",
      "iter 2298 ---  Loss: 3.6803283765912056    Accuracy: 87.03125\n",
      "iter 2299 ---  Loss: 3.160204067826271    Accuracy: 86.25\n",
      "iter 2300 ---  Loss: 3.24508748203516    Accuracy: 87.34375\n",
      "iter 2301 ---  Loss: 2.9444731548428535    Accuracy: 87.5\n",
      "iter 2302 ---  Loss: 2.7706228122115135    Accuracy: 87.8125\n",
      "iter 2303 ---  Loss: 3.699799209833145    Accuracy: 86.5625\n",
      "iter 2304 ---  Loss: 2.913204960525036    Accuracy: 86.71875\n",
      "iter 2305 ---  Loss: 3.133991688489914    Accuracy: 87.03125\n",
      "iter 2306 ---  Loss: 2.962538458406925    Accuracy: 87.03125\n",
      "iter 2307 ---  Loss: 3.7172442078590393    Accuracy: 85.9375\n",
      "iter 2308 ---  Loss: 2.800858184695244    Accuracy: 90.0\n",
      "iter 2309 ---  Loss: 2.485886760056019    Accuracy: 88.28125\n",
      "iter 2310 ---  Loss: 2.820479206740856    Accuracy: 87.65625\n",
      "iter 2311 ---  Loss: 3.4650106951594353    Accuracy: 87.5\n",
      "iter 2312 ---  Loss: 3.422530882060528    Accuracy: 88.28125\n",
      "iter 2313 ---  Loss: 3.5377361848950386    Accuracy: 85.9375\n",
      "iter 2314 ---  Loss: 3.332034669816494    Accuracy: 87.03125\n",
      "iter 2315 ---  Loss: 3.0356146842241287    Accuracy: 89.6875\n",
      "iter 2316 ---  Loss: 2.7563334330916405    Accuracy: 87.34375\n",
      "iter 2317 ---  Loss: 2.8563361763954163    Accuracy: 87.03125\n",
      "iter 2318 ---  Loss: 3.452080726623535    Accuracy: 87.1875\n",
      "iter 2319 ---  Loss: 3.0398339182138443    Accuracy: 86.40625\n",
      "iter 2320 ---  Loss: 3.1759085580706596    Accuracy: 88.59375\n",
      "iter 2321 ---  Loss: 3.2435944750905037    Accuracy: 86.71875\n",
      "iter 2322 ---  Loss: 2.6222806870937347    Accuracy: 88.90625\n",
      "iter 2323 ---  Loss: 2.649929851293564    Accuracy: 87.65625\n",
      "iter 2324 ---  Loss: 3.1167820915579796    Accuracy: 85.78125\n",
      "iter 2325 ---  Loss: 2.7499093264341354    Accuracy: 87.34375\n",
      "iter 2326 ---  Loss: 2.8980785086750984    Accuracy: 84.6875\n",
      "iter 2327 ---  Loss: 2.621215969324112    Accuracy: 87.1875\n",
      "iter 2328 ---  Loss: 3.5252623185515404    Accuracy: 87.5\n",
      "iter 2329 ---  Loss: 2.724874697625637    Accuracy: 87.65625\n",
      "iter 2330 ---  Loss: 3.2211843952536583    Accuracy: 86.71875\n",
      "iter 2331 ---  Loss: 2.8251812160015106    Accuracy: 90.15625\n",
      "iter 2332 ---  Loss: 3.3204586654901505    Accuracy: 85.9375\n",
      "iter 2333 ---  Loss: 3.0056640431284904    Accuracy: 87.34375\n",
      "iter 2334 ---  Loss: 2.971598155796528    Accuracy: 89.6875\n",
      "iter 2335 ---  Loss: 3.088661052286625    Accuracy: 86.71875\n",
      "iter 2336 ---  Loss: 3.1281027123332024    Accuracy: 88.59375\n",
      "iter 2337 ---  Loss: 2.862196184694767    Accuracy: 89.6875\n",
      "iter 2338 ---  Loss: 3.302696116268635    Accuracy: 87.03125\n",
      "iter 2339 ---  Loss: 2.52901142090559    Accuracy: 89.375\n",
      "iter 2340 ---  Loss: 2.5807762145996094    Accuracy: 89.6875\n",
      "iter 2341 ---  Loss: 2.608279801905155    Accuracy: 88.59375\n",
      "iter 2342 ---  Loss: 3.286991022527218    Accuracy: 86.5625\n",
      "iter 2343 ---  Loss: 3.126037687063217    Accuracy: 86.71875\n",
      "iter 2344 ---  Loss: 3.2920353710651398    Accuracy: 87.5\n",
      "iter 2345 ---  Loss: 2.6508843079209328    Accuracy: 88.125\n",
      "iter 2346 ---  Loss: 3.29708094894886    Accuracy: 87.5\n",
      "iter 2347 ---  Loss: 3.303018979728222    Accuracy: 87.34375\n",
      "iter 2348 ---  Loss: 3.03095293790102    Accuracy: 90.0\n",
      "iter 2349 ---  Loss: 3.858248569071293    Accuracy: 85.0\n",
      "iter 2350 ---  Loss: 3.121995761990547    Accuracy: 87.5\n",
      "iter 2351 ---  Loss: 2.9858864322304726    Accuracy: 86.875\n",
      "iter 2352 ---  Loss: 2.9538916498422623    Accuracy: 87.65625\n",
      "iter 2353 ---  Loss: 2.8479548916220665    Accuracy: 89.21875\n",
      "iter 2354 ---  Loss: 3.2746100276708603    Accuracy: 88.75\n",
      "iter 2355 ---  Loss: 4.056260630488396    Accuracy: 86.09375\n",
      "iter 2356 ---  Loss: 3.51365028321743    Accuracy: 89.0625\n",
      "iter 2357 ---  Loss: 3.0010840743780136    Accuracy: 88.125\n",
      "iter 2358 ---  Loss: 2.756871096789837    Accuracy: 87.5\n",
      "iter 2359 ---  Loss: 2.944795288145542    Accuracy: 87.1875\n",
      "iter 2360 ---  Loss: 3.3139511346817017    Accuracy: 86.25\n",
      "iter 2361 ---  Loss: 3.258345454931259    Accuracy: 86.5625\n",
      "iter 2362 ---  Loss: 3.523151345551014    Accuracy: 88.59375\n",
      "iter 2363 ---  Loss: 3.3799996227025986    Accuracy: 89.21875\n",
      "iter 2364 ---  Loss: 3.697256699204445    Accuracy: 87.34375\n",
      "iter 2365 ---  Loss: 3.375975728034973    Accuracy: 85.46875\n",
      "iter 2366 ---  Loss: 3.175921931862831    Accuracy: 86.25\n",
      "iter 2367 ---  Loss: 2.7179919630289078    Accuracy: 89.21875\n",
      "iter 2368 ---  Loss: 2.701188735663891    Accuracy: 90.78125\n",
      "iter 2369 ---  Loss: 2.9916830956935883    Accuracy: 86.71875\n",
      "iter 2370 ---  Loss: 3.058267816901207    Accuracy: 87.1875\n",
      "iter 2371 ---  Loss: 3.478263556957245    Accuracy: 86.5625\n",
      "iter 2372 ---  Loss: 3.6994049549102783    Accuracy: 87.34375\n",
      "iter 2373 ---  Loss: 2.458255633711815    Accuracy: 89.0625\n",
      "iter 2374 ---  Loss: 3.269735597074032    Accuracy: 88.59375\n",
      "iter 2375 ---  Loss: 3.197592355310917    Accuracy: 85.625\n",
      "iter 2376 ---  Loss: 3.4514739960432053    Accuracy: 87.03125\n",
      "iter 2377 ---  Loss: 2.9682388082146645    Accuracy: 87.1875\n",
      "iter 2378 ---  Loss: 2.7153072357177734    Accuracy: 89.21875\n",
      "iter 2379 ---  Loss: 3.116244576871395    Accuracy: 88.75\n",
      "iter 2380 ---  Loss: 3.3286178186535835    Accuracy: 87.1875\n",
      "iter 2381 ---  Loss: 3.921381965279579    Accuracy: 84.21875\n",
      "iter 2382 ---  Loss: 4.23139289021492    Accuracy: 87.5\n",
      "iter 2383 ---  Loss: 2.8421644791960716    Accuracy: 87.96875\n",
      "iter 2384 ---  Loss: 3.5108565017580986    Accuracy: 85.3125\n",
      "iter 2385 ---  Loss: 2.665728770196438    Accuracy: 88.90625\n",
      "iter 2386 ---  Loss: 2.8962846025824547    Accuracy: 86.875\n",
      "iter 2387 ---  Loss: 3.234747350215912    Accuracy: 87.03125\n",
      "iter 2388 ---  Loss: 2.630679152905941    Accuracy: 88.90625\n",
      "iter 2389 ---  Loss: 3.0838994532823563    Accuracy: 85.46875\n",
      "iter 2390 ---  Loss: 2.8877973705530167    Accuracy: 87.8125\n",
      "iter 2391 ---  Loss: 2.874793067574501    Accuracy: 87.03125\n",
      "iter 2392 ---  Loss: 2.9307975247502327    Accuracy: 86.5625\n",
      "iter 2393 ---  Loss: 3.012187361717224    Accuracy: 85.78125\n",
      "iter 2394 ---  Loss: 3.092591591179371    Accuracy: 88.59375\n",
      "iter 2395 ---  Loss: 2.748024970293045    Accuracy: 88.4375\n",
      "iter 2396 ---  Loss: 2.8786535263061523    Accuracy: 90.46875\n",
      "iter 2397 ---  Loss: 3.597284570336342    Accuracy: 85.15625\n",
      "iter 2398 ---  Loss: 3.458310142159462    Accuracy: 88.90625\n",
      "iter 2399 ---  Loss: 2.897045873105526    Accuracy: 88.59375\n",
      "iter 2400 ---  Loss: 2.832575000822544    Accuracy: 87.03125\n",
      "iter 2401 ---  Loss: 2.8485588654875755    Accuracy: 87.65625\n",
      "iter 2402 ---  Loss: 2.721311092376709    Accuracy: 86.71875\n",
      "iter 2403 ---  Loss: 2.613506592810154    Accuracy: 90.15625\n",
      "iter 2404 ---  Loss: 3.397235631942749    Accuracy: 87.65625\n",
      "iter 2405 ---  Loss: 3.387343853712082    Accuracy: 89.0625\n",
      "iter 2406 ---  Loss: 2.9739510640501976    Accuracy: 88.28125\n",
      "iter 2407 ---  Loss: 3.0547407418489456    Accuracy: 86.25\n",
      "iter 2408 ---  Loss: 2.9183955043554306    Accuracy: 88.59375\n",
      "iter 2409 ---  Loss: 2.810780420899391    Accuracy: 88.75\n",
      "iter 2410 ---  Loss: 2.9198998287320137    Accuracy: 89.53125\n",
      "iter 2411 ---  Loss: 3.080699823796749    Accuracy: 87.34375\n",
      "iter 2412 ---  Loss: 3.776552304625511    Accuracy: 85.46875\n",
      "iter 2413 ---  Loss: 3.3636133074760437    Accuracy: 87.03125\n",
      "iter 2414 ---  Loss: 3.2435068264603615    Accuracy: 87.65625\n",
      "iter 2415 ---  Loss: 2.875105693936348    Accuracy: 86.71875\n",
      "iter 2416 ---  Loss: 2.915433868765831    Accuracy: 90.0\n",
      "iter 2417 ---  Loss: 3.262363776564598    Accuracy: 86.09375\n",
      "iter 2418 ---  Loss: 3.192160665988922    Accuracy: 88.125\n",
      "iter 2419 ---  Loss: 2.8402549028396606    Accuracy: 89.84375\n",
      "iter 2420 ---  Loss: 3.437797024846077    Accuracy: 87.34375\n",
      "iter 2421 ---  Loss: 2.820951782166958    Accuracy: 90.0\n",
      "iter 2422 ---  Loss: 2.7631567642092705    Accuracy: 87.03125\n",
      "iter 2423 ---  Loss: 3.4778289273381233    Accuracy: 85.625\n",
      "iter 2424 ---  Loss: 3.2610925883054733    Accuracy: 87.96875\n",
      "iter 2425 ---  Loss: 2.6306361332535744    Accuracy: 87.96875\n",
      "iter 2426 ---  Loss: 3.374959670007229    Accuracy: 85.78125\n",
      "iter 2427 ---  Loss: 3.060711055994034    Accuracy: 89.0625\n",
      "iter 2428 ---  Loss: 3.1622002720832825    Accuracy: 86.25\n",
      "iter 2429 ---  Loss: 3.0399328842759132    Accuracy: 86.71875\n",
      "iter 2430 ---  Loss: 3.356691911816597    Accuracy: 85.78125\n",
      "iter 2431 ---  Loss: 2.9244779869914055    Accuracy: 87.96875\n",
      "iter 2432 ---  Loss: 3.217101126909256    Accuracy: 87.8125\n",
      "iter 2433 ---  Loss: 3.2052820175886154    Accuracy: 86.25\n",
      "iter 2434 ---  Loss: 3.432657189667225    Accuracy: 89.375\n",
      "iter 2435 ---  Loss: 2.5187397077679634    Accuracy: 89.0625\n",
      "iter 2436 ---  Loss: 2.6682740077376366    Accuracy: 87.8125\n",
      "iter 2437 ---  Loss: 4.033108629286289    Accuracy: 87.03125\n",
      "iter 2438 ---  Loss: 3.1668564528226852    Accuracy: 89.375\n",
      "iter 2439 ---  Loss: 2.7764685824513435    Accuracy: 87.96875\n",
      "iter 2440 ---  Loss: 3.4612974151968956    Accuracy: 86.40625\n",
      "iter 2441 ---  Loss: 3.569097712635994    Accuracy: 87.5\n",
      "iter 2442 ---  Loss: 2.787644736468792    Accuracy: 89.84375\n",
      "iter 2443 ---  Loss: 2.5930459797382355    Accuracy: 88.75\n",
      "iter 2444 ---  Loss: 3.035503961145878    Accuracy: 87.03125\n",
      "iter 2445 ---  Loss: 2.6356846913695335    Accuracy: 87.65625\n",
      "iter 2446 ---  Loss: 2.898966893553734    Accuracy: 87.1875\n",
      "iter 2447 ---  Loss: 3.5466348975896835    Accuracy: 86.25\n",
      "iter 2448 ---  Loss: 3.0510667636990547    Accuracy: 87.1875\n",
      "iter 2449 ---  Loss: 2.7607374265789986    Accuracy: 88.28125\n",
      "iter 2450 ---  Loss: 2.533622220158577    Accuracy: 90.0\n",
      "iter 2451 ---  Loss: 3.2130067870020866    Accuracy: 87.03125\n",
      "iter 2452 ---  Loss: 3.1921897530555725    Accuracy: 87.96875\n",
      "iter 2453 ---  Loss: 2.8348998069763187    Accuracy: 87.0\n",
      "Epoch 4/4\n",
      "-------------\n",
      "iter 0 ---  Loss: 3.7610823810100555    Accuracy: 87.34375\n",
      "iter 1 ---  Loss: 2.7352944687008858    Accuracy: 88.28125\n",
      "iter 2 ---  Loss: 2.950487866997719    Accuracy: 86.875\n",
      "iter 3 ---  Loss: 3.541075810790062    Accuracy: 89.53125\n",
      "iter 4 ---  Loss: 2.5603269189596176    Accuracy: 87.1875\n",
      "iter 5 ---  Loss: 3.454883426427841    Accuracy: 86.71875\n",
      "iter 6 ---  Loss: 3.4838788956403732    Accuracy: 85.625\n",
      "iter 7 ---  Loss: 3.224487252533436    Accuracy: 87.8125\n",
      "iter 8 ---  Loss: 2.7926372066140175    Accuracy: 88.4375\n",
      "iter 9 ---  Loss: 3.1424113288521767    Accuracy: 86.875\n",
      "iter 10 ---  Loss: 3.1805891767144203    Accuracy: 87.5\n",
      "iter 11 ---  Loss: 2.656579628586769    Accuracy: 88.75\n",
      "iter 12 ---  Loss: 2.843141548335552    Accuracy: 87.8125\n",
      "iter 13 ---  Loss: 2.7047592848539352    Accuracy: 89.0625\n",
      "iter 14 ---  Loss: 3.4911079853773117    Accuracy: 88.75\n",
      "iter 15 ---  Loss: 2.7553889378905296    Accuracy: 89.0625\n",
      "iter 16 ---  Loss: 3.158673755824566    Accuracy: 87.1875\n",
      "iter 17 ---  Loss: 2.997248910367489    Accuracy: 87.65625\n",
      "iter 18 ---  Loss: 3.7867010682821274    Accuracy: 85.625\n",
      "iter 19 ---  Loss: 3.642269693315029    Accuracy: 87.1875\n",
      "iter 20 ---  Loss: 2.902099661529064    Accuracy: 87.8125\n",
      "iter 21 ---  Loss: 3.4586697071790695    Accuracy: 87.5\n",
      "iter 22 ---  Loss: 2.761474758386612    Accuracy: 88.28125\n",
      "iter 23 ---  Loss: 2.7201187014579773    Accuracy: 89.21875\n",
      "iter 24 ---  Loss: 3.2419596388936043    Accuracy: 85.3125\n",
      "iter 25 ---  Loss: 2.7114793956279755    Accuracy: 89.21875\n",
      "iter 26 ---  Loss: 3.2253157272934914    Accuracy: 87.34375\n",
      "iter 27 ---  Loss: 4.212438486516476    Accuracy: 84.84375\n",
      "iter 28 ---  Loss: 2.7869546189904213    Accuracy: 87.8125\n",
      "iter 29 ---  Loss: 3.1262240558862686    Accuracy: 87.03125\n",
      "iter 30 ---  Loss: 3.184394173324108    Accuracy: 88.4375\n",
      "iter 31 ---  Loss: 3.169853776693344    Accuracy: 87.34375\n",
      "iter 32 ---  Loss: 3.2613003253936768    Accuracy: 86.40625\n",
      "iter 33 ---  Loss: 3.37465850263834    Accuracy: 87.96875\n",
      "iter 34 ---  Loss: 2.6784346625208855    Accuracy: 87.96875\n",
      "iter 35 ---  Loss: 3.3186435252428055    Accuracy: 87.65625\n",
      "iter 36 ---  Loss: 2.7661760598421097    Accuracy: 89.6875\n",
      "iter 37 ---  Loss: 2.6530680283904076    Accuracy: 89.21875\n",
      "iter 38 ---  Loss: 3.763700693845749    Accuracy: 86.71875\n",
      "iter 39 ---  Loss: 3.0617151260375977    Accuracy: 86.71875\n",
      "iter 40 ---  Loss: 2.526999644935131    Accuracy: 88.90625\n",
      "iter 41 ---  Loss: 3.1484243869781494    Accuracy: 84.84375\n",
      "iter 42 ---  Loss: 2.8103152215480804    Accuracy: 87.34375\n",
      "iter 43 ---  Loss: 3.308005541563034    Accuracy: 86.71875\n",
      "iter 44 ---  Loss: 3.4030314460396767    Accuracy: 85.46875\n",
      "iter 45 ---  Loss: 2.905269183218479    Accuracy: 87.5\n",
      "iter 46 ---  Loss: 2.823378138244152    Accuracy: 87.96875\n",
      "iter 47 ---  Loss: 2.8554965779185295    Accuracy: 87.03125\n",
      "iter 48 ---  Loss: 2.871946319937706    Accuracy: 89.84375\n",
      "iter 49 ---  Loss: 2.739625856280327    Accuracy: 87.96875\n",
      "iter 50 ---  Loss: 3.627015247941017    Accuracy: 85.46875\n",
      "iter 51 ---  Loss: 2.5185594111680984    Accuracy: 88.59375\n",
      "iter 52 ---  Loss: 3.0572577863931656    Accuracy: 88.125\n",
      "iter 53 ---  Loss: 3.459864191710949    Accuracy: 86.5625\n",
      "iter 54 ---  Loss: 2.636078394949436    Accuracy: 90.15625\n",
      "iter 55 ---  Loss: 3.233884520828724    Accuracy: 88.75\n",
      "iter 56 ---  Loss: 3.812820367515087    Accuracy: 85.78125\n",
      "iter 57 ---  Loss: 3.1266281828284264    Accuracy: 87.96875\n",
      "iter 58 ---  Loss: 3.6380918473005295    Accuracy: 85.15625\n",
      "iter 59 ---  Loss: 3.2037230879068375    Accuracy: 88.4375\n",
      "iter 60 ---  Loss: 2.7448023557662964    Accuracy: 87.96875\n",
      "iter 61 ---  Loss: 2.9622106328606606    Accuracy: 86.71875\n",
      "iter 62 ---  Loss: 2.732113152742386    Accuracy: 87.8125\n",
      "iter 63 ---  Loss: 3.2022831961512566    Accuracy: 86.5625\n",
      "iter 64 ---  Loss: 2.939762942492962    Accuracy: 87.34375\n",
      "iter 65 ---  Loss: 2.532072991132736    Accuracy: 87.34375\n",
      "iter 66 ---  Loss: 2.8214574679732323    Accuracy: 86.09375\n",
      "iter 67 ---  Loss: 3.423896923661232    Accuracy: 88.75\n",
      "iter 68 ---  Loss: 3.7072949707508087    Accuracy: 87.1875\n",
      "iter 69 ---  Loss: 3.0873357504606247    Accuracy: 88.59375\n",
      "iter 70 ---  Loss: 3.326562501490116    Accuracy: 87.5\n",
      "iter 71 ---  Loss: 2.9060745760798454    Accuracy: 87.5\n",
      "iter 72 ---  Loss: 2.5881519839167595    Accuracy: 88.90625\n",
      "iter 73 ---  Loss: 3.271796330809593    Accuracy: 87.03125\n",
      "iter 74 ---  Loss: 2.6534766107797623    Accuracy: 86.5625\n",
      "iter 75 ---  Loss: 3.3118868470191956    Accuracy: 88.90625\n",
      "iter 76 ---  Loss: 3.149199642241001    Accuracy: 87.1875\n",
      "iter 77 ---  Loss: 2.7034133225679398    Accuracy: 87.96875\n",
      "iter 78 ---  Loss: 3.100570149719715    Accuracy: 85.625\n",
      "iter 79 ---  Loss: 2.836229182779789    Accuracy: 89.0625\n",
      "iter 80 ---  Loss: 3.120465934276581    Accuracy: 88.59375\n",
      "iter 81 ---  Loss: 2.651014491915703    Accuracy: 88.4375\n",
      "iter 82 ---  Loss: 3.437456823885441    Accuracy: 86.875\n",
      "iter 83 ---  Loss: 3.4799588918685913    Accuracy: 87.5\n",
      "iter 84 ---  Loss: 3.0190486013889313    Accuracy: 88.4375\n",
      "iter 85 ---  Loss: 3.5233824476599693    Accuracy: 87.65625\n",
      "iter 86 ---  Loss: 3.0975874587893486    Accuracy: 86.71875\n",
      "iter 87 ---  Loss: 2.6448677107691765    Accuracy: 88.75\n",
      "iter 88 ---  Loss: 2.618166297674179    Accuracy: 88.28125\n",
      "iter 89 ---  Loss: 2.938758745789528    Accuracy: 88.28125\n",
      "iter 90 ---  Loss: 3.2828511968255043    Accuracy: 87.65625\n",
      "iter 91 ---  Loss: 3.1358414590358734    Accuracy: 89.53125\n",
      "iter 92 ---  Loss: 3.61201760917902    Accuracy: 86.40625\n",
      "iter 93 ---  Loss: 3.360407665371895    Accuracy: 86.25\n",
      "iter 94 ---  Loss: 3.1296856105327606    Accuracy: 87.1875\n",
      "iter 95 ---  Loss: 3.1533946245908737    Accuracy: 87.65625\n",
      "iter 96 ---  Loss: 3.1762779355049133    Accuracy: 86.40625\n",
      "iter 97 ---  Loss: 3.093822568655014    Accuracy: 86.875\n",
      "iter 98 ---  Loss: 3.384922631084919    Accuracy: 87.65625\n",
      "iter 99 ---  Loss: 2.8973880112171173    Accuracy: 87.34375\n",
      "iter 100 ---  Loss: 2.978777326643467    Accuracy: 87.5\n",
      "iter 101 ---  Loss: 2.972306542098522    Accuracy: 87.5\n",
      "iter 102 ---  Loss: 3.759293310344219    Accuracy: 84.53125\n",
      "iter 103 ---  Loss: 2.4821005389094353    Accuracy: 87.8125\n",
      "iter 104 ---  Loss: 2.84394084662199    Accuracy: 87.34375\n",
      "iter 105 ---  Loss: 2.954191356897354    Accuracy: 87.5\n",
      "iter 106 ---  Loss: 3.360548973083496    Accuracy: 86.71875\n",
      "iter 107 ---  Loss: 2.8708091154694557    Accuracy: 87.65625\n",
      "iter 108 ---  Loss: 2.969530828297138    Accuracy: 87.65625\n",
      "iter 109 ---  Loss: 2.865265928208828    Accuracy: 89.0625\n",
      "iter 110 ---  Loss: 2.9953293949365616    Accuracy: 86.71875\n",
      "iter 111 ---  Loss: 2.8956851214170456    Accuracy: 87.96875\n",
      "iter 112 ---  Loss: 2.683926723897457    Accuracy: 87.5\n",
      "iter 113 ---  Loss: 2.8473367616534233    Accuracy: 89.375\n",
      "iter 114 ---  Loss: 3.157942794263363    Accuracy: 87.5\n",
      "iter 115 ---  Loss: 3.3533833995461464    Accuracy: 88.59375\n",
      "iter 116 ---  Loss: 3.1061395406723022    Accuracy: 86.40625\n",
      "iter 117 ---  Loss: 3.3795814141631126    Accuracy: 89.0625\n",
      "iter 118 ---  Loss: 2.99239419400692    Accuracy: 87.96875\n",
      "iter 119 ---  Loss: 3.6380904763936996    Accuracy: 84.84375\n",
      "iter 120 ---  Loss: 3.398009307682514    Accuracy: 87.34375\n",
      "iter 121 ---  Loss: 2.701525293290615    Accuracy: 89.0625\n",
      "iter 122 ---  Loss: 3.1474992781877518    Accuracy: 86.5625\n",
      "iter 123 ---  Loss: 3.493727281689644    Accuracy: 86.25\n",
      "iter 124 ---  Loss: 3.301869757473469    Accuracy: 85.9375\n",
      "iter 125 ---  Loss: 3.018540419638157    Accuracy: 87.34375\n",
      "iter 126 ---  Loss: 3.1296378895640373    Accuracy: 85.9375\n",
      "iter 127 ---  Loss: 2.8399693369865417    Accuracy: 87.8125\n",
      "iter 128 ---  Loss: 2.6914488300681114    Accuracy: 90.3125\n",
      "iter 129 ---  Loss: 2.6932803615927696    Accuracy: 87.03125\n",
      "iter 130 ---  Loss: 3.290691703557968    Accuracy: 86.09375\n",
      "iter 131 ---  Loss: 2.920817658305168    Accuracy: 86.25\n",
      "iter 132 ---  Loss: 2.936347544193268    Accuracy: 86.71875\n",
      "iter 133 ---  Loss: 2.9082146361470222    Accuracy: 88.125\n",
      "iter 134 ---  Loss: 3.4971465468406677    Accuracy: 86.71875\n",
      "iter 135 ---  Loss: 2.796923950314522    Accuracy: 89.0625\n",
      "iter 136 ---  Loss: 3.0296104699373245    Accuracy: 85.625\n",
      "iter 137 ---  Loss: 3.2366665825247765    Accuracy: 87.1875\n",
      "iter 138 ---  Loss: 2.8780857622623444    Accuracy: 87.34375\n",
      "iter 139 ---  Loss: 2.8393098786473274    Accuracy: 86.71875\n",
      "iter 140 ---  Loss: 3.3325651586055756    Accuracy: 85.0\n",
      "iter 141 ---  Loss: 2.9678520932793617    Accuracy: 86.25\n",
      "iter 142 ---  Loss: 2.788876786828041    Accuracy: 89.0625\n",
      "iter 143 ---  Loss: 3.1772526651620865    Accuracy: 87.8125\n",
      "iter 144 ---  Loss: 2.826911248266697    Accuracy: 87.65625\n",
      "iter 145 ---  Loss: 3.0899858698248863    Accuracy: 87.5\n",
      "iter 146 ---  Loss: 3.0638529881834984    Accuracy: 85.9375\n",
      "iter 147 ---  Loss: 3.016037195920944    Accuracy: 85.15625\n",
      "iter 148 ---  Loss: 2.938337780535221    Accuracy: 86.40625\n",
      "iter 149 ---  Loss: 3.1423774138092995    Accuracy: 87.03125\n",
      "iter 150 ---  Loss: 2.7436445206403732    Accuracy: 87.65625\n",
      "iter 151 ---  Loss: 3.0855060815811157    Accuracy: 88.4375\n",
      "iter 152 ---  Loss: 3.0586477145552635    Accuracy: 87.1875\n",
      "iter 153 ---  Loss: 2.7856295853853226    Accuracy: 87.1875\n",
      "iter 154 ---  Loss: 2.81139525026083    Accuracy: 87.65625\n",
      "iter 155 ---  Loss: 2.7030802443623543    Accuracy: 88.28125\n",
      "iter 156 ---  Loss: 3.4590898230671883    Accuracy: 87.96875\n",
      "iter 157 ---  Loss: 3.018038161098957    Accuracy: 85.0\n",
      "iter 158 ---  Loss: 2.722564235329628    Accuracy: 86.5625\n",
      "iter 159 ---  Loss: 3.1373124569654465    Accuracy: 87.5\n",
      "iter 160 ---  Loss: 3.384903833270073    Accuracy: 85.0\n",
      "iter 161 ---  Loss: 2.7038028091192245    Accuracy: 88.75\n",
      "iter 162 ---  Loss: 2.9756726771593094    Accuracy: 88.28125\n",
      "iter 163 ---  Loss: 3.1132741272449493    Accuracy: 86.5625\n",
      "iter 164 ---  Loss: 2.8782027289271355    Accuracy: 89.6875\n",
      "iter 165 ---  Loss: 2.871702156960964    Accuracy: 87.65625\n",
      "iter 166 ---  Loss: 2.885826624929905    Accuracy: 89.375\n",
      "iter 167 ---  Loss: 3.2056545317173004    Accuracy: 87.34375\n",
      "iter 168 ---  Loss: 3.3118236362934113    Accuracy: 86.875\n",
      "iter 169 ---  Loss: 2.590556524693966    Accuracy: 87.96875\n",
      "iter 170 ---  Loss: 3.029445469379425    Accuracy: 87.5\n",
      "iter 171 ---  Loss: 2.6950824335217476    Accuracy: 86.875\n",
      "iter 172 ---  Loss: 3.4848020896315575    Accuracy: 85.78125\n",
      "iter 173 ---  Loss: 2.9624285995960236    Accuracy: 86.40625\n",
      "iter 174 ---  Loss: 3.5327970013022423    Accuracy: 87.34375\n",
      "iter 175 ---  Loss: 3.538750037550926    Accuracy: 85.625\n",
      "iter 176 ---  Loss: 3.238542638719082    Accuracy: 87.8125\n",
      "iter 177 ---  Loss: 2.6790295019745827    Accuracy: 88.90625\n",
      "iter 178 ---  Loss: 3.132853589951992    Accuracy: 87.65625\n",
      "iter 179 ---  Loss: 2.9122237265110016    Accuracy: 88.28125\n",
      "iter 180 ---  Loss: 2.778670519590378    Accuracy: 87.5\n",
      "iter 181 ---  Loss: 3.761602461338043    Accuracy: 85.9375\n",
      "iter 182 ---  Loss: 3.143698789179325    Accuracy: 84.53125\n",
      "iter 183 ---  Loss: 3.3972212374210358    Accuracy: 86.5625\n",
      "iter 184 ---  Loss: 2.8286246806383133    Accuracy: 87.96875\n",
      "iter 185 ---  Loss: 3.255303665995598    Accuracy: 87.8125\n",
      "iter 186 ---  Loss: 3.7794572338461876    Accuracy: 84.6875\n",
      "iter 187 ---  Loss: 2.862787239253521    Accuracy: 87.34375\n",
      "iter 188 ---  Loss: 2.726107321679592    Accuracy: 86.71875\n",
      "iter 189 ---  Loss: 3.402940332889557    Accuracy: 86.5625\n",
      "iter 190 ---  Loss: 3.2788304463028908    Accuracy: 89.375\n",
      "iter 191 ---  Loss: 3.4306023493409157    Accuracy: 85.0\n",
      "iter 192 ---  Loss: 2.8029057905077934    Accuracy: 85.78125\n",
      "iter 193 ---  Loss: 2.782463699579239    Accuracy: 87.03125\n",
      "iter 194 ---  Loss: 3.357472874224186    Accuracy: 87.34375\n",
      "iter 195 ---  Loss: 3.691098354756832    Accuracy: 85.625\n",
      "iter 196 ---  Loss: 2.711255818605423    Accuracy: 89.0625\n",
      "iter 197 ---  Loss: 3.7049284502863884    Accuracy: 87.03125\n",
      "iter 198 ---  Loss: 3.282114177942276    Accuracy: 86.5625\n",
      "iter 199 ---  Loss: 3.021835185587406    Accuracy: 87.1875\n",
      "iter 200 ---  Loss: 3.8255283683538437    Accuracy: 85.9375\n",
      "iter 201 ---  Loss: 3.4557661563158035    Accuracy: 86.71875\n",
      "iter 202 ---  Loss: 2.929899610579014    Accuracy: 87.1875\n",
      "iter 203 ---  Loss: 3.491570331156254    Accuracy: 86.875\n",
      "iter 204 ---  Loss: 2.7516862750053406    Accuracy: 86.875\n",
      "iter 205 ---  Loss: 3.2635388225317    Accuracy: 85.78125\n",
      "iter 206 ---  Loss: 2.884901575744152    Accuracy: 87.8125\n",
      "iter 207 ---  Loss: 2.8349250182509422    Accuracy: 85.15625\n",
      "iter 208 ---  Loss: 2.5548531636595726    Accuracy: 86.40625\n",
      "iter 209 ---  Loss: 3.04777655005455    Accuracy: 86.09375\n",
      "iter 210 ---  Loss: 3.0505076870322227    Accuracy: 86.5625\n",
      "iter 211 ---  Loss: 2.8642453998327255    Accuracy: 88.125\n",
      "iter 212 ---  Loss: 2.5137512758374214    Accuracy: 88.4375\n",
      "iter 213 ---  Loss: 2.805357903242111    Accuracy: 87.03125\n",
      "iter 214 ---  Loss: 3.0531412959098816    Accuracy: 86.09375\n",
      "iter 215 ---  Loss: 3.290878713130951    Accuracy: 86.71875\n",
      "iter 216 ---  Loss: 2.7819049283862114    Accuracy: 86.71875\n",
      "iter 217 ---  Loss: 2.930185578763485    Accuracy: 89.0625\n",
      "iter 218 ---  Loss: 2.648710682988167    Accuracy: 87.5\n",
      "iter 219 ---  Loss: 2.760512411594391    Accuracy: 88.59375\n",
      "iter 220 ---  Loss: 2.6655247509479523    Accuracy: 87.65625\n",
      "iter 221 ---  Loss: 2.92814302444458    Accuracy: 85.15625\n",
      "iter 222 ---  Loss: 3.126192420721054    Accuracy: 86.5625\n",
      "iter 223 ---  Loss: 2.8185545280575752    Accuracy: 88.75\n",
      "iter 224 ---  Loss: 3.302089974284172    Accuracy: 86.5625\n",
      "iter 225 ---  Loss: 3.284237839281559    Accuracy: 87.5\n",
      "iter 226 ---  Loss: 2.555122710764408    Accuracy: 89.375\n",
      "iter 227 ---  Loss: 3.486646443605423    Accuracy: 85.78125\n",
      "iter 228 ---  Loss: 3.1654593348503113    Accuracy: 85.46875\n",
      "iter 229 ---  Loss: 2.858786001801491    Accuracy: 87.03125\n",
      "iter 230 ---  Loss: 3.678960084915161    Accuracy: 87.96875\n",
      "iter 231 ---  Loss: 3.1938252598047256    Accuracy: 86.875\n",
      "iter 232 ---  Loss: 2.647734612226486    Accuracy: 86.875\n",
      "iter 233 ---  Loss: 2.6183666065335274    Accuracy: 88.28125\n",
      "iter 234 ---  Loss: 2.8476367443799973    Accuracy: 86.875\n",
      "iter 235 ---  Loss: 3.8043357878923416    Accuracy: 84.21875\n",
      "iter 236 ---  Loss: 3.552598848938942    Accuracy: 85.15625\n",
      "iter 237 ---  Loss: 3.1118037700653076    Accuracy: 87.96875\n",
      "iter 238 ---  Loss: 3.074289433658123    Accuracy: 86.71875\n",
      "iter 239 ---  Loss: 3.138079509139061    Accuracy: 86.09375\n",
      "iter 240 ---  Loss: 2.994104787707329    Accuracy: 87.8125\n",
      "iter 241 ---  Loss: 3.329311966896057    Accuracy: 86.40625\n",
      "iter 242 ---  Loss: 2.9629871174693108    Accuracy: 87.34375\n",
      "iter 243 ---  Loss: 2.5513888895511627    Accuracy: 85.78125\n",
      "iter 244 ---  Loss: 2.9923626482486725    Accuracy: 87.03125\n",
      "iter 245 ---  Loss: 3.5923105999827385    Accuracy: 86.09375\n",
      "iter 246 ---  Loss: 2.9049181044101715    Accuracy: 86.5625\n",
      "iter 247 ---  Loss: 3.0891498923301697    Accuracy: 88.75\n",
      "iter 248 ---  Loss: 3.0567243546247482    Accuracy: 87.5\n",
      "iter 249 ---  Loss: 2.7041492015123367    Accuracy: 87.5\n",
      "iter 250 ---  Loss: 2.887362502515316    Accuracy: 87.34375\n",
      "iter 251 ---  Loss: 3.371682234108448    Accuracy: 85.9375\n",
      "iter 252 ---  Loss: 2.9849928095936775    Accuracy: 86.875\n",
      "iter 253 ---  Loss: 3.6089634224772453    Accuracy: 87.5\n",
      "iter 254 ---  Loss: 3.207382895052433    Accuracy: 86.40625\n",
      "iter 255 ---  Loss: 3.2534967958927155    Accuracy: 87.34375\n",
      "iter 256 ---  Loss: 2.5376855805516243    Accuracy: 89.0625\n",
      "iter 257 ---  Loss: 2.9662995114922523    Accuracy: 87.34375\n",
      "iter 258 ---  Loss: 2.9595085829496384    Accuracy: 87.1875\n",
      "iter 259 ---  Loss: 3.062602624297142    Accuracy: 87.03125\n",
      "iter 260 ---  Loss: 3.577348940074444    Accuracy: 86.09375\n",
      "iter 261 ---  Loss: 3.386089973151684    Accuracy: 87.1875\n",
      "iter 262 ---  Loss: 2.636185109615326    Accuracy: 88.75\n",
      "iter 263 ---  Loss: 3.046287924051285    Accuracy: 87.34375\n",
      "iter 264 ---  Loss: 3.210757367312908    Accuracy: 86.40625\n",
      "iter 265 ---  Loss: 3.093871995806694    Accuracy: 87.1875\n",
      "iter 266 ---  Loss: 4.059328109025955    Accuracy: 85.625\n",
      "iter 267 ---  Loss: 3.170500449836254    Accuracy: 87.5\n",
      "iter 268 ---  Loss: 2.853858560323715    Accuracy: 87.96875\n",
      "iter 269 ---  Loss: 3.3061245009303093    Accuracy: 85.3125\n",
      "iter 270 ---  Loss: 2.539800427854061    Accuracy: 87.03125\n",
      "iter 271 ---  Loss: 2.80959864705801    Accuracy: 85.3125\n",
      "iter 272 ---  Loss: 2.510570742189884    Accuracy: 86.71875\n",
      "iter 273 ---  Loss: 2.5458554178476334    Accuracy: 87.96875\n",
      "iter 274 ---  Loss: 3.645743675529957    Accuracy: 87.34375\n",
      "iter 275 ---  Loss: 3.022005870938301    Accuracy: 87.5\n",
      "iter 276 ---  Loss: 2.636224679648876    Accuracy: 88.59375\n",
      "iter 277 ---  Loss: 2.7949953749775887    Accuracy: 87.1875\n",
      "iter 278 ---  Loss: 3.193795531988144    Accuracy: 87.5\n",
      "iter 279 ---  Loss: 2.983676068484783    Accuracy: 88.28125\n",
      "iter 280 ---  Loss: 4.070509418845177    Accuracy: 84.0625\n",
      "iter 281 ---  Loss: 2.691478557884693    Accuracy: 89.53125\n",
      "iter 282 ---  Loss: 3.3121918961405754    Accuracy: 85.0\n",
      "iter 283 ---  Loss: 2.5133180543780327    Accuracy: 87.65625\n",
      "iter 284 ---  Loss: 2.897690497338772    Accuracy: 88.59375\n",
      "iter 285 ---  Loss: 2.9433471858501434    Accuracy: 86.25\n",
      "iter 286 ---  Loss: 3.121195062994957    Accuracy: 86.71875\n",
      "iter 287 ---  Loss: 3.0354138389229774    Accuracy: 87.34375\n",
      "iter 288 ---  Loss: 2.884175419807434    Accuracy: 87.34375\n",
      "iter 289 ---  Loss: 3.19022049754858    Accuracy: 87.03125\n",
      "iter 290 ---  Loss: 3.563639037311077    Accuracy: 85.78125\n",
      "iter 291 ---  Loss: 3.0778925642371178    Accuracy: 85.9375\n",
      "iter 292 ---  Loss: 3.440266616642475    Accuracy: 85.9375\n",
      "iter 293 ---  Loss: 3.1097768619656563    Accuracy: 85.78125\n",
      "iter 294 ---  Loss: 3.8909534737467766    Accuracy: 85.0\n",
      "iter 295 ---  Loss: 2.866608738899231    Accuracy: 87.03125\n",
      "iter 296 ---  Loss: 3.1488615944981575    Accuracy: 86.71875\n",
      "iter 297 ---  Loss: 3.4902891889214516    Accuracy: 85.46875\n",
      "iter 298 ---  Loss: 3.3415064960718155    Accuracy: 86.71875\n",
      "iter 299 ---  Loss: 3.3075508773326874    Accuracy: 85.78125\n",
      "iter 300 ---  Loss: 3.36736848205328    Accuracy: 85.78125\n",
      "iter 301 ---  Loss: 3.0856286585330963    Accuracy: 84.84375\n",
      "iter 302 ---  Loss: 2.965312235057354    Accuracy: 87.1875\n",
      "iter 303 ---  Loss: 3.3326589316129684    Accuracy: 85.625\n",
      "iter 304 ---  Loss: 2.6495778635144234    Accuracy: 88.75\n",
      "iter 305 ---  Loss: 2.8250722438097    Accuracy: 86.875\n",
      "iter 306 ---  Loss: 3.3036221340298653    Accuracy: 85.15625\n",
      "iter 307 ---  Loss: 3.9245227351784706    Accuracy: 85.78125\n",
      "iter 308 ---  Loss: 2.972062699496746    Accuracy: 85.9375\n",
      "iter 309 ---  Loss: 3.1940407902002335    Accuracy: 86.25\n",
      "iter 310 ---  Loss: 3.3823981657624245    Accuracy: 85.0\n",
      "iter 311 ---  Loss: 3.0234066545963287    Accuracy: 87.1875\n",
      "iter 312 ---  Loss: 3.1329443380236626    Accuracy: 84.84375\n",
      "iter 313 ---  Loss: 3.2374666705727577    Accuracy: 85.0\n",
      "iter 314 ---  Loss: 2.600442498922348    Accuracy: 87.5\n",
      "iter 315 ---  Loss: 3.1041100695729256    Accuracy: 86.40625\n",
      "iter 316 ---  Loss: 2.87352392077446    Accuracy: 86.875\n",
      "iter 317 ---  Loss: 3.2024012729525566    Accuracy: 87.34375\n",
      "iter 318 ---  Loss: 3.0299669355154037    Accuracy: 86.40625\n",
      "iter 319 ---  Loss: 3.00087558478117    Accuracy: 86.5625\n",
      "iter 320 ---  Loss: 3.955784097313881    Accuracy: 82.65625\n",
      "iter 321 ---  Loss: 3.0243735536932945    Accuracy: 86.5625\n",
      "iter 322 ---  Loss: 2.8201503977179527    Accuracy: 86.40625\n",
      "iter 323 ---  Loss: 2.5844771414995193    Accuracy: 88.28125\n",
      "iter 324 ---  Loss: 3.300753138959408    Accuracy: 87.1875\n",
      "iter 325 ---  Loss: 2.958302356302738    Accuracy: 85.78125\n",
      "iter 326 ---  Loss: 3.3138152956962585    Accuracy: 84.53125\n",
      "iter 327 ---  Loss: 2.920246295630932    Accuracy: 86.5625\n",
      "iter 328 ---  Loss: 3.0235838890075684    Accuracy: 87.34375\n",
      "iter 329 ---  Loss: 3.124202996492386    Accuracy: 85.78125\n",
      "iter 330 ---  Loss: 3.5028435587882996    Accuracy: 85.9375\n",
      "iter 331 ---  Loss: 3.3233812898397446    Accuracy: 85.3125\n",
      "iter 332 ---  Loss: 3.4276102259755135    Accuracy: 86.71875\n",
      "iter 333 ---  Loss: 3.035197861492634    Accuracy: 85.0\n",
      "iter 334 ---  Loss: 2.827874705195427    Accuracy: 86.875\n",
      "iter 335 ---  Loss: 3.368817523121834    Accuracy: 86.40625\n",
      "iter 336 ---  Loss: 3.1653424352407455    Accuracy: 85.46875\n",
      "iter 337 ---  Loss: 3.458458296954632    Accuracy: 86.25\n",
      "iter 338 ---  Loss: 3.0306860879063606    Accuracy: 85.9375\n",
      "iter 339 ---  Loss: 3.646328568458557    Accuracy: 86.40625\n",
      "iter 340 ---  Loss: 3.082758255302906    Accuracy: 84.21875\n",
      "iter 341 ---  Loss: 3.9548517391085625    Accuracy: 85.9375\n",
      "iter 342 ---  Loss: 3.030706472694874    Accuracy: 88.125\n",
      "iter 343 ---  Loss: 2.8928611055016518    Accuracy: 87.03125\n",
      "iter 344 ---  Loss: 3.548710733652115    Accuracy: 85.3125\n",
      "iter 345 ---  Loss: 3.8700429499149323    Accuracy: 86.25\n",
      "iter 346 ---  Loss: 3.6663916260004044    Accuracy: 87.1875\n",
      "iter 347 ---  Loss: 3.4541463926434517    Accuracy: 86.5625\n",
      "iter 348 ---  Loss: 4.218570835888386    Accuracy: 85.625\n",
      "iter 349 ---  Loss: 3.0725779458880424    Accuracy: 84.84375\n",
      "iter 350 ---  Loss: 3.430041655898094    Accuracy: 85.78125\n",
      "iter 351 ---  Loss: 3.344207301735878    Accuracy: 86.25\n",
      "iter 352 ---  Loss: 2.773737244307995    Accuracy: 87.34375\n",
      "iter 353 ---  Loss: 3.1227704286575317    Accuracy: 88.75\n",
      "iter 354 ---  Loss: 2.803187370300293    Accuracy: 87.5\n",
      "iter 355 ---  Loss: 2.93229553848505    Accuracy: 86.71875\n",
      "iter 356 ---  Loss: 3.5170644372701645    Accuracy: 86.25\n",
      "iter 357 ---  Loss: 3.1798919066786766    Accuracy: 87.5\n",
      "iter 358 ---  Loss: 3.199167124927044    Accuracy: 85.15625\n",
      "iter 359 ---  Loss: 2.744966045022011    Accuracy: 86.40625\n",
      "iter 360 ---  Loss: 3.1514190956950188    Accuracy: 86.71875\n",
      "iter 361 ---  Loss: 2.738506779074669    Accuracy: 87.34375\n",
      "iter 362 ---  Loss: 2.8025399819016457    Accuracy: 87.65625\n",
      "iter 363 ---  Loss: 3.4157915115356445    Accuracy: 88.28125\n",
      "iter 364 ---  Loss: 3.6373442709445953    Accuracy: 85.625\n",
      "iter 365 ---  Loss: 3.0995974615216255    Accuracy: 85.15625\n",
      "iter 366 ---  Loss: 2.9915882870554924    Accuracy: 88.59375\n",
      "iter 367 ---  Loss: 3.359585002064705    Accuracy: 86.25\n",
      "iter 368 ---  Loss: 3.5071786791086197    Accuracy: 86.875\n",
      "iter 369 ---  Loss: 2.9837502166628838    Accuracy: 87.96875\n",
      "iter 370 ---  Loss: 2.8378950133919716    Accuracy: 88.4375\n",
      "iter 371 ---  Loss: 2.753244787454605    Accuracy: 89.375\n",
      "iter 372 ---  Loss: 2.5795206651091576    Accuracy: 88.75\n",
      "iter 373 ---  Loss: 3.047222316265106    Accuracy: 86.25\n",
      "iter 374 ---  Loss: 2.843220964074135    Accuracy: 90.0\n",
      "iter 375 ---  Loss: 4.1120492815971375    Accuracy: 86.40625\n",
      "iter 376 ---  Loss: 4.260916896164417    Accuracy: 84.6875\n",
      "iter 377 ---  Loss: 2.547876313328743    Accuracy: 89.53125\n",
      "iter 378 ---  Loss: 2.9423324689269066    Accuracy: 87.5\n",
      "iter 379 ---  Loss: 2.850722976028919    Accuracy: 89.375\n",
      "iter 380 ---  Loss: 3.158029943704605    Accuracy: 88.28125\n",
      "iter 381 ---  Loss: 2.5747235789895058    Accuracy: 87.96875\n",
      "iter 382 ---  Loss: 3.0312300845980644    Accuracy: 86.09375\n",
      "iter 383 ---  Loss: 2.9128179773688316    Accuracy: 86.40625\n",
      "iter 384 ---  Loss: 3.212389186024666    Accuracy: 87.03125\n",
      "iter 385 ---  Loss: 3.073868088424206    Accuracy: 85.9375\n",
      "iter 386 ---  Loss: 3.032780669629574    Accuracy: 89.0625\n",
      "iter 387 ---  Loss: 3.393742799758911    Accuracy: 87.8125\n",
      "iter 388 ---  Loss: 2.653086043894291    Accuracy: 87.1875\n",
      "iter 389 ---  Loss: 3.166384331882    Accuracy: 87.1875\n",
      "iter 390 ---  Loss: 2.986882507801056    Accuracy: 88.28125\n",
      "iter 391 ---  Loss: 3.0932910963892937    Accuracy: 86.71875\n",
      "iter 392 ---  Loss: 3.012940898537636    Accuracy: 87.65625\n",
      "iter 393 ---  Loss: 3.257463328540325    Accuracy: 87.96875\n",
      "iter 394 ---  Loss: 3.205504350364208    Accuracy: 86.875\n",
      "iter 395 ---  Loss: 3.451337121427059    Accuracy: 85.625\n",
      "iter 396 ---  Loss: 2.368196375668049    Accuracy: 88.4375\n",
      "iter 397 ---  Loss: 2.9964489340782166    Accuracy: 87.96875\n",
      "iter 398 ---  Loss: 2.749037817120552    Accuracy: 86.71875\n",
      "iter 399 ---  Loss: 3.32320424169302    Accuracy: 86.71875\n",
      "iter 400 ---  Loss: 2.4567834362387657    Accuracy: 88.90625\n",
      "iter 401 ---  Loss: 2.9613937065005302    Accuracy: 87.8125\n",
      "iter 402 ---  Loss: 3.143780715763569    Accuracy: 86.5625\n",
      "iter 403 ---  Loss: 3.4724728912115097    Accuracy: 86.25\n",
      "iter 404 ---  Loss: 3.504863478243351    Accuracy: 85.0\n",
      "iter 405 ---  Loss: 3.0614104494452477    Accuracy: 87.8125\n",
      "iter 406 ---  Loss: 3.132254905998707    Accuracy: 87.65625\n",
      "iter 407 ---  Loss: 3.289909154176712    Accuracy: 85.78125\n",
      "iter 408 ---  Loss: 2.8281473368406296    Accuracy: 88.4375\n",
      "iter 409 ---  Loss: 2.4640128165483475    Accuracy: 88.4375\n",
      "iter 410 ---  Loss: 3.1408086717128754    Accuracy: 88.125\n",
      "iter 411 ---  Loss: 2.917714938521385    Accuracy: 86.09375\n",
      "iter 412 ---  Loss: 2.531083032488823    Accuracy: 88.28125\n",
      "iter 413 ---  Loss: 2.7700270041823387    Accuracy: 88.90625\n",
      "iter 414 ---  Loss: 2.7863069474697113    Accuracy: 88.90625\n",
      "iter 415 ---  Loss: 3.3983188793063164    Accuracy: 86.5625\n",
      "iter 416 ---  Loss: 3.570157006382942    Accuracy: 85.3125\n",
      "iter 417 ---  Loss: 2.888416863977909    Accuracy: 88.75\n",
      "iter 418 ---  Loss: 2.6688298285007477    Accuracy: 87.8125\n",
      "iter 419 ---  Loss: 3.2668151557445526    Accuracy: 87.1875\n",
      "iter 420 ---  Loss: 3.1718764677643776    Accuracy: 86.71875\n",
      "iter 421 ---  Loss: 3.2159437462687492    Accuracy: 87.1875\n",
      "iter 422 ---  Loss: 2.607929967343807    Accuracy: 88.4375\n",
      "iter 423 ---  Loss: 2.8758940249681473    Accuracy: 88.90625\n",
      "iter 424 ---  Loss: 3.592166967689991    Accuracy: 86.71875\n",
      "iter 425 ---  Loss: 3.213216558098793    Accuracy: 86.875\n",
      "iter 426 ---  Loss: 2.9428463131189346    Accuracy: 88.125\n",
      "iter 427 ---  Loss: 2.9621322751045227    Accuracy: 87.8125\n",
      "iter 428 ---  Loss: 3.111159473657608    Accuracy: 86.40625\n",
      "iter 429 ---  Loss: 3.372224472463131    Accuracy: 86.09375\n",
      "iter 430 ---  Loss: 2.8222582191228867    Accuracy: 90.15625\n",
      "iter 431 ---  Loss: 2.956019304692745    Accuracy: 88.59375\n",
      "iter 432 ---  Loss: 3.142715349793434    Accuracy: 87.34375\n",
      "iter 433 ---  Loss: 2.836604155600071    Accuracy: 87.1875\n",
      "iter 434 ---  Loss: 2.9456175789237022    Accuracy: 88.4375\n",
      "iter 435 ---  Loss: 3.8911272063851357    Accuracy: 85.3125\n",
      "iter 436 ---  Loss: 2.867383673787117    Accuracy: 87.65625\n",
      "iter 437 ---  Loss: 4.116709798574448    Accuracy: 86.71875\n",
      "iter 438 ---  Loss: 3.3136642202734947    Accuracy: 86.71875\n",
      "iter 439 ---  Loss: 3.2764912843704224    Accuracy: 85.3125\n",
      "iter 440 ---  Loss: 3.1452084705233574    Accuracy: 86.25\n",
      "iter 441 ---  Loss: 3.104951933026314    Accuracy: 86.5625\n",
      "iter 442 ---  Loss: 3.127513162791729    Accuracy: 86.71875\n",
      "iter 443 ---  Loss: 2.677042633295059    Accuracy: 89.84375\n",
      "iter 444 ---  Loss: 3.5740898847579956    Accuracy: 86.5625\n",
      "iter 445 ---  Loss: 3.255840450525284    Accuracy: 87.96875\n",
      "iter 446 ---  Loss: 2.8640455827116966    Accuracy: 86.71875\n",
      "iter 447 ---  Loss: 2.5376319140195847    Accuracy: 88.75\n",
      "iter 448 ---  Loss: 3.116032660007477    Accuracy: 87.96875\n",
      "iter 449 ---  Loss: 3.1508089005947113    Accuracy: 86.5625\n",
      "iter 450 ---  Loss: 3.4890231639146805    Accuracy: 85.625\n",
      "iter 451 ---  Loss: 2.854965016245842    Accuracy: 87.8125\n",
      "iter 452 ---  Loss: 3.191896677017212    Accuracy: 86.5625\n",
      "iter 453 ---  Loss: 3.1791338324546814    Accuracy: 87.8125\n",
      "iter 454 ---  Loss: 2.6825091391801834    Accuracy: 86.875\n",
      "iter 455 ---  Loss: 3.411053568124771    Accuracy: 87.1875\n",
      "iter 456 ---  Loss: 2.895357295870781    Accuracy: 86.09375\n",
      "iter 457 ---  Loss: 3.1087387576699257    Accuracy: 87.03125\n",
      "iter 458 ---  Loss: 3.353859283030033    Accuracy: 86.40625\n",
      "iter 459 ---  Loss: 3.604423686861992    Accuracy: 85.9375\n",
      "iter 460 ---  Loss: 2.5529864728450775    Accuracy: 88.75\n",
      "iter 461 ---  Loss: 3.076356701552868    Accuracy: 87.34375\n",
      "iter 462 ---  Loss: 2.826212704181671    Accuracy: 86.09375\n",
      "iter 463 ---  Loss: 2.9911555498838425    Accuracy: 88.90625\n",
      "iter 464 ---  Loss: 3.60793499648571    Accuracy: 87.8125\n",
      "iter 465 ---  Loss: 3.608821414411068    Accuracy: 86.25\n",
      "iter 466 ---  Loss: 2.8118860125541687    Accuracy: 87.34375\n",
      "iter 467 ---  Loss: 3.2790893837809563    Accuracy: 84.53125\n",
      "iter 468 ---  Loss: 3.5810948982834816    Accuracy: 86.71875\n",
      "iter 469 ---  Loss: 3.04934474080801    Accuracy: 86.40625\n",
      "iter 470 ---  Loss: 3.4055258855223656    Accuracy: 87.8125\n",
      "iter 471 ---  Loss: 3.1757653579115868    Accuracy: 87.65625\n",
      "iter 472 ---  Loss: 2.951344884932041    Accuracy: 85.78125\n",
      "iter 473 ---  Loss: 2.6896848306059837    Accuracy: 88.4375\n",
      "iter 474 ---  Loss: 3.0987490341067314    Accuracy: 86.5625\n",
      "iter 475 ---  Loss: 3.193296119570732    Accuracy: 88.4375\n",
      "iter 476 ---  Loss: 3.173442490398884    Accuracy: 87.1875\n",
      "iter 477 ---  Loss: 2.8377418890595436    Accuracy: 89.0625\n",
      "iter 478 ---  Loss: 3.1539966836571693    Accuracy: 86.71875\n",
      "iter 479 ---  Loss: 3.5125883370637894    Accuracy: 88.90625\n",
      "iter 480 ---  Loss: 3.510534919798374    Accuracy: 87.5\n",
      "iter 481 ---  Loss: 3.314206287264824    Accuracy: 86.875\n",
      "iter 482 ---  Loss: 4.273729860782623    Accuracy: 85.46875\n",
      "iter 483 ---  Loss: 3.6316435635089874    Accuracy: 86.25\n",
      "iter 484 ---  Loss: 2.8515120819211006    Accuracy: 87.1875\n",
      "iter 485 ---  Loss: 3.370065212249756    Accuracy: 86.40625\n",
      "iter 486 ---  Loss: 3.363060437142849    Accuracy: 84.6875\n",
      "iter 487 ---  Loss: 2.957650162279606    Accuracy: 89.53125\n",
      "iter 488 ---  Loss: 3.5741554498672485    Accuracy: 87.65625\n",
      "iter 489 ---  Loss: 3.033351421356201    Accuracy: 88.125\n",
      "iter 490 ---  Loss: 3.565511107444763    Accuracy: 85.3125\n",
      "iter 491 ---  Loss: 2.6646105498075485    Accuracy: 89.21875\n",
      "iter 492 ---  Loss: 3.7760690823197365    Accuracy: 84.0625\n",
      "iter 493 ---  Loss: 3.652750290930271    Accuracy: 86.71875\n",
      "iter 494 ---  Loss: 2.4939440116286278    Accuracy: 88.4375\n",
      "iter 495 ---  Loss: 2.529999814927578    Accuracy: 89.6875\n",
      "iter 496 ---  Loss: 3.3094777315855026    Accuracy: 85.0\n",
      "iter 497 ---  Loss: 2.9833405315876007    Accuracy: 86.09375\n",
      "iter 498 ---  Loss: 2.6764467507600784    Accuracy: 89.53125\n",
      "iter 499 ---  Loss: 2.5334047749638557    Accuracy: 88.75\n",
      "iter 500 ---  Loss: 3.0506025925278664    Accuracy: 87.03125\n",
      "iter 501 ---  Loss: 2.696938134729862    Accuracy: 87.34375\n",
      "iter 502 ---  Loss: 2.6234531924128532    Accuracy: 87.65625\n",
      "iter 503 ---  Loss: 3.210811384022236    Accuracy: 87.1875\n",
      "iter 504 ---  Loss: 3.97121699154377    Accuracy: 85.15625\n",
      "iter 505 ---  Loss: 3.0880562514066696    Accuracy: 87.65625\n",
      "iter 506 ---  Loss: 2.9613820239901543    Accuracy: 87.03125\n",
      "iter 507 ---  Loss: 2.5041784569621086    Accuracy: 88.90625\n",
      "iter 508 ---  Loss: 2.888772413134575    Accuracy: 86.40625\n",
      "iter 509 ---  Loss: 3.458590753376484    Accuracy: 85.3125\n",
      "iter 510 ---  Loss: 3.138514630496502    Accuracy: 86.25\n",
      "iter 511 ---  Loss: 3.9149236977100372    Accuracy: 87.34375\n",
      "iter 512 ---  Loss: 2.597984477877617    Accuracy: 87.5\n",
      "iter 513 ---  Loss: 2.8470732420682907    Accuracy: 87.65625\n",
      "iter 514 ---  Loss: 2.8463780358433723    Accuracy: 89.21875\n",
      "iter 515 ---  Loss: 2.6695951372385025    Accuracy: 89.6875\n",
      "iter 516 ---  Loss: 3.0068974047899246    Accuracy: 87.65625\n",
      "iter 517 ---  Loss: 3.286081239581108    Accuracy: 87.03125\n",
      "iter 518 ---  Loss: 3.9402767419815063    Accuracy: 85.15625\n",
      "iter 519 ---  Loss: 3.351599596440792    Accuracy: 85.9375\n",
      "iter 520 ---  Loss: 2.5865300446748734    Accuracy: 88.59375\n",
      "iter 521 ---  Loss: 2.8231103122234344    Accuracy: 87.8125\n",
      "iter 522 ---  Loss: 3.499789074063301    Accuracy: 86.5625\n",
      "iter 523 ---  Loss: 2.719837635755539    Accuracy: 88.4375\n",
      "iter 524 ---  Loss: 2.705502465367317    Accuracy: 86.25\n",
      "iter 525 ---  Loss: 3.348524920642376    Accuracy: 86.40625\n",
      "iter 526 ---  Loss: 3.4556685388088226    Accuracy: 87.8125\n",
      "iter 527 ---  Loss: 3.6778005808591843    Accuracy: 86.5625\n",
      "iter 528 ---  Loss: 3.5223389491438866    Accuracy: 87.5\n",
      "iter 529 ---  Loss: 2.81376925855875    Accuracy: 86.40625\n",
      "iter 530 ---  Loss: 2.9912454411387444    Accuracy: 88.125\n",
      "iter 531 ---  Loss: 4.229486420750618    Accuracy: 84.375\n",
      "iter 532 ---  Loss: 2.94850342720747    Accuracy: 87.03125\n",
      "iter 533 ---  Loss: 2.949133552610874    Accuracy: 87.1875\n",
      "iter 534 ---  Loss: 2.6621897518634796    Accuracy: 88.4375\n",
      "iter 535 ---  Loss: 3.285873405635357    Accuracy: 87.1875\n",
      "iter 536 ---  Loss: 3.031216949224472    Accuracy: 88.4375\n",
      "iter 537 ---  Loss: 3.2224840000271797    Accuracy: 86.25\n",
      "iter 538 ---  Loss: 2.6757442131638527    Accuracy: 86.40625\n",
      "iter 539 ---  Loss: 3.5755774676799774    Accuracy: 87.5\n",
      "iter 540 ---  Loss: 3.3471693098545074    Accuracy: 86.09375\n",
      "iter 541 ---  Loss: 3.4686447605490685    Accuracy: 87.34375\n",
      "iter 542 ---  Loss: 3.4435412287712097    Accuracy: 87.8125\n",
      "iter 543 ---  Loss: 2.971820645034313    Accuracy: 87.65625\n",
      "iter 544 ---  Loss: 2.597379855811596    Accuracy: 88.90625\n",
      "iter 545 ---  Loss: 3.248424969613552    Accuracy: 87.1875\n",
      "iter 546 ---  Loss: 3.7835473269224167    Accuracy: 85.0\n",
      "iter 547 ---  Loss: 2.5838389173150063    Accuracy: 87.65625\n",
      "iter 548 ---  Loss: 2.6767532974481583    Accuracy: 87.96875\n",
      "iter 549 ---  Loss: 2.807244136929512    Accuracy: 88.75\n",
      "iter 550 ---  Loss: 3.0109538957476616    Accuracy: 88.75\n",
      "iter 551 ---  Loss: 2.6147909238934517    Accuracy: 89.53125\n",
      "iter 552 ---  Loss: 3.3225587978959084    Accuracy: 87.8125\n",
      "iter 553 ---  Loss: 3.5005781576037407    Accuracy: 87.03125\n",
      "iter 554 ---  Loss: 2.6608211398124695    Accuracy: 89.375\n",
      "iter 555 ---  Loss: 3.2762635722756386    Accuracy: 86.25\n",
      "iter 556 ---  Loss: 2.634012259542942    Accuracy: 88.28125\n",
      "iter 557 ---  Loss: 2.490499831736088    Accuracy: 88.4375\n",
      "iter 558 ---  Loss: 2.796939641237259    Accuracy: 90.0\n",
      "iter 559 ---  Loss: 3.370301254093647    Accuracy: 87.1875\n",
      "iter 560 ---  Loss: 3.2608115822076797    Accuracy: 86.875\n",
      "iter 561 ---  Loss: 2.845249190926552    Accuracy: 87.8125\n",
      "iter 562 ---  Loss: 3.113495893776417    Accuracy: 86.875\n",
      "iter 563 ---  Loss: 2.566784456372261    Accuracy: 88.75\n",
      "iter 564 ---  Loss: 2.9029573127627373    Accuracy: 86.40625\n",
      "iter 565 ---  Loss: 3.411788858473301    Accuracy: 86.875\n",
      "iter 566 ---  Loss: 3.5050061121582985    Accuracy: 86.25\n",
      "iter 567 ---  Loss: 3.417464926838875    Accuracy: 87.96875\n",
      "iter 568 ---  Loss: 3.09756513684988    Accuracy: 87.34375\n",
      "iter 569 ---  Loss: 2.940951906144619    Accuracy: 87.96875\n",
      "iter 570 ---  Loss: 3.357568249106407    Accuracy: 86.40625\n",
      "iter 571 ---  Loss: 3.5726640969514847    Accuracy: 87.1875\n",
      "iter 572 ---  Loss: 2.9678797498345375    Accuracy: 87.8125\n",
      "iter 573 ---  Loss: 2.7891392782330513    Accuracy: 88.75\n",
      "iter 574 ---  Loss: 2.8177201226353645    Accuracy: 88.90625\n",
      "iter 575 ---  Loss: 3.4900258481502533    Accuracy: 87.8125\n",
      "iter 576 ---  Loss: 2.81449556350708    Accuracy: 87.8125\n",
      "iter 577 ---  Loss: 3.6150125563144684    Accuracy: 86.09375\n",
      "iter 578 ---  Loss: 2.9399043023586273    Accuracy: 86.875\n",
      "iter 579 ---  Loss: 2.765792466700077    Accuracy: 86.875\n",
      "iter 580 ---  Loss: 3.3983142375946045    Accuracy: 85.3125\n",
      "iter 581 ---  Loss: 2.56017779558897    Accuracy: 88.59375\n",
      "iter 582 ---  Loss: 2.929577976465225    Accuracy: 87.96875\n",
      "iter 583 ---  Loss: 3.097275123000145    Accuracy: 87.03125\n",
      "iter 584 ---  Loss: 3.0751761198043823    Accuracy: 86.40625\n",
      "iter 585 ---  Loss: 2.8446548879146576    Accuracy: 85.78125\n",
      "iter 586 ---  Loss: 2.7886991649866104    Accuracy: 86.71875\n",
      "iter 587 ---  Loss: 2.44993007928133    Accuracy: 89.6875\n",
      "iter 588 ---  Loss: 2.6545813158154488    Accuracy: 88.59375\n",
      "iter 589 ---  Loss: 3.0688640773296356    Accuracy: 87.1875\n",
      "iter 590 ---  Loss: 3.0087667629122734    Accuracy: 86.71875\n",
      "iter 591 ---  Loss: 3.5909365862607956    Accuracy: 85.625\n",
      "iter 592 ---  Loss: 3.0372287705540657    Accuracy: 87.03125\n",
      "iter 593 ---  Loss: 3.682320311665535    Accuracy: 85.625\n",
      "iter 594 ---  Loss: 2.8801003098487854    Accuracy: 86.71875\n",
      "iter 595 ---  Loss: 3.1778171733021736    Accuracy: 87.34375\n",
      "iter 596 ---  Loss: 3.2633681148290634    Accuracy: 86.875\n",
      "iter 597 ---  Loss: 3.308033861219883    Accuracy: 86.5625\n",
      "iter 598 ---  Loss: 3.7946263924241066    Accuracy: 86.5625\n",
      "iter 599 ---  Loss: 3.1952008977532387    Accuracy: 86.09375\n",
      "iter 600 ---  Loss: 2.9609479010105133    Accuracy: 86.71875\n",
      "iter 601 ---  Loss: 3.7476426288485527    Accuracy: 85.46875\n",
      "iter 602 ---  Loss: 2.460713043808937    Accuracy: 89.375\n",
      "iter 603 ---  Loss: 2.9939862862229347    Accuracy: 86.71875\n",
      "iter 604 ---  Loss: 3.2806228920817375    Accuracy: 86.71875\n",
      "iter 605 ---  Loss: 3.4636058136820793    Accuracy: 86.71875\n",
      "iter 606 ---  Loss: 2.827956050634384    Accuracy: 87.34375\n",
      "iter 607 ---  Loss: 3.3511011600494385    Accuracy: 86.25\n",
      "iter 608 ---  Loss: 2.816924564540386    Accuracy: 88.4375\n",
      "iter 609 ---  Loss: 2.814134865999222    Accuracy: 86.875\n",
      "iter 610 ---  Loss: 2.9002293571829796    Accuracy: 86.875\n",
      "iter 611 ---  Loss: 3.1052335873246193    Accuracy: 85.9375\n",
      "iter 612 ---  Loss: 2.867256812751293    Accuracy: 88.125\n",
      "iter 613 ---  Loss: 3.121730662882328    Accuracy: 87.5\n",
      "iter 614 ---  Loss: 2.8309059143066406    Accuracy: 87.96875\n",
      "iter 615 ---  Loss: 2.8653028160333633    Accuracy: 87.34375\n",
      "iter 616 ---  Loss: 2.43881656229496    Accuracy: 89.53125\n",
      "iter 617 ---  Loss: 3.379526875913143    Accuracy: 86.875\n",
      "iter 618 ---  Loss: 2.8495180681347847    Accuracy: 87.96875\n",
      "iter 619 ---  Loss: 2.7736244425177574    Accuracy: 87.03125\n",
      "iter 620 ---  Loss: 3.270276002585888    Accuracy: 87.1875\n",
      "iter 621 ---  Loss: 3.0534212440252304    Accuracy: 87.65625\n",
      "iter 622 ---  Loss: 2.597820170223713    Accuracy: 88.90625\n",
      "iter 623 ---  Loss: 3.1194482669234276    Accuracy: 87.1875\n",
      "iter 624 ---  Loss: 2.754706434905529    Accuracy: 87.96875\n",
      "iter 625 ---  Loss: 2.5914575308561325    Accuracy: 89.53125\n",
      "iter 626 ---  Loss: 2.9162035435438156    Accuracy: 87.5\n",
      "iter 627 ---  Loss: 2.8402139246463776    Accuracy: 86.5625\n",
      "iter 628 ---  Loss: 3.1442751958966255    Accuracy: 86.71875\n",
      "iter 629 ---  Loss: 2.7608355432748795    Accuracy: 87.34375\n",
      "iter 630 ---  Loss: 3.125432536005974    Accuracy: 85.46875\n",
      "iter 631 ---  Loss: 2.8508110120892525    Accuracy: 90.15625\n",
      "iter 632 ---  Loss: 2.673852361738682    Accuracy: 87.1875\n",
      "iter 633 ---  Loss: 2.8587760403752327    Accuracy: 87.96875\n",
      "iter 634 ---  Loss: 3.4932036250829697    Accuracy: 85.46875\n",
      "iter 635 ---  Loss: 2.9412017837166786    Accuracy: 87.8125\n",
      "iter 636 ---  Loss: 2.7411254793405533    Accuracy: 88.59375\n",
      "iter 637 ---  Loss: 3.2824222296476364    Accuracy: 85.625\n",
      "iter 638 ---  Loss: 2.8447211235761642    Accuracy: 89.375\n",
      "iter 639 ---  Loss: 3.573282517492771    Accuracy: 85.625\n",
      "iter 640 ---  Loss: 2.9972086772322655    Accuracy: 88.90625\n",
      "iter 641 ---  Loss: 2.6308909580111504    Accuracy: 89.53125\n",
      "iter 642 ---  Loss: 3.139172211289406    Accuracy: 86.875\n",
      "iter 643 ---  Loss: 3.6607132479548454    Accuracy: 86.25\n",
      "iter 644 ---  Loss: 2.312511958181858    Accuracy: 89.0625\n",
      "iter 645 ---  Loss: 2.574367567896843    Accuracy: 89.375\n",
      "iter 646 ---  Loss: 2.733531355857849    Accuracy: 88.75\n",
      "iter 647 ---  Loss: 3.4342713430523872    Accuracy: 86.09375\n",
      "iter 648 ---  Loss: 2.961086228489876    Accuracy: 88.28125\n",
      "iter 649 ---  Loss: 2.9962210431694984    Accuracy: 86.40625\n",
      "iter 650 ---  Loss: 3.1577636748552322    Accuracy: 86.5625\n",
      "iter 651 ---  Loss: 2.860132120549679    Accuracy: 87.03125\n",
      "iter 652 ---  Loss: 3.5153336599469185    Accuracy: 85.46875\n",
      "iter 653 ---  Loss: 2.944715417921543    Accuracy: 89.0625\n",
      "iter 654 ---  Loss: 2.9072856307029724    Accuracy: 87.03125\n",
      "iter 655 ---  Loss: 3.391334503889084    Accuracy: 85.15625\n",
      "iter 656 ---  Loss: 2.9861404970288277    Accuracy: 89.53125\n",
      "iter 657 ---  Loss: 3.228034906089306    Accuracy: 87.34375\n",
      "iter 658 ---  Loss: 3.543112561106682    Accuracy: 85.46875\n",
      "iter 659 ---  Loss: 3.65040934830904    Accuracy: 85.78125\n",
      "iter 660 ---  Loss: 3.3211540132761    Accuracy: 87.8125\n",
      "iter 661 ---  Loss: 3.226096734404564    Accuracy: 86.875\n",
      "iter 662 ---  Loss: 3.4057688117027283    Accuracy: 86.09375\n",
      "iter 663 ---  Loss: 3.2387757152318954    Accuracy: 88.28125\n",
      "iter 664 ---  Loss: 2.9802134558558464    Accuracy: 88.125\n",
      "iter 665 ---  Loss: 3.4881247133016586    Accuracy: 85.625\n",
      "iter 666 ---  Loss: 2.868966281414032    Accuracy: 89.0625\n",
      "iter 667 ---  Loss: 3.00701642036438    Accuracy: 85.15625\n",
      "iter 668 ---  Loss: 2.8815182894468307    Accuracy: 87.5\n",
      "iter 669 ---  Loss: 3.250751405954361    Accuracy: 87.96875\n",
      "iter 670 ---  Loss: 2.835682652890682    Accuracy: 85.46875\n",
      "iter 671 ---  Loss: 3.123779222369194    Accuracy: 87.96875\n",
      "iter 672 ---  Loss: 3.2058666795492172    Accuracy: 87.65625\n",
      "iter 673 ---  Loss: 2.960240490734577    Accuracy: 86.875\n",
      "iter 674 ---  Loss: 2.924820341169834    Accuracy: 87.8125\n",
      "iter 675 ---  Loss: 2.829352594912052    Accuracy: 87.8125\n",
      "iter 676 ---  Loss: 2.785289876163006    Accuracy: 88.125\n",
      "iter 677 ---  Loss: 2.984516456723213    Accuracy: 87.65625\n",
      "iter 678 ---  Loss: 2.628452904522419    Accuracy: 87.96875\n",
      "iter 679 ---  Loss: 2.8615095019340515    Accuracy: 87.65625\n",
      "iter 680 ---  Loss: 2.954256132245064    Accuracy: 86.5625\n",
      "iter 681 ---  Loss: 3.174450494349003    Accuracy: 87.8125\n",
      "iter 682 ---  Loss: 3.1743776872754097    Accuracy: 86.71875\n",
      "iter 683 ---  Loss: 3.065138392150402    Accuracy: 86.875\n",
      "iter 684 ---  Loss: 3.5083693861961365    Accuracy: 88.4375\n",
      "iter 685 ---  Loss: 3.282983548939228    Accuracy: 85.9375\n",
      "iter 686 ---  Loss: 2.5461800396442413    Accuracy: 88.90625\n",
      "iter 687 ---  Loss: 3.2859212830662727    Accuracy: 86.09375\n",
      "iter 688 ---  Loss: 3.3515017107129097    Accuracy: 84.84375\n",
      "iter 689 ---  Loss: 3.23373956233263    Accuracy: 87.5\n",
      "iter 690 ---  Loss: 3.166914254426956    Accuracy: 87.03125\n",
      "iter 691 ---  Loss: 2.6921000257134438    Accuracy: 87.1875\n",
      "iter 692 ---  Loss: 4.0381182581186295    Accuracy: 85.625\n",
      "iter 693 ---  Loss: 3.4497138410806656    Accuracy: 87.1875\n",
      "iter 694 ---  Loss: 3.0813879892230034    Accuracy: 88.59375\n",
      "iter 695 ---  Loss: 3.169644519686699    Accuracy: 86.5625\n",
      "iter 696 ---  Loss: 3.9746025055646896    Accuracy: 86.71875\n",
      "iter 697 ---  Loss: 2.469124525785446    Accuracy: 87.65625\n",
      "iter 698 ---  Loss: 3.114199250936508    Accuracy: 86.09375\n",
      "iter 699 ---  Loss: 3.1699574813246727    Accuracy: 87.65625\n",
      "iter 700 ---  Loss: 2.7266414389014244    Accuracy: 87.1875\n",
      "iter 701 ---  Loss: 3.1094766184687614    Accuracy: 87.03125\n",
      "iter 702 ---  Loss: 2.9995603263378143    Accuracy: 87.03125\n",
      "iter 703 ---  Loss: 3.423934541642666    Accuracy: 85.625\n",
      "iter 704 ---  Loss: 3.275063745677471    Accuracy: 86.875\n",
      "iter 705 ---  Loss: 3.0972405150532722    Accuracy: 88.90625\n",
      "iter 706 ---  Loss: 3.0932935550808907    Accuracy: 88.90625\n",
      "iter 707 ---  Loss: 3.103461518883705    Accuracy: 89.21875\n",
      "iter 708 ---  Loss: 2.964367352426052    Accuracy: 87.1875\n",
      "iter 709 ---  Loss: 3.0709319710731506    Accuracy: 85.78125\n",
      "iter 710 ---  Loss: 2.7522857934236526    Accuracy: 87.8125\n",
      "iter 711 ---  Loss: 2.8685026466846466    Accuracy: 87.1875\n",
      "iter 712 ---  Loss: 3.015811562538147    Accuracy: 87.65625\n",
      "iter 713 ---  Loss: 2.627623751759529    Accuracy: 86.40625\n",
      "iter 714 ---  Loss: 3.179378516972065    Accuracy: 87.5\n",
      "iter 715 ---  Loss: 2.552898585796356    Accuracy: 88.90625\n",
      "iter 716 ---  Loss: 2.7479190304875374    Accuracy: 88.4375\n",
      "iter 717 ---  Loss: 3.1954758912324905    Accuracy: 86.875\n",
      "iter 718 ---  Loss: 3.259022742509842    Accuracy: 86.09375\n",
      "iter 719 ---  Loss: 2.9169104248285294    Accuracy: 87.8125\n",
      "iter 720 ---  Loss: 2.5053942501544952    Accuracy: 89.0625\n",
      "iter 721 ---  Loss: 3.0360457375645638    Accuracy: 88.4375\n",
      "iter 722 ---  Loss: 3.3184350430965424    Accuracy: 88.125\n",
      "iter 723 ---  Loss: 3.13494148850441    Accuracy: 85.625\n",
      "iter 724 ---  Loss: 2.7729616910219193    Accuracy: 88.125\n",
      "iter 725 ---  Loss: 2.5555094853043556    Accuracy: 87.8125\n",
      "iter 726 ---  Loss: 2.884433329105377    Accuracy: 87.5\n",
      "iter 727 ---  Loss: 3.3265704438090324    Accuracy: 86.25\n",
      "iter 728 ---  Loss: 2.4726743325591087    Accuracy: 87.1875\n",
      "iter 729 ---  Loss: 2.862573482096195    Accuracy: 87.65625\n",
      "iter 730 ---  Loss: 2.854611001908779    Accuracy: 87.03125\n",
      "iter 731 ---  Loss: 2.843660205602646    Accuracy: 87.65625\n",
      "iter 732 ---  Loss: 2.7767193391919136    Accuracy: 85.46875\n",
      "iter 733 ---  Loss: 2.715093769133091    Accuracy: 89.21875\n",
      "iter 734 ---  Loss: 2.898081935942173    Accuracy: 87.8125\n",
      "iter 735 ---  Loss: 2.85738617926836    Accuracy: 87.8125\n",
      "iter 736 ---  Loss: 2.909604787826538    Accuracy: 87.03125\n",
      "iter 737 ---  Loss: 2.8803360760211945    Accuracy: 87.34375\n",
      "iter 738 ---  Loss: 3.599947638809681    Accuracy: 85.625\n",
      "iter 739 ---  Loss: 3.10125819593668    Accuracy: 88.125\n",
      "iter 740 ---  Loss: 2.849860578775406    Accuracy: 87.65625\n",
      "iter 741 ---  Loss: 3.4454468861222267    Accuracy: 85.9375\n",
      "iter 742 ---  Loss: 3.0917178988456726    Accuracy: 87.1875\n",
      "iter 743 ---  Loss: 2.7096551060676575    Accuracy: 87.8125\n",
      "iter 744 ---  Loss: 3.102112852036953    Accuracy: 85.15625\n",
      "iter 745 ---  Loss: 3.0136354342103004    Accuracy: 87.65625\n",
      "iter 746 ---  Loss: 3.659560076892376    Accuracy: 86.5625\n",
      "iter 747 ---  Loss: 2.8597349524497986    Accuracy: 86.71875\n",
      "iter 748 ---  Loss: 3.1682583913207054    Accuracy: 89.84375\n",
      "iter 749 ---  Loss: 3.2076293900609016    Accuracy: 85.9375\n",
      "iter 750 ---  Loss: 2.665021426975727    Accuracy: 87.96875\n",
      "iter 751 ---  Loss: 2.917262017726898    Accuracy: 87.65625\n",
      "iter 752 ---  Loss: 3.4066481590270996    Accuracy: 88.125\n",
      "iter 753 ---  Loss: 3.3830762580037117    Accuracy: 86.71875\n",
      "iter 754 ---  Loss: 2.679918110370636    Accuracy: 87.8125\n",
      "iter 755 ---  Loss: 3.1860178261995316    Accuracy: 87.5\n",
      "iter 756 ---  Loss: 2.6114917024970055    Accuracy: 89.21875\n",
      "iter 757 ---  Loss: 2.8432438522577286    Accuracy: 88.28125\n",
      "iter 758 ---  Loss: 2.8791859596967697    Accuracy: 88.90625\n",
      "iter 759 ---  Loss: 3.3811517357826233    Accuracy: 86.71875\n",
      "iter 760 ---  Loss: 2.790356531739235    Accuracy: 87.5\n",
      "iter 761 ---  Loss: 3.077846623957157    Accuracy: 87.96875\n",
      "iter 762 ---  Loss: 2.81843002140522    Accuracy: 88.125\n",
      "iter 763 ---  Loss: 3.3857699781656265    Accuracy: 86.09375\n",
      "iter 764 ---  Loss: 2.69121316075325    Accuracy: 88.28125\n",
      "iter 765 ---  Loss: 3.0966780111193657    Accuracy: 87.1875\n",
      "iter 766 ---  Loss: 3.220565617084503    Accuracy: 86.09375\n",
      "iter 767 ---  Loss: 2.755552850663662    Accuracy: 89.6875\n",
      "iter 768 ---  Loss: 3.1542124152183533    Accuracy: 87.8125\n",
      "iter 769 ---  Loss: 3.007069580256939    Accuracy: 87.1875\n",
      "iter 770 ---  Loss: 3.167843297123909    Accuracy: 87.5\n",
      "iter 771 ---  Loss: 2.7762775272130966    Accuracy: 87.1875\n",
      "iter 772 ---  Loss: 3.0736783519387245    Accuracy: 86.875\n",
      "iter 773 ---  Loss: 2.443269096314907    Accuracy: 87.65625\n",
      "iter 774 ---  Loss: 3.0545127391815186    Accuracy: 87.1875\n",
      "iter 775 ---  Loss: 3.3054119497537613    Accuracy: 88.75\n",
      "iter 776 ---  Loss: 2.7954480946063995    Accuracy: 87.1875\n",
      "iter 777 ---  Loss: 3.1081710532307625    Accuracy: 86.875\n",
      "iter 778 ---  Loss: 3.4689508229494095    Accuracy: 87.65625\n",
      "iter 779 ---  Loss: 2.683856561779976    Accuracy: 88.90625\n",
      "iter 780 ---  Loss: 3.6041205003857613    Accuracy: 86.875\n",
      "iter 781 ---  Loss: 3.106393612921238    Accuracy: 86.71875\n",
      "iter 782 ---  Loss: 3.280020661652088    Accuracy: 87.96875\n",
      "iter 783 ---  Loss: 2.6213970109820366    Accuracy: 87.1875\n",
      "iter 784 ---  Loss: 2.932023622095585    Accuracy: 87.8125\n",
      "iter 785 ---  Loss: 2.8664543703198433    Accuracy: 88.4375\n",
      "iter 786 ---  Loss: 3.1349436789751053    Accuracy: 88.125\n",
      "iter 787 ---  Loss: 2.9357056096196175    Accuracy: 88.125\n",
      "iter 788 ---  Loss: 3.3916425481438637    Accuracy: 88.125\n",
      "iter 789 ---  Loss: 2.9446556493639946    Accuracy: 87.34375\n",
      "iter 790 ---  Loss: 2.8493523374199867    Accuracy: 89.0625\n",
      "iter 791 ---  Loss: 3.427319675683975    Accuracy: 87.5\n",
      "iter 792 ---  Loss: 2.85840006172657    Accuracy: 87.65625\n",
      "iter 793 ---  Loss: 2.665641650557518    Accuracy: 89.84375\n",
      "iter 794 ---  Loss: 3.096341833472252    Accuracy: 86.875\n",
      "iter 795 ---  Loss: 3.1547790840268135    Accuracy: 87.5\n",
      "iter 796 ---  Loss: 3.7544437795877457    Accuracy: 86.25\n",
      "iter 797 ---  Loss: 3.1551938578486443    Accuracy: 87.65625\n",
      "iter 798 ---  Loss: 3.246017411351204    Accuracy: 88.59375\n",
      "iter 799 ---  Loss: 3.017557457089424    Accuracy: 87.96875\n",
      "iter 800 ---  Loss: 2.925134100019932    Accuracy: 88.125\n",
      "iter 801 ---  Loss: 3.2917148545384407    Accuracy: 85.3125\n",
      "iter 802 ---  Loss: 3.4736504778265953    Accuracy: 87.03125\n",
      "iter 803 ---  Loss: 3.0446180403232574    Accuracy: 87.96875\n",
      "iter 804 ---  Loss: 3.170820876955986    Accuracy: 88.59375\n",
      "iter 805 ---  Loss: 3.1641789600253105    Accuracy: 87.1875\n",
      "iter 806 ---  Loss: 3.1287713050842285    Accuracy: 87.96875\n",
      "iter 807 ---  Loss: 3.3391170725226402    Accuracy: 87.65625\n",
      "iter 808 ---  Loss: 3.243783675134182    Accuracy: 86.09375\n",
      "iter 809 ---  Loss: 2.9834521636366844    Accuracy: 89.375\n",
      "iter 810 ---  Loss: 2.5430282577872276    Accuracy: 89.375\n",
      "iter 811 ---  Loss: 2.5594262033700943    Accuracy: 88.125\n",
      "iter 812 ---  Loss: 3.302569530904293    Accuracy: 87.03125\n",
      "iter 813 ---  Loss: 2.7255490347743034    Accuracy: 88.75\n",
      "iter 814 ---  Loss: 3.293067693710327    Accuracy: 86.875\n",
      "iter 815 ---  Loss: 2.5401179492473602    Accuracy: 88.75\n",
      "iter 816 ---  Loss: 2.8975615054368973    Accuracy: 87.34375\n",
      "iter 817 ---  Loss: 3.0108661204576492    Accuracy: 87.34375\n",
      "iter 818 ---  Loss: 3.0247824415564537    Accuracy: 88.90625\n",
      "iter 819 ---  Loss: 3.185322068631649    Accuracy: 88.125\n",
      "iter 820 ---  Loss: 3.2839173674583435    Accuracy: 89.53125\n",
      "iter 821 ---  Loss: 2.71966589987278    Accuracy: 90.46875\n",
      "iter 822 ---  Loss: 2.878833681344986    Accuracy: 87.1875\n",
      "iter 823 ---  Loss: 3.4911103397607803    Accuracy: 86.5625\n",
      "iter 824 ---  Loss: 2.713737413287163    Accuracy: 87.34375\n",
      "iter 825 ---  Loss: 3.160993292927742    Accuracy: 87.8125\n",
      "iter 826 ---  Loss: 2.7287661135196686    Accuracy: 86.875\n",
      "iter 827 ---  Loss: 2.9673880264163017    Accuracy: 87.65625\n",
      "iter 828 ---  Loss: 3.7357911989092827    Accuracy: 86.40625\n",
      "iter 829 ---  Loss: 3.613453261554241    Accuracy: 88.75\n",
      "iter 830 ---  Loss: 2.7202363461256027    Accuracy: 87.34375\n",
      "iter 831 ---  Loss: 3.3177691847085953    Accuracy: 86.71875\n",
      "iter 832 ---  Loss: 3.424421176314354    Accuracy: 86.09375\n",
      "iter 833 ---  Loss: 3.458003908395767    Accuracy: 85.9375\n",
      "iter 834 ---  Loss: 2.879421643912792    Accuracy: 88.125\n",
      "iter 835 ---  Loss: 3.0700137093663216    Accuracy: 88.75\n",
      "iter 836 ---  Loss: 3.4384415969252586    Accuracy: 87.65625\n",
      "iter 837 ---  Loss: 3.6537516564130783    Accuracy: 88.90625\n",
      "iter 838 ---  Loss: 2.9367493987083435    Accuracy: 88.75\n",
      "iter 839 ---  Loss: 2.6632393449544907    Accuracy: 86.71875\n",
      "iter 840 ---  Loss: 3.5747509598731995    Accuracy: 86.25\n",
      "iter 841 ---  Loss: 2.925941914319992    Accuracy: 89.84375\n",
      "iter 842 ---  Loss: 3.002728559076786    Accuracy: 87.03125\n",
      "iter 843 ---  Loss: 3.2610332891345024    Accuracy: 89.375\n",
      "iter 844 ---  Loss: 3.87970270216465    Accuracy: 85.9375\n",
      "iter 845 ---  Loss: 3.4043856784701347    Accuracy: 87.03125\n",
      "iter 846 ---  Loss: 3.3214301839470863    Accuracy: 87.96875\n",
      "iter 847 ---  Loss: 2.9413309320807457    Accuracy: 86.875\n",
      "iter 848 ---  Loss: 3.082553878426552    Accuracy: 88.125\n",
      "iter 849 ---  Loss: 2.8041361644864082    Accuracy: 87.34375\n",
      "iter 850 ---  Loss: 3.129061333835125    Accuracy: 86.40625\n",
      "iter 851 ---  Loss: 3.882485754787922    Accuracy: 87.5\n",
      "iter 852 ---  Loss: 2.70342855155468    Accuracy: 88.59375\n",
      "iter 853 ---  Loss: 2.9174563214182854    Accuracy: 87.1875\n",
      "iter 854 ---  Loss: 3.3560642302036285    Accuracy: 85.0\n",
      "iter 855 ---  Loss: 3.5802050679922104    Accuracy: 87.5\n",
      "iter 856 ---  Loss: 3.4629252329468727    Accuracy: 87.1875\n",
      "iter 857 ---  Loss: 2.9049278125166893    Accuracy: 86.71875\n",
      "iter 858 ---  Loss: 3.3728072941303253    Accuracy: 88.28125\n",
      "iter 859 ---  Loss: 2.8019726052880287    Accuracy: 87.8125\n",
      "iter 860 ---  Loss: 3.0994101464748383    Accuracy: 86.71875\n",
      "iter 861 ---  Loss: 2.6909412667155266    Accuracy: 90.0\n",
      "iter 862 ---  Loss: 3.342932850122452    Accuracy: 87.5\n",
      "iter 863 ---  Loss: 3.319536045193672    Accuracy: 86.40625\n",
      "iter 864 ---  Loss: 3.24556977301836    Accuracy: 85.9375\n",
      "iter 865 ---  Loss: 2.7606473937630653    Accuracy: 88.4375\n",
      "iter 866 ---  Loss: 3.1888387128710747    Accuracy: 85.9375\n",
      "iter 867 ---  Loss: 3.3829855993390083    Accuracy: 86.875\n",
      "iter 868 ---  Loss: 3.0330972149968147    Accuracy: 86.25\n",
      "iter 869 ---  Loss: 3.086102858185768    Accuracy: 87.03125\n",
      "iter 870 ---  Loss: 3.12452682107687    Accuracy: 86.71875\n",
      "iter 871 ---  Loss: 2.921587161719799    Accuracy: 89.21875\n",
      "iter 872 ---  Loss: 2.684849426150322    Accuracy: 88.75\n",
      "iter 873 ---  Loss: 3.3195549845695496    Accuracy: 87.5\n",
      "iter 874 ---  Loss: 2.6359084770083427    Accuracy: 89.0625\n",
      "iter 875 ---  Loss: 2.774739980697632    Accuracy: 87.5\n",
      "iter 876 ---  Loss: 2.8853421807289124    Accuracy: 88.90625\n",
      "iter 877 ---  Loss: 2.869031496345997    Accuracy: 86.71875\n",
      "iter 878 ---  Loss: 3.4243546202778816    Accuracy: 86.5625\n",
      "iter 879 ---  Loss: 2.9921932071447372    Accuracy: 88.4375\n",
      "iter 880 ---  Loss: 3.1830981597304344    Accuracy: 86.5625\n",
      "iter 881 ---  Loss: 3.473947986960411    Accuracy: 88.125\n",
      "iter 882 ---  Loss: 3.0499558821320534    Accuracy: 86.40625\n",
      "iter 883 ---  Loss: 2.8610685244202614    Accuracy: 87.8125\n",
      "iter 884 ---  Loss: 2.4200014770030975    Accuracy: 88.125\n",
      "iter 885 ---  Loss: 2.752697989344597    Accuracy: 87.34375\n",
      "iter 886 ---  Loss: 2.9843757301568985    Accuracy: 88.90625\n",
      "iter 887 ---  Loss: 3.744315341114998    Accuracy: 86.40625\n",
      "iter 888 ---  Loss: 3.911428950726986    Accuracy: 87.34375\n",
      "iter 889 ---  Loss: 2.9858173206448555    Accuracy: 87.03125\n",
      "iter 890 ---  Loss: 3.010762967169285    Accuracy: 86.71875\n",
      "iter 891 ---  Loss: 2.745315857231617    Accuracy: 88.59375\n",
      "iter 892 ---  Loss: 3.0570330694317818    Accuracy: 87.8125\n",
      "iter 893 ---  Loss: 3.32742453366518    Accuracy: 87.96875\n",
      "iter 894 ---  Loss: 3.494455672800541    Accuracy: 88.125\n",
      "iter 895 ---  Loss: 2.591751478612423    Accuracy: 89.84375\n",
      "iter 896 ---  Loss: 3.144870288670063    Accuracy: 87.65625\n",
      "iter 897 ---  Loss: 3.688187927007675    Accuracy: 87.34375\n",
      "iter 898 ---  Loss: 3.4604760110378265    Accuracy: 85.46875\n",
      "iter 899 ---  Loss: 3.114593207836151    Accuracy: 88.59375\n",
      "iter 900 ---  Loss: 3.4058388620615005    Accuracy: 87.34375\n",
      "iter 901 ---  Loss: 2.960855685174465    Accuracy: 88.125\n",
      "iter 902 ---  Loss: 2.82527744024992    Accuracy: 89.53125\n",
      "iter 903 ---  Loss: 3.1094847694039345    Accuracy: 87.03125\n",
      "iter 904 ---  Loss: 3.0611427426338196    Accuracy: 89.53125\n",
      "iter 905 ---  Loss: 2.882892571389675    Accuracy: 87.8125\n",
      "iter 906 ---  Loss: 3.1357888728380203    Accuracy: 89.0625\n",
      "iter 907 ---  Loss: 3.223638206720352    Accuracy: 88.4375\n",
      "iter 908 ---  Loss: 3.6343538388609886    Accuracy: 86.40625\n",
      "iter 909 ---  Loss: 3.163287363946438    Accuracy: 88.59375\n",
      "iter 910 ---  Loss: 2.7997160106897354    Accuracy: 87.8125\n",
      "iter 911 ---  Loss: 2.7267188504338264    Accuracy: 87.8125\n",
      "iter 912 ---  Loss: 3.038840629160404    Accuracy: 87.65625\n",
      "iter 913 ---  Loss: 2.9721899405121803    Accuracy: 88.75\n",
      "iter 914 ---  Loss: 3.5590062513947487    Accuracy: 87.5\n",
      "iter 915 ---  Loss: 3.055991291999817    Accuracy: 87.03125\n",
      "iter 916 ---  Loss: 3.181254230439663    Accuracy: 86.71875\n",
      "iter 917 ---  Loss: 2.7637006416916847    Accuracy: 88.75\n",
      "iter 918 ---  Loss: 2.736621528863907    Accuracy: 88.90625\n",
      "iter 919 ---  Loss: 2.603909783065319    Accuracy: 86.40625\n",
      "iter 920 ---  Loss: 2.9357831925153732    Accuracy: 89.53125\n",
      "iter 921 ---  Loss: 2.9487387016415596    Accuracy: 87.1875\n",
      "iter 922 ---  Loss: 3.338310696184635    Accuracy: 86.09375\n",
      "iter 923 ---  Loss: 3.2165879756212234    Accuracy: 88.28125\n",
      "iter 924 ---  Loss: 3.0059376433491707    Accuracy: 87.8125\n",
      "iter 925 ---  Loss: 2.9426831156015396    Accuracy: 87.5\n",
      "iter 926 ---  Loss: 2.807695746421814    Accuracy: 87.65625\n",
      "iter 927 ---  Loss: 2.7416957169771194    Accuracy: 90.46875\n",
      "iter 928 ---  Loss: 2.8306599780917168    Accuracy: 88.90625\n",
      "iter 929 ---  Loss: 3.1236285343766212    Accuracy: 86.40625\n",
      "iter 930 ---  Loss: 3.0485235452651978    Accuracy: 88.125\n",
      "iter 931 ---  Loss: 2.6121580451726913    Accuracy: 89.375\n",
      "iter 932 ---  Loss: 3.048731006681919    Accuracy: 87.5\n",
      "iter 933 ---  Loss: 2.8358273655176163    Accuracy: 88.59375\n",
      "iter 934 ---  Loss: 3.207026816904545    Accuracy: 87.5\n",
      "iter 935 ---  Loss: 2.6550079062581062    Accuracy: 89.0625\n",
      "iter 936 ---  Loss: 2.844471797347069    Accuracy: 88.125\n",
      "iter 937 ---  Loss: 3.2439377903938293    Accuracy: 87.96875\n",
      "iter 938 ---  Loss: 3.367123134434223    Accuracy: 86.09375\n",
      "iter 939 ---  Loss: 3.21311666816473    Accuracy: 85.9375\n",
      "iter 940 ---  Loss: 2.8337026312947273    Accuracy: 87.8125\n",
      "iter 941 ---  Loss: 3.5165781304240227    Accuracy: 85.625\n",
      "iter 942 ---  Loss: 3.739026978611946    Accuracy: 85.15625\n",
      "iter 943 ---  Loss: 3.2802688255906105    Accuracy: 88.125\n",
      "iter 944 ---  Loss: 3.435568630695343    Accuracy: 85.46875\n",
      "iter 945 ---  Loss: 3.071167476475239    Accuracy: 87.1875\n",
      "iter 946 ---  Loss: 3.3130028694868088    Accuracy: 88.4375\n",
      "iter 947 ---  Loss: 3.127086862921715    Accuracy: 88.4375\n",
      "iter 948 ---  Loss: 2.7256176471710205    Accuracy: 87.34375\n",
      "iter 949 ---  Loss: 3.5177099853754044    Accuracy: 87.65625\n",
      "iter 950 ---  Loss: 3.3633808717131615    Accuracy: 87.5\n",
      "iter 951 ---  Loss: 3.267876297235489    Accuracy: 86.5625\n",
      "iter 952 ---  Loss: 3.045269012451172    Accuracy: 87.96875\n",
      "iter 953 ---  Loss: 3.049052618443966    Accuracy: 88.90625\n",
      "iter 954 ---  Loss: 3.1531836539506912    Accuracy: 87.5\n",
      "iter 955 ---  Loss: 2.7747881039977074    Accuracy: 88.75\n",
      "iter 956 ---  Loss: 2.995192088186741    Accuracy: 89.84375\n",
      "iter 957 ---  Loss: 2.712688185274601    Accuracy: 87.5\n",
      "iter 958 ---  Loss: 3.2803255170583725    Accuracy: 87.1875\n",
      "iter 959 ---  Loss: 2.884151428937912    Accuracy: 86.40625\n",
      "iter 960 ---  Loss: 2.8191326037049294    Accuracy: 87.96875\n",
      "iter 961 ---  Loss: 2.88419958204031    Accuracy: 88.28125\n",
      "iter 962 ---  Loss: 3.2752201333642006    Accuracy: 88.28125\n",
      "iter 963 ---  Loss: 2.590158239006996    Accuracy: 87.65625\n",
      "iter 964 ---  Loss: 3.4467874094843864    Accuracy: 87.34375\n",
      "iter 965 ---  Loss: 3.1800994127988815    Accuracy: 84.53125\n",
      "iter 966 ---  Loss: 3.5905440375208855    Accuracy: 85.78125\n",
      "iter 967 ---  Loss: 3.084444999694824    Accuracy: 86.71875\n",
      "iter 968 ---  Loss: 2.692975364625454    Accuracy: 88.28125\n",
      "iter 969 ---  Loss: 2.7408938258886337    Accuracy: 87.1875\n",
      "iter 970 ---  Loss: 2.8603332936763763    Accuracy: 89.21875\n",
      "iter 971 ---  Loss: 2.936048202216625    Accuracy: 86.5625\n",
      "iter 972 ---  Loss: 2.9632176011800766    Accuracy: 85.78125\n",
      "iter 973 ---  Loss: 3.1830808520317078    Accuracy: 89.84375\n",
      "iter 974 ---  Loss: 3.232446514070034    Accuracy: 86.5625\n",
      "iter 975 ---  Loss: 2.890664331614971    Accuracy: 88.4375\n",
      "iter 976 ---  Loss: 3.2879940569400787    Accuracy: 86.875\n",
      "iter 977 ---  Loss: 3.70219200104475    Accuracy: 86.40625\n",
      "iter 978 ---  Loss: 3.273701660335064    Accuracy: 87.03125\n",
      "iter 979 ---  Loss: 2.7433056011795998    Accuracy: 89.0625\n",
      "iter 980 ---  Loss: 3.0851142928004265    Accuracy: 87.8125\n",
      "iter 981 ---  Loss: 3.5453226417303085    Accuracy: 86.40625\n",
      "iter 982 ---  Loss: 3.2806681618094444    Accuracy: 87.65625\n",
      "iter 983 ---  Loss: 2.7080173641443253    Accuracy: 87.8125\n",
      "iter 984 ---  Loss: 2.772437661886215    Accuracy: 89.21875\n",
      "iter 985 ---  Loss: 3.077848695218563    Accuracy: 85.78125\n",
      "iter 986 ---  Loss: 2.737709417939186    Accuracy: 88.59375\n",
      "iter 987 ---  Loss: 3.514686055481434    Accuracy: 86.40625\n",
      "iter 988 ---  Loss: 2.6424328088760376    Accuracy: 87.8125\n",
      "iter 989 ---  Loss: 3.03813349455595    Accuracy: 87.03125\n",
      "iter 990 ---  Loss: 3.072944536805153    Accuracy: 86.25\n",
      "iter 991 ---  Loss: 3.2617035433650017    Accuracy: 85.78125\n",
      "iter 992 ---  Loss: 3.556800998747349    Accuracy: 86.40625\n",
      "iter 993 ---  Loss: 2.965707778930664    Accuracy: 87.03125\n",
      "iter 994 ---  Loss: 2.9258937016129494    Accuracy: 88.75\n",
      "iter 995 ---  Loss: 2.82988915592432    Accuracy: 87.03125\n",
      "iter 996 ---  Loss: 2.638679936528206    Accuracy: 89.21875\n",
      "iter 997 ---  Loss: 2.8204998299479485    Accuracy: 89.6875\n",
      "iter 998 ---  Loss: 3.004023961722851    Accuracy: 87.1875\n",
      "iter 999 ---  Loss: 3.116086371243    Accuracy: 87.96875\n",
      "iter 1000 ---  Loss: 2.9364760518074036    Accuracy: 87.03125\n",
      "iter 1001 ---  Loss: 2.983989678323269    Accuracy: 88.125\n",
      "iter 1002 ---  Loss: 3.57009045034647    Accuracy: 87.1875\n",
      "iter 1003 ---  Loss: 2.496303863823414    Accuracy: 88.28125\n",
      "iter 1004 ---  Loss: 2.6697021946310997    Accuracy: 87.96875\n",
      "iter 1005 ---  Loss: 3.0275552198290825    Accuracy: 87.96875\n",
      "iter 1006 ---  Loss: 3.1823861971497536    Accuracy: 86.25\n",
      "iter 1007 ---  Loss: 3.252892129123211    Accuracy: 87.5\n",
      "iter 1008 ---  Loss: 3.3276306688785553    Accuracy: 88.90625\n",
      "iter 1009 ---  Loss: 3.2635552510619164    Accuracy: 86.71875\n",
      "iter 1010 ---  Loss: 2.735475219786167    Accuracy: 89.0625\n",
      "iter 1011 ---  Loss: 3.155608646571636    Accuracy: 86.875\n",
      "iter 1012 ---  Loss: 3.2118184119462967    Accuracy: 86.09375\n",
      "iter 1013 ---  Loss: 2.887652203440666    Accuracy: 87.5\n",
      "iter 1014 ---  Loss: 3.156389258801937    Accuracy: 86.5625\n",
      "iter 1015 ---  Loss: 3.0926761999726295    Accuracy: 87.8125\n",
      "iter 1016 ---  Loss: 3.6186535954475403    Accuracy: 86.5625\n",
      "iter 1017 ---  Loss: 3.8634955808520317    Accuracy: 84.53125\n",
      "iter 1018 ---  Loss: 3.506745658814907    Accuracy: 87.1875\n",
      "iter 1019 ---  Loss: 2.45455414801836    Accuracy: 89.0625\n",
      "iter 1020 ---  Loss: 3.397741459310055    Accuracy: 85.0\n",
      "iter 1021 ---  Loss: 3.6275458186864853    Accuracy: 86.40625\n",
      "iter 1022 ---  Loss: 2.6112940311431885    Accuracy: 87.5\n",
      "iter 1023 ---  Loss: 3.2430285960435867    Accuracy: 86.5625\n",
      "iter 1024 ---  Loss: 2.7867084443569183    Accuracy: 89.375\n",
      "iter 1025 ---  Loss: 2.7237941920757294    Accuracy: 86.40625\n",
      "iter 1026 ---  Loss: 2.536604918539524    Accuracy: 87.96875\n",
      "iter 1027 ---  Loss: 2.9115223363041878    Accuracy: 88.90625\n",
      "iter 1028 ---  Loss: 2.887189067900181    Accuracy: 88.75\n",
      "iter 1029 ---  Loss: 2.9269151762127876    Accuracy: 88.125\n",
      "iter 1030 ---  Loss: 3.018027737736702    Accuracy: 87.65625\n",
      "iter 1031 ---  Loss: 3.0095199197530746    Accuracy: 87.5\n",
      "iter 1032 ---  Loss: 2.5194870606064796    Accuracy: 88.75\n",
      "iter 1033 ---  Loss: 3.2838351279497147    Accuracy: 86.09375\n",
      "iter 1034 ---  Loss: 3.036348834633827    Accuracy: 86.875\n",
      "iter 1035 ---  Loss: 3.1594159603118896    Accuracy: 86.71875\n",
      "iter 1036 ---  Loss: 3.1940981820225716    Accuracy: 85.0\n",
      "iter 1037 ---  Loss: 3.508294329047203    Accuracy: 86.40625\n",
      "iter 1038 ---  Loss: 2.9711531698703766    Accuracy: 87.65625\n",
      "iter 1039 ---  Loss: 3.728723667562008    Accuracy: 85.0\n",
      "iter 1040 ---  Loss: 3.3784635588526726    Accuracy: 86.875\n",
      "iter 1041 ---  Loss: 3.039863981306553    Accuracy: 86.875\n",
      "iter 1042 ---  Loss: 2.668194778263569    Accuracy: 88.125\n",
      "iter 1043 ---  Loss: 2.8744268491864204    Accuracy: 86.40625\n",
      "iter 1044 ---  Loss: 3.118461459875107    Accuracy: 88.28125\n",
      "iter 1045 ---  Loss: 3.174440771341324    Accuracy: 87.03125\n",
      "iter 1046 ---  Loss: 2.670285277068615    Accuracy: 87.96875\n",
      "iter 1047 ---  Loss: 2.8677156269550323    Accuracy: 87.8125\n",
      "iter 1048 ---  Loss: 2.9527709558606148    Accuracy: 85.9375\n",
      "iter 1049 ---  Loss: 3.0635956153273582    Accuracy: 87.03125\n",
      "iter 1050 ---  Loss: 2.8538338020443916    Accuracy: 87.1875\n",
      "iter 1051 ---  Loss: 2.853768512606621    Accuracy: 88.75\n",
      "iter 1052 ---  Loss: 3.024557374417782    Accuracy: 86.875\n",
      "iter 1053 ---  Loss: 3.4141196608543396    Accuracy: 87.1875\n",
      "iter 1054 ---  Loss: 2.9318540319800377    Accuracy: 88.90625\n",
      "iter 1055 ---  Loss: 2.8183411061763763    Accuracy: 87.34375\n",
      "iter 1056 ---  Loss: 3.520313560962677    Accuracy: 84.84375\n",
      "iter 1057 ---  Loss: 3.1982528418302536    Accuracy: 86.25\n",
      "iter 1058 ---  Loss: 2.5960999503731728    Accuracy: 87.96875\n",
      "iter 1059 ---  Loss: 2.901755712926388    Accuracy: 88.125\n",
      "iter 1060 ---  Loss: 3.793394073843956    Accuracy: 85.625\n",
      "iter 1061 ---  Loss: 2.6385933458805084    Accuracy: 87.34375\n",
      "iter 1062 ---  Loss: 2.855899930000305    Accuracy: 86.09375\n",
      "iter 1063 ---  Loss: 3.07406272739172    Accuracy: 88.59375\n",
      "iter 1064 ---  Loss: 3.0652839690446854    Accuracy: 89.0625\n",
      "iter 1065 ---  Loss: 3.0551768243312836    Accuracy: 85.78125\n",
      "iter 1066 ---  Loss: 3.0565151646733284    Accuracy: 86.09375\n",
      "iter 1067 ---  Loss: 3.632232703268528    Accuracy: 85.9375\n",
      "iter 1068 ---  Loss: 3.2895294055342674    Accuracy: 87.03125\n",
      "iter 1069 ---  Loss: 2.7653440684080124    Accuracy: 89.375\n",
      "iter 1070 ---  Loss: 3.2204699516296387    Accuracy: 86.875\n",
      "iter 1071 ---  Loss: 3.258546508848667    Accuracy: 86.875\n",
      "iter 1072 ---  Loss: 2.9916108027100563    Accuracy: 87.8125\n",
      "iter 1073 ---  Loss: 2.550812654197216    Accuracy: 89.0625\n",
      "iter 1074 ---  Loss: 3.199333168566227    Accuracy: 86.71875\n",
      "iter 1075 ---  Loss: 3.080500639975071    Accuracy: 86.5625\n",
      "iter 1076 ---  Loss: 2.998731017112732    Accuracy: 87.34375\n",
      "iter 1077 ---  Loss: 3.4485030323266983    Accuracy: 86.875\n",
      "iter 1078 ---  Loss: 3.0238305181264877    Accuracy: 87.1875\n",
      "iter 1079 ---  Loss: 3.4746672436594963    Accuracy: 86.40625\n",
      "iter 1080 ---  Loss: 3.345396861433983    Accuracy: 87.34375\n",
      "iter 1081 ---  Loss: 3.018074721097946    Accuracy: 87.1875\n",
      "iter 1082 ---  Loss: 2.745526507496834    Accuracy: 87.1875\n",
      "iter 1083 ---  Loss: 3.311701238155365    Accuracy: 86.875\n",
      "iter 1084 ---  Loss: 2.9709935784339905    Accuracy: 87.1875\n",
      "iter 1085 ---  Loss: 3.3829602152109146    Accuracy: 88.4375\n",
      "iter 1086 ---  Loss: 3.022421784698963    Accuracy: 88.59375\n",
      "iter 1087 ---  Loss: 3.0373225435614586    Accuracy: 87.1875\n",
      "iter 1088 ---  Loss: 2.6711466908454895    Accuracy: 87.96875\n",
      "iter 1089 ---  Loss: 3.158097930252552    Accuracy: 85.9375\n",
      "iter 1090 ---  Loss: 3.368349462747574    Accuracy: 87.34375\n",
      "iter 1091 ---  Loss: 3.2620833590626717    Accuracy: 86.25\n",
      "iter 1092 ---  Loss: 3.6826552972197533    Accuracy: 85.9375\n",
      "iter 1093 ---  Loss: 2.762134850025177    Accuracy: 86.5625\n",
      "iter 1094 ---  Loss: 2.867536313831806    Accuracy: 88.90625\n",
      "iter 1095 ---  Loss: 2.5246220603585243    Accuracy: 88.59375\n",
      "iter 1096 ---  Loss: 2.913235403597355    Accuracy: 89.0625\n",
      "iter 1097 ---  Loss: 3.2077047377824783    Accuracy: 87.96875\n",
      "iter 1098 ---  Loss: 3.112340532243252    Accuracy: 86.71875\n",
      "iter 1099 ---  Loss: 2.9954819083213806    Accuracy: 87.8125\n",
      "iter 1100 ---  Loss: 3.6997855827212334    Accuracy: 85.0\n",
      "iter 1101 ---  Loss: 3.1850403770804405    Accuracy: 86.40625\n",
      "iter 1102 ---  Loss: 2.4840003177523613    Accuracy: 88.4375\n",
      "iter 1103 ---  Loss: 2.8334369137883186    Accuracy: 88.90625\n",
      "iter 1104 ---  Loss: 2.6686928123235703    Accuracy: 88.4375\n",
      "iter 1105 ---  Loss: 2.7803448513150215    Accuracy: 87.1875\n",
      "iter 1106 ---  Loss: 3.8352391496300697    Accuracy: 85.15625\n",
      "iter 1107 ---  Loss: 3.2857445999979973    Accuracy: 88.4375\n",
      "iter 1108 ---  Loss: 2.9711489900946617    Accuracy: 87.8125\n",
      "iter 1109 ---  Loss: 2.682766370475292    Accuracy: 88.28125\n",
      "iter 1110 ---  Loss: 3.0152810886502266    Accuracy: 86.5625\n",
      "iter 1111 ---  Loss: 2.9447498247027397    Accuracy: 88.4375\n",
      "iter 1112 ---  Loss: 3.413487456738949    Accuracy: 85.78125\n",
      "iter 1113 ---  Loss: 2.951928600668907    Accuracy: 87.1875\n",
      "iter 1114 ---  Loss: 3.0180039405822754    Accuracy: 87.34375\n",
      "iter 1115 ---  Loss: 3.0824034959077835    Accuracy: 87.96875\n",
      "iter 1116 ---  Loss: 3.2203002497553825    Accuracy: 86.40625\n",
      "iter 1117 ---  Loss: 3.224579192698002    Accuracy: 87.34375\n",
      "iter 1118 ---  Loss: 3.3045231476426125    Accuracy: 87.03125\n",
      "iter 1119 ---  Loss: 3.037893533706665    Accuracy: 87.03125\n",
      "iter 1120 ---  Loss: 3.1938032656908035    Accuracy: 88.28125\n",
      "iter 1121 ---  Loss: 3.240846961736679    Accuracy: 87.96875\n",
      "iter 1122 ---  Loss: 2.980782337486744    Accuracy: 86.875\n",
      "iter 1123 ---  Loss: 3.1479340195655823    Accuracy: 87.8125\n",
      "iter 1124 ---  Loss: 3.324026644229889    Accuracy: 87.03125\n",
      "iter 1125 ---  Loss: 3.389882005751133    Accuracy: 87.03125\n",
      "iter 1126 ---  Loss: 2.9029458835721016    Accuracy: 86.71875\n",
      "iter 1127 ---  Loss: 3.2270950078964233    Accuracy: 86.71875\n",
      "iter 1128 ---  Loss: 3.4522097259759903    Accuracy: 86.875\n",
      "iter 1129 ---  Loss: 3.0285221561789513    Accuracy: 85.3125\n",
      "iter 1130 ---  Loss: 3.826946720480919    Accuracy: 87.34375\n",
      "iter 1131 ---  Loss: 2.7482956498861313    Accuracy: 87.34375\n",
      "iter 1132 ---  Loss: 3.14615648239851    Accuracy: 86.71875\n",
      "iter 1133 ---  Loss: 2.5178484693169594    Accuracy: 88.59375\n",
      "iter 1134 ---  Loss: 3.3050009459257126    Accuracy: 85.15625\n",
      "iter 1135 ---  Loss: 3.2973731607198715    Accuracy: 85.78125\n",
      "iter 1136 ---  Loss: 3.648261107504368    Accuracy: 87.34375\n",
      "iter 1137 ---  Loss: 2.875769905745983    Accuracy: 86.71875\n",
      "iter 1138 ---  Loss: 3.1344161108136177    Accuracy: 87.96875\n",
      "iter 1139 ---  Loss: 2.7263833209872246    Accuracy: 87.34375\n",
      "iter 1140 ---  Loss: 3.2257046699523926    Accuracy: 87.65625\n",
      "iter 1141 ---  Loss: 2.63862032443285    Accuracy: 89.84375\n",
      "iter 1142 ---  Loss: 3.1221906170248985    Accuracy: 87.96875\n",
      "iter 1143 ---  Loss: 3.474940173327923    Accuracy: 86.875\n",
      "iter 1144 ---  Loss: 2.5650529265403748    Accuracy: 88.125\n",
      "iter 1145 ---  Loss: 3.0474221259355545    Accuracy: 88.125\n",
      "iter 1146 ---  Loss: 3.916964828968048    Accuracy: 86.875\n",
      "iter 1147 ---  Loss: 3.3382943719625473    Accuracy: 88.125\n",
      "iter 1148 ---  Loss: 2.782235659658909    Accuracy: 88.59375\n",
      "iter 1149 ---  Loss: 3.148126997053623    Accuracy: 86.71875\n",
      "iter 1150 ---  Loss: 2.964444063603878    Accuracy: 88.4375\n",
      "iter 1151 ---  Loss: 3.4139584377408028    Accuracy: 87.1875\n",
      "iter 1152 ---  Loss: 2.8959684297442436    Accuracy: 85.625\n",
      "iter 1153 ---  Loss: 2.5239745378494263    Accuracy: 88.125\n",
      "iter 1154 ---  Loss: 3.1726748794317245    Accuracy: 87.34375\n",
      "iter 1155 ---  Loss: 3.9645264744758606    Accuracy: 84.53125\n",
      "iter 1156 ---  Loss: 2.873038850724697    Accuracy: 85.46875\n",
      "iter 1157 ---  Loss: 3.0052720680832863    Accuracy: 87.1875\n",
      "iter 1158 ---  Loss: 3.20373348146677    Accuracy: 86.71875\n",
      "iter 1159 ---  Loss: 3.2526677399873734    Accuracy: 85.15625\n",
      "iter 1160 ---  Loss: 2.9365250915288925    Accuracy: 86.25\n",
      "iter 1161 ---  Loss: 3.1743544563651085    Accuracy: 85.3125\n",
      "iter 1162 ---  Loss: 2.9674850404262543    Accuracy: 87.1875\n",
      "iter 1163 ---  Loss: 3.104955792427063    Accuracy: 85.46875\n",
      "iter 1164 ---  Loss: 2.835846960544586    Accuracy: 87.1875\n",
      "iter 1165 ---  Loss: 2.821713000535965    Accuracy: 87.03125\n",
      "iter 1166 ---  Loss: 2.690146781504154    Accuracy: 88.125\n",
      "iter 1167 ---  Loss: 3.2137822806835175    Accuracy: 87.03125\n",
      "iter 1168 ---  Loss: 2.918666549026966    Accuracy: 87.34375\n",
      "iter 1169 ---  Loss: 3.152024917304516    Accuracy: 87.03125\n",
      "iter 1170 ---  Loss: 2.4310791939496994    Accuracy: 88.59375\n",
      "iter 1171 ---  Loss: 3.063436910510063    Accuracy: 85.46875\n",
      "iter 1172 ---  Loss: 3.2911426872015    Accuracy: 87.8125\n",
      "iter 1173 ---  Loss: 3.5893467366695404    Accuracy: 86.25\n",
      "iter 1174 ---  Loss: 2.774972267448902    Accuracy: 89.21875\n",
      "iter 1175 ---  Loss: 2.9995542392134666    Accuracy: 87.8125\n",
      "iter 1176 ---  Loss: 2.9523848593235016    Accuracy: 89.0625\n",
      "iter 1177 ---  Loss: 2.9025921002030373    Accuracy: 88.4375\n",
      "iter 1178 ---  Loss: 3.1662743017077446    Accuracy: 86.5625\n",
      "iter 1179 ---  Loss: 3.0464569106698036    Accuracy: 87.03125\n",
      "iter 1180 ---  Loss: 2.8284965604543686    Accuracy: 88.28125\n",
      "iter 1181 ---  Loss: 3.5203076750040054    Accuracy: 85.3125\n",
      "iter 1182 ---  Loss: 3.316169895231724    Accuracy: 86.71875\n",
      "iter 1183 ---  Loss: 3.0480141565203667    Accuracy: 85.625\n",
      "iter 1184 ---  Loss: 3.1530510410666466    Accuracy: 85.9375\n",
      "iter 1185 ---  Loss: 2.895301379263401    Accuracy: 89.0625\n",
      "iter 1186 ---  Loss: 3.2099662721157074    Accuracy: 86.71875\n",
      "iter 1187 ---  Loss: 3.012490078806877    Accuracy: 86.875\n",
      "iter 1188 ---  Loss: 3.2252286598086357    Accuracy: 86.09375\n",
      "iter 1189 ---  Loss: 2.904709443449974    Accuracy: 87.65625\n",
      "iter 1190 ---  Loss: 3.057120457291603    Accuracy: 89.53125\n",
      "iter 1191 ---  Loss: 3.0029215067625046    Accuracy: 86.5625\n",
      "iter 1192 ---  Loss: 2.8055097237229347    Accuracy: 86.40625\n",
      "iter 1193 ---  Loss: 3.1672305911779404    Accuracy: 86.40625\n",
      "iter 1194 ---  Loss: 2.8230703622102737    Accuracy: 84.84375\n",
      "iter 1195 ---  Loss: 2.7107702791690826    Accuracy: 88.125\n",
      "iter 1196 ---  Loss: 4.356894664466381    Accuracy: 84.21875\n",
      "iter 1197 ---  Loss: 2.84029583632946    Accuracy: 88.28125\n",
      "iter 1198 ---  Loss: 2.509388715028763    Accuracy: 87.34375\n",
      "iter 1199 ---  Loss: 3.5805436968803406    Accuracy: 85.78125\n",
      "iter 1200 ---  Loss: 2.4952571988105774    Accuracy: 88.90625\n",
      "iter 1201 ---  Loss: 3.2744856402277946    Accuracy: 85.78125\n",
      "iter 1202 ---  Loss: 2.8635356798768044    Accuracy: 88.28125\n",
      "iter 1203 ---  Loss: 3.036321200430393    Accuracy: 87.8125\n",
      "iter 1204 ---  Loss: 3.2404531687498093    Accuracy: 87.96875\n",
      "iter 1205 ---  Loss: 3.3995979502797127    Accuracy: 86.5625\n",
      "iter 1206 ---  Loss: 3.1276391744613647    Accuracy: 89.375\n",
      "iter 1207 ---  Loss: 3.304229214787483    Accuracy: 88.125\n",
      "iter 1208 ---  Loss: 3.001418374478817    Accuracy: 89.0625\n",
      "iter 1209 ---  Loss: 2.950246348977089    Accuracy: 86.25\n",
      "iter 1210 ---  Loss: 3.060100793838501    Accuracy: 87.34375\n",
      "iter 1211 ---  Loss: 2.9201144874095917    Accuracy: 88.59375\n",
      "iter 1212 ---  Loss: 3.700637675821781    Accuracy: 87.03125\n",
      "iter 1213 ---  Loss: 2.578067973256111    Accuracy: 90.15625\n",
      "iter 1214 ---  Loss: 2.8589810356497765    Accuracy: 87.1875\n",
      "iter 1215 ---  Loss: 2.9737526550889015    Accuracy: 87.34375\n",
      "iter 1216 ---  Loss: 3.1463148072361946    Accuracy: 88.75\n",
      "iter 1217 ---  Loss: 3.585766412317753    Accuracy: 85.78125\n",
      "iter 1218 ---  Loss: 3.912668138742447    Accuracy: 87.5\n",
      "iter 1219 ---  Loss: 4.11269586533308    Accuracy: 86.71875\n",
      "iter 1220 ---  Loss: 4.217903882265091    Accuracy: 86.5625\n",
      "iter 1221 ---  Loss: 2.9356452375650406    Accuracy: 87.1875\n",
      "iter 1222 ---  Loss: 2.516092613339424    Accuracy: 87.8125\n",
      "iter 1223 ---  Loss: 2.7198179736733437    Accuracy: 87.65625\n",
      "iter 1224 ---  Loss: 3.1583212465047836    Accuracy: 87.8125\n",
      "iter 1225 ---  Loss: 3.1137885078787804    Accuracy: 87.8125\n",
      "iter 1226 ---  Loss: 3.1000390350818634    Accuracy: 85.78125\n",
      "iter 1227 ---  Loss: 2.5317816138267517    Accuracy: 88.90625\n",
      "iter 1228 ---  Loss: 2.928562693297863    Accuracy: 86.09375\n",
      "iter 1229 ---  Loss: 2.588926173746586    Accuracy: 89.6875\n",
      "iter 1230 ---  Loss: 2.899891085922718    Accuracy: 87.03125\n",
      "iter 1231 ---  Loss: 3.311760403215885    Accuracy: 85.78125\n",
      "iter 1232 ---  Loss: 2.9516084864735603    Accuracy: 86.40625\n",
      "iter 1233 ---  Loss: 3.3720433339476585    Accuracy: 87.03125\n",
      "iter 1234 ---  Loss: 3.0379232838749886    Accuracy: 87.8125\n",
      "iter 1235 ---  Loss: 2.8284217193722725    Accuracy: 88.4375\n",
      "iter 1236 ---  Loss: 3.2817461416125298    Accuracy: 88.125\n",
      "iter 1237 ---  Loss: 2.9330365881323814    Accuracy: 89.375\n",
      "iter 1238 ---  Loss: 2.7880413979291916    Accuracy: 86.25\n",
      "iter 1239 ---  Loss: 3.4594074711203575    Accuracy: 86.09375\n",
      "iter 1240 ---  Loss: 3.4984045997262    Accuracy: 87.65625\n",
      "iter 1241 ---  Loss: 2.684459410607815    Accuracy: 90.3125\n",
      "iter 1242 ---  Loss: 3.070074401795864    Accuracy: 86.5625\n",
      "iter 1243 ---  Loss: 3.218226373195648    Accuracy: 88.4375\n",
      "iter 1244 ---  Loss: 3.703942157328129    Accuracy: 85.78125\n",
      "iter 1245 ---  Loss: 3.175837069749832    Accuracy: 87.96875\n",
      "iter 1246 ---  Loss: 3.299486592411995    Accuracy: 86.875\n",
      "iter 1247 ---  Loss: 3.0177086144685745    Accuracy: 85.625\n",
      "iter 1248 ---  Loss: 3.3197626769542694    Accuracy: 86.40625\n",
      "iter 1249 ---  Loss: 2.4402332454919815    Accuracy: 88.90625\n",
      "iter 1250 ---  Loss: 3.283446677029133    Accuracy: 86.71875\n",
      "iter 1251 ---  Loss: 2.861884705722332    Accuracy: 87.5\n",
      "iter 1252 ---  Loss: 2.890717074275017    Accuracy: 89.6875\n",
      "iter 1253 ---  Loss: 3.2616466507315636    Accuracy: 86.5625\n",
      "iter 1254 ---  Loss: 3.5507966056466103    Accuracy: 86.5625\n",
      "iter 1255 ---  Loss: 2.7935649156570435    Accuracy: 87.5\n",
      "iter 1256 ---  Loss: 2.4861380457878113    Accuracy: 88.4375\n",
      "iter 1257 ---  Loss: 2.7002173736691475    Accuracy: 87.8125\n",
      "iter 1258 ---  Loss: 2.6855967193841934    Accuracy: 89.21875\n",
      "iter 1259 ---  Loss: 3.2803475484251976    Accuracy: 87.96875\n",
      "iter 1260 ---  Loss: 2.6318613439798355    Accuracy: 89.21875\n",
      "iter 1261 ---  Loss: 2.7908519208431244    Accuracy: 88.75\n",
      "iter 1262 ---  Loss: 2.5618258640170097    Accuracy: 89.375\n",
      "iter 1263 ---  Loss: 3.4516013711690903    Accuracy: 87.1875\n",
      "iter 1264 ---  Loss: 2.967550627887249    Accuracy: 88.75\n",
      "iter 1265 ---  Loss: 3.2763598188757896    Accuracy: 86.40625\n",
      "iter 1266 ---  Loss: 2.9255022034049034    Accuracy: 87.96875\n",
      "iter 1267 ---  Loss: 2.787479028105736    Accuracy: 89.53125\n",
      "iter 1268 ---  Loss: 2.990640453994274    Accuracy: 87.65625\n",
      "iter 1269 ---  Loss: 2.9798427000641823    Accuracy: 89.21875\n",
      "iter 1270 ---  Loss: 2.967183545231819    Accuracy: 88.125\n",
      "iter 1271 ---  Loss: 3.4451149627566338    Accuracy: 86.5625\n",
      "iter 1272 ---  Loss: 3.2799732014536858    Accuracy: 87.34375\n",
      "iter 1273 ---  Loss: 2.6426341831684113    Accuracy: 89.53125\n",
      "iter 1274 ---  Loss: 2.8730818778276443    Accuracy: 88.4375\n",
      "iter 1275 ---  Loss: 3.0126344114542007    Accuracy: 87.1875\n",
      "iter 1276 ---  Loss: 3.022891379892826    Accuracy: 88.75\n",
      "iter 1277 ---  Loss: 3.64405457675457    Accuracy: 86.71875\n",
      "iter 1278 ---  Loss: 3.2795420736074448    Accuracy: 88.75\n",
      "iter 1279 ---  Loss: 3.123813182115555    Accuracy: 87.8125\n",
      "iter 1280 ---  Loss: 2.684407189488411    Accuracy: 87.1875\n",
      "iter 1281 ---  Loss: 3.0592495650053024    Accuracy: 88.28125\n",
      "iter 1282 ---  Loss: 3.940209984779358    Accuracy: 85.46875\n",
      "iter 1283 ---  Loss: 3.7460834681987762    Accuracy: 87.5\n",
      "iter 1284 ---  Loss: 3.156135067343712    Accuracy: 86.5625\n",
      "iter 1285 ---  Loss: 2.606892079114914    Accuracy: 87.96875\n",
      "iter 1286 ---  Loss: 3.364549547433853    Accuracy: 87.03125\n",
      "iter 1287 ---  Loss: 3.3288758918642998    Accuracy: 86.25\n",
      "iter 1288 ---  Loss: 3.479953646659851    Accuracy: 87.96875\n",
      "iter 1289 ---  Loss: 3.1442689821124077    Accuracy: 86.875\n",
      "iter 1290 ---  Loss: 3.1324002519249916    Accuracy: 87.96875\n",
      "iter 1291 ---  Loss: 3.472439832985401    Accuracy: 87.03125\n",
      "iter 1292 ---  Loss: 3.4080372750759125    Accuracy: 86.25\n",
      "iter 1293 ---  Loss: 2.8308765590190887    Accuracy: 86.40625\n",
      "iter 1294 ---  Loss: 3.085479475557804    Accuracy: 89.6875\n",
      "iter 1295 ---  Loss: 3.7506450712680817    Accuracy: 86.09375\n",
      "iter 1296 ---  Loss: 2.840712882578373    Accuracy: 87.8125\n",
      "iter 1297 ---  Loss: 2.9927613884210587    Accuracy: 86.71875\n",
      "iter 1298 ---  Loss: 2.9336729422211647    Accuracy: 86.09375\n",
      "iter 1299 ---  Loss: 3.1785974204540253    Accuracy: 87.65625\n",
      "iter 1300 ---  Loss: 3.1470596492290497    Accuracy: 89.21875\n",
      "iter 1301 ---  Loss: 2.8553113266825676    Accuracy: 90.0\n",
      "iter 1302 ---  Loss: 3.1814405396580696    Accuracy: 88.59375\n",
      "iter 1303 ---  Loss: 3.502893902361393    Accuracy: 86.25\n",
      "iter 1304 ---  Loss: 2.8766332790255547    Accuracy: 87.03125\n",
      "iter 1305 ---  Loss: 3.1687946170568466    Accuracy: 86.875\n",
      "iter 1306 ---  Loss: 3.563446208834648    Accuracy: 86.5625\n",
      "iter 1307 ---  Loss: 3.153032086789608    Accuracy: 86.875\n",
      "iter 1308 ---  Loss: 3.1647518277168274    Accuracy: 85.625\n",
      "iter 1309 ---  Loss: 2.4046365544199944    Accuracy: 88.75\n",
      "iter 1310 ---  Loss: 2.5481310039758682    Accuracy: 88.90625\n",
      "iter 1311 ---  Loss: 2.7701664492487907    Accuracy: 88.125\n",
      "iter 1312 ---  Loss: 3.644577667117119    Accuracy: 85.46875\n",
      "iter 1313 ---  Loss: 2.912032425403595    Accuracy: 87.65625\n",
      "iter 1314 ---  Loss: 3.2338369637727737    Accuracy: 87.1875\n",
      "iter 1315 ---  Loss: 3.067005217075348    Accuracy: 87.8125\n",
      "iter 1316 ---  Loss: 2.901750087738037    Accuracy: 88.28125\n",
      "iter 1317 ---  Loss: 3.1762513145804405    Accuracy: 87.03125\n",
      "iter 1318 ---  Loss: 3.1802244260907173    Accuracy: 87.65625\n",
      "iter 1319 ---  Loss: 3.3889440149068832    Accuracy: 86.71875\n",
      "iter 1320 ---  Loss: 3.4522403553128242    Accuracy: 86.71875\n",
      "iter 1321 ---  Loss: 3.0304713994264603    Accuracy: 88.4375\n",
      "iter 1322 ---  Loss: 3.227793551981449    Accuracy: 86.71875\n",
      "iter 1323 ---  Loss: 3.101578116416931    Accuracy: 87.96875\n",
      "iter 1324 ---  Loss: 2.934168726205826    Accuracy: 86.40625\n",
      "iter 1325 ---  Loss: 3.3978422060608864    Accuracy: 87.8125\n",
      "iter 1326 ---  Loss: 2.9751047641038895    Accuracy: 87.34375\n",
      "iter 1327 ---  Loss: 3.733475722372532    Accuracy: 85.0\n",
      "iter 1328 ---  Loss: 2.7607802152633667    Accuracy: 87.65625\n",
      "iter 1329 ---  Loss: 3.356977589428425    Accuracy: 86.71875\n",
      "iter 1330 ---  Loss: 3.283221274614334    Accuracy: 88.28125\n",
      "iter 1331 ---  Loss: 2.6062540113925934    Accuracy: 88.59375\n",
      "iter 1332 ---  Loss: 2.9866708293557167    Accuracy: 88.28125\n",
      "iter 1333 ---  Loss: 3.028262384235859    Accuracy: 87.1875\n",
      "iter 1334 ---  Loss: 3.1496284678578377    Accuracy: 88.28125\n",
      "iter 1335 ---  Loss: 2.951592206954956    Accuracy: 86.71875\n",
      "iter 1336 ---  Loss: 2.856184057891369    Accuracy: 89.6875\n",
      "iter 1337 ---  Loss: 2.7959507033228874    Accuracy: 88.28125\n",
      "iter 1338 ---  Loss: 2.8093687891960144    Accuracy: 86.5625\n",
      "iter 1339 ---  Loss: 2.7013192251324654    Accuracy: 88.125\n",
      "iter 1340 ---  Loss: 2.7449622973799706    Accuracy: 89.0625\n",
      "iter 1341 ---  Loss: 2.9980913177132607    Accuracy: 89.53125\n",
      "iter 1342 ---  Loss: 3.106412820518017    Accuracy: 87.96875\n",
      "iter 1343 ---  Loss: 2.5811249762773514    Accuracy: 88.59375\n",
      "iter 1344 ---  Loss: 3.2723854929208755    Accuracy: 86.71875\n",
      "iter 1345 ---  Loss: 3.1213159039616585    Accuracy: 86.5625\n",
      "iter 1346 ---  Loss: 2.7810399308800697    Accuracy: 87.65625\n",
      "iter 1347 ---  Loss: 3.2366316691040993    Accuracy: 85.0\n",
      "iter 1348 ---  Loss: 2.8519271835684776    Accuracy: 90.3125\n",
      "iter 1349 ---  Loss: 3.0918193608522415    Accuracy: 86.40625\n",
      "iter 1350 ---  Loss: 3.420036844909191    Accuracy: 86.71875\n",
      "iter 1351 ---  Loss: 3.3529924377799034    Accuracy: 86.5625\n",
      "iter 1352 ---  Loss: 3.3147628158330917    Accuracy: 87.1875\n",
      "iter 1353 ---  Loss: 3.252858817577362    Accuracy: 86.40625\n",
      "iter 1354 ---  Loss: 3.451610714197159    Accuracy: 85.0\n",
      "iter 1355 ---  Loss: 3.033555917441845    Accuracy: 86.71875\n",
      "iter 1356 ---  Loss: 3.029543489217758    Accuracy: 87.8125\n",
      "iter 1357 ---  Loss: 3.4059318751096725    Accuracy: 86.5625\n",
      "iter 1358 ---  Loss: 2.8203972801566124    Accuracy: 88.4375\n",
      "iter 1359 ---  Loss: 2.5693869814276695    Accuracy: 89.375\n",
      "iter 1360 ---  Loss: 3.1438326835632324    Accuracy: 88.75\n",
      "iter 1361 ---  Loss: 2.9473845809698105    Accuracy: 87.65625\n",
      "iter 1362 ---  Loss: 3.223583906888962    Accuracy: 88.4375\n",
      "iter 1363 ---  Loss: 2.600361444056034    Accuracy: 86.875\n",
      "iter 1364 ---  Loss: 2.825276605784893    Accuracy: 88.4375\n",
      "iter 1365 ---  Loss: 2.685201331973076    Accuracy: 87.96875\n",
      "iter 1366 ---  Loss: 2.801500551402569    Accuracy: 90.0\n",
      "iter 1367 ---  Loss: 3.0795273035764694    Accuracy: 86.25\n",
      "iter 1368 ---  Loss: 2.5500146448612213    Accuracy: 89.53125\n",
      "iter 1369 ---  Loss: 2.63006728887558    Accuracy: 87.5\n",
      "iter 1370 ---  Loss: 3.1734758913517    Accuracy: 86.40625\n",
      "iter 1371 ---  Loss: 2.797655612230301    Accuracy: 88.28125\n",
      "iter 1372 ---  Loss: 2.710743598639965    Accuracy: 87.5\n",
      "iter 1373 ---  Loss: 2.765890173614025    Accuracy: 88.125\n",
      "iter 1374 ---  Loss: 2.944746918976307    Accuracy: 87.34375\n",
      "iter 1375 ---  Loss: 2.447368621826172    Accuracy: 88.125\n",
      "iter 1376 ---  Loss: 2.926098018884659    Accuracy: 87.8125\n",
      "iter 1377 ---  Loss: 3.5466950610280037    Accuracy: 87.1875\n",
      "iter 1378 ---  Loss: 3.8027151823043823    Accuracy: 88.125\n",
      "iter 1379 ---  Loss: 3.2734340354800224    Accuracy: 87.5\n",
      "iter 1380 ---  Loss: 3.198716826736927    Accuracy: 89.0625\n",
      "iter 1381 ---  Loss: 3.1102182790637016    Accuracy: 86.25\n",
      "iter 1382 ---  Loss: 3.1162016838788986    Accuracy: 87.8125\n",
      "iter 1383 ---  Loss: 3.353239484131336    Accuracy: 87.03125\n",
      "iter 1384 ---  Loss: 2.806369684636593    Accuracy: 87.34375\n",
      "iter 1385 ---  Loss: 2.94842878729105    Accuracy: 88.59375\n",
      "iter 1386 ---  Loss: 2.734053909778595    Accuracy: 89.53125\n",
      "iter 1387 ---  Loss: 4.045815736055374    Accuracy: 87.1875\n",
      "iter 1388 ---  Loss: 3.2760378643870354    Accuracy: 87.03125\n",
      "iter 1389 ---  Loss: 2.769464299082756    Accuracy: 88.28125\n",
      "iter 1390 ---  Loss: 2.788794867694378    Accuracy: 87.34375\n",
      "iter 1391 ---  Loss: 3.327780857682228    Accuracy: 86.5625\n",
      "iter 1392 ---  Loss: 2.6799950003623962    Accuracy: 87.34375\n",
      "iter 1393 ---  Loss: 4.057132326066494    Accuracy: 85.9375\n",
      "iter 1394 ---  Loss: 3.1311111822724342    Accuracy: 87.8125\n",
      "iter 1395 ---  Loss: 2.7022753953933716    Accuracy: 86.5625\n",
      "iter 1396 ---  Loss: 3.1804774925112724    Accuracy: 87.1875\n",
      "iter 1397 ---  Loss: 3.3641498014330864    Accuracy: 88.28125\n",
      "iter 1398 ---  Loss: 2.7449335232377052    Accuracy: 88.4375\n",
      "iter 1399 ---  Loss: 2.9623582288622856    Accuracy: 87.1875\n",
      "iter 1400 ---  Loss: 2.8887613862752914    Accuracy: 87.03125\n",
      "iter 1401 ---  Loss: 2.732087641954422    Accuracy: 87.5\n",
      "iter 1402 ---  Loss: 3.239961251616478    Accuracy: 86.25\n",
      "iter 1403 ---  Loss: 2.783109910786152    Accuracy: 89.375\n",
      "iter 1404 ---  Loss: 2.6637497320771217    Accuracy: 88.75\n",
      "iter 1405 ---  Loss: 2.681756369769573    Accuracy: 87.8125\n",
      "iter 1406 ---  Loss: 3.621712401509285    Accuracy: 86.71875\n",
      "iter 1407 ---  Loss: 3.0230440869927406    Accuracy: 88.28125\n",
      "iter 1408 ---  Loss: 3.2536726370453835    Accuracy: 87.5\n",
      "iter 1409 ---  Loss: 2.9988126531243324    Accuracy: 87.1875\n",
      "iter 1410 ---  Loss: 3.152409851551056    Accuracy: 86.25\n",
      "iter 1411 ---  Loss: 2.876893065869808    Accuracy: 88.28125\n",
      "iter 1412 ---  Loss: 3.4496009573340416    Accuracy: 84.6875\n",
      "iter 1413 ---  Loss: 3.073832832276821    Accuracy: 88.90625\n",
      "iter 1414 ---  Loss: 3.5318326875567436    Accuracy: 85.625\n",
      "iter 1415 ---  Loss: 3.004022993147373    Accuracy: 88.59375\n",
      "iter 1416 ---  Loss: 3.3122674077749252    Accuracy: 89.375\n",
      "iter 1417 ---  Loss: 3.2033559530973434    Accuracy: 85.3125\n",
      "iter 1418 ---  Loss: 3.0672162771224976    Accuracy: 88.125\n",
      "iter 1419 ---  Loss: 3.717449553310871    Accuracy: 85.78125\n",
      "iter 1420 ---  Loss: 2.6823908612132072    Accuracy: 87.65625\n",
      "iter 1421 ---  Loss: 3.3156804889440536    Accuracy: 85.9375\n",
      "iter 1422 ---  Loss: 3.4498475939035416    Accuracy: 87.1875\n",
      "iter 1423 ---  Loss: 2.5725826248526573    Accuracy: 88.59375\n",
      "iter 1424 ---  Loss: 3.3982069864869118    Accuracy: 86.71875\n",
      "iter 1425 ---  Loss: 2.601454608142376    Accuracy: 88.28125\n",
      "iter 1426 ---  Loss: 2.74081701785326    Accuracy: 87.1875\n",
      "iter 1427 ---  Loss: 2.9332915768027306    Accuracy: 86.25\n",
      "iter 1428 ---  Loss: 3.4806108251214027    Accuracy: 85.9375\n",
      "iter 1429 ---  Loss: 3.039778709411621    Accuracy: 88.28125\n",
      "iter 1430 ---  Loss: 3.1597946658730507    Accuracy: 86.5625\n",
      "iter 1431 ---  Loss: 3.2484032437205315    Accuracy: 86.5625\n",
      "iter 1432 ---  Loss: 2.762995943427086    Accuracy: 87.96875\n",
      "iter 1433 ---  Loss: 3.872681938111782    Accuracy: 86.5625\n",
      "iter 1434 ---  Loss: 2.8606665208935738    Accuracy: 88.125\n",
      "iter 1435 ---  Loss: 2.7029027119278908    Accuracy: 88.59375\n",
      "iter 1436 ---  Loss: 3.337962880730629    Accuracy: 87.03125\n",
      "iter 1437 ---  Loss: 3.1023148521780968    Accuracy: 88.4375\n",
      "iter 1438 ---  Loss: 2.969831794500351    Accuracy: 87.5\n",
      "iter 1439 ---  Loss: 3.004424460232258    Accuracy: 86.875\n",
      "iter 1440 ---  Loss: 3.582707941532135    Accuracy: 87.1875\n",
      "iter 1441 ---  Loss: 3.030462332069874    Accuracy: 86.40625\n",
      "iter 1442 ---  Loss: 2.785519279539585    Accuracy: 89.21875\n",
      "iter 1443 ---  Loss: 2.621394544839859    Accuracy: 88.4375\n",
      "iter 1444 ---  Loss: 3.047163136303425    Accuracy: 86.5625\n",
      "iter 1445 ---  Loss: 2.7923315465450287    Accuracy: 88.75\n",
      "iter 1446 ---  Loss: 2.827179066836834    Accuracy: 86.875\n",
      "iter 1447 ---  Loss: 3.00502397865057    Accuracy: 87.8125\n",
      "iter 1448 ---  Loss: 3.0334455743432045    Accuracy: 86.5625\n",
      "iter 1449 ---  Loss: 3.2456322386860847    Accuracy: 87.65625\n",
      "iter 1450 ---  Loss: 2.8918696865439415    Accuracy: 87.03125\n",
      "iter 1451 ---  Loss: 2.9427125975489616    Accuracy: 87.34375\n",
      "iter 1452 ---  Loss: 3.069720968604088    Accuracy: 87.96875\n",
      "iter 1453 ---  Loss: 3.625985823571682    Accuracy: 86.5625\n",
      "iter 1454 ---  Loss: 2.9439120814204216    Accuracy: 86.09375\n",
      "iter 1455 ---  Loss: 2.8303014934062958    Accuracy: 88.59375\n",
      "iter 1456 ---  Loss: 2.6795091181993484    Accuracy: 87.03125\n",
      "iter 1457 ---  Loss: 2.9746390506625175    Accuracy: 87.96875\n",
      "iter 1458 ---  Loss: 3.173753634095192    Accuracy: 88.59375\n",
      "iter 1459 ---  Loss: 3.1584457457065582    Accuracy: 86.875\n",
      "iter 1460 ---  Loss: 2.822044000029564    Accuracy: 87.65625\n",
      "iter 1461 ---  Loss: 2.888305589556694    Accuracy: 86.09375\n",
      "iter 1462 ---  Loss: 2.515486553311348    Accuracy: 86.25\n",
      "iter 1463 ---  Loss: 3.1701053604483604    Accuracy: 86.5625\n",
      "iter 1464 ---  Loss: 3.530507370829582    Accuracy: 87.65625\n",
      "iter 1465 ---  Loss: 3.056238666176796    Accuracy: 85.625\n",
      "iter 1466 ---  Loss: 3.4871857091784477    Accuracy: 88.4375\n",
      "iter 1467 ---  Loss: 2.8002178743481636    Accuracy: 87.1875\n",
      "iter 1468 ---  Loss: 2.9349579140543938    Accuracy: 87.8125\n",
      "iter 1469 ---  Loss: 2.8326667845249176    Accuracy: 87.1875\n",
      "iter 1470 ---  Loss: 3.086697928607464    Accuracy: 87.1875\n",
      "iter 1471 ---  Loss: 2.7974837347865105    Accuracy: 87.65625\n",
      "iter 1472 ---  Loss: 3.682221792638302    Accuracy: 85.3125\n",
      "iter 1473 ---  Loss: 2.5244452133774757    Accuracy: 89.375\n",
      "iter 1474 ---  Loss: 2.657795764505863    Accuracy: 88.4375\n",
      "iter 1475 ---  Loss: 3.065203383564949    Accuracy: 87.96875\n",
      "iter 1476 ---  Loss: 3.171984314918518    Accuracy: 87.5\n",
      "iter 1477 ---  Loss: 2.9573047682642937    Accuracy: 87.65625\n",
      "iter 1478 ---  Loss: 3.042683281004429    Accuracy: 85.3125\n",
      "iter 1479 ---  Loss: 3.009129859507084    Accuracy: 87.96875\n",
      "iter 1480 ---  Loss: 2.93891891092062    Accuracy: 87.65625\n",
      "iter 1481 ---  Loss: 3.2760173305869102    Accuracy: 87.34375\n",
      "iter 1482 ---  Loss: 2.752308614552021    Accuracy: 88.28125\n",
      "iter 1483 ---  Loss: 3.0449196994304657    Accuracy: 88.4375\n",
      "iter 1484 ---  Loss: 3.101100169122219    Accuracy: 86.25\n",
      "iter 1485 ---  Loss: 2.6588268354535103    Accuracy: 88.4375\n",
      "iter 1486 ---  Loss: 3.0788891538977623    Accuracy: 88.4375\n",
      "iter 1487 ---  Loss: 3.190183013677597    Accuracy: 88.28125\n",
      "iter 1488 ---  Loss: 2.931493319571018    Accuracy: 88.125\n",
      "iter 1489 ---  Loss: 2.8865936398506165    Accuracy: 89.21875\n",
      "iter 1490 ---  Loss: 2.9282672330737114    Accuracy: 87.65625\n",
      "iter 1491 ---  Loss: 3.2306902334094048    Accuracy: 87.03125\n",
      "iter 1492 ---  Loss: 2.6447282433509827    Accuracy: 88.4375\n",
      "iter 1493 ---  Loss: 3.153137966990471    Accuracy: 86.71875\n",
      "iter 1494 ---  Loss: 2.526697240769863    Accuracy: 88.4375\n",
      "iter 1495 ---  Loss: 2.91331784427166    Accuracy: 88.28125\n",
      "iter 1496 ---  Loss: 3.3205884620547295    Accuracy: 88.28125\n",
      "iter 1497 ---  Loss: 3.0135633647441864    Accuracy: 87.34375\n",
      "iter 1498 ---  Loss: 3.6601201370358467    Accuracy: 88.28125\n",
      "iter 1499 ---  Loss: 2.928470991551876    Accuracy: 89.375\n",
      "iter 1500 ---  Loss: 3.6899979785084724    Accuracy: 85.78125\n",
      "iter 1501 ---  Loss: 3.786632500588894    Accuracy: 87.1875\n",
      "iter 1502 ---  Loss: 2.960002101957798    Accuracy: 87.03125\n",
      "iter 1503 ---  Loss: 2.834960162639618    Accuracy: 90.0\n",
      "iter 1504 ---  Loss: 2.8734718337655067    Accuracy: 87.65625\n",
      "iter 1505 ---  Loss: 3.163114696741104    Accuracy: 86.875\n",
      "iter 1506 ---  Loss: 2.8074873238801956    Accuracy: 90.0\n",
      "iter 1507 ---  Loss: 2.6419727876782417    Accuracy: 89.0625\n",
      "iter 1508 ---  Loss: 3.1589509323239326    Accuracy: 87.5\n",
      "iter 1509 ---  Loss: 2.748678982257843    Accuracy: 88.90625\n",
      "iter 1510 ---  Loss: 3.383282132446766    Accuracy: 86.875\n",
      "iter 1511 ---  Loss: 2.5631293058395386    Accuracy: 88.59375\n",
      "iter 1512 ---  Loss: 3.4119223579764366    Accuracy: 84.6875\n",
      "iter 1513 ---  Loss: 2.49112831056118    Accuracy: 89.53125\n",
      "iter 1514 ---  Loss: 3.393468901515007    Accuracy: 90.15625\n",
      "iter 1515 ---  Loss: 3.2720220535993576    Accuracy: 86.71875\n",
      "iter 1516 ---  Loss: 3.2598411217331886    Accuracy: 85.78125\n",
      "iter 1517 ---  Loss: 3.0246847718954086    Accuracy: 86.71875\n",
      "iter 1518 ---  Loss: 2.3900892063975334    Accuracy: 90.9375\n",
      "iter 1519 ---  Loss: 3.3845992013812065    Accuracy: 87.96875\n",
      "iter 1520 ---  Loss: 3.112134873867035    Accuracy: 86.5625\n",
      "iter 1521 ---  Loss: 2.883619487285614    Accuracy: 89.53125\n",
      "iter 1522 ---  Loss: 2.6996626630425453    Accuracy: 88.75\n",
      "iter 1523 ---  Loss: 3.7172061651945114    Accuracy: 84.6875\n",
      "iter 1524 ---  Loss: 3.231300987303257    Accuracy: 87.96875\n",
      "iter 1525 ---  Loss: 3.0206085443496704    Accuracy: 88.75\n",
      "iter 1526 ---  Loss: 4.0147911086678505    Accuracy: 85.0\n",
      "iter 1527 ---  Loss: 3.3727892637252808    Accuracy: 86.25\n",
      "iter 1528 ---  Loss: 2.8598075807094574    Accuracy: 89.375\n",
      "iter 1529 ---  Loss: 3.334857188165188    Accuracy: 86.71875\n",
      "iter 1530 ---  Loss: 3.111904002726078    Accuracy: 88.4375\n",
      "iter 1531 ---  Loss: 3.332835778594017    Accuracy: 87.8125\n",
      "iter 1532 ---  Loss: 2.8810927122831345    Accuracy: 87.5\n",
      "iter 1533 ---  Loss: 2.896060861647129    Accuracy: 88.125\n",
      "iter 1534 ---  Loss: 3.4429981634020805    Accuracy: 87.8125\n",
      "iter 1535 ---  Loss: 2.6479587480425835    Accuracy: 86.875\n",
      "iter 1536 ---  Loss: 3.2174669355154037    Accuracy: 88.4375\n",
      "iter 1537 ---  Loss: 2.401515446603298    Accuracy: 90.0\n",
      "iter 1538 ---  Loss: 3.0492004081606865    Accuracy: 88.125\n",
      "iter 1539 ---  Loss: 3.237311251461506    Accuracy: 89.21875\n",
      "iter 1540 ---  Loss: 3.15130328387022    Accuracy: 87.34375\n",
      "iter 1541 ---  Loss: 3.3213047608733177    Accuracy: 87.5\n",
      "iter 1542 ---  Loss: 2.849912002682686    Accuracy: 87.1875\n",
      "iter 1543 ---  Loss: 2.861363962292671    Accuracy: 87.65625\n",
      "iter 1544 ---  Loss: 3.121089056134224    Accuracy: 86.40625\n",
      "iter 1545 ---  Loss: 3.3423400297760963    Accuracy: 87.5\n",
      "iter 1546 ---  Loss: 2.7880410254001617    Accuracy: 87.5\n",
      "iter 1547 ---  Loss: 3.2625231593847275    Accuracy: 87.34375\n",
      "iter 1548 ---  Loss: 3.3020721152424812    Accuracy: 85.3125\n",
      "iter 1549 ---  Loss: 3.276368521153927    Accuracy: 85.0\n",
      "iter 1550 ---  Loss: 3.370819181203842    Accuracy: 84.53125\n",
      "iter 1551 ---  Loss: 3.037544012069702    Accuracy: 88.28125\n",
      "iter 1552 ---  Loss: 3.3435284346342087    Accuracy: 86.5625\n",
      "iter 1553 ---  Loss: 3.1020262241363525    Accuracy: 85.0\n",
      "iter 1554 ---  Loss: 3.528027355670929    Accuracy: 87.8125\n",
      "iter 1555 ---  Loss: 3.233540065586567    Accuracy: 86.875\n",
      "iter 1556 ---  Loss: 3.4235331416130066    Accuracy: 86.40625\n",
      "iter 1557 ---  Loss: 2.355084590613842    Accuracy: 88.28125\n",
      "iter 1558 ---  Loss: 3.4591593742370605    Accuracy: 87.5\n",
      "iter 1559 ---  Loss: 3.113886147737503    Accuracy: 87.8125\n",
      "iter 1560 ---  Loss: 2.6471472680568695    Accuracy: 88.4375\n",
      "iter 1561 ---  Loss: 2.95195060223341    Accuracy: 87.1875\n",
      "iter 1562 ---  Loss: 2.857678674161434    Accuracy: 88.75\n",
      "iter 1563 ---  Loss: 3.3262165039777756    Accuracy: 87.1875\n",
      "iter 1564 ---  Loss: 3.1810040920972824    Accuracy: 86.40625\n",
      "iter 1565 ---  Loss: 2.490447372198105    Accuracy: 89.53125\n",
      "iter 1566 ---  Loss: 3.2705302387475967    Accuracy: 88.90625\n",
      "iter 1567 ---  Loss: 3.130881145596504    Accuracy: 87.03125\n",
      "iter 1568 ---  Loss: 3.521267794072628    Accuracy: 86.09375\n",
      "iter 1569 ---  Loss: 2.783707082271576    Accuracy: 87.34375\n",
      "iter 1570 ---  Loss: 3.454507991671562    Accuracy: 87.65625\n",
      "iter 1571 ---  Loss: 2.9198259338736534    Accuracy: 87.96875\n",
      "iter 1572 ---  Loss: 3.313499264419079    Accuracy: 86.5625\n",
      "iter 1573 ---  Loss: 2.9786396101117134    Accuracy: 89.6875\n",
      "iter 1574 ---  Loss: 3.252290666103363    Accuracy: 85.9375\n",
      "iter 1575 ---  Loss: 3.4464111253619194    Accuracy: 85.78125\n",
      "iter 1576 ---  Loss: 2.942374564707279    Accuracy: 87.96875\n",
      "iter 1577 ---  Loss: 2.9960754737257957    Accuracy: 88.28125\n",
      "iter 1578 ---  Loss: 3.210346758365631    Accuracy: 86.71875\n",
      "iter 1579 ---  Loss: 3.6453337222337723    Accuracy: 85.9375\n",
      "iter 1580 ---  Loss: 2.862578436732292    Accuracy: 85.78125\n",
      "iter 1581 ---  Loss: 2.808143340051174    Accuracy: 86.40625\n",
      "iter 1582 ---  Loss: 3.451656937599182    Accuracy: 86.71875\n",
      "iter 1583 ---  Loss: 2.792838640511036    Accuracy: 87.1875\n",
      "iter 1584 ---  Loss: 2.779543675482273    Accuracy: 86.71875\n",
      "iter 1585 ---  Loss: 3.38434836268425    Accuracy: 86.5625\n",
      "iter 1586 ---  Loss: 2.910975433886051    Accuracy: 87.1875\n",
      "iter 1587 ---  Loss: 3.3664263412356377    Accuracy: 87.8125\n",
      "iter 1588 ---  Loss: 2.7787192091345787    Accuracy: 88.125\n",
      "iter 1589 ---  Loss: 2.830922670662403    Accuracy: 88.90625\n",
      "iter 1590 ---  Loss: 3.446465753018856    Accuracy: 87.96875\n",
      "iter 1591 ---  Loss: 2.6010358184576035    Accuracy: 88.90625\n",
      "iter 1592 ---  Loss: 2.53975273668766    Accuracy: 87.65625\n",
      "iter 1593 ---  Loss: 3.019607223570347    Accuracy: 88.75\n",
      "iter 1594 ---  Loss: 2.9475109055638313    Accuracy: 88.125\n",
      "iter 1595 ---  Loss: 3.253733567893505    Accuracy: 87.1875\n",
      "iter 1596 ---  Loss: 2.562908746302128    Accuracy: 86.875\n",
      "iter 1597 ---  Loss: 3.1733718812465668    Accuracy: 89.21875\n",
      "iter 1598 ---  Loss: 3.195457011461258    Accuracy: 85.78125\n",
      "iter 1599 ---  Loss: 3.5879504084587097    Accuracy: 86.875\n",
      "iter 1600 ---  Loss: 2.9863378405570984    Accuracy: 86.71875\n",
      "iter 1601 ---  Loss: 2.953890159726143    Accuracy: 90.15625\n",
      "iter 1602 ---  Loss: 2.8154615610837936    Accuracy: 87.5\n",
      "iter 1603 ---  Loss: 3.165452428162098    Accuracy: 88.4375\n",
      "iter 1604 ---  Loss: 3.1254134848713875    Accuracy: 87.96875\n",
      "iter 1605 ---  Loss: 3.7282401993870735    Accuracy: 86.09375\n",
      "iter 1606 ---  Loss: 2.8380154073238373    Accuracy: 86.71875\n",
      "iter 1607 ---  Loss: 2.6947080716490746    Accuracy: 86.09375\n",
      "iter 1608 ---  Loss: 2.7093067169189453    Accuracy: 88.28125\n",
      "iter 1609 ---  Loss: 3.3596746921539307    Accuracy: 86.09375\n",
      "iter 1610 ---  Loss: 3.007256790995598    Accuracy: 86.09375\n",
      "iter 1611 ---  Loss: 2.4536373391747475    Accuracy: 91.25\n",
      "iter 1612 ---  Loss: 3.228744052350521    Accuracy: 86.71875\n",
      "iter 1613 ---  Loss: 3.1432586014270782    Accuracy: 87.1875\n",
      "iter 1614 ---  Loss: 3.1806250512599945    Accuracy: 87.8125\n",
      "iter 1615 ---  Loss: 2.8383872881531715    Accuracy: 88.75\n",
      "iter 1616 ---  Loss: 2.833436757326126    Accuracy: 88.125\n",
      "iter 1617 ---  Loss: 2.853287495672703    Accuracy: 86.71875\n",
      "iter 1618 ---  Loss: 3.4924164190888405    Accuracy: 86.25\n",
      "iter 1619 ---  Loss: 2.7359672635793686    Accuracy: 86.5625\n",
      "iter 1620 ---  Loss: 3.4047996178269386    Accuracy: 87.03125\n",
      "iter 1621 ---  Loss: 3.0398979634046555    Accuracy: 88.28125\n",
      "iter 1622 ---  Loss: 2.570625513792038    Accuracy: 88.125\n",
      "iter 1623 ---  Loss: 2.6166006177663803    Accuracy: 87.8125\n",
      "iter 1624 ---  Loss: 3.2713406085968018    Accuracy: 87.96875\n",
      "iter 1625 ---  Loss: 3.005581319332123    Accuracy: 86.71875\n",
      "iter 1626 ---  Loss: 3.0292753875255585    Accuracy: 87.03125\n",
      "iter 1627 ---  Loss: 2.689309537410736    Accuracy: 87.5\n",
      "iter 1628 ---  Loss: 2.9720862805843353    Accuracy: 88.28125\n",
      "iter 1629 ---  Loss: 2.6974990144371986    Accuracy: 87.34375\n",
      "iter 1630 ---  Loss: 3.2255661636590958    Accuracy: 86.5625\n",
      "iter 1631 ---  Loss: 3.0347763895988464    Accuracy: 88.4375\n",
      "iter 1632 ---  Loss: 3.0162993520498276    Accuracy: 87.5\n",
      "iter 1633 ---  Loss: 3.2963807731866837    Accuracy: 88.75\n",
      "iter 1634 ---  Loss: 2.7451276555657387    Accuracy: 88.59375\n",
      "iter 1635 ---  Loss: 2.9559190794825554    Accuracy: 87.65625\n",
      "iter 1636 ---  Loss: 2.9334683567285538    Accuracy: 87.5\n",
      "iter 1637 ---  Loss: 2.731884278357029    Accuracy: 88.75\n",
      "iter 1638 ---  Loss: 3.7003546580672264    Accuracy: 85.625\n",
      "iter 1639 ---  Loss: 3.227278247475624    Accuracy: 86.09375\n",
      "iter 1640 ---  Loss: 3.4769212529063225    Accuracy: 87.03125\n",
      "iter 1641 ---  Loss: 2.855784684419632    Accuracy: 88.75\n",
      "iter 1642 ---  Loss: 3.0040253698825836    Accuracy: 86.25\n",
      "iter 1643 ---  Loss: 3.287070006132126    Accuracy: 85.9375\n",
      "iter 1644 ---  Loss: 2.806229881942272    Accuracy: 89.21875\n",
      "iter 1645 ---  Loss: 3.1633306965231895    Accuracy: 86.71875\n",
      "iter 1646 ---  Loss: 2.7976618334650993    Accuracy: 87.03125\n",
      "iter 1647 ---  Loss: 3.3201913312077522    Accuracy: 86.875\n",
      "iter 1648 ---  Loss: 2.5028244629502296    Accuracy: 89.21875\n",
      "iter 1649 ---  Loss: 2.8732073307037354    Accuracy: 89.53125\n",
      "iter 1650 ---  Loss: 2.9737045913934708    Accuracy: 87.8125\n",
      "iter 1651 ---  Loss: 2.6570307910442352    Accuracy: 87.96875\n",
      "iter 1652 ---  Loss: 2.7748949751257896    Accuracy: 87.65625\n",
      "iter 1653 ---  Loss: 2.9621910229325294    Accuracy: 88.28125\n",
      "iter 1654 ---  Loss: 3.722018674015999    Accuracy: 87.96875\n",
      "iter 1655 ---  Loss: 3.2462936267256737    Accuracy: 86.71875\n",
      "iter 1656 ---  Loss: 2.845697022974491    Accuracy: 89.0625\n",
      "iter 1657 ---  Loss: 2.657904729247093    Accuracy: 89.375\n",
      "iter 1658 ---  Loss: 2.89433041960001    Accuracy: 87.96875\n",
      "iter 1659 ---  Loss: 2.875977396965027    Accuracy: 89.0625\n",
      "iter 1660 ---  Loss: 2.733737073838711    Accuracy: 88.59375\n",
      "iter 1661 ---  Loss: 2.701625242829323    Accuracy: 88.75\n",
      "iter 1662 ---  Loss: 2.7557371109724045    Accuracy: 88.4375\n",
      "iter 1663 ---  Loss: 2.8708477541804314    Accuracy: 87.65625\n",
      "iter 1664 ---  Loss: 3.3464501351118088    Accuracy: 86.25\n",
      "iter 1665 ---  Loss: 2.71383885294199    Accuracy: 87.96875\n",
      "iter 1666 ---  Loss: 3.379949137568474    Accuracy: 86.25\n",
      "iter 1667 ---  Loss: 3.1207158863544464    Accuracy: 86.40625\n",
      "iter 1668 ---  Loss: 3.091973230242729    Accuracy: 88.125\n",
      "iter 1669 ---  Loss: 3.4555000364780426    Accuracy: 87.03125\n",
      "iter 1670 ---  Loss: 3.1165779680013657    Accuracy: 88.125\n",
      "iter 1671 ---  Loss: 3.50964717566967    Accuracy: 86.25\n",
      "iter 1672 ---  Loss: 3.066377215087414    Accuracy: 86.71875\n",
      "iter 1673 ---  Loss: 3.5787633284926414    Accuracy: 85.9375\n",
      "iter 1674 ---  Loss: 3.2345821857452393    Accuracy: 89.0625\n",
      "iter 1675 ---  Loss: 3.2827923372387886    Accuracy: 88.4375\n",
      "iter 1676 ---  Loss: 3.0968018546700478    Accuracy: 87.34375\n",
      "iter 1677 ---  Loss: 2.6808663830161095    Accuracy: 89.0625\n",
      "iter 1678 ---  Loss: 2.7991861775517464    Accuracy: 88.90625\n",
      "iter 1679 ---  Loss: 4.025231666862965    Accuracy: 85.9375\n",
      "iter 1680 ---  Loss: 3.5467348769307137    Accuracy: 86.71875\n",
      "iter 1681 ---  Loss: 3.478311501443386    Accuracy: 88.4375\n",
      "iter 1682 ---  Loss: 2.9433019161224365    Accuracy: 85.46875\n",
      "iter 1683 ---  Loss: 3.4267042204737663    Accuracy: 87.5\n",
      "iter 1684 ---  Loss: 3.679242640733719    Accuracy: 87.03125\n",
      "iter 1685 ---  Loss: 3.216083750128746    Accuracy: 85.78125\n",
      "iter 1686 ---  Loss: 3.4099340736865997    Accuracy: 84.84375\n",
      "iter 1687 ---  Loss: 2.624539613723755    Accuracy: 87.96875\n",
      "iter 1688 ---  Loss: 3.841161198914051    Accuracy: 85.625\n",
      "iter 1689 ---  Loss: 3.259853772819042    Accuracy: 88.125\n",
      "iter 1690 ---  Loss: 2.7778816372156143    Accuracy: 88.4375\n",
      "iter 1691 ---  Loss: 2.8102880120277405    Accuracy: 88.125\n",
      "iter 1692 ---  Loss: 2.611549697816372    Accuracy: 88.90625\n",
      "iter 1693 ---  Loss: 2.685839183628559    Accuracy: 87.1875\n",
      "iter 1694 ---  Loss: 2.6349510177969933    Accuracy: 88.75\n",
      "iter 1695 ---  Loss: 3.0853179320693016    Accuracy: 85.9375\n",
      "iter 1696 ---  Loss: 3.240552395582199    Accuracy: 84.84375\n",
      "iter 1697 ---  Loss: 3.074820853769779    Accuracy: 87.03125\n",
      "iter 1698 ---  Loss: 3.027792625129223    Accuracy: 87.8125\n",
      "iter 1699 ---  Loss: 2.700592130422592    Accuracy: 87.65625\n",
      "iter 1700 ---  Loss: 3.6107890978455544    Accuracy: 87.1875\n",
      "iter 1701 ---  Loss: 3.1867762580513954    Accuracy: 88.125\n",
      "iter 1702 ---  Loss: 2.9828419014811516    Accuracy: 86.875\n",
      "iter 1703 ---  Loss: 2.8478545024991035    Accuracy: 87.8125\n",
      "iter 1704 ---  Loss: 3.2418509274721146    Accuracy: 87.34375\n",
      "iter 1705 ---  Loss: 3.212923042476177    Accuracy: 87.03125\n",
      "iter 1706 ---  Loss: 3.21978210657835    Accuracy: 87.03125\n",
      "iter 1707 ---  Loss: 2.735769420862198    Accuracy: 86.875\n",
      "iter 1708 ---  Loss: 3.5039036944508553    Accuracy: 87.65625\n",
      "iter 1709 ---  Loss: 3.363306447863579    Accuracy: 86.5625\n",
      "iter 1710 ---  Loss: 2.6553760692477226    Accuracy: 87.8125\n",
      "iter 1711 ---  Loss: 3.421014405786991    Accuracy: 85.78125\n",
      "iter 1712 ---  Loss: 2.6649008616805077    Accuracy: 88.125\n",
      "iter 1713 ---  Loss: 2.4955611675977707    Accuracy: 88.59375\n",
      "iter 1714 ---  Loss: 2.977292411029339    Accuracy: 87.34375\n",
      "iter 1715 ---  Loss: 2.7666119188070297    Accuracy: 87.65625\n",
      "iter 1716 ---  Loss: 3.4948063492774963    Accuracy: 87.65625\n",
      "iter 1717 ---  Loss: 3.2937706485390663    Accuracy: 85.78125\n",
      "iter 1718 ---  Loss: 3.1245208755135536    Accuracy: 87.03125\n",
      "iter 1719 ---  Loss: 3.186517670750618    Accuracy: 87.34375\n",
      "iter 1720 ---  Loss: 3.0950299948453903    Accuracy: 89.21875\n",
      "iter 1721 ---  Loss: 3.4132688269019127    Accuracy: 85.3125\n",
      "iter 1722 ---  Loss: 3.263256423175335    Accuracy: 85.9375\n",
      "iter 1723 ---  Loss: 3.379182994365692    Accuracy: 85.15625\n",
      "iter 1724 ---  Loss: 3.5887218192219734    Accuracy: 85.625\n",
      "iter 1725 ---  Loss: 3.0771248191595078    Accuracy: 85.78125\n",
      "iter 1726 ---  Loss: 2.9583882614970207    Accuracy: 87.8125\n",
      "iter 1727 ---  Loss: 2.634742058813572    Accuracy: 88.90625\n",
      "iter 1728 ---  Loss: 2.7752509713172913    Accuracy: 88.28125\n",
      "iter 1729 ---  Loss: 3.444805808365345    Accuracy: 87.03125\n",
      "iter 1730 ---  Loss: 2.937119960784912    Accuracy: 86.71875\n",
      "iter 1731 ---  Loss: 2.910128600895405    Accuracy: 87.96875\n",
      "iter 1732 ---  Loss: 2.966949477791786    Accuracy: 89.84375\n",
      "iter 1733 ---  Loss: 2.8526186496019363    Accuracy: 87.34375\n",
      "iter 1734 ---  Loss: 2.7631588727235794    Accuracy: 87.1875\n",
      "iter 1735 ---  Loss: 2.593842536211014    Accuracy: 87.5\n",
      "iter 1736 ---  Loss: 2.65936578810215    Accuracy: 87.65625\n",
      "iter 1737 ---  Loss: 3.59915304929018    Accuracy: 86.25\n",
      "iter 1738 ---  Loss: 3.339827597141266    Accuracy: 87.03125\n",
      "iter 1739 ---  Loss: 3.3891845121979713    Accuracy: 88.90625\n",
      "iter 1740 ---  Loss: 2.6565017625689507    Accuracy: 87.03125\n",
      "iter 1741 ---  Loss: 2.8373611494898796    Accuracy: 89.84375\n",
      "iter 1742 ---  Loss: 3.0202373936772346    Accuracy: 86.09375\n",
      "iter 1743 ---  Loss: 3.4854251220822334    Accuracy: 87.03125\n",
      "iter 1744 ---  Loss: 2.4136708080768585    Accuracy: 90.46875\n",
      "iter 1745 ---  Loss: 2.747619867324829    Accuracy: 88.4375\n",
      "iter 1746 ---  Loss: 3.6956538558006287    Accuracy: 88.90625\n",
      "iter 1747 ---  Loss: 2.9804175570607185    Accuracy: 86.5625\n",
      "iter 1748 ---  Loss: 2.599996864795685    Accuracy: 88.75\n",
      "iter 1749 ---  Loss: 2.8197604939341545    Accuracy: 85.625\n",
      "iter 1750 ---  Loss: 3.0226989537477493    Accuracy: 87.8125\n",
      "iter 1751 ---  Loss: 2.706018842756748    Accuracy: 88.59375\n",
      "iter 1752 ---  Loss: 3.079733431339264    Accuracy: 85.3125\n",
      "iter 1753 ---  Loss: 3.6773988753557205    Accuracy: 86.71875\n",
      "iter 1754 ---  Loss: 3.084506541490555    Accuracy: 87.65625\n",
      "iter 1755 ---  Loss: 3.5433424785733223    Accuracy: 87.8125\n",
      "iter 1756 ---  Loss: 3.154258146882057    Accuracy: 87.34375\n",
      "iter 1757 ---  Loss: 3.234006367623806    Accuracy: 85.625\n",
      "iter 1758 ---  Loss: 3.106706030666828    Accuracy: 86.25\n",
      "iter 1759 ---  Loss: 2.7007937654852867    Accuracy: 87.03125\n",
      "iter 1760 ---  Loss: 3.6093998849391937    Accuracy: 86.5625\n",
      "iter 1761 ---  Loss: 2.94317889213562    Accuracy: 86.5625\n",
      "iter 1762 ---  Loss: 2.9483068883419037    Accuracy: 87.03125\n",
      "iter 1763 ---  Loss: 2.7326100543141365    Accuracy: 88.28125\n",
      "iter 1764 ---  Loss: 3.1652581989765167    Accuracy: 85.46875\n",
      "iter 1765 ---  Loss: 2.706758201122284    Accuracy: 86.25\n",
      "iter 1766 ---  Loss: 3.0192065834999084    Accuracy: 85.9375\n",
      "iter 1767 ---  Loss: 3.6452966779470444    Accuracy: 86.09375\n",
      "iter 1768 ---  Loss: 2.977740168571472    Accuracy: 87.96875\n",
      "iter 1769 ---  Loss: 3.177832283079624    Accuracy: 88.59375\n",
      "iter 1770 ---  Loss: 2.731615997850895    Accuracy: 88.28125\n",
      "iter 1771 ---  Loss: 3.1814745739102364    Accuracy: 84.375\n",
      "iter 1772 ---  Loss: 3.020410045981407    Accuracy: 87.03125\n",
      "iter 1773 ---  Loss: 3.436981126666069    Accuracy: 87.34375\n",
      "iter 1774 ---  Loss: 2.7672241777181625    Accuracy: 87.8125\n",
      "iter 1775 ---  Loss: 3.286011204123497    Accuracy: 87.96875\n",
      "iter 1776 ---  Loss: 3.4901308491826057    Accuracy: 87.03125\n",
      "iter 1777 ---  Loss: 3.1340448781847954    Accuracy: 86.875\n",
      "iter 1778 ---  Loss: 2.594663478434086    Accuracy: 89.53125\n",
      "iter 1779 ---  Loss: 3.4276905804872513    Accuracy: 87.8125\n",
      "iter 1780 ---  Loss: 2.9255370497703552    Accuracy: 86.25\n",
      "iter 1781 ---  Loss: 2.8929580971598625    Accuracy: 86.5625\n",
      "iter 1782 ---  Loss: 2.61086218804121    Accuracy: 85.78125\n",
      "iter 1783 ---  Loss: 4.054144188761711    Accuracy: 86.09375\n",
      "iter 1784 ---  Loss: 3.00161837041378    Accuracy: 87.65625\n",
      "iter 1785 ---  Loss: 3.309171251952648    Accuracy: 88.28125\n",
      "iter 1786 ---  Loss: 2.592042364180088    Accuracy: 88.4375\n",
      "iter 1787 ---  Loss: 3.3219307959079742    Accuracy: 85.9375\n",
      "iter 1788 ---  Loss: 3.2036280035972595    Accuracy: 87.5\n",
      "iter 1789 ---  Loss: 2.9549953565001488    Accuracy: 88.28125\n",
      "iter 1790 ---  Loss: 3.162653885781765    Accuracy: 87.5\n",
      "iter 1791 ---  Loss: 2.9567929804325104    Accuracy: 87.8125\n",
      "iter 1792 ---  Loss: 3.7250039130449295    Accuracy: 86.25\n",
      "iter 1793 ---  Loss: 2.643082730472088    Accuracy: 87.8125\n",
      "iter 1794 ---  Loss: 2.465085670351982    Accuracy: 89.53125\n",
      "iter 1795 ---  Loss: 3.088640011847019    Accuracy: 87.8125\n",
      "iter 1796 ---  Loss: 3.0610113590955734    Accuracy: 87.8125\n",
      "iter 1797 ---  Loss: 2.6418279707431793    Accuracy: 87.34375\n",
      "iter 1798 ---  Loss: 2.905916891992092    Accuracy: 87.34375\n",
      "iter 1799 ---  Loss: 2.7971441000699997    Accuracy: 88.125\n",
      "iter 1800 ---  Loss: 3.343173272907734    Accuracy: 86.875\n",
      "iter 1801 ---  Loss: 3.453473635017872    Accuracy: 88.125\n",
      "iter 1802 ---  Loss: 3.018843822181225    Accuracy: 86.40625\n",
      "iter 1803 ---  Loss: 3.279001086950302    Accuracy: 86.71875\n",
      "iter 1804 ---  Loss: 3.0859648883342743    Accuracy: 88.75\n",
      "iter 1805 ---  Loss: 2.6035210862755775    Accuracy: 87.65625\n",
      "iter 1806 ---  Loss: 2.8896487653255463    Accuracy: 87.96875\n",
      "iter 1807 ---  Loss: 3.353272922337055    Accuracy: 87.03125\n",
      "iter 1808 ---  Loss: 3.065976031124592    Accuracy: 88.59375\n",
      "iter 1809 ---  Loss: 2.8923231586813927    Accuracy: 86.09375\n",
      "iter 1810 ---  Loss: 2.836878150701523    Accuracy: 87.65625\n",
      "iter 1811 ---  Loss: 3.0479028150439262    Accuracy: 87.34375\n",
      "iter 1812 ---  Loss: 2.852592535316944    Accuracy: 89.0625\n",
      "iter 1813 ---  Loss: 3.272674210369587    Accuracy: 87.96875\n",
      "iter 1814 ---  Loss: 3.000113621354103    Accuracy: 88.125\n",
      "iter 1815 ---  Loss: 2.7897024005651474    Accuracy: 87.34375\n",
      "iter 1816 ---  Loss: 2.9892607927322388    Accuracy: 86.25\n",
      "iter 1817 ---  Loss: 2.8459818735718727    Accuracy: 88.75\n",
      "iter 1818 ---  Loss: 3.2546693608164787    Accuracy: 88.4375\n",
      "iter 1819 ---  Loss: 3.495013900101185    Accuracy: 86.40625\n",
      "iter 1820 ---  Loss: 2.9533005580306053    Accuracy: 88.90625\n",
      "iter 1821 ---  Loss: 3.691375009715557    Accuracy: 87.34375\n",
      "iter 1822 ---  Loss: 2.880790650844574    Accuracy: 89.21875\n",
      "iter 1823 ---  Loss: 3.449373811483383    Accuracy: 85.46875\n",
      "iter 1824 ---  Loss: 3.699001371860504    Accuracy: 86.71875\n",
      "iter 1825 ---  Loss: 2.810932442545891    Accuracy: 87.65625\n",
      "iter 1826 ---  Loss: 3.315911613404751    Accuracy: 87.8125\n",
      "iter 1827 ---  Loss: 3.245074324309826    Accuracy: 85.625\n",
      "iter 1828 ---  Loss: 3.1212213039398193    Accuracy: 87.8125\n",
      "iter 1829 ---  Loss: 3.8937051594257355    Accuracy: 85.15625\n",
      "iter 1830 ---  Loss: 3.1658763885498047    Accuracy: 86.40625\n",
      "iter 1831 ---  Loss: 2.909714512526989    Accuracy: 86.875\n",
      "iter 1832 ---  Loss: 3.2414554953575134    Accuracy: 85.46875\n",
      "iter 1833 ---  Loss: 3.214727930724621    Accuracy: 86.875\n",
      "iter 1834 ---  Loss: 3.498488336801529    Accuracy: 85.46875\n",
      "iter 1835 ---  Loss: 3.1832959800958633    Accuracy: 88.4375\n",
      "iter 1836 ---  Loss: 3.0580830723047256    Accuracy: 89.53125\n",
      "iter 1837 ---  Loss: 2.994672268629074    Accuracy: 88.75\n",
      "iter 1838 ---  Loss: 3.2862304970622063    Accuracy: 86.25\n",
      "iter 1839 ---  Loss: 2.6722575798630714    Accuracy: 89.6875\n",
      "iter 1840 ---  Loss: 3.440009444952011    Accuracy: 86.09375\n",
      "iter 1841 ---  Loss: 3.527709163725376    Accuracy: 87.8125\n",
      "iter 1842 ---  Loss: 3.0261250659823418    Accuracy: 87.03125\n",
      "iter 1843 ---  Loss: 3.4092801436781883    Accuracy: 86.875\n",
      "iter 1844 ---  Loss: 2.925968937575817    Accuracy: 86.5625\n",
      "iter 1845 ---  Loss: 3.0148354843258858    Accuracy: 89.375\n",
      "iter 1846 ---  Loss: 2.463898256421089    Accuracy: 89.53125\n",
      "iter 1847 ---  Loss: 2.861036993563175    Accuracy: 87.03125\n",
      "iter 1848 ---  Loss: 3.883232682943344    Accuracy: 87.34375\n",
      "iter 1849 ---  Loss: 3.52286546677351    Accuracy: 87.03125\n",
      "iter 1850 ---  Loss: 3.0082174092531204    Accuracy: 86.71875\n",
      "iter 1851 ---  Loss: 2.8640394136309624    Accuracy: 85.0\n",
      "iter 1852 ---  Loss: 2.801017828285694    Accuracy: 87.5\n",
      "iter 1853 ---  Loss: 2.887564666569233    Accuracy: 87.8125\n",
      "iter 1854 ---  Loss: 3.6429751366376877    Accuracy: 84.53125\n",
      "iter 1855 ---  Loss: 3.3395185619592667    Accuracy: 86.875\n",
      "iter 1856 ---  Loss: 3.3574448004364967    Accuracy: 86.25\n",
      "iter 1857 ---  Loss: 4.008057914674282    Accuracy: 86.71875\n",
      "iter 1858 ---  Loss: 3.5490462258458138    Accuracy: 85.9375\n",
      "iter 1859 ---  Loss: 2.856550671160221    Accuracy: 88.28125\n",
      "iter 1860 ---  Loss: 3.5027021542191505    Accuracy: 87.1875\n",
      "iter 1861 ---  Loss: 2.8315814584493637    Accuracy: 88.28125\n",
      "iter 1862 ---  Loss: 3.0538518130779266    Accuracy: 89.84375\n",
      "iter 1863 ---  Loss: 3.1449232921004295    Accuracy: 87.1875\n",
      "iter 1864 ---  Loss: 2.905622608959675    Accuracy: 85.78125\n",
      "iter 1865 ---  Loss: 3.4541474506258965    Accuracy: 86.25\n",
      "iter 1866 ---  Loss: 2.833924174308777    Accuracy: 88.59375\n",
      "iter 1867 ---  Loss: 3.379941575229168    Accuracy: 88.4375\n",
      "iter 1868 ---  Loss: 3.370901294052601    Accuracy: 87.5\n",
      "iter 1869 ---  Loss: 3.363939568400383    Accuracy: 87.65625\n",
      "iter 1870 ---  Loss: 2.8082202449440956    Accuracy: 85.15625\n",
      "iter 1871 ---  Loss: 3.1105291545391083    Accuracy: 86.875\n",
      "iter 1872 ---  Loss: 3.1237009689211845    Accuracy: 86.09375\n",
      "iter 1873 ---  Loss: 3.209632381796837    Accuracy: 85.3125\n",
      "iter 1874 ---  Loss: 3.096472881734371    Accuracy: 87.03125\n",
      "iter 1875 ---  Loss: 2.825628951191902    Accuracy: 88.4375\n",
      "iter 1876 ---  Loss: 2.9132102131843567    Accuracy: 87.34375\n",
      "iter 1877 ---  Loss: 2.7708482816815376    Accuracy: 86.875\n",
      "iter 1878 ---  Loss: 3.555593952536583    Accuracy: 88.59375\n",
      "iter 1879 ---  Loss: 2.6753453984856606    Accuracy: 88.75\n",
      "iter 1880 ---  Loss: 2.7287198454141617    Accuracy: 88.75\n",
      "iter 1881 ---  Loss: 2.9432126730680466    Accuracy: 88.125\n",
      "iter 1882 ---  Loss: 3.8073270842432976    Accuracy: 85.15625\n",
      "iter 1883 ---  Loss: 2.788363941013813    Accuracy: 87.96875\n",
      "iter 1884 ---  Loss: 2.851670742034912    Accuracy: 88.125\n",
      "iter 1885 ---  Loss: 3.1773839965462685    Accuracy: 86.5625\n",
      "iter 1886 ---  Loss: 3.3381744250655174    Accuracy: 86.5625\n",
      "iter 1887 ---  Loss: 2.6246106922626495    Accuracy: 88.4375\n",
      "iter 1888 ---  Loss: 2.928226888179779    Accuracy: 89.0625\n",
      "iter 1889 ---  Loss: 2.922915019094944    Accuracy: 85.9375\n",
      "iter 1890 ---  Loss: 2.8848980218172073    Accuracy: 87.1875\n",
      "iter 1891 ---  Loss: 2.655620113015175    Accuracy: 90.0\n",
      "iter 1892 ---  Loss: 2.5134799033403397    Accuracy: 89.21875\n",
      "iter 1893 ---  Loss: 2.5651738420128822    Accuracy: 89.375\n",
      "iter 1894 ---  Loss: 2.943513609468937    Accuracy: 87.5\n",
      "iter 1895 ---  Loss: 3.5324986428022385    Accuracy: 85.3125\n",
      "iter 1896 ---  Loss: 2.954887017607689    Accuracy: 87.96875\n",
      "iter 1897 ---  Loss: 2.818132348358631    Accuracy: 87.65625\n",
      "iter 1898 ---  Loss: 3.2560563683509827    Accuracy: 87.03125\n",
      "iter 1899 ---  Loss: 2.5920272693037987    Accuracy: 87.8125\n",
      "iter 1900 ---  Loss: 2.8741234689950943    Accuracy: 88.125\n",
      "iter 1901 ---  Loss: 2.853313632309437    Accuracy: 87.65625\n",
      "iter 1902 ---  Loss: 3.7091869935393333    Accuracy: 86.875\n",
      "iter 1903 ---  Loss: 2.723475858569145    Accuracy: 85.9375\n",
      "iter 1904 ---  Loss: 3.093969389796257    Accuracy: 87.1875\n",
      "iter 1905 ---  Loss: 3.054637812077999    Accuracy: 89.0625\n",
      "iter 1906 ---  Loss: 3.3084607645869255    Accuracy: 85.78125\n",
      "iter 1907 ---  Loss: 2.953947938978672    Accuracy: 86.40625\n",
      "iter 1908 ---  Loss: 2.9695811420679092    Accuracy: 88.59375\n",
      "iter 1909 ---  Loss: 3.035394497215748    Accuracy: 89.6875\n",
      "iter 1910 ---  Loss: 3.0949476808309555    Accuracy: 86.40625\n",
      "iter 1911 ---  Loss: 3.3492563366889954    Accuracy: 88.125\n",
      "iter 1912 ---  Loss: 3.094661623239517    Accuracy: 88.28125\n",
      "iter 1913 ---  Loss: 2.910630941390991    Accuracy: 89.21875\n",
      "iter 1914 ---  Loss: 3.04658043384552    Accuracy: 87.65625\n",
      "iter 1915 ---  Loss: 2.8683644756674767    Accuracy: 87.34375\n",
      "iter 1916 ---  Loss: 3.035040646791458    Accuracy: 86.71875\n",
      "iter 1917 ---  Loss: 2.595846511423588    Accuracy: 88.28125\n",
      "iter 1918 ---  Loss: 3.371576987206936    Accuracy: 88.28125\n",
      "iter 1919 ---  Loss: 3.7273443564772606    Accuracy: 85.9375\n",
      "iter 1920 ---  Loss: 3.581760063767433    Accuracy: 86.875\n",
      "iter 1921 ---  Loss: 3.040990836918354    Accuracy: 88.90625\n",
      "iter 1922 ---  Loss: 2.895610362291336    Accuracy: 87.8125\n",
      "iter 1923 ---  Loss: 3.6237404346466064    Accuracy: 85.9375\n",
      "iter 1924 ---  Loss: 3.3445905223488808    Accuracy: 87.03125\n",
      "iter 1925 ---  Loss: 3.242925778031349    Accuracy: 86.875\n",
      "iter 1926 ---  Loss: 3.7987839058041573    Accuracy: 84.21875\n",
      "iter 1927 ---  Loss: 2.979450672864914    Accuracy: 86.71875\n",
      "iter 1928 ---  Loss: 2.987165942788124    Accuracy: 88.59375\n",
      "iter 1929 ---  Loss: 3.0660243928432465    Accuracy: 87.1875\n",
      "iter 1930 ---  Loss: 2.9946155101060867    Accuracy: 87.03125\n",
      "iter 1931 ---  Loss: 3.0436782836914062    Accuracy: 87.96875\n",
      "iter 1932 ---  Loss: 3.046882800757885    Accuracy: 88.28125\n",
      "iter 1933 ---  Loss: 2.555969513952732    Accuracy: 87.65625\n",
      "iter 1934 ---  Loss: 3.2562257423996925    Accuracy: 87.03125\n",
      "iter 1935 ---  Loss: 2.8615990355610847    Accuracy: 88.125\n",
      "iter 1936 ---  Loss: 2.836356520652771    Accuracy: 88.28125\n",
      "iter 1937 ---  Loss: 3.152827002108097    Accuracy: 86.25\n",
      "iter 1938 ---  Loss: 3.2022561728954315    Accuracy: 86.875\n",
      "iter 1939 ---  Loss: 3.2828454300761223    Accuracy: 86.875\n",
      "iter 1940 ---  Loss: 3.1567163541913033    Accuracy: 87.34375\n",
      "iter 1941 ---  Loss: 2.7869265377521515    Accuracy: 88.75\n",
      "iter 1942 ---  Loss: 3.00594449788332    Accuracy: 87.03125\n",
      "iter 1943 ---  Loss: 2.893835626542568    Accuracy: 86.71875\n",
      "iter 1944 ---  Loss: 2.841254897415638    Accuracy: 87.8125\n",
      "iter 1945 ---  Loss: 3.3271548226475716    Accuracy: 86.25\n",
      "iter 1946 ---  Loss: 3.126863792538643    Accuracy: 88.90625\n",
      "iter 1947 ---  Loss: 3.210464134812355    Accuracy: 86.5625\n",
      "iter 1948 ---  Loss: 3.83718903362751    Accuracy: 86.40625\n",
      "iter 1949 ---  Loss: 3.145282879471779    Accuracy: 84.0625\n",
      "iter 1950 ---  Loss: 2.9213647544384003    Accuracy: 89.0625\n",
      "iter 1951 ---  Loss: 2.880086436867714    Accuracy: 87.5\n",
      "iter 1952 ---  Loss: 3.428382746875286    Accuracy: 87.5\n",
      "iter 1953 ---  Loss: 3.325410947203636    Accuracy: 86.71875\n",
      "iter 1954 ---  Loss: 3.439074367284775    Accuracy: 86.40625\n",
      "iter 1955 ---  Loss: 2.730000674724579    Accuracy: 87.5\n",
      "iter 1956 ---  Loss: 2.7747444584965706    Accuracy: 87.1875\n",
      "iter 1957 ---  Loss: 2.667213872075081    Accuracy: 86.40625\n",
      "iter 1958 ---  Loss: 2.5375145226716995    Accuracy: 88.75\n",
      "iter 1959 ---  Loss: 2.9256293326616287    Accuracy: 87.96875\n",
      "iter 1960 ---  Loss: 2.4699768871068954    Accuracy: 89.21875\n",
      "iter 1961 ---  Loss: 3.047268182039261    Accuracy: 86.875\n",
      "iter 1962 ---  Loss: 2.5853552371263504    Accuracy: 89.0625\n",
      "iter 1963 ---  Loss: 3.392763577401638    Accuracy: 85.78125\n",
      "iter 1964 ---  Loss: 3.5950047597289085    Accuracy: 85.9375\n",
      "iter 1965 ---  Loss: 2.857280917465687    Accuracy: 87.1875\n",
      "iter 1966 ---  Loss: 3.03315968811512    Accuracy: 87.8125\n",
      "iter 1967 ---  Loss: 2.91288723051548    Accuracy: 87.96875\n",
      "iter 1968 ---  Loss: 3.5829964950680733    Accuracy: 87.5\n",
      "iter 1969 ---  Loss: 3.0930952578783035    Accuracy: 87.5\n",
      "iter 1970 ---  Loss: 2.5432832837104797    Accuracy: 88.4375\n",
      "iter 1971 ---  Loss: 2.7649755626916885    Accuracy: 88.59375\n",
      "iter 1972 ---  Loss: 3.0890635028481483    Accuracy: 86.40625\n",
      "iter 1973 ---  Loss: 2.7632033824920654    Accuracy: 89.0625\n",
      "iter 1974 ---  Loss: 2.7944308817386627    Accuracy: 87.1875\n",
      "iter 1975 ---  Loss: 2.914467640221119    Accuracy: 88.75\n",
      "iter 1976 ---  Loss: 2.8949823677539825    Accuracy: 88.4375\n",
      "iter 1977 ---  Loss: 3.0705870762467384    Accuracy: 86.5625\n",
      "iter 1978 ---  Loss: 3.425466202199459    Accuracy: 86.40625\n",
      "iter 1979 ---  Loss: 2.7758317664265633    Accuracy: 86.71875\n",
      "iter 1980 ---  Loss: 3.1261288821697235    Accuracy: 88.59375\n",
      "iter 1981 ---  Loss: 2.563795432448387    Accuracy: 90.15625\n",
      "iter 1982 ---  Loss: 3.634219966828823    Accuracy: 86.5625\n",
      "iter 1983 ---  Loss: 3.156843900680542    Accuracy: 87.8125\n",
      "iter 1984 ---  Loss: 2.7146046087145805    Accuracy: 87.1875\n",
      "iter 1985 ---  Loss: 2.4530454576015472    Accuracy: 89.0625\n",
      "iter 1986 ---  Loss: 2.917634531855583    Accuracy: 87.65625\n",
      "iter 1987 ---  Loss: 4.007596909999847    Accuracy: 85.625\n",
      "iter 1988 ---  Loss: 2.521863728761673    Accuracy: 86.5625\n",
      "iter 1989 ---  Loss: 3.116228826344013    Accuracy: 88.59375\n",
      "iter 1990 ---  Loss: 3.8243217170238495    Accuracy: 86.40625\n",
      "iter 1991 ---  Loss: 3.0476678609848022    Accuracy: 86.40625\n",
      "iter 1992 ---  Loss: 3.1844354420900345    Accuracy: 89.6875\n",
      "iter 1993 ---  Loss: 2.4901796355843544    Accuracy: 89.84375\n",
      "iter 1994 ---  Loss: 2.958751417696476    Accuracy: 88.4375\n",
      "iter 1995 ---  Loss: 4.013388924300671    Accuracy: 86.5625\n",
      "iter 1996 ---  Loss: 2.6357464343309402    Accuracy: 87.8125\n",
      "iter 1997 ---  Loss: 3.9182163402438164    Accuracy: 85.9375\n",
      "iter 1998 ---  Loss: 3.4726870134472847    Accuracy: 89.21875\n",
      "iter 1999 ---  Loss: 2.4577733278274536    Accuracy: 88.28125\n",
      "iter 2000 ---  Loss: 3.051890142261982    Accuracy: 86.875\n",
      "iter 2001 ---  Loss: 3.2770202979445457    Accuracy: 86.71875\n",
      "iter 2002 ---  Loss: 2.8610109388828278    Accuracy: 86.875\n",
      "iter 2003 ---  Loss: 2.837922491133213    Accuracy: 88.59375\n",
      "iter 2004 ---  Loss: 3.1241345182061195    Accuracy: 87.03125\n",
      "iter 2005 ---  Loss: 3.132183663547039    Accuracy: 88.28125\n",
      "iter 2006 ---  Loss: 3.2298129722476006    Accuracy: 86.71875\n",
      "iter 2007 ---  Loss: 2.426418274641037    Accuracy: 88.4375\n",
      "iter 2008 ---  Loss: 3.594084180891514    Accuracy: 86.25\n",
      "iter 2009 ---  Loss: 2.6075928062200546    Accuracy: 87.65625\n",
      "iter 2010 ---  Loss: 3.2480208724737167    Accuracy: 87.34375\n",
      "iter 2011 ---  Loss: 2.6862169951200485    Accuracy: 90.0\n",
      "iter 2012 ---  Loss: 2.5178387239575386    Accuracy: 87.96875\n",
      "iter 2013 ---  Loss: 3.354922115802765    Accuracy: 84.375\n",
      "iter 2014 ---  Loss: 2.966463156044483    Accuracy: 88.28125\n",
      "iter 2015 ---  Loss: 3.2599506452679634    Accuracy: 89.84375\n",
      "iter 2016 ---  Loss: 2.803157813847065    Accuracy: 89.375\n",
      "iter 2017 ---  Loss: 2.9320047795772552    Accuracy: 86.25\n",
      "iter 2018 ---  Loss: 2.886293113231659    Accuracy: 88.28125\n",
      "iter 2019 ---  Loss: 2.9198032841086388    Accuracy: 87.65625\n",
      "iter 2020 ---  Loss: 3.3631840869784355    Accuracy: 86.875\n",
      "iter 2021 ---  Loss: 2.9428104609251022    Accuracy: 85.625\n",
      "iter 2022 ---  Loss: 3.0354766994714737    Accuracy: 87.96875\n",
      "iter 2023 ---  Loss: 2.8464010879397392    Accuracy: 88.4375\n",
      "iter 2024 ---  Loss: 3.3329073265194893    Accuracy: 85.9375\n",
      "iter 2025 ---  Loss: 3.201714724302292    Accuracy: 88.125\n",
      "iter 2026 ---  Loss: 2.768942564725876    Accuracy: 87.5\n",
      "iter 2027 ---  Loss: 2.949957348406315    Accuracy: 87.96875\n",
      "iter 2028 ---  Loss: 2.9474544301629066    Accuracy: 88.28125\n",
      "iter 2029 ---  Loss: 2.7588309347629547    Accuracy: 88.4375\n",
      "iter 2030 ---  Loss: 3.073040783405304    Accuracy: 84.53125\n",
      "iter 2031 ---  Loss: 2.5129468366503716    Accuracy: 89.21875\n",
      "iter 2032 ---  Loss: 2.9186574667692184    Accuracy: 85.625\n",
      "iter 2033 ---  Loss: 3.12331859767437    Accuracy: 88.28125\n",
      "iter 2034 ---  Loss: 2.567503646016121    Accuracy: 89.53125\n",
      "iter 2035 ---  Loss: 3.3981061577796936    Accuracy: 85.3125\n",
      "iter 2036 ---  Loss: 2.7781156674027443    Accuracy: 88.4375\n",
      "iter 2037 ---  Loss: 3.1044994071125984    Accuracy: 87.96875\n",
      "iter 2038 ---  Loss: 2.848073497414589    Accuracy: 87.34375\n",
      "iter 2039 ---  Loss: 3.1261465176939964    Accuracy: 86.875\n",
      "iter 2040 ---  Loss: 3.4047251790761948    Accuracy: 85.9375\n",
      "iter 2041 ---  Loss: 2.669021315872669    Accuracy: 86.71875\n",
      "iter 2042 ---  Loss: 3.3926660791039467    Accuracy: 86.5625\n",
      "iter 2043 ---  Loss: 3.5116759538650513    Accuracy: 87.34375\n",
      "iter 2044 ---  Loss: 3.119956135749817    Accuracy: 86.25\n",
      "iter 2045 ---  Loss: 2.524275355041027    Accuracy: 89.375\n",
      "iter 2046 ---  Loss: 2.898476056754589    Accuracy: 88.90625\n",
      "iter 2047 ---  Loss: 2.863643892109394    Accuracy: 87.03125\n",
      "iter 2048 ---  Loss: 3.473001591861248    Accuracy: 87.1875\n",
      "iter 2049 ---  Loss: 3.2222547382116318    Accuracy: 84.375\n",
      "iter 2050 ---  Loss: 3.51591220498085    Accuracy: 86.09375\n",
      "iter 2051 ---  Loss: 2.711605489253998    Accuracy: 87.8125\n",
      "iter 2052 ---  Loss: 3.0204946473240852    Accuracy: 87.34375\n",
      "iter 2053 ---  Loss: 3.1310335621237755    Accuracy: 86.875\n",
      "iter 2054 ---  Loss: 3.631893537938595    Accuracy: 87.1875\n",
      "iter 2055 ---  Loss: 3.107355870306492    Accuracy: 86.25\n",
      "iter 2056 ---  Loss: 3.922363795340061    Accuracy: 85.46875\n",
      "iter 2057 ---  Loss: 3.4165429323911667    Accuracy: 86.875\n",
      "iter 2058 ---  Loss: 2.5757602751255035    Accuracy: 87.1875\n",
      "iter 2059 ---  Loss: 3.070256546139717    Accuracy: 87.03125\n",
      "iter 2060 ---  Loss: 2.903910204768181    Accuracy: 88.90625\n",
      "iter 2061 ---  Loss: 3.735001802444458    Accuracy: 86.71875\n",
      "iter 2062 ---  Loss: 2.8935588523745537    Accuracy: 87.03125\n",
      "iter 2063 ---  Loss: 3.7033049687743187    Accuracy: 84.84375\n",
      "iter 2064 ---  Loss: 3.2247712165117264    Accuracy: 87.03125\n",
      "iter 2065 ---  Loss: 3.7506879419088364    Accuracy: 86.25\n",
      "iter 2066 ---  Loss: 3.1466665491461754    Accuracy: 88.4375\n",
      "iter 2067 ---  Loss: 2.7031998857855797    Accuracy: 86.09375\n",
      "iter 2068 ---  Loss: 3.096504256129265    Accuracy: 85.78125\n",
      "iter 2069 ---  Loss: 2.780327506363392    Accuracy: 87.1875\n",
      "iter 2070 ---  Loss: 2.8185545802116394    Accuracy: 86.25\n",
      "iter 2071 ---  Loss: 2.922480769455433    Accuracy: 89.375\n",
      "iter 2072 ---  Loss: 3.0109214931726456    Accuracy: 89.21875\n",
      "iter 2073 ---  Loss: 3.1322012543678284    Accuracy: 87.03125\n",
      "iter 2074 ---  Loss: 2.8762667924165726    Accuracy: 87.1875\n",
      "iter 2075 ---  Loss: 2.6882559582591057    Accuracy: 87.5\n",
      "iter 2076 ---  Loss: 3.331686571240425    Accuracy: 86.40625\n",
      "iter 2077 ---  Loss: 3.0034433007240295    Accuracy: 86.25\n",
      "iter 2078 ---  Loss: 2.7666451930999756    Accuracy: 86.5625\n",
      "iter 2079 ---  Loss: 2.911445401608944    Accuracy: 87.65625\n",
      "iter 2080 ---  Loss: 3.044544279575348    Accuracy: 88.59375\n",
      "iter 2081 ---  Loss: 2.5685377791523933    Accuracy: 89.375\n",
      "iter 2082 ---  Loss: 3.089537560939789    Accuracy: 87.96875\n",
      "iter 2083 ---  Loss: 2.971842885017395    Accuracy: 87.03125\n",
      "iter 2084 ---  Loss: 3.0885582268238068    Accuracy: 87.34375\n",
      "iter 2085 ---  Loss: 3.016459956765175    Accuracy: 86.875\n",
      "iter 2086 ---  Loss: 2.5480643585324287    Accuracy: 87.03125\n",
      "iter 2087 ---  Loss: 3.2100078016519547    Accuracy: 87.03125\n",
      "iter 2088 ---  Loss: 3.0406258180737495    Accuracy: 87.96875\n",
      "iter 2089 ---  Loss: 2.892087087035179    Accuracy: 85.46875\n",
      "iter 2090 ---  Loss: 3.35700586438179    Accuracy: 88.4375\n",
      "iter 2091 ---  Loss: 2.6999312192201614    Accuracy: 89.6875\n",
      "iter 2092 ---  Loss: 3.2285195887088776    Accuracy: 85.625\n",
      "iter 2093 ---  Loss: 3.279909811913967    Accuracy: 85.625\n",
      "iter 2094 ---  Loss: 2.5965250730514526    Accuracy: 87.65625\n",
      "iter 2095 ---  Loss: 3.5815066397190094    Accuracy: 87.5\n",
      "iter 2096 ---  Loss: 3.116954669356346    Accuracy: 86.25\n",
      "iter 2097 ---  Loss: 2.5238472372293472    Accuracy: 89.0625\n",
      "iter 2098 ---  Loss: 2.823132947087288    Accuracy: 87.5\n",
      "iter 2099 ---  Loss: 3.0489128828048706    Accuracy: 87.03125\n",
      "iter 2100 ---  Loss: 3.1559061259031296    Accuracy: 87.96875\n",
      "iter 2101 ---  Loss: 3.0424246191978455    Accuracy: 87.1875\n",
      "iter 2102 ---  Loss: 3.2122905999422073    Accuracy: 87.96875\n",
      "iter 2103 ---  Loss: 3.234470121562481    Accuracy: 87.65625\n",
      "iter 2104 ---  Loss: 2.7418698146939278    Accuracy: 90.9375\n",
      "iter 2105 ---  Loss: 3.1551525965332985    Accuracy: 87.03125\n",
      "iter 2106 ---  Loss: 3.144491247832775    Accuracy: 85.3125\n",
      "iter 2107 ---  Loss: 3.548254072666168    Accuracy: 85.9375\n",
      "iter 2108 ---  Loss: 3.5897191762924194    Accuracy: 86.5625\n",
      "iter 2109 ---  Loss: 3.3720520958304405    Accuracy: 85.15625\n",
      "iter 2110 ---  Loss: 2.627797983586788    Accuracy: 88.90625\n",
      "iter 2111 ---  Loss: 3.0293443724513054    Accuracy: 86.875\n",
      "iter 2112 ---  Loss: 2.9868419989943504    Accuracy: 86.5625\n",
      "iter 2113 ---  Loss: 2.8771404325962067    Accuracy: 88.4375\n",
      "iter 2114 ---  Loss: 2.812386989593506    Accuracy: 87.03125\n",
      "iter 2115 ---  Loss: 2.873453289270401    Accuracy: 88.4375\n",
      "iter 2116 ---  Loss: 3.1000731214880943    Accuracy: 87.34375\n",
      "iter 2117 ---  Loss: 2.909602977335453    Accuracy: 86.5625\n",
      "iter 2118 ---  Loss: 2.9101853519678116    Accuracy: 87.96875\n",
      "iter 2119 ---  Loss: 2.6019583120942116    Accuracy: 88.59375\n",
      "iter 2120 ---  Loss: 2.7457749769091606    Accuracy: 86.71875\n",
      "iter 2121 ---  Loss: 2.853028677403927    Accuracy: 86.25\n",
      "iter 2122 ---  Loss: 2.822106294333935    Accuracy: 87.5\n",
      "iter 2123 ---  Loss: 3.439582109451294    Accuracy: 85.3125\n",
      "iter 2124 ---  Loss: 3.448768250644207    Accuracy: 87.5\n",
      "iter 2125 ---  Loss: 2.7576417177915573    Accuracy: 87.65625\n",
      "iter 2126 ---  Loss: 2.933277353644371    Accuracy: 84.6875\n",
      "iter 2127 ---  Loss: 2.8090795278549194    Accuracy: 87.65625\n",
      "iter 2128 ---  Loss: 2.9385855197906494    Accuracy: 88.125\n",
      "iter 2129 ---  Loss: 2.811243586242199    Accuracy: 87.5\n",
      "iter 2130 ---  Loss: 3.190082371234894    Accuracy: 85.78125\n",
      "iter 2131 ---  Loss: 3.392510198056698    Accuracy: 86.25\n",
      "iter 2132 ---  Loss: 3.323613002896309    Accuracy: 87.5\n",
      "iter 2133 ---  Loss: 2.8475203290581703    Accuracy: 88.125\n",
      "iter 2134 ---  Loss: 3.4729197695851326    Accuracy: 86.5625\n",
      "iter 2135 ---  Loss: 3.386731080710888    Accuracy: 86.5625\n",
      "iter 2136 ---  Loss: 3.1197401583194733    Accuracy: 87.34375\n",
      "iter 2137 ---  Loss: 3.5160882771015167    Accuracy: 85.9375\n",
      "iter 2138 ---  Loss: 2.7240990847349167    Accuracy: 88.4375\n",
      "iter 2139 ---  Loss: 2.9625352174043655    Accuracy: 87.03125\n",
      "iter 2140 ---  Loss: 3.7195011004805565    Accuracy: 86.71875\n",
      "iter 2141 ---  Loss: 2.8634035289287567    Accuracy: 88.4375\n",
      "iter 2142 ---  Loss: 2.9110998287796974    Accuracy: 89.6875\n",
      "iter 2143 ---  Loss: 2.747348167002201    Accuracy: 88.59375\n",
      "iter 2144 ---  Loss: 3.6368143782019615    Accuracy: 85.625\n",
      "iter 2145 ---  Loss: 3.147887483239174    Accuracy: 89.21875\n",
      "iter 2146 ---  Loss: 2.765873022377491    Accuracy: 88.28125\n",
      "iter 2147 ---  Loss: 3.1025223955512047    Accuracy: 87.34375\n",
      "iter 2148 ---  Loss: 2.931590862572193    Accuracy: 87.65625\n",
      "iter 2149 ---  Loss: 2.7880416363477707    Accuracy: 87.1875\n",
      "iter 2150 ---  Loss: 2.801013670861721    Accuracy: 89.0625\n",
      "iter 2151 ---  Loss: 2.9408832862973213    Accuracy: 88.4375\n",
      "iter 2152 ---  Loss: 3.287823513150215    Accuracy: 88.59375\n",
      "iter 2153 ---  Loss: 3.7452069967985153    Accuracy: 84.21875\n",
      "iter 2154 ---  Loss: 3.624441549181938    Accuracy: 85.46875\n",
      "iter 2155 ---  Loss: 2.995566926896572    Accuracy: 85.15625\n",
      "iter 2156 ---  Loss: 3.242375284433365    Accuracy: 87.1875\n",
      "iter 2157 ---  Loss: 2.90484269708395    Accuracy: 88.28125\n",
      "iter 2158 ---  Loss: 3.4707184433937073    Accuracy: 87.03125\n",
      "iter 2159 ---  Loss: 3.047940008342266    Accuracy: 87.34375\n",
      "iter 2160 ---  Loss: 2.9532444551587105    Accuracy: 86.5625\n",
      "iter 2161 ---  Loss: 2.862704575061798    Accuracy: 86.71875\n",
      "iter 2162 ---  Loss: 3.403742700815201    Accuracy: 86.40625\n",
      "iter 2163 ---  Loss: 3.01231187582016    Accuracy: 87.96875\n",
      "iter 2164 ---  Loss: 3.148821771144867    Accuracy: 84.21875\n",
      "iter 2165 ---  Loss: 2.923063799738884    Accuracy: 87.5\n",
      "iter 2166 ---  Loss: 3.1010331884026527    Accuracy: 87.65625\n",
      "iter 2167 ---  Loss: 3.1320082545280457    Accuracy: 85.625\n",
      "iter 2168 ---  Loss: 3.100752405822277    Accuracy: 85.46875\n",
      "iter 2169 ---  Loss: 2.7584179118275642    Accuracy: 87.65625\n",
      "iter 2170 ---  Loss: 2.864042103290558    Accuracy: 86.71875\n",
      "iter 2171 ---  Loss: 3.333713613450527    Accuracy: 84.6875\n",
      "iter 2172 ---  Loss: 3.3264255225658417    Accuracy: 86.25\n",
      "iter 2173 ---  Loss: 2.9798921048641205    Accuracy: 87.5\n",
      "iter 2174 ---  Loss: 2.439559556543827    Accuracy: 88.125\n",
      "iter 2175 ---  Loss: 3.59906118363142    Accuracy: 88.90625\n",
      "iter 2176 ---  Loss: 3.3130968734622    Accuracy: 86.5625\n",
      "iter 2177 ---  Loss: 3.1923630833625793    Accuracy: 87.1875\n",
      "iter 2178 ---  Loss: 3.600516587495804    Accuracy: 84.84375\n",
      "iter 2179 ---  Loss: 2.8886363804340363    Accuracy: 85.625\n",
      "iter 2180 ---  Loss: 3.2508124336600304    Accuracy: 86.25\n",
      "iter 2181 ---  Loss: 2.749803453683853    Accuracy: 87.8125\n",
      "iter 2182 ---  Loss: 2.679668039083481    Accuracy: 88.125\n",
      "iter 2183 ---  Loss: 2.889447972178459    Accuracy: 87.03125\n",
      "iter 2184 ---  Loss: 3.069656051695347    Accuracy: 85.46875\n",
      "iter 2185 ---  Loss: 2.9496072456240654    Accuracy: 88.4375\n",
      "iter 2186 ---  Loss: 2.7433245331048965    Accuracy: 88.59375\n",
      "iter 2187 ---  Loss: 3.3176839649677277    Accuracy: 87.65625\n",
      "iter 2188 ---  Loss: 3.5265853255987167    Accuracy: 86.875\n",
      "iter 2189 ---  Loss: 2.9084398820996284    Accuracy: 88.28125\n",
      "iter 2190 ---  Loss: 2.775242641568184    Accuracy: 89.53125\n",
      "iter 2191 ---  Loss: 2.8561115488409996    Accuracy: 86.25\n",
      "iter 2192 ---  Loss: 2.5094835832715034    Accuracy: 88.59375\n",
      "iter 2193 ---  Loss: 3.3046046793460846    Accuracy: 87.8125\n",
      "iter 2194 ---  Loss: 3.4064949303865433    Accuracy: 87.03125\n",
      "iter 2195 ---  Loss: 3.326030895113945    Accuracy: 87.34375\n",
      "iter 2196 ---  Loss: 3.09839253872633    Accuracy: 88.4375\n",
      "iter 2197 ---  Loss: 2.836335465312004    Accuracy: 86.5625\n",
      "iter 2198 ---  Loss: 3.0298446342349052    Accuracy: 86.5625\n",
      "iter 2199 ---  Loss: 3.3647775426506996    Accuracy: 87.8125\n",
      "iter 2200 ---  Loss: 3.2949472293257713    Accuracy: 84.0625\n",
      "iter 2201 ---  Loss: 2.7961702421307564    Accuracy: 86.875\n",
      "iter 2202 ---  Loss: 3.2347804829478264    Accuracy: 87.96875\n",
      "iter 2203 ---  Loss: 3.1889233738183975    Accuracy: 86.875\n",
      "iter 2204 ---  Loss: 2.808058016002178    Accuracy: 87.34375\n",
      "iter 2205 ---  Loss: 3.1390562877058983    Accuracy: 86.71875\n",
      "iter 2206 ---  Loss: 2.5765082016587257    Accuracy: 89.0625\n",
      "iter 2207 ---  Loss: 2.79587584733963    Accuracy: 88.75\n",
      "iter 2208 ---  Loss: 2.5021737813949585    Accuracy: 88.75\n",
      "iter 2209 ---  Loss: 3.2684072852134705    Accuracy: 86.09375\n",
      "iter 2210 ---  Loss: 3.1360165923833847    Accuracy: 86.25\n",
      "iter 2211 ---  Loss: 2.852112539112568    Accuracy: 85.3125\n",
      "iter 2212 ---  Loss: 3.193059630692005    Accuracy: 87.5\n",
      "iter 2213 ---  Loss: 3.0895036160945892    Accuracy: 85.46875\n",
      "iter 2214 ---  Loss: 2.585855782032013    Accuracy: 88.4375\n",
      "iter 2215 ---  Loss: 3.5655157268047333    Accuracy: 86.09375\n",
      "iter 2216 ---  Loss: 2.8880135491490364    Accuracy: 87.8125\n",
      "iter 2217 ---  Loss: 3.1935248523950577    Accuracy: 85.46875\n",
      "iter 2218 ---  Loss: 3.1342009752988815    Accuracy: 86.5625\n",
      "iter 2219 ---  Loss: 2.959630385041237    Accuracy: 86.875\n",
      "iter 2220 ---  Loss: 2.66031713783741    Accuracy: 86.71875\n",
      "iter 2221 ---  Loss: 3.12153197824955    Accuracy: 87.03125\n",
      "iter 2222 ---  Loss: 3.0000529065728188    Accuracy: 87.65625\n",
      "iter 2223 ---  Loss: 3.370256580412388    Accuracy: 85.9375\n",
      "iter 2224 ---  Loss: 3.1046438738703728    Accuracy: 87.1875\n",
      "iter 2225 ---  Loss: 3.1021431982517242    Accuracy: 87.65625\n",
      "iter 2226 ---  Loss: 2.583385020494461    Accuracy: 87.65625\n",
      "iter 2227 ---  Loss: 3.0092066153883934    Accuracy: 87.34375\n",
      "iter 2228 ---  Loss: 3.9460195153951645    Accuracy: 86.09375\n",
      "iter 2229 ---  Loss: 3.0766550451517105    Accuracy: 87.65625\n",
      "iter 2230 ---  Loss: 2.890927590429783    Accuracy: 87.03125\n",
      "iter 2231 ---  Loss: 3.621190622448921    Accuracy: 87.03125\n",
      "iter 2232 ---  Loss: 3.2141717597842216    Accuracy: 87.65625\n",
      "iter 2233 ---  Loss: 2.827687196433544    Accuracy: 89.53125\n",
      "iter 2234 ---  Loss: 2.7322791814804077    Accuracy: 87.8125\n",
      "iter 2235 ---  Loss: 3.2116949409246445    Accuracy: 87.5\n",
      "iter 2236 ---  Loss: 2.9646829441189766    Accuracy: 87.1875\n",
      "iter 2237 ---  Loss: 2.901938498020172    Accuracy: 87.34375\n",
      "iter 2238 ---  Loss: 2.650636248290539    Accuracy: 87.96875\n",
      "iter 2239 ---  Loss: 2.8441262543201447    Accuracy: 87.8125\n",
      "iter 2240 ---  Loss: 2.8997493386268616    Accuracy: 87.5\n",
      "iter 2241 ---  Loss: 2.8196446746587753    Accuracy: 86.71875\n",
      "iter 2242 ---  Loss: 2.941338323056698    Accuracy: 86.09375\n",
      "iter 2243 ---  Loss: 3.4965903535485268    Accuracy: 88.4375\n",
      "iter 2244 ---  Loss: 2.8504227846860886    Accuracy: 87.34375\n",
      "iter 2245 ---  Loss: 2.5233902856707573    Accuracy: 88.59375\n",
      "iter 2246 ---  Loss: 2.766405925154686    Accuracy: 87.65625\n",
      "iter 2247 ---  Loss: 3.3995482474565506    Accuracy: 84.84375\n",
      "iter 2248 ---  Loss: 2.968539983034134    Accuracy: 87.03125\n",
      "iter 2249 ---  Loss: 2.5070152580738068    Accuracy: 88.125\n",
      "iter 2250 ---  Loss: 2.866440385580063    Accuracy: 87.1875\n",
      "iter 2251 ---  Loss: 3.257717341184616    Accuracy: 87.5\n",
      "iter 2252 ---  Loss: 3.09917926043272    Accuracy: 88.75\n",
      "iter 2253 ---  Loss: 2.981447421014309    Accuracy: 88.4375\n",
      "iter 2254 ---  Loss: 3.2773291170597076    Accuracy: 86.5625\n",
      "iter 2255 ---  Loss: 2.7478405237197876    Accuracy: 86.09375\n",
      "iter 2256 ---  Loss: 2.8654384687542915    Accuracy: 87.8125\n",
      "iter 2257 ---  Loss: 3.031324677169323    Accuracy: 85.78125\n",
      "iter 2258 ---  Loss: 3.052035965025425    Accuracy: 86.5625\n",
      "iter 2259 ---  Loss: 3.1388760581612587    Accuracy: 87.1875\n",
      "iter 2260 ---  Loss: 3.185396060347557    Accuracy: 87.96875\n",
      "iter 2261 ---  Loss: 3.059088133275509    Accuracy: 87.8125\n",
      "iter 2262 ---  Loss: 3.4489156007766724    Accuracy: 85.9375\n",
      "iter 2263 ---  Loss: 3.034634053707123    Accuracy: 87.1875\n",
      "iter 2264 ---  Loss: 3.7105651572346687    Accuracy: 87.1875\n",
      "iter 2265 ---  Loss: 3.4454927518963814    Accuracy: 86.09375\n",
      "iter 2266 ---  Loss: 3.334936998784542    Accuracy: 84.53125\n",
      "iter 2267 ---  Loss: 3.153711698949337    Accuracy: 87.1875\n",
      "iter 2268 ---  Loss: 3.276192083954811    Accuracy: 87.1875\n",
      "iter 2269 ---  Loss: 3.1251888647675514    Accuracy: 86.09375\n",
      "iter 2270 ---  Loss: 3.961416579782963    Accuracy: 84.375\n",
      "iter 2271 ---  Loss: 2.937207281589508    Accuracy: 87.34375\n",
      "iter 2272 ---  Loss: 3.0094792023301125    Accuracy: 87.1875\n",
      "iter 2273 ---  Loss: 3.160320073366165    Accuracy: 86.71875\n",
      "iter 2274 ---  Loss: 3.125540278851986    Accuracy: 86.71875\n",
      "iter 2275 ---  Loss: 2.938618429005146    Accuracy: 88.90625\n",
      "iter 2276 ---  Loss: 3.3568137511610985    Accuracy: 85.78125\n",
      "iter 2277 ---  Loss: 3.428301975131035    Accuracy: 85.46875\n",
      "iter 2278 ---  Loss: 3.6241984367370605    Accuracy: 85.78125\n",
      "iter 2279 ---  Loss: 2.9442997574806213    Accuracy: 86.25\n",
      "iter 2280 ---  Loss: 3.288022920489311    Accuracy: 85.78125\n",
      "iter 2281 ---  Loss: 3.3263534381985664    Accuracy: 86.875\n",
      "iter 2282 ---  Loss: 2.44180840998888    Accuracy: 86.5625\n",
      "iter 2283 ---  Loss: 2.893113411962986    Accuracy: 88.4375\n",
      "iter 2284 ---  Loss: 2.935960441827774    Accuracy: 85.78125\n",
      "iter 2285 ---  Loss: 3.089541994035244    Accuracy: 87.34375\n",
      "iter 2286 ---  Loss: 3.3165634870529175    Accuracy: 86.40625\n",
      "iter 2287 ---  Loss: 2.970175124704838    Accuracy: 88.75\n",
      "iter 2288 ---  Loss: 2.9523905143141747    Accuracy: 89.0625\n",
      "iter 2289 ---  Loss: 2.4187441393733025    Accuracy: 88.59375\n",
      "iter 2290 ---  Loss: 2.845430836081505    Accuracy: 86.71875\n",
      "iter 2291 ---  Loss: 2.7789447382092476    Accuracy: 86.71875\n",
      "iter 2292 ---  Loss: 3.5234961956739426    Accuracy: 88.28125\n",
      "iter 2293 ---  Loss: 3.5334426909685135    Accuracy: 87.5\n",
      "iter 2294 ---  Loss: 2.5198376178741455    Accuracy: 88.75\n",
      "iter 2295 ---  Loss: 3.137809596955776    Accuracy: 86.5625\n",
      "iter 2296 ---  Loss: 3.62412092089653    Accuracy: 87.1875\n",
      "iter 2297 ---  Loss: 2.920039601624012    Accuracy: 87.65625\n",
      "iter 2298 ---  Loss: 3.6064151376485825    Accuracy: 86.875\n",
      "iter 2299 ---  Loss: 3.3445743545889854    Accuracy: 86.25\n",
      "iter 2300 ---  Loss: 3.5199256911873817    Accuracy: 87.34375\n",
      "iter 2301 ---  Loss: 3.234170451760292    Accuracy: 87.96875\n",
      "iter 2302 ---  Loss: 2.960324563086033    Accuracy: 87.34375\n",
      "iter 2303 ---  Loss: 2.6887084543704987    Accuracy: 87.96875\n",
      "iter 2304 ---  Loss: 2.7543317899107933    Accuracy: 87.65625\n",
      "iter 2305 ---  Loss: 3.537928029894829    Accuracy: 86.09375\n",
      "iter 2306 ---  Loss: 2.827195420861244    Accuracy: 87.8125\n",
      "iter 2307 ---  Loss: 2.678738087415695    Accuracy: 88.125\n",
      "iter 2308 ---  Loss: 2.6964138001203537    Accuracy: 88.75\n",
      "iter 2309 ---  Loss: 2.8008432909846306    Accuracy: 86.71875\n",
      "iter 2310 ---  Loss: 2.927017278969288    Accuracy: 87.96875\n",
      "iter 2311 ---  Loss: 3.0563950166106224    Accuracy: 87.03125\n",
      "iter 2312 ---  Loss: 3.2494863644242287    Accuracy: 85.78125\n",
      "iter 2313 ---  Loss: 2.5803615376353264    Accuracy: 89.6875\n",
      "iter 2314 ---  Loss: 3.446543261408806    Accuracy: 86.09375\n",
      "iter 2315 ---  Loss: 3.3128542378544807    Accuracy: 85.46875\n",
      "iter 2316 ---  Loss: 4.305808447301388    Accuracy: 85.3125\n",
      "iter 2317 ---  Loss: 3.3357751071453094    Accuracy: 86.25\n",
      "iter 2318 ---  Loss: 2.992716744542122    Accuracy: 86.5625\n",
      "iter 2319 ---  Loss: 3.526142254471779    Accuracy: 87.03125\n",
      "iter 2320 ---  Loss: 3.271787315607071    Accuracy: 88.90625\n",
      "iter 2321 ---  Loss: 2.8675914853811264    Accuracy: 86.5625\n",
      "iter 2322 ---  Loss: 2.6381461545825005    Accuracy: 87.8125\n",
      "iter 2323 ---  Loss: 2.5791694447398186    Accuracy: 90.15625\n",
      "iter 2324 ---  Loss: 3.174765892326832    Accuracy: 88.28125\n",
      "iter 2325 ---  Loss: 2.8741856813430786    Accuracy: 87.03125\n",
      "iter 2326 ---  Loss: 2.7892204374074936    Accuracy: 88.4375\n",
      "iter 2327 ---  Loss: 3.1669845432043076    Accuracy: 87.34375\n",
      "iter 2328 ---  Loss: 3.1686475798487663    Accuracy: 88.4375\n",
      "iter 2329 ---  Loss: 3.3658179938793182    Accuracy: 85.78125\n",
      "iter 2330 ---  Loss: 2.8874466866254807    Accuracy: 86.5625\n",
      "iter 2331 ---  Loss: 3.194590263068676    Accuracy: 87.1875\n",
      "iter 2332 ---  Loss: 2.939542882144451    Accuracy: 85.625\n",
      "iter 2333 ---  Loss: 3.107124611735344    Accuracy: 87.5\n",
      "iter 2334 ---  Loss: 3.0891368240118027    Accuracy: 88.4375\n",
      "iter 2335 ---  Loss: 3.6281644254922867    Accuracy: 86.09375\n",
      "iter 2336 ---  Loss: 3.104896232485771    Accuracy: 89.375\n",
      "iter 2337 ---  Loss: 3.011352516710758    Accuracy: 86.25\n",
      "iter 2338 ---  Loss: 3.9576670676469803    Accuracy: 86.40625\n",
      "iter 2339 ---  Loss: 3.343741238117218    Accuracy: 85.625\n",
      "iter 2340 ---  Loss: 2.6768054217100143    Accuracy: 88.59375\n",
      "iter 2341 ---  Loss: 3.0823458582162857    Accuracy: 87.1875\n",
      "iter 2342 ---  Loss: 3.5052444264292717    Accuracy: 87.65625\n",
      "iter 2343 ---  Loss: 2.7409853264689445    Accuracy: 88.75\n",
      "iter 2344 ---  Loss: 2.866516776382923    Accuracy: 89.0625\n",
      "iter 2345 ---  Loss: 2.9027370139956474    Accuracy: 86.875\n",
      "iter 2346 ---  Loss: 2.8672676011919975    Accuracy: 88.90625\n",
      "iter 2347 ---  Loss: 4.070151969790459    Accuracy: 87.1875\n",
      "iter 2348 ---  Loss: 2.983294740319252    Accuracy: 87.1875\n",
      "iter 2349 ---  Loss: 2.6142095550894737    Accuracy: 88.125\n",
      "iter 2350 ---  Loss: 3.5163333266973495    Accuracy: 86.09375\n",
      "iter 2351 ---  Loss: 3.3555424213409424    Accuracy: 86.71875\n",
      "iter 2352 ---  Loss: 3.3819083273410797    Accuracy: 87.65625\n",
      "iter 2353 ---  Loss: 3.4796157851815224    Accuracy: 85.3125\n",
      "iter 2354 ---  Loss: 2.9098325595259666    Accuracy: 88.28125\n",
      "iter 2355 ---  Loss: 3.1103897988796234    Accuracy: 88.59375\n",
      "iter 2356 ---  Loss: 3.172117441892624    Accuracy: 86.71875\n",
      "iter 2357 ---  Loss: 2.8657678812742233    Accuracy: 86.5625\n",
      "iter 2358 ---  Loss: 3.443322367966175    Accuracy: 87.03125\n",
      "iter 2359 ---  Loss: 3.2801395803689957    Accuracy: 87.65625\n",
      "iter 2360 ---  Loss: 3.1834664344787598    Accuracy: 86.875\n",
      "iter 2361 ---  Loss: 2.985049292445183    Accuracy: 88.90625\n",
      "iter 2362 ---  Loss: 2.9771935492753983    Accuracy: 87.8125\n",
      "iter 2363 ---  Loss: 3.1100141629576683    Accuracy: 88.59375\n",
      "iter 2364 ---  Loss: 3.2452592700719833    Accuracy: 87.96875\n",
      "iter 2365 ---  Loss: 2.9309682101011276    Accuracy: 87.34375\n",
      "iter 2366 ---  Loss: 2.67860896140337    Accuracy: 87.03125\n",
      "iter 2367 ---  Loss: 3.4284993410110474    Accuracy: 86.875\n",
      "iter 2368 ---  Loss: 2.9709284529089928    Accuracy: 86.40625\n",
      "iter 2369 ---  Loss: 2.573133982717991    Accuracy: 87.96875\n",
      "iter 2370 ---  Loss: 3.0205512940883636    Accuracy: 86.71875\n",
      "iter 2371 ---  Loss: 3.0108960419893265    Accuracy: 88.4375\n",
      "iter 2372 ---  Loss: 2.9306727051734924    Accuracy: 89.0625\n",
      "iter 2373 ---  Loss: 3.469546653330326    Accuracy: 86.5625\n",
      "iter 2374 ---  Loss: 2.7181735187768936    Accuracy: 87.34375\n",
      "iter 2375 ---  Loss: 3.698592357337475    Accuracy: 86.25\n",
      "iter 2376 ---  Loss: 3.2916127890348434    Accuracy: 86.40625\n",
      "iter 2377 ---  Loss: 3.104561537504196    Accuracy: 87.65625\n",
      "iter 2378 ---  Loss: 3.260956771671772    Accuracy: 89.375\n",
      "iter 2379 ---  Loss: 3.5176093578338623    Accuracy: 84.0625\n",
      "iter 2380 ---  Loss: 2.9410057365894318    Accuracy: 85.9375\n",
      "iter 2381 ---  Loss: 2.8645436838269234    Accuracy: 88.125\n",
      "iter 2382 ---  Loss: 3.7389461770653725    Accuracy: 85.9375\n",
      "iter 2383 ---  Loss: 3.109485439956188    Accuracy: 86.09375\n",
      "iter 2384 ---  Loss: 2.8561227694153786    Accuracy: 87.5\n",
      "iter 2385 ---  Loss: 2.7518866062164307    Accuracy: 87.1875\n",
      "iter 2386 ---  Loss: 2.9653541818261147    Accuracy: 87.96875\n",
      "iter 2387 ---  Loss: 3.1025301814079285    Accuracy: 85.0\n",
      "iter 2388 ---  Loss: 2.728569947183132    Accuracy: 88.4375\n",
      "iter 2389 ---  Loss: 2.759243905544281    Accuracy: 87.8125\n",
      "iter 2390 ---  Loss: 3.380262792110443    Accuracy: 85.9375\n",
      "iter 2391 ---  Loss: 4.353267155587673    Accuracy: 84.53125\n",
      "iter 2392 ---  Loss: 3.1556219905614853    Accuracy: 87.34375\n",
      "iter 2393 ---  Loss: 3.0817848667502403    Accuracy: 86.09375\n",
      "iter 2394 ---  Loss: 2.9469518437981606    Accuracy: 87.96875\n",
      "iter 2395 ---  Loss: 2.698808267712593    Accuracy: 87.65625\n",
      "iter 2396 ---  Loss: 3.253334619104862    Accuracy: 88.125\n",
      "iter 2397 ---  Loss: 3.0745189636945724    Accuracy: 87.03125\n",
      "iter 2398 ---  Loss: 3.1686163395643234    Accuracy: 86.5625\n",
      "iter 2399 ---  Loss: 2.9495253190398216    Accuracy: 87.1875\n",
      "iter 2400 ---  Loss: 2.8832509517669678    Accuracy: 85.9375\n",
      "iter 2401 ---  Loss: 3.062968410551548    Accuracy: 87.1875\n",
      "iter 2402 ---  Loss: 2.594435155391693    Accuracy: 88.75\n",
      "iter 2403 ---  Loss: 3.153728596866131    Accuracy: 85.9375\n",
      "iter 2404 ---  Loss: 3.62654697149992    Accuracy: 86.40625\n",
      "iter 2405 ---  Loss: 2.8624253645539284    Accuracy: 86.5625\n",
      "iter 2406 ---  Loss: 3.044891156256199    Accuracy: 88.125\n",
      "iter 2407 ---  Loss: 2.7927665188908577    Accuracy: 87.5\n",
      "iter 2408 ---  Loss: 3.100514255464077    Accuracy: 87.65625\n",
      "iter 2409 ---  Loss: 3.4627254381775856    Accuracy: 86.875\n",
      "iter 2410 ---  Loss: 2.8114553466439247    Accuracy: 87.1875\n",
      "iter 2411 ---  Loss: 3.0774295032024384    Accuracy: 85.9375\n",
      "iter 2412 ---  Loss: 3.640880547463894    Accuracy: 84.375\n",
      "iter 2413 ---  Loss: 3.0639485865831375    Accuracy: 87.65625\n",
      "iter 2414 ---  Loss: 3.2899393662810326    Accuracy: 85.9375\n",
      "iter 2415 ---  Loss: 2.8094197511672974    Accuracy: 88.28125\n",
      "iter 2416 ---  Loss: 3.485731914639473    Accuracy: 84.21875\n",
      "iter 2417 ---  Loss: 3.1374732479453087    Accuracy: 87.96875\n",
      "iter 2418 ---  Loss: 3.2299855798482895    Accuracy: 87.03125\n",
      "iter 2419 ---  Loss: 2.443363808095455    Accuracy: 89.375\n",
      "iter 2420 ---  Loss: 3.9666328355669975    Accuracy: 86.09375\n",
      "iter 2421 ---  Loss: 3.0722797363996506    Accuracy: 86.25\n",
      "iter 2422 ---  Loss: 3.0901279747486115    Accuracy: 86.40625\n",
      "iter 2423 ---  Loss: 3.040666416287422    Accuracy: 87.5\n",
      "iter 2424 ---  Loss: 2.822091318666935    Accuracy: 88.125\n",
      "iter 2425 ---  Loss: 2.6377966701984406    Accuracy: 87.65625\n",
      "iter 2426 ---  Loss: 3.962273545563221    Accuracy: 85.9375\n",
      "iter 2427 ---  Loss: 3.2932631745934486    Accuracy: 87.65625\n",
      "iter 2428 ---  Loss: 2.9958413541316986    Accuracy: 86.875\n",
      "iter 2429 ---  Loss: 4.167990833520889    Accuracy: 84.84375\n",
      "iter 2430 ---  Loss: 2.6859987154603004    Accuracy: 87.1875\n",
      "iter 2431 ---  Loss: 2.8397053629159927    Accuracy: 88.59375\n",
      "iter 2432 ---  Loss: 3.263778828084469    Accuracy: 86.25\n",
      "iter 2433 ---  Loss: 4.016962252557278    Accuracy: 86.71875\n",
      "iter 2434 ---  Loss: 3.122412294149399    Accuracy: 86.5625\n",
      "iter 2435 ---  Loss: 2.5331811755895615    Accuracy: 88.4375\n",
      "iter 2436 ---  Loss: 3.153046742081642    Accuracy: 87.1875\n",
      "iter 2437 ---  Loss: 3.239346891641617    Accuracy: 87.5\n",
      "iter 2438 ---  Loss: 2.704863019287586    Accuracy: 88.28125\n",
      "iter 2439 ---  Loss: 2.4866662845015526    Accuracy: 87.96875\n",
      "iter 2440 ---  Loss: 3.1939795091748238    Accuracy: 87.03125\n",
      "iter 2441 ---  Loss: 3.3016266971826553    Accuracy: 86.25\n",
      "iter 2442 ---  Loss: 2.877402886748314    Accuracy: 87.03125\n",
      "iter 2443 ---  Loss: 2.896099269390106    Accuracy: 88.28125\n",
      "iter 2444 ---  Loss: 2.6004750058054924    Accuracy: 88.90625\n",
      "iter 2445 ---  Loss: 2.482235513627529    Accuracy: 88.125\n",
      "iter 2446 ---  Loss: 3.17202228307724    Accuracy: 85.78125\n",
      "iter 2447 ---  Loss: 3.4309120774269104    Accuracy: 86.71875\n",
      "iter 2448 ---  Loss: 2.6665715277194977    Accuracy: 87.8125\n",
      "iter 2449 ---  Loss: 2.9305851757526398    Accuracy: 87.5\n",
      "iter 2450 ---  Loss: 2.8893307223916054    Accuracy: 88.28125\n",
      "iter 2451 ---  Loss: 4.0745377242565155    Accuracy: 85.46875\n",
      "iter 2452 ---  Loss: 3.3183377608656883    Accuracy: 86.25\n",
      "iter 2453 ---  Loss: 3.4375380277633667    Accuracy: 85.0\n"
     ]
    }
   ],
   "source": [
    "# Let's do fine-tuning\n",
    "finetune_model(model=vgg16, data_loader=train_loader, num_epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.load_state_dict(torch.load(os.path.join(state_dict_path, \"vgg16_finetune_params.pth\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function that would evaluate the model.\n",
    "\n",
    "Make sure it outputs all of the accuracies of all 20 conditions. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def evaluate_model(model, data_loader, limit:int, device:str):\n",
    "    \"\"\"\n",
    "    Instance method that would evaluate with a given\n",
    "    data loader, the accuracies obtained by the VGGNET16\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    threshold = 0.5\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    #Use no grad to not perform backpropagation for inference time\n",
    "    with torch.no_grad():\n",
    "        #Iterate through each of the images and labels\n",
    "        \n",
    "        # Calculate the total numbers for metrics\n",
    "        TP, FP, TN, FN = 0.0, 0.0, 0.0, 0.0\n",
    "        for idx, batch in enumerate(data_loader):\n",
    "    \n",
    "            #See if it works\n",
    "            images_inputs, images_labels = batch\n",
    "            images_inputs, images_labels = images_inputs.to(device), images_labels.to(device)\n",
    "\n",
    "            #Print the shape of each one of them\n",
    "            print(f\"Inputs shape: {images_inputs.shape}, Labels shape: {labels.shape}\")\n",
    "\n",
    "            #Send the outputs to model in device\n",
    "            outputs = model(images_inputs)\n",
    "\n",
    "            #Binarize the output with threshold\n",
    "            pred_labels = (outputs > threshold).float()\n",
    "\n",
    "            # Calculate batch-wise TP, FP, TN, FN\n",
    "            b_TP = torch.sum((pred_labels == 1) & (images_labels == 1)).item()\n",
    "            b_FP = torch.sum((pred_labels == 1) & (images_labels == 0)).item()\n",
    "            b_TN = torch.sum((pred_labels == 0) & (images_labels == 0)).item()\n",
    "            b_FN = torch.sum((pred_labels == 0) & (images_labels == 1)).item()\n",
    "            TP += b_TP\n",
    "            FP += b_FP\n",
    "            TN += b_TN\n",
    "            FN += b_FN\n",
    "\n",
    "        #_, predicted = torch.max(outputs, 1)  # Get the index of the maximum log-probability\n",
    "        accuracy = ((TP + TN) / (TP + FP + TN + FN)) * 100.0\n",
    "        precision = (TP / (TP + FP)) * 100.0 if (TP + FP) > 0 else 0.0\n",
    "        recall = (TP / (TP + FN)) * 100.0 if (TP + FN) > 0 else 0.0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "        print(\"Accuracy: {:.2f}%\".format(accuracy))\n",
    "        print(\"Precision: {:.2f}%\".format(precision))\n",
    "        print(\"Recall: {:.2f}%\".format(recall))\n",
    "        print(\"F1 Score: {:.2f}%\".format(f1_score))\n",
    "\n",
    "            # accuracies.append(accuracy)\n",
    "            # precisions.append(precision)\n",
    "            # recalls.append(recall)\n",
    "            # f1_scores.append(f1_score)\n",
    "\n",
    "            # if idx == limit:\n",
    "            #     print(\"Limit reached\")\n",
    "            #     break\n",
    "    return accuracies, precisions, recalls, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([32, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Inputs shape: torch.Size([25, 3, 224, 224]), Labels shape: torch.Size([32, 20])\n",
      "Accuracy: 51.61%\n",
      "Precision: 8.31%\n",
      "Recall: 54.95%\n",
      "F1 Score: 14.44%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the eval set\n",
    "accuracies, precisions, recalls, f1_scores = evaluate_model(vgg16, test_loader, 5, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
